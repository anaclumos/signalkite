[
  {
    "id": 40384013,
    "title": "Fake Apple Employee #10 badge sold on eBay",
    "originLink": "https://cabel.com/2024/05/16/the-forged-apple-employee-badge/",
    "originBody": "Hereâ€™s a quick and cautionary tale. This eBay auction, spotted by Eric Vitiello, immediately caught my eye: Wow. Someone was selling Apple Employee #10â€™s employee badge?! What an incredible piece of Apple history! Sure, itâ€™s not Steve Jobsâ€™ badge (despite the auction title), but there are only so many of these in the world â€” especially from one of the first ten employees. I persistently pored through the provided pictures. At first, it looked good. The plastic was scuffed with age, the tape on the map was yellowed, the logo was (mostly) correct, and Sherry Livingston really was Employee #10. But it also felt a little off. The scuffing lookedâ€¦ sandpapery. The splotches on the map felt overcooked. And I couldnâ€™t stop looking at the â€œtypewrittenâ€ partâ€¦ This badge wouldâ€™ve been (obviously!) made before desktop publishing. A badge template wouldâ€™ve been printed by a local printing company, then fed into a typewriter to type the individual employee details. And that typed text is suspiciously uniform. And just as I was beginning to ðŸ§, along came Chris: â€œThatâ€™sâ€¦ fake. Both of them.â€ Oh snap. Itâ€™s really fake? What does this Chris guy know, anyway? Well, heâ€™s Chris Espinosa. Who just so happens to be Apple Employee #8. (Trivia: he joined the company when he was 14â€¦ and still works there!) And we know exactly what Chrisâ€™ badge looked like: I asked Chris (who I truly admire!) for more thoughts: So, yeah. One of the most qualified people on planet earth to say this is a fake, is saying this is a fake. I had no choice at this point. I simply had to meddle. Fromâ€¦ the German Red Cross?! How specific! It seems like the German Red Cross runs a kind of second hand/charity shop, so ok, sure. But why would the German Red Cross have the employee badge for Apple Employee #10? I couldnâ€™t wait. The seller sent the Red â€œCroosâ€ proof just a few hours later. (Enough time toâ€¦ create it?) At first blush, again, this provenance looks pretty good, right? A German purchase receipt, dated 2001, for the item pictured. The right logo. A nice emboss. Seems plausible. But, again again, I had a weird feeling â€” this series of photos was trying too hard. That binder labelled â€œBILLS 200[0]â€”2010â€, conveniently flipped upside down for casual authenticity? Why would you put that in these photos unless you were trying a bit too hard to make your case? It felt like a set dresser trying to stage a movie scene. The seller added: As you can see, the invoice is expressed in the old German currency, the German mark, before the entry of the EURO in the years following. No way. A regular human wouldnâ€™t point this out. Someone proud of a detail they thought of in their forgery would point this out. This little detail wouldâ€™ve been far more effective for me to discover on my own. It was time to totally close the case. It was time to engage the internet. The Mastodon response from Germans was swift and brutal. There was no doubt. This â€œproofâ€ was yet another forgery. I told the seller this. And then, weirdly, for the amount of effort put into this, they made a very dumb error: Waitâ€¦ what?!? I never received a reply. Case closed!? Thereâ€™s just one small, sad problemâ€¦ â€¦yes, the item sold before I could finish this post. So, my sincere apologies to whoever out there just spent $946.00 on a total (but interesting!) work of fiction. Here are the key takeaways from our meeting today: Beware of fraudulent pieces of Apple history Donâ€™t buy anything from this particular seller When in doubt, Engage The InternetÂ® Best, Cabel PS: I hope youâ€™re having a nice week Like this: Like Loadingâ€¦",
    "commentLink": "https://news.ycombinator.com/item?id=40384013",
    "commentBody": "A forged Apple employee badge (cabel.com)623 points by ecliptik 11 hours agohidepastfavorite208 comments derefr 8 hours ago> And that typed text is way, way cleaner than any typewriter Iâ€™ve seen. Pedantic point: electric typewriters (which have existed since the 1960s) do type in a way that looks exactly like this. (In fact, note that the text on the real employee ID card, shown later in the article, doesn't look any less clean! It's just set in a different, narrower font.) The smudginess of mechanical typewriters comes from 1. them striking (and especially, releasing) at the same speed you're depressing the key, and 2. having many of the keys necessarily approach the ribbon from an angle. The keys being swung weakly by your fingers, also has the additional implication that the ink ribbons used in mechanical typewriters have to be soft and squishy (so: made of cloth), and use thin inks. These properties ensure a transfer from even a low-velocity impact. But the trade-off is that cloth ink ribbons transfer only a rough outline of what's struck; and thin inks are high-bleed inks. An electric typewriter, playing out a pre-buffered line with a crisp, predictable report, using linear actuators and a rotating-ball type-head to bang a tape ribbon loaded with high-viscosity ink onto the page, can create text indistinguishable from books/newspapers of the same period, or from modern laser-printer reproductions of the same font faces. They're essentially character-at-a-time letterpresses! (Also, ignoring electric typewriters for a sec: inks bleed more on thin, cheap paper. But this is [a forgery of] an employee ID card â€” where, for durability, a nice heavyweight paper or cardstock would have been used. You're always going to get a better-looking result inking such paper.) reply dreamcompiler 2 hours agoparent> An electric typewriter, playing out a pre-buffered line with a crisp, predictable report, using linear actuators and a rotating-ball type-head to bang a tape ribbon loaded with high-viscosity ink onto the page The machine you just described is an IBM Composer, except the ribbon was not \"high viscosity\". Rather it was essentially solid, being a carbon ribbon with a mylar back. Most electric typewriters were not Composers, so they did not pre-buffer lines. In fact most electric typewriters were not Selectrics so they didn't even use a ball. The IBM Executive for example used swinging type bars just like a manual typewriter, and it produced excellent copy that was frequently used as a master for offset lithography. (Source: Me. I used to own a print shop.) The presence or absence of swinging type bars, pre-buffering, or balls makes no difference. Carbon ribbons and the repeatability of impression that electric provides are what matter. reply anon946 8 hours agoparentprevI have used multiple typewriters in my life, and agree. In addition, the look of film/tape vs cloth/nylon is very different, and tape ribbon can look very crisp: https://en.wikipedia.org/wiki/Ink_ribbon#Single-pass_(polyme.... reply joe_guy 6 hours agorootparentDo you mind if I ask why you still use typewriters? reply satvikpendem 4 hours agorootparentYou might be interested in this video about why Gen Z is starting to use typewriters again [0]. In a word, focus. They say they are often too distracted from writing when using a computer as it is easy to surf the web instead of writing your paper, so having a single purpose utility rather than a multipurpose one is actually a boon. [0] https://youtu.be/PdYPZr1Flog reply sdedovic 4 hours agorootparentprevnot the OP but, I am in my 20s and I use a typewriter somewhat regularly to journal. I was raised on computers, getting the jumble from my brain onto paper is faster with a keyboard than a pen/pencil and paper. And a typewriter is nice and analog - no screen, no lights, no battery. I'm disconnected, focused, and performant. reply talldatethrow 6 hours agorootparentprevI bought one recently at an estate sale so that I could write things without the ability to open a window and browse the web. reply okasaki 3 hours agorootparentWhy not just use a pen? reply bayindirh 2 hours agorootparentAs an avid pen/paper user I can say that using a pen takes more time, plus you can't OCR it as easily as a typewriter output. Nevertheless carrying a nice pen and a good notebook always beats having a heavy typewriter with you. reply fernandotakai 16 minutes agorootparentprevin my case, writing with a pen for long periods of time makes my hand cramp/hurt real bad (i still write on my journal daily but it's not pleasant). (i don't have a typewriter, but i prefer to type anything because of this). reply notduncansmith 2 hours agorootparentprevI can type on QWERTY much faster and more legibly than I can write with a pen. I suspect this is true for most proficient QWERTY typists. reply okasaki 1 hour agorootparentI've never tested it, but you may be right. On the other hand a pen is smaller, and you can draw and doodle with it. reply ljf 55 minutes agorootparentI used to love doodling and drawing, but as soon as I start to write my hand cramps up. I take hand written (short notes) for work and I struggle to read them a month or so later when the context is gone. I also really struggle to spell, and will consistently get common words wrong. BUT on a keyboard I can type almost as fast as I can think - and I can also spell 90% better - I don't know how it happens but it is like the words 'flow' out of my fingers when i type - and I can easily spell words that if you asked me how to spell I wouldn't have a clue. Also if you asked me to find you a key on a keyboard I'd have to look - but when I'm typing my fingers just know where they are. I'm a 44 yo successful man, but I still don't know my alphabet well (for example I couldn't start in the middle or recite it backwards) - but put me in front of a keyboard and I can type all day long (note - I am VERY thankful for spellcheck though!) reply petesergeant 3 hours agorootparentprevThat piqued my interest for sure. This kind of thing exists too: https://getfreewrite.com/products/freewrite-smart-typewriter... but I'd really like to bring my own keyboard and have the e-ink display at a more ergonomic height. Combine that with Vim, and that'd be something I'd use reply spondylosaurus 3 hours agorootparentYou might enjoy some of the full-fledged e-ink tablets (with folio keyboards, iPad style) on the market right now. Some even run Android, so you could definitely find a way to run Vim. I was just looking at some today but the biggest downside right now is that they're pretty expensive for what you get. reply Maxion 4 hours agorootparentprevAnd, today, with LLMs it'll take you a few seconds to digitize the document, too. For this reason I've also been considering a typewriter... reply fmbb 4 hours agorootparentOCR has been a solved problem for years. Long before LLMs started being hyped. At least from typewritten documents that you did not torch or shred etc. reply satvikpendem 4 hours agorootparentprevReminds me of those tablets (and pens) that you can write on / with and they automatically digitize and OCR whatever was written, as if by magic. reply TeMPOraL 3 hours agorootparentDoes one exist that actually works? reply ChrisMarshallNY 1 hour agorootparentThe iPad, with the Apple Pencil is pretty much there. Itâ€™s actually amazingly good. I have terrible handwriting, and it doesnâ€™t seem to have a problem with it. If anyone ever tried using a Newton, there was a series of Doonesbury comics[0] about its awful handwriting recognition. [0] https://www.computerhistory.org/revolution/mobile-computing/... reply SoftTalker 6 hours agorootparentprevFor some things (e.g. a one-off need to address an envelope) they are still faster and easier than anything else. reply Twisell 3 hours agorootparent...except a pen reply Faaak 3 hours agorootparentI don't think I would write faster with a pen than with a typewriter..? reply ghaff 2 hours agorootparentYes. But for the one off need described (or similar) itâ€™s way faster to write an address than to get things set up with a typewriter. Of course for certain forms, better legibility in many cases may make it worth it. reply Fatnino 3 hours agorootparentprevI dont think the person you are replying to said they still use one. Just that they have used multiple typewriters in the past. I have too, for that matter, but I haven't touched one in over 25 years. reply Groxx 7 hours agoparentprevSome nice up close content about some fancy electronic typewriters, from Technology Connections: https://youtu.be/YE0U018Copw reply jart 7 hours agoparentprevThis is one of those times when I wish Hacker News had something like Reddit Gold. Wonderful comment. reply fragmede 7 hours agorootparentnot the same thing but https://news.ycombinator.com/highlights reply KennyBlanken 6 hours agorootparentprevFor a comment easily disproved by a simple google image search which returns plenty of examples of selectric output where the characters have anywhere to a very subtle but not perfect (like in the badge) alignment, to examples where the characters have \"visible at arm's length\" vertical and horizontal, and even rotational, issues? reply ssl-3 6 hours agorootparentWere those examples typed in 1977 on a fresh Selectric, or were they typed decades later on a tired Selectric? 1977 was a long time ago, even in typewriter years. reply dkjaudyeqooe 5 hours agoparentprevAt least in the 80's, there were also printers that worked like that, ie a character ball plus some sort of transfer material to mark the page. reply Aloha 8 hours agoparentprevand an a Selectric II/III didnt use a felt ribbon, but rather a wax transfer. reply dreamcompiler 2 hours agorootparentIBM called it a \"carbon\" ribbon. reply KennyBlanken 6 hours agoparentprev> Pedantic point: electric typewriters (which have existed since the 1960s) do type in a way that looks exactly like this. Wrong. Literally gooogle \"selectric type sample\" and see dozens of examples of them not typing anywhere near in a perfect line. Maybe machines with very low hours or kept in excellent condition might have excellent spacing, but there's plenty of examples of them obviously not having perfect spacing. https://www.flickr.com/photos/nicksherman/14249132603 https://www.reddit.com/r/typewriters/comments/e7xxct/typefac... Another example where misalignment is even more obvious: https://www.reddit.com/r/typewriters/comments/sc519r/ibm_sel... http://www.jollinger.com/typewriters/typewriters/IBM_Selectr... you can also see inconsistent letter spacing, more obvious on some fonts than others, but you can see some characters are connected and others aren't. And no, it's not just the position of the character relative to others on the ball. As the author points out, these characters have perfect vertical alignment. Then go look at high speed footage of the 'golfball' in action and you can see the substantial deflection caused by how fast and forceful the movements are. You can see the entire assembly is bouncing around as the rails it's on flex: https://www.youtube.com/watch?v=RTtKaqIpOJc reply masswerk 6 hours agorootparentTo be fair, the specimen shows some misalignment as well, e.g., the \"S\" at the very beginning is up and a bit to the left, the \"Y\" is shifted to the right, and there are small irregularities in \"NGST\", as well. However, I don't think that they add up in a sensible manner. Notably, the Red Cross invoice is much worse: additionally to what has been noted in the article already, why would you have a hyphen in \"VerkÃ¤ufername\"? Also mind the reoccurring use of \"#\" for \"Nummer\", which would have been rather unacceptable in a formal German document. reply KennyBlanken 6 hours agorootparentThe image provided is so low resolution that this is probably a side effect of the edges of the characters being on the boundary between pixels on the camera's sensor. Magnify it to full screen and you'll see what I'm talking about. Now go back and look at the samples I linked to, where you can clearly see vertical misalignment. I remember everyone in my school system had selectrics when I was a kid, and I assure you, they could produce text that was all over the place. Probably because the ones in a public school saw heavy use / were not properly maintained and serviced to the degree required. reply masswerk 6 hours agorootparentThere's an image with suitable resolution to show the misalignment: https://i0.wp.com/cabel.com/wp-content/uploads/2024/05/image... BTW, also mind the drop of the \"0\" in \"10\". Edit: We can all pretend it's perfectly aligned print, but, regardless, whether purposefully manufactured or genuine, there are obvious misalignments in that image. reply hilti 4 hours agoprevThere is so much wrong with the faked Red Cross invoice 1) A German date is always written DD.MM.YYYY 2) PLZ not ZIP 3) â€žWir danken fÃ¼r ihr Unternehmenâ€œ is a bad translation for â€žThank you for your businessâ€œ â€¦ but it means a complete different thing -> â€žThank you for your companyâ€œ But Iâ€˜m still impressed how much effort this guy put into all this. And Iâ€˜m sure my friends would have bought me this badge, because they had no idea itâ€˜s fake. reply tomaskafka 3 hours agoparentThank you! So, to paraphrase a Cunningham's Law, \"the best way to make a good fake on the internet is not to ask a question; it's to post the wrong fake.\" Future defrauders will love both Cabel's post and this discussion :) reply yumong 4 hours agoparentprevAnd the locally used abbreviation for the currency at the time was DM, not DEM. For close to $1000, a little bit of effort is not unexpected. (Also, why assume this was a guy?) reply serf 39 minutes agorootparent'guy'/'guys' is used without a gender context in certain regions, more like synonyms of 'folks '. I hear \"hey guys\" routinely in SoCal said without intention of labeling people. reply Cthulhu_ 1 hour agoparentprevI mean I appreciate the effort put into it and to the untrained eye this looks good enough for e.g. movie props. I wonder if the creator is just a professional scammer or works in the movie / reproduction industry? reply raverbashing 3 hours agoparentprevEven funnier is that when googling I see some examples of actual invoices/receipts by the German Red Cross. But of course they would need to know what to actually google ;) reply ttepasse 7 hours agoprevI find myself fascinated by the forged DRK invoice. At first glance it looks like the shitty desktop formatting common to 2001, its in a German two ring binder, crumpled and yellowed. But then there are multiple things which are obviously and subtile off, the most glaring is the obviously AI-translated phrase at the bottom. I'd love to know the mind of the forger. They did put some serious work into the invoice but then AI-translated an idiomatic American phrase (wrongly!) which wouldnâ€™t by used on a German invoice. Itâ€™s accepted that the US movies and television industry canâ€™t get contemporary Germany right [1], often for economic limitations of the productions, but something that still getâ€™s me is when the badly pronounced dialogue was obviously written in idiomatic English and only then translated mindlessly word for word, as if other countries cultures and languages are semantically the same, only the words are different. Maybe thatâ€™s what happened with the forger - you canâ€™t know there would be differences if you donâ€™t have a sensibility for difference. [1] https://old.reddit.com/r/AskAGerman/comments/1ct1k73/what_is... reply gield 2 hours agoparent>Itâ€™s accepted that the US movies and television industry canâ€™t get contemporary Germany right The US movies and television industry can rarely get any language right. This reminds me of the Dutch-speaking scene in Oppenheimer which no Dutch speaker can understand [1]. It's like a sped-up pronunciation of a nonsense Dutch sentence by an English-speaker trying to speak a horrible German accent. [1] https://www.youtube.com/watch?v=lFORgWaYrBU reply davedx 1 hour agorootparentHa yeah I remember that part. I speak Dutch and it basically sounded like German to me? Really strange. reply Maxion 4 hours agoparentprev> AI-translated phrase at the bottom. I'd love to know the mind of the forger. They did put some serious work into the invoice but then AI-translated an idiomatic American phrase (wrongly!) which wouldnâ€™t by used on a German invoice. This is especially stupid because LLMs like ChatGPT CAN output phrases that wouldn't be out of tune. I assume the forger got that phrase by literally asking the LLM to translate an english phrase to german, rather than asking the LLM what would be a good german phrase to use. reply winkelmann 3 hours agorootparent> literally asking the LLM to translate an english phrase to german I tried it a few times on arena.lmsys.org and given the prompt \"Please translate \"We thank you for your business\" into German\", the most common result was \"Wir danken Ihnen fÃ¼r Ihr GeschÃ¤ft\", I got one bad result from some random tiny model and some more extensive responses from Gemini with suggestions for more idiomatic expressions. Modern LLMs are typically smart enough to understand this nuance when translating to German. reply selfhoster11 1 hour agorootparentThatâ€™s an interesting result. Iâ€™ve re-run your prompt with one change (made it â€œtranslate idiomaticallyâ€ instead) to guide models towards a more natively German mode of expression and a few actually came back with a more appropriate phrase than that literal translation. reply croes 4 hours agorootparentprevOr he didn't use a LLM at all, they were translation programs before ChatGPT reply astrange 1 hour agorootparentLLMs are based on the model architecture for Google Translate, so it's not a whole lot different. Of course they're much more \"intelligent\". reply aaron695 4 hours agoparentprevWhen we forged some documents it had a photo of a grotesque in the background. We worked out where it was and photographed it ourselves. Had to stand on a trash can to get the angle. We joked our documents were high quality than the original, which they were. Used them for years. Do it. It all makes sense after actually doing it yourself. People think forgers copy pixel by pixel but it's remaking assets. We guessed the iso standard on the barcodes. We were no experts. We probably got it right, but you have to do this on every asset. reply labcomputer 6 hours agoprevI'm surprised that neither the blog post nor the comments here yet mentioned another obvious giveaway to the forgery: The photo and card inside the plastic lamination show signs of wear. Parts of the photo are rubbed off around the edge, and the paper is stained. At the same time, the lamination is relatively clean. How does that make any sense? That's suspicious, even without seeing Espinosa's badge. [edit: the photo of Espinosa's badge shows a worn lamination and clean, unworn paper and photo] On top of that, the lamination has a cutout so it can be attached to a lanyard or retractor. The cutout shows no sign of wear. It's as if the forger imagined company badges work like library cards: You keep them in your wallet, and only remove them to check out a book. In the forger's head canon, the company must have later decided to laminate the badges (without replacing them!) and require everyone had to wear them visibly (hence the cutout). It makes no sense. reply kevin_thibedeau 6 hours agoparentRetractable lanyards weren't a thing in the 70's and would never be used for a landscape format ID. These would have been clipped to a pocket or collar. https://www.watson.ch/digital/wirtschaft/272982293-vom-hacke... reply labcomputer 5 hours agorootparentSure, but the point is that the hole shows the badge is meant to be clipped to something and worn in a visible place. As such, it will naturally bump into things and the lamination will accrue wear marks. reply refurb 3 hours agorootparentI noticed the badge hole too. It looks present punched and never been used. reply astrange 59 minutes agoparentprevI keep my badge in my pocket since the clip occasionally wears out, and I don't think anyone has ever commented on this. reply ghaff 31 minutes agorootparentProbably depended how security conscious where you worked was. Pretty common into at least to 80s was a clip that attached to your front shirt pocket which pretty much everyone had and badge readers werenâ€™t mostly a thing. If security were laxer you often just kept the badge in your pocket. But as another comment notes you didnâ€™t tend to just keep your badge in your wallet. reply eloisant 1 hour agoprevAlso, as cool as it is, I don't think it would have been worth 3000DEM in 2001. Adjusted for inflation it's worth almost 3000 of today's USD. That was just a month after the release of the original iPod, that eventually brought back Apple to relevancy. Apple was still the small competitor that Microsoft kept alive to avoid more problems in their anti-trust lawsuit. reply philips 9 hours agoprevCabel, the postâ€™s author, tells a similar story about someone trying to jump the line for a Playdate console preorder during this GDC talk. http://gdcvault.com/play/1034707/The-Playdate-Story-What-Was? reply meblum 4 hours agoprevHereâ€™s a link to the sold item: https://www.ebay.com/itm/285841371389?mkcid=16&mkevt=1&mkrid... reply echoangle 7 hours agoprevWhat was even the point of faking the DRK invoice? How does that in any way mean the item is real? If itâ€™s just some charity sale, I donâ€™t think the item would be authenticated reply kristopolous 3 hours agoparentI'd imagine forgers get some enjoyment out of the craft. It's kinda like asking a painter to paint. Doesn't mean they'll be good, but they probably like doing it reply s0rce 6 hours agoparentprevThis is what I thought, its not like a receipt from Sotheby's. reply KerrAvon 5 hours agoparentprevItâ€™s an attempt to create plausible deniability â€” â€œI bought it from someone else who said it was real.â€ The problem being that no one would think such a thing was valuable back in 2001; Apple was in much better shape than in the mid-90â€™s, but it wasnâ€™t that far from Dell suggesting they shut down the company. ebay really should yank this personâ€™s account. reply yumong 3 hours agorootparentThey bought it for 3000 DM and then sell it for less than half that price over 20 years later? reply mewpmewp2 1 hour agorootparentThey have trouble supporting their family after Covid19 happened and they lost their job. Please have some empathy. reply austhrow743 4 hours agoparentprevApple was a far smaller, less significant company in 2001. Much less chance that someone would go to the effort to make a fake employee 10 badge back then. reply callalex 4 hours agorootparentCalling Apple small and insignificant in 2001 is justâ€¦not factually accurate. As someone who lived through that time I donâ€™t really know what the most useful citation to provide you would be. If you knew what a computer was, you knew what Apple was many times over, and how they were the revolutionaryâ„¢ brand even back then. For goodness sake, 2001 is post-iMac by several years/generations. reply p_l 1 hour agorootparentApple's perceived status was bigger in USA than elsewhere. Don't know about Germany, but in Poland Mac at the time was pretty much pigeonholed into few artistic endeavours[1] or DTP - you were most likely to see something Mac related because a publishing company preparing ads made a screenshot on a mac when trying to make and showing webpage in a web browser. [1] And by 2001 was not that far from there being reasonable discussion whether you should not instead get an Atari ST if you wanted to do electronic music. (there was sorta ecosystem for ST as midi controller that was still surviving, at least in Poland, partially thanks to disco scene) reply justsomehnguy 3 hours agorootparentprev> For goodness sake, 2001 is post-iMac by several years/generations Oh come on, G3 is 1998, G4 is 2002. No other objections though. My favourite anecdote about that time is what Sex in the City had a MacBook, specifically PowerBook G3, as, well, a solid part of the story and even had a dedicated episode! https://www.youtube.com/watch?v=YWSZJXhOvBw reply amatecha 5 hours agoprevOh man, I was getting in on that Mastodon thread at the time (particularly scrutinizing the \"receipt\", like how it shows fresh creases/folds despite having supposedly been in a plastic sleeve and squished between pages in a binder for 20+ years), and hoped there would be enough momentum that the fraudulent item would be pulled. I'm very disappointed to learn someone actually bought this fake stuff. Sad times. reply callalex 4 hours agoparentI have a hard time feeling bad for someone who can be that uncritical before spending $1000. At that point the buyer is clearly looking to spend money for good feelings, not artifacts, so they probably actually got their moneyâ€™s worth. reply wruza 2 hours agorootparentYes, they buy a piece of paper for memories and they have it. Real or fake is irrelevant as this whole thing with collection and art is irrational. It must just look real enough to you and your guests to serve its purpose. reply modzu 5 hours agoparentprevi mean, if nothing else, its art reply toddmorey 6 hours agoprevThis sort of appeal for empathy too (in the context of an auction or collectable) is also a big red flag: \"I honestly hate to sell it but since Covid19 I'm unemployed and need to support my family.\" reply paxys 9 hours agoprevThe detective work was fun I'm sure but ultimately unnecessary. The burden of proof lies on the seller. Stuff like this is fake by default unless it comes with a certificate of authenticity issued by some trusted party. There's a reason that entire industry exists. Believe me there are much, much better fakes than this one sold online for pretty much every collectable in existence. reply acchow 8 hours agoparentHow does one... authenticate... the certificate of authenticity? reply throwaway290 8 hours agorootparentCall the body that issued it and ask reply kelseyfrog 8 hours agorootparentYou're saying I could gain a lot of money by issuing fake certificates of authenticity and then answer, \"Yes, it is authentic,\" to anyone who calls and asks? reply tbyehl 5 hours agorootparentKeep thinking like that and you'll be a ratings agency for Mortgage-Backed Securities. reply lettergram 5 hours agorootparentHey man, those banks, brokers, and agencies are still in business lol still trust them? reply astrange 57 minutes agorootparentNo they're not, Lehman Brothers is gone and Fannie Mae got nationalized. AIG did survive though. reply labcomputer 6 hours agorootparentprev> You're saying I could gain a lot of money by issuing fake certificates of authenticity and then answer, \"Yes, it is authentic,\" to anyone who calls and asks? No, you make the money by offering to sell real certificates of authenticity to authenticate the fake certificates of authenticity to people who those who calls and asks. reply yumong 3 hours agorootparentprevThe assumption was that a trusted third party exists. Since you trust it, by definition, you can contact it to confirm authenticity of the certificate. reply s0rce 6 hours agorootparentprevIf you somehow built up trust/reputation then yes. reply FabHK 8 hours agorootparentprev> issued by some trusted party reply saagarjha 7 hours agorootparentWhat authenticates the trusted party? reply tedunangst 7 hours agorootparentShared hallucination. reply callalex 3 hours agorootparent(To those that might dismiss this as snark, look up the definition of currency. And if you find that adventure interesting follow up by reading the excellent book â€œSapiens: A Brief History of Humankindâ€ by Yuval Noah Harari for an easy read that thoroughly explains the concept in an afternoon of reading. In that book it is called â€œshared delusionsâ€ instead.) reply p_l 1 hour agorootparentCurrency by itself, yes. Gold is probably best example. Most fiat currencies impose a degree of solidity by being required for payment for certain services (read: taxes) reply TeMPOraL 3 hours agorootparentprev> In that book it is called â€œshared delusionsâ€ instead. Or, by less casual name, \"intersubjectivity\". And yes, it's a very important idea that directly applies here. reply throwaway290 4 hours agorootparentprevLegal system. reply adolph 7 hours agorootparentprevYes On August 9, 2010, Symantec completed its approximately $1.28 billion acquisition of Verisign's authentication business, including the Secure Sockets Layer (SSL) Certificate Services, the Public Key Infrastructure (PKI) Services, the Verisign Trust Services, the Verisign Identity Protection (VIP) Authentication Service, and the majority stake in Verisign Japan. https://en.wikipedia.org/wiki/Verisign reply omarfarooq 7 hours agorootparentThat's based on verifiable cryptography. reply d0gsg0w00f 6 hours agorootparentYeah, but someone has to first trust the signer. I can start a CA tomorrow, doesn't mean anyone will put my root on their OS distro. reply throwaway290 4 hours agorootparentprevThe first step is removing the \"fake\" part. You can issue authentic certificates of authenticity. If your certificates are based on some expert verification that you do, people will actually pay you, can you imagine that! ;) And yes they would want you to say \"yes/no, it is/isn't authentic\" to anyone who calls and asks. But if you screw up your records and say \"yes\" to fake certificates of authenticity that imitate yours then people will stop paying you very quickly. (Also you may end up in jail) reply lesuorac 8 hours agorootparentprevI mean first set-up a website and second ghost write some articles in forbes & etc to gain credibility. But yeah; until somebody gets a different trusted party to look at the item. Fraud generally pays pretty well until you get caught. reply fragmede 7 hours agorootparentIf the penalty doesn't involve jail time, and the fine is less than the proceeds, it pays pretty well well after being caught reply chasontherobot 4 hours agorootparentnow you're just describing the business model of most fintech companies reply op00to 9 hours agoparentprevCmon, he had an invoice and everything! reply ecshafer 7 hours agoprevI think its mildly interesting that Apple went through the trouble of making employee ids when they have 10 people. That seems a bit superfluous at that size. Unless of course they made them when they were larger, and still just added numbers for people. reply p_l 22 minutes agoparentIt's both for \"corporate social capital\" and for practical necessities. Employee IDs pretty much start happening when you end up getting actual space that isn't your garage or repurposed residential buildings, especially if you're doing manufacturing of any kind. Then you might want to have employee IDs if only for minimal security (contractors! Visitors!) or workplace safety reasons (tracking who was left in the building, for example). It is, also, a sign of \"making it somewhere\", yes - along with some of the above parts also making up the \"corporate social capital\". Similarly using customized paperwork, having logos, branding style etc. all helps to build up a company image that might help in landing sales or investors or whatever. reply mozman 7 hours agoparentprevI think it aligns with the strategy of pretending to be bigger than you are so you can attract business customers. An old startup I worked at used customer IDs in communications that started from an arbitrary 5 digit number to give a false impression of our customer base. reply ender341341 2 hours agorootparentsimilarly it's used to be super common to get checkbooks starting with a higher check number cause some places were cautious of taking check #1 from someone assuming they didn't have any sort of credit history. reply fyrn_ 7 hours agoparentprevJust because it's employ ID #10 does not mean they made them when they hired the 10th employee. Probably it was later reply WA 2 hours agorootparentThe original badge in the article literally says issued in 1977: https://i0.wp.com/cabel.com/wp-content/uploads/2024/05/image... reply cdchn 7 hours agoprevInteresting that the exchange with the real Apple employee happened on Mastodon. Seems to be breaking the critical mass for serendipitous exchange. reply archagon 5 hours agoparentIn fairness, Espinosa's been on Mastodon for years. reply mgoetzke 4 hours agoprevHe went to so much trouble with the Red Cross thing to forget its DM for Deutsche Mark instead of DEM. reply Kwpolska 54 minutes agoparentAccounting software might have used ISO 4217 currency symbols (DEM, USD) instead of local symbols (DM, $). reply rcbdev 4 hours agoparentprevIn the old SAP docs they do write it as DEM. reply netsharc 3 hours agoparentprevAnd using slash as the date separator. Germans are taught to write dates as DD.MM.YYYY reply Tempest1981 5 hours agoprevMore interesting question: Your friend pulls out the fake badge, proud of himself for having the winning bid on eBay... \"check it out! badge #10!\" Do you tell them that it's fake? Or let them live happily in their joy-filled bubble? reply dkjaudyeqooe 5 hours agoparentYou tell them so that they can get a refund from ebay, if you catch them in time, also so they don't end up accused of fraud when they try to resell it. reply Findecanor 13 minutes agoprevMy first thought was that perhaps it could be a movie prop from perhaps \"Pirates of Silicon Valley\" or some other movie about Apple but the badly faked provenance proves that it is not even that. reply eps 3 hours agoprevFunny enough forgers now have an example of authentic badge with the list of things to focus on if they decide to make another badge. reply tomaskafka 3 hours agoparentCunningham's Law still works :) https://meta.m.wikimedia.org/wiki/Cunningham%27s_Law#:~:text.... reply ChrisMarshallNY 1 hour agoprevThis type of forgery is becoming quite common. I participate in a community that has some historical literature, where early editions of our literature fetch fairly significant premiums. There are some extremely well-done forgeries. I am told they come from China, but I suspect the means to make them, are available in many venues. I heard a story about a guy that purchased a Winchester rifle from an estate auction. It was one of those old western-style guns, with the repeater action. As an original, it was worth a great deal. He took it to an expert, who almost immediately declared it a forgery. He said it was mainly because it was in too good a shape. It was supposed to be over 150 years old, and looked like it was only ten years old. I have also heard, from a watchmaker I knew, that Rolex forgeries are so good, that even seasoned watchmakers are fooled, and the only way to tell, is open the watch. reply brlnwest 41 minutes agoprevgreat detective work by Cabel! Always loved his attention to detail. reply Maro 5 hours agoprevI think the price is also a yellow flag. $1k seems to low.. reply croes 4 hours agoparentIt's just the starting bid reply yumong 3 hours agorootparentFrom somebody who paid more than that 20 years ago? reply croes 3 hours agorootparentLower starting bids attract more people, sometime leads to higher end bid because of bidding wars reply fennecfoxy 1 hour agoprevAnd somebody still bought it... reply hnthrowaway0328 7 hours agoprevA sideline question: In Jason Bourne movie there are a few shots showing the protagonist faking passports. Does such technique (looks like no advanced tools are used) exist or just a film fantasy? reply Stevvo 45 minutes agoparentDepends on the security features of the passport. Most modern passports are highly secure. A 1960s passport from an African country would have lacked security features and been much simpler to fake or modify. reply gen220 7 hours agoparentprevIt depends on who you're trying to convince. TSA/customs? A prospective employer? The guy who runs the corner store? To varying degrees, the answer is yes, the tools exist. reply londons_explore 3 hours agorootparentMost rich countries now use passports with an RFID chip which contains a copy of all the data in the passport and a digital signature. They also host a server allowing trusted third parties to verify that a given passport is still valid (ie. Not withdrawn). The combination of those mean you will never edit details on a passport, but you might be able to copy a passport 1:1, because the security is only mifare classic. reply carabiner 7 hours agoparentprevIn a Tom Clancy book they talked about terrorists just buying the commercial equipment used to make ID's. On Silk Road, I remember some guy claiming to sell British passports genuinely made from within the UK government. reply dumbfounder 7 hours agorootparentI bought a fake id 30 years ago that used the actual backs from Rhode Island DMV that they acquired somehow, but then faked the fronts. Equipment like that can absolutely go missing. reply function_seven 5 hours agorootparentI used to make fake IDs that reused both the plastic backing and the hologram layer from a real license. I spent some time creating a template in Photoshop that I ink-jetted onto photo paper. The final result was very close to the real thing in all aspects: look, thickness, weight, â€œbendynessâ€, real hologram, and light transmission (i.e. the bouncer shining a flashlight through the back of the ID would see what he expected to see. A bit of translucency) I never got around to modifying the data on mag stripe. I just dragged a hard-drive magnet over it until it didnâ€™t scan at all. My takeaway from all that? The hologram that was used to strengthen the official IDs had an unintended side effect of making the fakes easier to believe. reply tomaskafka 3 hours agorootparentprevOr, he was a scammer as well - what are you going to do with an anonymous person who sold you fake passports? Report him to police? reply mozman 7 hours agorootparentprevSome DMV employees were busted selling real IDs with fake supporting documents in Arizona. My friends daughter bought a fake ID stating that she was over 21 but only 16 - it would scan as authentic at stores but would not pass with police. reply adolph 7 hours agoparentprevBusy spy crossroads such as Dubai, Jordan, India and many E.U. points of entry are employing iris scanners to link eyeballs irrevocably to a particular name. . . . For a clandestine field operative, flying under a false name could be a one-way ticket to a headquarters desk, since theyâ€™re irrevocably chained to whatever name and passport they used. https://www.schneier.com/blog/archives/2012/04/biometric_pas... reply slyall 6 hours agorootparentIt's funny how the lack of ability for spies to take aliases anymore may make James Bond going under his real name everywhere more realistic. reply nolongerthere 3 hours agorootparentprevCould you just wear a contact that obfuscates your iris? reply ChuckMcM 3 hours agoprevAlways interesting to see people who grift like this. My Dad used to engrave and restore guns. He was quite good at it, and so good that at one point the manufacturer's representative from Colt told him at a gun show that had my Dad not told him he would have sworn the revolver he was looking at had not been restored. I asked him if he ever got people trying to get him to \"enhance\" the value of their guns and he laughed and said, \"Ayup, all the time.\" Art and antique forgery has always been kind of fascinating to me for that reason. reply system2 3 hours agoprevHow about reporting it to eBay so they can refund the money and ban this person? EDIT: I reported it myself including the original article. reply informal007 9 hours agoprevWhy people will pay much to buy those kinds of thing that can't identify? reply hi-v-rocknroll 7 hours agoparentMost low information buyers can't grok provenance. reply gosub100 9 hours agoparentprevThey implicitly trust the facilitator of the transaction. It's a variation on the \"greater fool\" scam. They think it's the old days where the auction house had any skin in the game, they're not wise to the old (in this case almost 30 year old) silicon valley grift: we profit off a scam, but [ its such small amounts/backed by enormous VC capital/\"safe\" (for the scammer) harbor/ done across state lines/authorized by predatory ToS (with arbitration clause) ] that the victim is powerless. Thanks for playing, better luck next time :D reply talldayo 8 hours agorootparentBingo. Some rich shmuck who's collecting Imagineering memorabilia and Avatar 3D movie cutouts will see that on Ebay and think it's a great deal. Maybe another 20 such people ignore it because it's sketchy (or because they read an article like this), but somebody less-informed will take the risk and give the seller a profit. When I first read the article, my knee-jerk reaction was that this is a victimless crime. If you pay $700 for a laminated square that has an Apple employee on it, you probably shouldn't get upset when your due-diligence fails you and it's a fake. reply throwaway290 8 hours agorootparentprevYou sneakily jump from \"victim is trusting\" to \"victim is powerless\" Yes the victim is trusting because he probably won't think to authenticate the fake. The victim is not powerless, actually. the victim has all the power to get money back. many stories how very easy to get a transaction reversed with paypal/ebay and leave the seller holding the bag, even if the seller is legit. reply nullc 7 hours agorootparent> The victim is not powerless, actually. the victim has all the power to get money back. many stories how very easy to get a transaction reversed with paypal/ebay and leave the seller holding the bag, even if the seller is legit. Ebay's policies have substantially reversed from where they were in the past and the scammer's know it. Make sure to always pay for ebay with a credit card to be confident that you can reverse fraudulent transactions. reply amatecha 5 hours agorootparentI could be wrong but I'm pretty sure your eBay and PayPal accounts will get banned if you chargeback a transaction. reply nullc 3 hours agorootparentI've performed a very large chargeback against eBay without any ban. YMMV. reply throwaway290 4 hours agorootparentprevFun times... reply gosub100 7 hours agorootparentpreveBay sneakily allows the listing to be posted in the first place, even though they have access to the same information as the rest of us. They trust that there will always be a greater fool, they trust that they can claim \"we didn't know! you assume the risk when you buy this stuff, we're just a third party \", again, SV shenanigans. Not innovation or even an honest business. reply hi-v-rocknroll 7 hours agorootparenteBay allows sellers to offer all sorts of fake and illegal shit because it's profitable and most people don't know the difference. There are tons of pirated games and software being sold as original \"electronic downloads\". And where else would stolen items be sold, including carrier- and Apple-blacklisted iPhones that cannot be activated? reply croes 3 hours agoprevWho would have paid 3000 Marks for an Apple badge in 2001? reply tjungblut 3 hours agoparentand why would the German red cross own it and sell it on Ebay? Ebay wasn't even a thing back when the DM was still around. reply chrizel 2 hours agorootparentThat's not true. I have a German eBay account from May 2001 when we still had the DM. eBay was very popular back then and had a completely different feeling because it was mostly used by private individuals for selling their stuff instead of mostly professional merchants like it is today. reply croes 3 hours agorootparentprevThat was the forgers error. At first he claimed he bought it from the Red Cross in 2001 and didn'tmention how, then he claimed it was one of the first items he bought on ebay in 2003/2004 and didn't mention from whom he bought it, implying he bought it inlcuding the invoice. reply londons_explore 3 hours agorootparentprevGermany has always been a rather privacy conscious country. Even now, I suspect if that badge fell into the hands of most Germans, they would either try to return it to it's owner or shred it on the basis that it's someone else's private data. reply art3m 8 hours agoprevMore likely that seller truly purchased this on Ebay before and just resisting to admit (or investigate) that he bought fake item. reply nardi 8 hours agoparentI would agree, except the seller seems to have made a new forgery of their receipt on the fly in response to Cabel's inquiry, which leads me to believe they probably made the original forgery as well. reply polpo 6 hours agorootparentAnd the other item the seller had was a Taylor Swift concert ticket that used the wrong font. Thereâ€™s definitely a pattern there. https://social.panic.com/@cabel/112452964691814590 reply etchalon 9 hours agoprevThis post will ensure a better fake is up on eBay tomorrow. reply StrLght 1 hour agoparentAlternatively, it'll raise awareness. If only a few people learn to verify what exactly they're buying before paying relatively huge amounts of money â€” that would be a win in my book. reply KennyBlanken 7 hours agoprev> At first, it looked good. The plastic was scuffed with age, No, the plastic is very clearly scuffed with something abrasive like sandpaper. You'd never see wear patterns like that from age/use - it would be a very matte look, not clear scratches. reply mjlee 1 hour agoparent> But it also felt a little off. The scuffing lookedâ€¦ sandpapery. Is in the very next paragraph. reply throwaway22032 8 hours agoprevI feel as if the article is missing the important detail that eBay auctions are full, absolutely full, of fake/timewaster bids. I've basically given up on the auction format entirely because of the number of people that try to \"pull out\" not realising that their offer is binding. reply csomar 7 hours agoparenteBay is so full of garbage I don't understand how they have $10bn of revenue. Yes, that's billions. But then maybe there is a huge garbage market opportunity out there. reply Nerada 8 hours agoprevThis is honestly something that would be interesting to own. It's not $950 interesting, but interesting nonetheless, just for a conversation piece about an elaborate forgery. I've always wanted to either create or purchase intricate set props like the journal from Supernatural [0]. Fantastically fake, but just interesting to have. [0] https://waywardjournal.tumblr.com/post/187259600588/reapers reply stoltzmann 3 hours agoparentYou know, you could also have a forged forged employee badge. Give me a hundred quid and I'll forge one for you. Throw in some extra and I'll make sure it's extra forged and you'll have a story to tell to your friends. reply knallfrosch 3 hours agorootparentBut please don't send him the original #10 Apple employee badge. That would be fraud. In a sense, it would be a forged forged forged badge. reply SoftTalker 6 hours agopreveBay is a cesspool of fraud and forgeries. It would be more surprising if the badge were genuine. reply raverbashing 9 hours agoprevHere's the thing, I don't think the purchaser of that listing was worried it was fake. Though it's weird that Chris's typewriter part looks more fake than the faked card (it's supposed to be an IBM printer rather than a typewriter it seems) reply floren 7 hours agoparentIt's supposed to be typed with the \"Orator\" typeball for the IBM Selectric typewriter. reply FabHK 8 hours agoparentprevAgreed. The \"original\" seemed to use a proportional font (with a very narrow \"I\"), while the fake seemed to use a mono-spaced non-proportional (with a wide \"I\"), which seemed more plausible to me (for a typewriter). reply mavili 4 hours agoprevMaybe because my first language isn't English but \"forged\" to me implies card would've been used for access, or at least attempted, and therefore I feel like the title is click-bait. Had it said \"fake\" instead I would probably not think the same. That aside, if he hasn't already he should've reported to eBay immediately so the buyer isn't conned. reply callalex 3 hours agoparentWhat word would you use in your native language to mean 1) historical document/artifact that was created later by a liar 2) A written signature on a document trying to impersonate someone who didnâ€™t actually read and approve of said document 3) An ID card a teenager uses to gain entrance to a bar/club 4) a verbal statement that the speaker knows is false when said, for example â€œof course that dress does not make you look fatâ€ (does this word change if the receiver also knows the statement is false? In English I would call this a â€œwhite lieâ€) 5) A body part that has been altered with surgery (silicone implants, saline injections) reply mavili 2 hours agorootparent1) Fake 2) Forged 3) Forged 4) Lie 5) Fake As you can probably tell, from my understanding (possibly wrong connection) I think of the word 'to forge' in the context of actually trying to get access to somewhere or something with fake documents. When the intention or the consequence of using such document is more for monetary or material gain, I tend to think of it as fake. I suppose dictionary definition does allow for both usage, i.e. to forge is to make a fake resemblance of something.. etc. I didn't think not knowing accurate definition of a word warranted downvotes but oh well. reply MarceColl 6 minutes agorootparent> I didn't think not knowing accurate definition of a word warranted downvotes I think the downvotes comes from then accusing the person writing it of clickbait. So while it's fine to not know the accurate definition of a word, it's not so fine to accuse the author of something because you don't know the accurate definition. reply croes 4 hours agoparentprevSeems to be pretty much synonymous. Example https://en.wikipedia.org/wiki/Hitler_Diaries Forged all over the place reply batmanthehorse 9 hours agoprevInteresting but I wasn't entirely convinced that it's fake. There might be more to this story. Maybe the seller is the one who got scammed when they bought it 20 years ago. reply ttmb 9 hours agoparentMaybe they did. Do you suppose they got scammed on eBay - which they \"perfectly\" remember buying it from - or from the Red Cross, which they have an invoice for? reply groby_b 9 hours agoparentprevThat German Red Cross invoice is 100% absolutely a fake. Source: I'm a German who has donated to the red cross. That ain't it. (Also: There needs to be a a specific key phrase without which the German equivalent of the IRS will come down on you like a ton of bricks. It is missing) reply cromulent 6 hours agorootparentThe date 8.12.2001 is a Saturday. This also seems off. reply simantel 8 hours agoparentprevDid you miss the part where Chris Espinosa said \"Thatâ€™s not Sherry Livingston\"? Chris also has a follow-up post not shown in Cabel's blog where he says there aren't any photos of Sherry online: https://mastodon.social/@Cdespinosa/112391173495267599 reply jandrese 8 hours agorootparentWhich is kind of amazing when you think about it. There's no \"The Apple Team\" group photo that includes employee #10 anywhere? No wonder the scammer chose her when making the fake, it would be impossible to verify the photo without tracking down either Sherry herself or someone who personally knew her back in 1977. reply CamperBob2 7 hours agorootparentprevThat's an interesting thing to assert. How does he know there are no photos of a given person online? It's getting into Russell's Teapot territory. reply quesera 7 hours agorootparentPossibly an overstated version of \"I know what Sherry looks like, and an image search for her name does not turn up any pictures of the real person\". I might say the same for several of my friends. reply alvah 9 hours agoparentprevI have a bridge for sale. Completely genuine, honest! reply wetpaws 9 hours agoparentprevThey did not cause their \"invoice\" was also fake reply quink 9 hours agorootparentWith a price on the invoice of â€œ3.000â€ Mark, with the decimal point being the thousands separator. Or about 1,500 EUR in todayâ€™s money. Yeah, I donâ€™t think so. reply ttepasse 8 hours agorootparentIn Germany the dot is the most used thousands separator. It is still a fake. reply quink 6 hours agorootparentI know that, I wasnâ€™t expressing incredulity at that, I was expressing incredulity at the price of 3,000 DMâ€¦ while also wanting to make clear that it wasnâ€™t 3 DM. reply DEADMINCE 4 hours agoprevThe author is a little paranoid IMO. Sure given his suspicions I assumed this was more a case of a broken clock being correct twice a day. For example: > But, again again, I had a weird feeling â€” this series of photos was trying too hard. That binder labelled â€œBILLS 200[0]â€”2010â€, conveniently flipped upside down for casual authenticity? Why would you put that in these photos unless you were trying a bit too hard to make your case? That's just ridiculous. reply cabel 3 hours agoparentIt's totally ok that you wouldn't have had the same gut feeling â€” but I absolutely did. I wrote that because it seemed like the binder was unnecessary information posed specifically in the photo to try to gain my trust. I think that's largely because the binder was unnecessary information posed specifically in the photo to try to gain my trust. Bonus trivia I didn't mention: if you look at the invoice preceding the one in the binder, it has the logo for the 1992 (!) Barcelona Olympics at the top. A real weird thing to put in your 'Bills 2000 â€” 2010' binder! I do think this binder is totally real, but should actually be labelled 'My Forged Invoices' ;) reply UberFly 3 hours agoparentprevSeems ok to me. Just a stream of pure intuition that ended up being totally correct. reply yumong 4 hours agoparentprevI'd also ask how come a single binder would suffice for 10 years of bills. reply croes 4 hours agoparentprevBut in the end he was right reply neilv 9 hours agoprev [â€“] I'm not going to speculate on the truth of allegations of fraud here, but two side points: * A few times skimming this, I didn't understand some of the assertions and logic. For example, I couldn't say just by glancing at the photos that the card wasn't filled out on an IBM Selectric II (introduced in 1971, before Apple was founded). For another example, I see people commenting on VAT tax missing on the receipt from the German Red Cross, and also the confusion over whether it was bought on eBay or from the German Red Cross, but no mention of whether that invoice might be something that the German Red Cross adapted to work with early eBay doing the payments (at least in the US, sales tax for online purchases was very murky, and eBay punted). Also, the author seems to be ignoring cross-cultural differences, in their psychoanalytic speculation about subtleties of seller's behavior, such as seller's perceived earnestness in composing a photo. * This article is going out of its way to publicly defame someone. If they have strong evidence of the counterfeiting and fraud that they allege, they should be going to a legal authority. Given that they decided to get Internet Points out of it, they'd better hope that their allegations are correct, and also that they can prove it sufficiently if sued in some jurisdiction. I would guess that glomming onto mob behavior (\"We did it, Reddit!\") won't be a good defense. reply Retr0id 8 hours agoparent> they should be going to a legal authority I'd really hope legal authorities have better things to do than act as arbitrators of provenance of niche-interest historic artifacts. Without being the person who \"won\" the auction, I doubt you'd even get your foot in the door. reply poizan42 8 hours agoparentprev* Chris says it's not a picture of Sherry * The issue date of the badge for employee number 10 predates that of employee number 8 * The German invoice uses American comma separator * The German invoice is also missing the invoicing entitiy's legally required information, is missing VAT and uses American terms. reply trelane 7 hours agorootparentAlso, \"Wir danken Ihnen fÃ¼r Ihr Unternehmen?\" Really?! reply jprete 7 hours agoparentprevYes, there are worlds in which a huge series of accidents and coincidences explain how this person isn't a scammer. They're just unbelievably unlikely to the point of being able to disregard the possibility entirely. reply anewcolor 8 hours agoparentprevThe picture in the ID is not a photo of Sherry Livingston (says Chris, who knows Sherry) reply goosedragons 8 hours agoparentprev [â€“] If you look at the employee #8 badge it has an issue date of 3/17/77. So how is employee #10's 3/10/77? There's lots of holes. reply neilv 8 hours agorootparent> * If you look at the employee #8 badge it has an issue date of 3/17/77. So how is employee #10's 3/10/77? There's lots of holes.* For \"lots of holes\", I think that's not a great one to single out as an example. This is a tiny company, in California, in the 1970s..., and we're assuming, ahem, German precision, around when they can get a nerd to sit for a photo to laminate an ID card? Again, like I said upfront, I'm not commenting on the truth of the allegations -- just commenting on the weak Internet detective work. The article says: > When in doubt, Engage The InternetÂ® The Internet can be dumb as snot. Have doubt. reply djao 5 hours agorootparentThe employee #8 badge, which we know is real, is typed in a completely different font from the #10 badge, has different dimensions, different photo dimensions, and the photos were clearly taken with dramatically different cameras and lighting. None of these differences makes any sense if the #10 badge (supposedly made within a week of the #8 badge) is real. reply filmgirlcw 6 hours agorootparentprev> The Internet can be dumb as snot. Have doubt. Yeah, thatâ€™s sort of the point of the original post. Have doubt. One of the central rules of the internet (and outside the internet. But especially on the internet.) is that people are often fucking liars. This is especially true when it comes to memorabilia. This sellerâ€™s history is littered selling so-called authentic things like business cards and concert tickets and based on this incident, I personally think every single one of them is fraudulent. You might like playing contrarian to defend the honor of an obvious forger, and thatâ€™s your right. But it isnâ€™t defamation to call a liar a liar. Truth is an affirmative defense. Someone with an actual Apple badge from that era said the badge is fake. The text doesnâ€™t match that personâ€™s badge. The photo use for Sherry is obviously both a stock photo and too high resolution to be used on an employee badge from a tiny company in California in the 1970s. The badge is too well-preserved, even for a relic that the seller claims to have purchased in 2001 (or was it 2003 or 2004, seeing as their own story kept changing). There are so many red flags when looking at this thing that it doesnâ€™t matter if one of the proof points doesnâ€™t live up to your standards. This is a fake item. Youâ€™re the one trying to score internet points, not the author who was sharing an interesting exchange he had with a seller who was not only selling a fake item, but probably also forged receipt documents related to the fake item. reply I_AM_A_SMURF 7 hours agorootparentprevThat's not necessarily a hole. Maybe Employee #8 was hired before #10 but had a later start date, hence a different issue date. reply jonathankoren 7 hours agorootparentYeah, itâ€™s an â€œissue dateâ€ someone just didnâ€™t go across the room and get it. Also, the early employee numbers are famously semibogus. Jobs was 0 because he hated coming after Woz, who was 1. reply fragmede 7 hours agorootparentprev [â€“] If you find this kind of detective work up your alley, you might like Papers Please. https://store.steampowered.com/app/239030/Papers_Please/ reply queuebert 6 hours agorootparent [â€“] An amazing game that is secretly propaganda to make people respect and appreciate bureaucracy. Glory to Arstotzka! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "An eBay auction for a fake Apple Employee #10's badge was quickly debunked by internet users, despite the seller's forged documentation, selling for $946 before the fraud was exposed.",
      "It is crucial to exercise caution when purchasing items claiming to be part of Apple's history and always authenticate the items before making a purchase."
    ],
    "commentSummary": [
      "The discussion explores the text quality of mechanical and electric typewriters, reasons for preferring typewriters over modern tech, and experiences with different typewriters.",
      "Participants share insights on authenticity, forgery techniques, and concerns when buying potentially fake items online, like employee badges.",
      "The conversation emphasizes trust, verification, and security measures' importance, including chargeback consequences and vulnerabilities in current security systems."
    ],
    "points": 623,
    "commentCount": 208,
    "retryCount": 0,
    "time": 1715897946
  },
  {
    "id": 40383978,
    "title": "Protecting Customer Data in Slack's AI Training",
    "originLink": "https://slack.com/trust/data-management/privacy-principles?nojsmode=1",
    "originBody": "Privacy Principles: Search, Learning and Artificial Intelligence Trust navigation Additional privacy principles PagesClose Legal Navigation Getting started Overview Privacy Privacy Slack Privacy Policy Privacy FAQ Data Requests Data Requests Data Request Overview Data Request Policy Transparency Report Compliance Compliance Cookie Policy Slack's GDPR Commitment California Consumer Privacy Act (CCPA) FAQ CCPA Metric Disclosure FERPA Compliance Security Security Overview Data Management Data Management Transparency and Control Privacy principles: Search, Learning, and Intelligence Legal Data Management Legal Overview Privacy Principles: Search, Learning and Artificial Intelligence Our mission is to build a product that makes work life simpler, more pleasant and more productive. Our guiding principle as we build this product is that the privacy and security of Customer Data is sacrosanct, as detailed in our Privacy Policy, Security Documentation and SPARC and the Slack Terms. Machine Learning (ML) and Artificial Intelligence (AI) are useful tools that we use in limited ways to enhance our product mission. To develop AI/ML models, our systems analyze Customer Data (e.g. messages, content, and files) submitted to Slack as well as Other Information (including usage information) as defined in our Privacy Policy and in your customer agreement. To ensure the privacy and security of Customer Data in this particular context, we have a few guiding principles: Data will not leak across workspaces. For any model that will be used broadly across all of our customers, we do not build or train these models in such a way that they could learn, memorize, or be able to reproduce some part of Customer Data. We have technical controls in place to prevent access. When developing AI/ML models or otherwise analyzing Customer Data, Slack canâ€™t access the underlying content. We have various technical measures preventing this from occurring. Please read our Security White Paper for more info on these controls that protect the confidentiality and security of Customer Data. We offer Customers a choice around these practices. If you want to exclude your Customer Data from helping train Slack global models, you can opt out. If you opt out, Customer Data on your workspace will only be used to improve the experience on your own workspace and you will still enjoy all of the benefits of our globally trained AI/ML models without contributing to the underlying models. Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your Org or Workspace Owners or Primary Owner contact our Customer Experience team at feedback@slack.com with your Workspace/Org URL and the subject line â€œSlack Global model opt-out request.â€ We will process your request and respond once the opt out has been completed. Customer Data and Other Information How Slack may use Customer Data (e.g. messages, content, files) and Other Information to update our services Working from the above principles, here are a few examples of improvements and privacy protective techniques that our product and analytics teams may use to develop, update and improve Slack: Channel Recommendations: We may use insights to recommend that a user joins a new public channel in their company. We make these suggestions based on channel membership, activity, and topic overlaps. Our model learns from previous suggestions and whether or not a user joins the channel we recommend. We protect privacy while doing so by separating our model from Customer Data. We use external models (not trained on Slack messages) to evaluate topic similarity, outputting numerical scores. Our global model only makes recommendations based on these numerical scores and non-Customer Data. For more technical details, please visit our Engineering Blog to learn more. Search Results: Our search machine learning models help users find what they're seeking by identifying the right results for a particular query. We do this based on historical search results and previous engagements without learning from the underlying text of the search query, result, or proxy. Simply put, our model can't reconstruct the search query or result. Instead, it learns from team-specific, contextual information like the number of times a message has been clicked in a search or an overlap in the number of words in the query and recommended message. Autocomplete: Slack might make suggestions to complete search queries or other textâ€“ for example autocompleting the phrase \"Customer Support\" after a user types the first several letters of this phrase. These suggestions are local and sourced from common public message phrases in the userâ€™s workspace. Our algorithm that picks from potential suggestions is trained globally on previously suggested and accepted completions. We protect data privacy by using rules to score the similarity between the typed text and suggestion in various ways, including only using the numerical scores and counts of past interactions in the algorithm. Emoji Suggestion: Slack might suggest emoji reactions to messages using the content and sentiment of the message, the historic usage of the emoji, and the frequency of use of the emoji on the team in various contexts. For instance, if ðŸŽ‰ is a common reaction to celebratory messages in a particular channel, we will suggest users react to new, similarly positive messages with ðŸŽ‰. To do this while protecting Customer Data, we might use an etrnal model (not trained on Slack messages) to classify the sentiment of the message. Our model would then suggest an emoji only considering the frequency with which a particular emoji has been associated with messages of that sentiment in that workspace. These types of thoughtful personalizations and improvements are only possible if we study and understand how our users interact with Slack. Slack takes privacy seriously and our confidentiality obligations described in our customer agreements and Privacy Policy apply in each of these scenarios. Customers own their own Customer Data. Slack aggregates and disassociates Customer Data such that Slackâ€™s use of Customer Data to update the Services will never identify any of our customers or individuals as the source of any of these improvements to any third party, other than to Slackâ€™s affiliates or sub-processors.",
    "commentLink": "https://news.ycombinator.com/item?id=40383978",
    "commentBody": "Slack AI Training with Customer Data (slack.com)517 points by mlhpdx 11 hours agohidepastfavorite261 comments tifik 2 hours agoWell I really hope this massively blows up in their face when all of Europe goes to work just about now, and then North America in 5-8 hours. Let's see if we have another Helldivers 2 event that makes them do a hard backpedal after losing thousands of large customers that will not under any circumstances take the chance. I have a friend with a law firm who just called me yesterday for advice as he's thinking about switching to Slack from Teams. I gave him a glowing recommendation because it is literally night and day, but there is no way in hell he takes any chance any sensitive legal discussions leak out through prompt hacking. He might even be liable himself for knowingly using a tool that spells out \"we read and reuse your conversations\". reply KronisLV 1 hour agoparentPersonally, I rather liked self-hosted versions of these: Mattermost: https://mattermost.com/ Rocket.Chat: https://www.rocket.chat/ Nextcloud Talk: https://nextcloud.com/talk/ Out of those, Mattermost was the easiest to setup (just need PostgreSQL and a web server, in addition to the main container), however not being able to easily permanently delete instead of just archiving workspaces was awkward. Nextcloud Talk was very easy to get going if you already have Nextcloud but felt a bit barebones last I checked, whereas Rocket.Chat was overall the more pleasant option to use, although I wasn't the biggest fan of them using MongoDB for storage. The user experience is pretty good with all of them, however in the groups that I've been a part of, ultimately nobody cared about self-hosting an instance, since most orgs just prefer Teams/Slack (or even Skype for just chatting/meetings) and most informal groups just default to Discord. Oh well. reply bayindirh 1 hour agorootparentThe problem is not technical, but social with these platforms. i.e. How do you convince 40+ people from 5 countries to add yet another memory resident chat application and fragment their knowledge to another app/mental space? This gets way harder as the community becomes more dynamic and temporary (i.e. high circulation like students). I gave the good fight last year with someone, and they just didn't flex a nanometer citing ergonomics of Slack is way better than alternatives, and didn't care about data mining (was a possibility back then) or keeping older messages at ransom. reply KronisLV 47 minutes agorootparent> i.e. How do you convince 40+ people from 5 countries to add yet another memory resident chat application and fragment their knowledge to another app/mental space? If it's a company, you can just be like: \"Hey, we use this platform for communication, you can log in with your Active Directory credentials.\" It also has the added benefit of acting as a directory for every employee in the company, so getting in touch can be more convenient than e-mail (while you can also customize the notification preferences, so it doesn't get too spammy), as opposed to the situation which might develop, where some teams or org units are on Slack, others on Teams and getting in touch can be more messy. If it's a free-form social group, then you can throw that idea away because of network effects, it'd be an uphill battle, same as how sometimes people complain about people using Discord for various communities, but at the same time the reality is that old school forums and such were also killed off - since most people already have a Discord account and there's less friction to just use that. Either way, I'm happy that self-hosted software like that exists. reply bayindirh 29 minutes agorootparent> If it's a company That's a big if, and the answer is \"No\" in my case. If it was, that comment wouldn't be there. It's not a \"social group\" either, but a group of independent institutions working together. It's like a large gear-train. A lot of connections between small islands of people. So you have to work together, and have to find a way somehow. So, it's complicated. > Either way, I'm happy that self-hosted software like that exists. Me too. I happen to manage a Nextcloud instance, but nobody is interested in the \"Talk\" module. reply p1esk 2 hours agoparentprevBut you can opt out, right? So whatâ€™s the problem? Also, is Teams (and other messengers) any different? reply rpastuszak 1 hour agorootparentDefaults matter! Just look at how much Apple and Mozilla get from Google by having their browser as a default (ca. $20,000,000,000 and $400,000,000 IIRC per annum). Or look at how many people rejected the tracking prompt displayed for FB when it was added to iOS (+70%). reply apignotti 2 hours agorootparentprevYou can opt-out by manually writing an email to them. The process matters. reply whatevaa 1 hour agorootparentThey could make it even better, like requiring signed/certified physical mail /s. Or fax... reply notachatbot1234 1 hour agorootparentprevDo they discard everything processed so far every time someone opts out? reply troupo 2 hours agorootparentprev> But you can opt out, right? So whatâ€™s the problem? This thinking is the problem. \"Oh, we just added your entire private/privileged/NDA/corporate information to our training set without your consent. What's the problem?\" Opt-out must be the default. Edit: By \"Opt-out must be the default.\" I mean: no one's data must be included until they explicitly give consent via an opt-in :) reply zelphirkalt 2 hours agorootparentEspecially since once it has been trained, it is in the model, and I am not aware of any way anyone has discovered to later remove from the model single or selected training data points, except for re-training/re-learning the model. So basically the crime might already be done. But I also know that so many businesses are too sluggish to make a switch and employees incapable of understanding the risk. So unfortunately not all of Europe will switch away. But I hope a significant number gives them the middle finger. reply bayindirh 1 hour agorootparentThere's something called \"machine unlearning\" being worked on to address these issues. This doesn't mean that I support Slack or any opt-in without consent training model. On the contrary. I don't have any OpenAI/Midjourney/etc. account, and don't plan to have one. reply Liquidor 1 hour agorootparentprev> Opt-out must be the default. Don't you mean opt-in must be the default? Or am I misunderstanding the concept of opt-ins :P reply ellisnguyen 1 hour agorootparentOpt-out by default = Opt-in. Opt-in by default = Opt-out reply troupo 1 hour agorootparentprevOpt-in is \"I agree to have my data included\" Opt-out is \"I don't agree to have my data included\" reply falcor84 1 hour agorootparentprevExactly! Allowing access to your data should only be opt-in reply ADeerAppeared 1 hour agorootparentprevWorth noting: This is a legal requirement in Europe The GDPR mandates that consent is given affirmatively, with this kind of \"oh we put it in the EULA nobody reads\" being explicitly called out as non-compliant. reply torginus 2 hours agorootparentprevand how does that even work? Slack is a chat app. Does everyone involved in the chat need to opt out for it to be meaningful? What about bots? reply zmmmmm 9 hours agoprev> For any model that will be used broadly across all of our customers, we do not build or train these models in such a way that they could learn, memorise, or be able to reproduce some part of Customer Data This feels so full of subtle qualifiers and weasel words that it generates far more distrust than trust. It only refers to models used \"broadly across all\" customers - so if it's (a) not used \"broadly\" or (b) only used for some subset of customers, the whole statement doesn't apply. Which actually sounds really bad because the logical implication is that data CAN leak outside those circumstances. They need to reword this. Whoever wrote it is a liability. reply mayank 9 hours agoparent> They need to reword this. Whoever wrote it is a liability Sounds like itâ€™s been written specifically to avoid liability. reply MingFengLiu 8 hours agorootparentI'm sure it was lawyers. It's always lawyers. reply cqqxo4zV46cp 2 hours agorootparentYes, lawyers do tend to have a part to play in writing things that present a legally binding commitment being made by an organisation. Developers really canâ€™t throw stones from their glass houses here. How many of you have a pre-canned spiel explaining why the complexities of whichever codebase you spend your days on are ACTUALLY necessary, and are certainly NOT the result of over-engineering? Thought so. reply afc 7 hours agoparentprevEspecially when a few paragraphs below they say: > If you want to exclude your Customer Data from helping train Slack global models, you can opt out. So Customer Data is not used to train models \"used broadly across all of our customers [in such a way that ...]\", but... it is used to help train global models. Uh. reply DougBTX 4 hours agorootparentTo me it says that they _do_ train global models with customer data, but they are trying to ensure no data leakage (which will be hard, but maybe not impossible, if they are training with it). The caveats are for â€œlocalâ€ models, where you would want the model to be able to answer questions about discussions in the workspace. It makes me wonder how they handle â€œprivateâ€ chats, can they leak across a workspace? Presumably they are trying to train a generic language model which has very low recall for facts in the training data, then using RAG across the chats that the logged on user can see to provide local content. reply ENGNR 1 hour agorootparentMy intuition is that it's impossible to guarantee there are no leaks in the LLM as it stands today. It would surely require some new computer science to ensure that no part of any output that could ever possibly be developed isn't sensitive data from any of the input. It's one thing if the input is the published internet (even if covered by copyright), it's entirely another to be using private training data from corporate water coolers, where bots and other services routinely send updates and query sensitive internal services. reply visarga 36 minutes agorootparentThere is a way. Build a preference model from the sensitive dataset. Then use the preference model with RLAIF (like RLHF but with AI instead of humans) to fine-tune the LLM. This way only judgements about the LLM outputs will pass from the sensitive dataset. Copy the sense of what is good, not the data. reply hackernewds 7 hours agorootparentprevWhy are these kinda things opt-out? And need to be discovered.. We're literally discussing switching to Teams at my company (1500 employees) reply M4v3R 3 hours agorootparentIf you switch to Teams only for this reason I have some bad news for you - thereâ€™s no way Microsoft is not (or will not start in future) doing the same. And youâ€™ll get a subpar experience with that (which is an understatement). reply guappa 3 hours agorootparentI think a self hosted matrix/irc/jitsi is the way to do it. reply IshKebab 2 hours agorootparentWe've been using Mattermost and it works very well. Better than Slack. The only downside is their mobile app is a bit unreliable, in that it sometimes doesn't load threads properly. reply Shadowmist 5 hours agorootparentprevYouâ€™d be better off just not having chat than switching to Teams. reply metadat 5 hours agorootparentBut the business will suffer by most likely being less successful due to less cohesive communication.. it's \"The Ick\" either way. reply andy_ppp 4 hours agorootparentThe idea that Slack makes companies work better needs some proof behind it, Iâ€™d say the amount of extra distraction is a net negativeâ€¦ but as with a lot of things in software and startups nobody researches anything and everyone writes long essays about how they feel things are. reply unkulunkulu 1 hour agorootparentDistraction is not enforced. Learning to control your attention and how to help yourself do it is crucial whatever you do in whatever time and in whatever technological context or otherwise. It is the most long term valuable resource you have. I think we start to recognize this at larger scale. Slack easily saves a ton of time solving complex problems that require interaction and expertise of a lot of people, often unpredictable number of them for each problem. They can answer with delay, in a good culture this is totally accepted and people still can independently move forward or switch tasks if necessary, same as with slower communication tools. You are not forced to answer with any particular lag, however slack makes it possible when needed to reduce it to zero. Sometimes you are unsure if you need help or you can do smthing on your own. I certainly know that a lot of times eventually I had no chance whatsoever, because knowledge requires was too specialized, this is not always clear. Reducing barriers to communication in those cases is crucial and I don't see Slack being in the way here, only helpful. The goal of organizing Slack is such that you pay right amount of attention to right parts of communication for you. You can do this if you really spend (hmm) attention trying to figure out what that is and how to tune your tools to achieve that. reply andy_ppp 1 hour agorootparentThatâ€™s a lot of words with no proof isnâ€™t it, itâ€™s just your theory. Until I see a well designed study on such things I struggle to believe the conjecture you make either way. It could be quite possible that you benefit from Slack and I donâ€™t. Even receiving a message and not responding can be disruptive and on top Iâ€™d say being offline or ignoring messages is impossible in most companies. reply whatevaa 1 hour agorootparentYour idea also comes with no proof, just your personal experience. reply metadat 3 hours agorootparentprevGood point, could be that it reduces friction too far in some instances. However, in general less communication doesn't seem better for the bottom line. reply amne 3 hours agorootparentprevwe use Teams and it's fine. Just don't use the \"Team\" feature of it to chat. Use chat groups and 1-to-1 of course. We use \"Team\" channels only for bots: CI results, alerts, things like that. Meetings are also chat groups. We use the daily meeting as the dev-team chat itself so it's all there. Use Loops to track important tasks during the day. I'm curious what's missing/broken in Teams that you would rather not have chat at all? reply marricks 6 hours agorootparentprevObviously because no one would ever opt in. reply jeffdn 6 hours agorootparentprevI'd make sure to do an extended trial run first. Painful transition. reply hackernewds 4 hours agorootparentprevso if I don't want slack to train on _anything_ what do I do? I still suspect everything now reply j45 5 hours agorootparentprevHope it's not doublespeak, ambiguity leaves it grey, maybe to play. reply __loam 5 hours agorootparentprevOpt out is such bullshit. reply chefandy 7 hours agoparentprevNah. Whoever decided to create the reality their counsel is dancing around with this disclaimer is the actual problem, though it's mostly a problem for us, rather than them. reply FuckButtons 5 hours agorootparentItâ€™s a problem for them if it looses customer trust / customers. reply hackernewds 4 hours agorootparentif they lose enough, they will \"sorry we got caught\" if they don't, they will not do anything reply chefandy 4 hours agorootparentprevIf it impacted their business significantly, it would restore some of the faith I've lost in humanity recently. Frankly, I'm not holding my breath. reply IanCal 2 hours agoparentprevThe problem is this also covers very reasonable use cases. Use sampling across messages for spam detection, predicting customer retention, etc - pretty standard. Then there's cases where you could have models more like llms that can output data from the training set but you're running them for that customer. reply j45 5 hours agoparentprevI'm imagining a corporate slack, with information discussed in channels or private chats that exists nowhere else on the internet.. gets rolled into a model. Then, someone asks a very specific question.. conversationally.. about such a very specific scenario.. Seems plausible confidential data would get out, even if it wasn't attributed to the client. Not that itâ€™s possible to ask an llm how a specific or random company in an industry might design somethingâ€¦ reply hackernewds 4 hours agorootparentexactly. a fun game to see why it is so hard to prevent this https://gandalf.lakera.ai/ reply Nition 9 hours agoparentprev- Create a Slack account for your 95-year-old grandpa - Exclude that one account from using the models, he's never going to use Slack anyway - Now you can learn, memorise, or reproduce all the Customer Data you like reply dheera 8 hours agoparentprevSeems like time to start some slack workspaces and fill them with garbage. Maybe from Uncyclopedia (https://en.uncyclopedia.co/wiki/Main_Page) reply hsaliak 6 hours agorootparentThe Riders of the Lost Kek dataset is an excellent candidate https://arxiv.org/abs/2001.07487 reply __loam 5 hours agoparentprevIf you trained on customer data your service contains custom data. reply nyc_data_geek 9 hours agoprevStory time. I was at a VC conference last year and if I learned nothing else there, I learned how to spell \"AI\". Every single exhibitor just about had their signage proudly proclaiming their capabilities in this area, but one in particular struck me. They were touting the API integrations they could offer to train their \"Enterprise AI\"/LLM, and among those integrations were things like M365, Slack, etc. It struck me because of the garbage in, garbage out problem. I'd like to think that the amount of shitposting I do on Slack personally will poison that particular well of training data, but this seems to point to a larger problem to me. LLM's don't have a concept of truth or reality, or awareness of any sort. If the training data they are fed is poorly quality checked/unsanitized by human intelligence, the outputs will be as useless/noisy as the original data set. It feels to me that in the frothy rush to capture market buzz and VC, this is being forgotten. Am I missing something, here? reply wongarsu 7 hours agoparentMost shitposting is probably more straightforward to understand than business communication or press releases where realizing what wasn't said often carries more insight than the things that were said. Of course training an AI model on simple, straightforward and honest data provides good results. That's the essence behind \"textbooks is all you need\" which lead to the phi LLMs. Those are great small LLMs. But if you want your model to understand the complexity of human communication you have to include it in your training data. If you subscribe to the idea that to be the very best text completion engine possible you would need to have a perfect understanding of reality itself, how different humans perceive reality differently, and how they choose to communicate about this perception and their interaction with reality, themselves and other humans, then it's not unreasonable to expect that back-propagation would eventually find that optimal representation if given enough data, the right architecture and enough processing power. Or at least come somewhat close. In that paradigm there is no \"bad data\", only insufficient or badly balanced datasets. Just don't try doing that with a 3B parameter LLM. reply antipaul 8 hours agoparentprevWhat do you think chatGPT uses as training data? The whole worldâ€™s â€œsh*tpostingâ€: Reddit, blogs, and the rest of the internet. But also books and Wikipedia and what not. You can â€œsmoothâ€ all the crap out via the training procedure. But even more, Slack can easily filter training data to, say, only posts in high-use channels. Further, slack has other options: eg, use their customer data only for marginal fine-tuning, for example. Or, they donâ€™t even know their use case yet - but want to wrap their arms around your data pronto. reply rozap 6 hours agorootparentWhat makes you think I don't shitpost in the #engineering channel? And heuristics don't even scratch the surface of the bigger problem where it's trained on people who aren't great at their jobs but type a lot of words on slack about circling back on KPIs. reply bee_rider 5 hours agorootparentI think those types of people are actually shockingly well paid. If slack can make bots to replace them, theyâ€™ll print money, right? reply blackenedgem 1 hour agorootparentThat's all well and good until something goes down and you need someone knowledgeable to diplomatically shout at a vendor. reply nyc_data_geek 6 hours agorootparentprevChatGPT isn't known for it's accuracy though, is it? They coined the term \"hallucination\" because it is wrong so much. reply moneywoes 6 hours agorootparentprevhow does the training procedure smooth the garbage out? reply thomashop 6 hours agorootparentThrough regularization techniques, data augmentation, loss functions, and gradient optimization, ensuring the model focuses on meaningful patterns and reduces overfitting to noise. reply bigfudge 3 hours agorootparentItâ€™s not obvious how any of those would do anything but better approximate the average of a noisy dataset. RLHF might help, but only if itâ€™s not done by idiots. reply mvkel 8 hours agoparentprevThe best LLMs were trained on data from the open internet, which is full of garbage. They still do a pretty good job (granted it has been fine tuned and RLHF'd, but you can do that with Slack data too) reply IanCal 1 hour agoparentprevThe more obvious things are that it's not training llms fully on all channels. Some quick ideas: Search and summarize other messages. No new llms training and about mostly linking to existing answers. Fine tune on your messages, but only customer support messages in the public channel, not \"eng-shitpost\" Natural language requests over your company data. reply jorisboris 8 hours agoparentprevSame for Reddit or Facebook groups. There's a lot of shitposting there, but absolutely a lot of valuable information if LLMs manage to separate the wheat from the chaff. reply williamcotton 9 hours agoparentprevThe sheer scale of data on the long tail. Sure, the head is already a trash pile and has been for decades now, but there is plenty of non-monetized information all over the internet that is barely linked to or otherwise discoverable. reply krainboltgreene 8 hours agorootparentIt does not matter how hard they try, nothing will rival the CommonCrawl treasure trove except maybe Google's index itself. reply leoh 9 hours agoparentprevYes, consider an existing LLM being given â€œshitpost-yâ€ messages and asking it if there is anything interesting in there. It could probably summarize it well and that could then be used for training another LLM. etc etc reply nyc_data_geek 9 hours agorootparentThis assumes everything in the training data set is accurate. Sometimes people are wrong, obtuse, sarcastic, etc. LLM's don't have any way of detecting or accounting for this, do they? That output, then being used to train other LLM's, just creates an ouroboros of AI generated dogshit. reply sp332 9 hours agorootparentLLMs are state-of-the-art at detecting sarcasm. It won't help if the data is just wrong though. Edit: https://arxiv.org/abs/2312.03706 Human performance on this benchmark (detecting sarcasm in Reddit comments) was 0.82, a BERT-based LLM scored 0.79. https://arxiv.org/abd/2106.05752 LSTM, 98% at detecting sarcasm in a Project Gutenburg-based dataset. reply comboy 8 hours agorootparent> LLMs are state-of-the-art at detecting sarcasm. This is such a precious gem. reply E39M5S62 8 hours agorootparentprevI literally can't tell if you're being sarcastic or not. reply rrr_oh_man 8 hours agorootparentExactly reply brookst 5 hours agorootparentprevAnd yet human civilization has survived the fact that many humans are wrong, lying, delusional, etc. There is no assumption that everything in our personal training set is accurate. In fact, things work better when we explicitly reject that idea. LLMs do not rely on 100% factually accurate inputs. Sure, youâ€™d rather have less BS than more, but this is all statistics. Just like most people realize that flat earthers are nutty, LLMs can ingest falsehoods without reducing output quality (again, subject to statistics) reply bongodongobob 4 hours agorootparentprevThe training data doesn't need to be strictly accurate. If it was, you'd just be programming a deterministic robot. The whole point is the feed it actual human language. Giving it shitposts and sarcasm is literally what makes it good. Think of it like 100 people guessing the number of marbles in a jar. Average their guesses and it will be very close. The training data is the guesses, the inference is the average. reply chatmasta 9 hours agoparentprevWhy shouldnâ€™t AI be able to shitpost too? At the very least, and much more importantly, AI should be able to recognize shitposting. reply nyc_data_geek 9 hours agorootparentThis is the crux of it, and where I'm wondering if I'm missing something. Can it, today? My understanding is it cannot discern reality from fiction, thus \"hallucinations\" (a misnomer because it implies awareness, which these probability models lack). reply tomrod 8 hours agorootparentThe poorly named hallucinations are creation of ideas from provided prompts, which ideas are not grounded in reality. It isn't the mistaken adjudication of the reality of a provided prompt. reply fuchse 8 hours agorootparentprevThat sounds surprisingly human reply swalsh 7 hours agoparentprevAlong the same lines, phi-3 is kind of a sign of what you can do if you focus only on high quality data. It seems like while yes, quantity is very important, quality almot matters just as much. reply beeboobaa3 9 hours agoparentprevMore ignored than forgotten. reply nyc_data_geek 9 hours agorootparentWallpapered over? reply bongodongobob 4 hours agoparentprevI think what you're missing is assuming that what an LLM \"reads\" thinks is a true statement. Shitposting is almost like meta slang. I feel like that's a necessary thing for it to train on to truly understand language. I feel like people underestimate the depth LLMs can pick up on. reply koolba 9 hours agoprev> We offer Customers a choice around these practices. If you want to exclude your Customer Data from helping train Slack global models, you can opt out. If you opt out, Customer Data on your workspace will only be used to improve the experience on your own workspace and you will still enjoy all of the benefits of our globally trained AI/ML models without contributing to the underlying models. Why would anyone not opt-out? (Besides not knowing they have to of courseâ€¦) Seems like only a losing situation. reply tifik 2 hours agoparentWhats baffling to me is why companies think that when they slap AI on the press release, their customers will suddenly be perfectly fine with them scraping and monetizing all of their data on an industrial scale, without even asking for permission. In a paid service. Where the service is private communication. reply schneehertz 9 hours agoparentprev> We offer Customers a choice around these practices. I remembered the joke from The Hitchhiker's Guide to the Galaxy, maybe they will have a small hint in a very inconspicuous place, like inserting this into the user agreement on page 300 or so. reply bigfudge 3 hours agorootparentBut the plans were on displayâ€¦â€ â€œOn display? I eventually had to go down to the cellar to find them.â€ â€œThatâ€™s the display department.â€ â€œWith a flashlight.â€ â€œAh, well, the lights had probably gone.â€ â€œSo had the stairs.â€ â€œBut look, you found the notice, didnâ€™t you?â€ â€œYes,â€ said Arthur, â€œyes I did. It was on display in the bottom of a locked filing cabinet stuck in a disused lavatory with a sign on the door saying â€˜Beware of the Leopard. reply m463 7 hours agorootparentprevNever more true than with apple. Activating an iphone for example has a screen devoted to how privacy is important! It will show you literally thousands of pages of how they take privacy seriously! (and you can't say NO anywhere in the dialog, they just show you) They are normalizing \"you cannot do anything\", and then everyone does it. reply m463 9 hours agoparentprev> Why would anyone not opt-out? This is basically like all privacy on the internet. Everyone WOULD opt-out, if it was easy, and it becomes a whack-a-optput game. note how you opt-out (generic contact us), and what happens when you do opt-out (they still train anyway) reply halostatue 8 hours agorootparentWhen we send our notice, we are going to be sending a notice that we want none of our data used for any ML training from Slack or anyone else. reply __loam 5 hours agorootparentprevOpt out should be the default by law reply patrickk 4 hours agorootparentThis is how GDPR works, explicit opt-in consent is needed from the customer. https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-re... reply hackernewds 4 hours agorootparentprevso upgrades and customer approves everything? slippery slope to over regulation reply __loam 3 hours agorootparentThe status quo is consumer abuse. reply yellow_postit 2 hours agorootparentprevHence the cookie banners reply clwg 7 hours agoparentprevBecause they don't seem to make it easy. It doesn't seem as a individual user I have any say in how my data is used, I have to contact the Workspace Owner. When I do I'll be asking them to look at alternative platforms instead. \"Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your Org or Workspace Owners or Primary Owner contact our Customer Experience team at feedback@slack.com with your Workspace/Org URL and the subject line â€œSlack Global model opt-out request.â€ We will process your request and respond once the opt out has been completed.\" reply hackernewds 4 hours agorootparentYou can always quit your job right? /s reply mvkel 8 hours agoparentprevBecause it's default opt-in, and most people won't see this announcement. reply dheera 8 hours agorootparentYep, much like just about every credit card company shares your personal information BY DEFAULT with third parties unless you explicitly opt out (this includes Chase, Amex, Capital One, but likely all others). reply hackernewds 7 hours agorootparenthow do you opt out of these? I do share my data with rocket money though since there's no good alternatives :( reply sensanaty 44 minutes agoparentprevI'm willing to bet that for smaller companies, they just won't care enough to consider this an issue and that's what Slack/Salesforce is hedging on. I can't see a universe in which large corpos would allow such blatant corporate espionage for a product they pay for no less. But I can already imagine trying to talk my CTO (who is deep into the AI sycophancy) into opting us out is gonna be arduous at best. reply p1esk 8 hours agoparentprevIâ€™d be surprised if more 1% opt out. reply tifik 2 hours agorootparentI'd be surprised if any legal department in any company with one will not freak the f out when they read this. They will likely loose the biggest customers first, so even if it is 1% of customers, it will likely affect their bottom line enough to give it a second though. I don't see how they might profit from an in-house LLM more than from their enterprise-tier plans. Their customer support will have a hell of a day today. reply zeckalpha 7 hours agoparentprevOpting out in this way may implicitly opt you in to workspace specific models. reply IMTDb 8 hours agoparentprev> Why would anyone not opt-out? Because you might actually want to have the best possible global models ? Think of \"not opting out\" as \"helping them build a better product\". You are already paying for that product, if there is anything you can do, for free and without any additional time investment on your side that makes their next release better, why not do it ? You gain a better product for the same price, they get a better product to sell. It might look like they get more than you do in the trade, and that's probably true; but just because they gain more does not mean you lose. A \"win less / win more\" situation is still a win-win. (It's even a win-win-win if you take into account all the other users of the platform). Of course, if you value the privacy of these data a lot, and if you believe that by allowing them to train on them it is actually going to risk exposing private info, the story changes. But then you have an option to say stop. It's up to you to measure how much you value \"getting a better product\" vs \"estimated risk of exposing some information considered private\". Some will err on one side, some on the other. reply ericjmorey 7 hours agorootparentDo I have free access to and use of those models? If not, I don't care to help them. reply krainboltgreene 8 hours agorootparentprev> Think of \"not opting out\" as \"helping them build a better product\" I feel like someone would only have this opinion if they've never ever dealt with any in the tech industry, or capitalist, in their entire life. So like 8-19 year olds? Except even they seem to understand that the profit absolutist goals undermine everything. This idea has the same smell as \"We're a family\" company meetings. reply nomel 7 hours agorootparentCould you expand on that a bit? He clearly communicated hours perspective. Your point, and your reasons for disagreeing with it, are not clear. Not being able to communicate clearly, calling others children, is a a fairly strong indicator of immaturity. reply hehdhdjehehegwv 7 hours agorootparentprevI for one consider it my duty to bravely sacrifice my privacy to the alter of corporate profit so that the true beauty of LLM trained in emojis and cat gifs can bring humanity to the next epoch. reply kepano 9 hours agoprevIn summary, you must opt-out if you want to exclude your data from global models. Incredibly confusing language since they also vaguely state that \"data will not leak across workspaces\". Use tools that cannot leak data not \"will not\". reply semitones 8 hours agoparentAren't all tools, essentially, just one API call away from \"leaking data\"? reply kepano 7 hours agorootparentIn this case they mean leak into the global model â€” so no. You can have sovereignty of your data if you use an open protocol like IRC or Matrix, or a self-hosted tool like Zulip, Mattermost, Rocket Chat, etc reply mvkel 8 hours agoparentprevMost, if not all SaaS software is multi-tenant, so we've been living in the \"will not\" world for decades now. reply kepano 7 hours agorootparentThat's exactly my point. \"File over app\"[1] is just as relevant for businesses as it is for individuals â€” if you don't want your data to be used for training, then take sovereignty of it. [1] https://stephango.com/file-over-app reply zeckalpha 7 hours agorootparentprevIn your experience. reply creativeSlumber 9 hours agoparentprevwhat is the difference between \"will not\" and \"cannot\" in legalese? reply glennericksen 8 hours agorootparent\"Will not\" allows the existence of a bridge but it's not on your route and you say you're not going to go over it. \"Cannot\" is the absence of a bridge or the ability to cross it. reply gketuma 5 hours agorootparentWow, well explained. reply purplejacket 7 hours agorootparentprevMy off leash dog will not bite you, he is well behaved. My dog at home cannot bite you, he is too far away. reply ptman 1 hour agoprevWe really need to start using self-hosted solutions. Like matrix / element for team messaging. It's ok not wanting to run your own hardware at your own premises. But the solution is to run a solution that is end-to-end encrypted so that the hosting service cannot get at the data. cryptpad.fr is another great piece of software. reply neop1x 55 minutes agoparentZulip (https://zulip.com/) seems to be a great self-hosted python-based alternative to Slack/Teams. reply Ekaros 12 minutes agoprevI would expect this from free service, but from paid service with non trivial cost... It seems insane... Maybe whole model of doing business is broken... reply xyst 8 hours agoprevThe gold rush for data is wild. Private companies selling us out. - Slack - Discord - Reddit - Stackoverflow Letâ€™s just hope this data gold rush dies out faster than the web3 craze before OpenAI reaches critical mass and gets access to government server farms. Alphabet boys have server farms of domestic and foreign surveillance and intelligence. Exabytes of data [1] [1] https://en.m.wikipedia.org/wiki/Utah_Data_Center reply bigstrat2003 7 hours agoparentDon't forget Dropbox: https://twitter.com/Werner/status/1734890651378975007 reply BHSPitMonkey 3 hours agorootparentThat thread was a mischaracterization and a misunderstanding. The toggle simply exposed UI entry points to AI integrations that users could then opt to use, with consent. reply TechDebtDevin 3 hours agoparentprevMeh, tbh I think these guys live in a bit of a dream world about how much their data is worth. While investors and corporate partners will rush to these companies for their data, I'm not really convinced random internet conversations are going to push anything forward but let them sell shovels. Most of the miners always go broke. reply ilrwbwrkhv 8 hours agoparentprevI mean slack is sold off. Founders made money. For all intents and purposes it's dead software. reply smileysteve 7 hours agorootparentIt's owned by Salesforce;n if they stop growing it, it'll go the way of Heroku - and that breach didn't go well. reply eggdaft 3 hours agorootparentprevI actually think Slack is great and it has improved over the last 12 months. reply Liquix 7 hours agorootparentprevproprietary software that no one who cares about privacy or security should use? absolutely. dead? not exactly reply hex4def6 10 hours agoprevI'm confused about this statement: \"When developing AI/ML models or otherwise analyzing Customer Data, Slack canâ€™t access the underlying content. We have various technical measures preventing this from occurring\" \"Can't\" is a strong word. I'm curious how an AI model could access data, but Slack, Inc itself couldn't. I suspect they mean \"doesn't\" instead of \"can't\", unless I'm missing something. reply 015a 10 hours agoparentI also find the word \"Slack\" in that interesting. I assume they mean \"employees of Slack\", but the word \"Slack\" obviously means all the company's assets and agents, systems, computers, servers, AI models, etc. I would find even a statement from Signal like \"we can't access our users content\" to be tenuous and overly-optimistic. Like, when I heard the word \"can't\" my brain goes to: there is nothing anyone in the company could do, within the bounds of the law, to do this. Employees at Slack could turn off the technical measures preventing this from occurring. Employees at Signal could push an app update which side-channels all messages through to a different server, unencrypted. Better phrasing is \"Employees of Slack will not access the underlying content\". reply throwaway22032 9 hours agorootparentInterestingly I'd probably go the other way. If it's verifiably E2EE then I consider \"we can't access this\" to be a fairly powerful statement. Sure, the source could change, but if you have a reasonable distribution mechanism (e.g. all users get the same code, verifiably reproducible) then that's about as good as you can get. Privacy policies that state \"we won't do XYZ\" have literally zero value to me to the extent that I don't even look at them. If I give you some data, it's already leaked in my mind, it's just a matter of time. reply spywaregorilla 10 hours agoparentprevFrom their white paper linked in the same comment > Provisioning To minimize the risk of data exposure, Slack adheres to the principles of least privilege and role-based permissions when provisioning accessâ€”workers are only authorized to access data that they reasonably must handle in order to fulfill their current job responsibilities. All production access is reviewed at least quarterly. so... seems like they very clearly can. reply EGreg 10 hours agoparentprevEvery company that promises \"end-to-end encryption\" is just pinky-swearing to you also. Like Telegram or WhatsApp reply int_19h 6 hours agorootparentTelegram client is open source, so you can see what exactly happens there when you enable E2EE. reply EGreg 4 hours agorootparentReproducible builds somehow ? reply shultays 2 hours agorootparenthttps://core.telegram.org/reproducible-builds reply LelouBil 9 hours agorootparentprevYeah, at least if the client is open source you could verify. reply r_thambapillai 9 hours agoprevThe incentive for first party tool providers to do this is going to be huge, whether its Slack, Google, Microsoft, or really any other SaaS tool. Ultimately, if business want to avoid getting commoditized by their vendors, they need be in control of their data, and their AI strategy. And that probably ultimately means turning off all of these small-utility-very-expensive-and-might-ruin-your-business features, and actually creating a centralized, access controlled, well governed knowledge base which you can plug any open source or black box LLM, from any provider. reply jonnycomputer 8 hours agoparent\"commoditized by their vendors\" is exactly the phrase I was looking for. It's why I wanted my co to self-host Mattermost instead of using Slack. reply bn-l 8 hours agoparentprevItâ€™s definitely a moral hazard (/opportunity). As a reminder, by default on windows 11 Microsoft syncs your files to their server. reply Liquix 7 hours agorootparentall your files? no way that cozy of a blanket statement can be true. if you kept cycling in drives full of /dev/random you could fill up M$ servers with petabytes of junk? sounds like an appealing weekend project reply yorwba 1 hour agoprev\"We protect privacy while doing so by separating our model from Customer Data. We use external models (not trained on Slack messages) to evaluate topic similarity, outputting numerical scores. Our global model only makes recommendations based on these numerical scores and non-Customer Data.\" I think this deserves more attention. For many tasks like contextual recommendations, you can get most of the way by using an off-the-shelf model, but then you get a floating-point output and need to translate it into a binary \"show this to the user, yes or no?\" decision. That could be a simple thresholding model \"score > Î¸\", but that single parameter still needs to be trained somehow. I wonder how many trainable parameters people objecting to Slack's training policy would be willing to accept. reply pyromaker 9 hours agoprev>Our mission is to build a product that makes work life simpler, more pleasant and more productive. I know it would be impossible but I wish we go back to the days when we didn't have Slack (or tools alike). Our Slack is a cesspool of people complaining, talking behind other people's backs, echo chamber of negativity etc. That probably speaks more to the overall culture of the company, but Slack certainly doesn't help.You can also say \"tool is not the problem, people are\" - sure, we can always explain things away, but Slack certainly plays a role here. reply barkbyte 8 hours agoparentYour company sucks. Iâ€™ve used slack at four workplaces and itâ€™s not been at all like that. A previous company had mailing lists and they were toxic as you describe. The tool was not the issue. reply muglug 5 hours agorootparentYeah, written communication is harder than in-person communication. Itâ€™s easy to come across poorly in writing, but that issue has no easy resolution unless youâ€™re prepared to ban Slack, email, and any other text-based communication system between employees. Slack can sometimes be a place for people who donâ€™t feel heard in conventional spaces to vent â€” but thatâ€™s an organisational problem, not a Slack problem. reply zemo 4 hours agoparentprevHN isn't really a bastion of media literacy or tech criticism. If you ever ask \"does [some technology] affect [something qualitative] about [anything]\", the response on hn is always going to be \"technology isn't responsible, it's how the technology is used that is responsible!\", asserting, over and over again, that technology is always neutral. The idea that the mechanism of how people communicate affects what people communicate is a pretty foundational concept in media studies (a topic which is generally met with a hostile audience on HN). Slack almost certainly does play a role, but people who work in technology are incentivized to believe that technology does not affect people's behaviors, because that belief allows people who work in technology to be free of any and all qualitative or moral judgements on any grounds; the assertion that technology does not play a role is something that technology workers cling to because it absolves them of all guilt in all situations, and makes them, above all else, innocent in every situation. On the specific concept of a medium of communication affecting what is being communicated, McLuhan took these ideas to such an extreme that it's almost ludicrous, but he still had some pretty interesting observations worth thinking on, and his writing on this topic is some of the earlier work. This is generally the place where people first look, because much of the other work assumes you've understood McLuhan's work in advance. https://en.wikipedia.org/wiki/Understanding_Media reply userbinator 7 hours agoparentprevSwitch to Teams instead. Only half-kidding, but it's an application which is so repulsive it seems to discourage people from communicating at all. reply vasco 9 hours agoparentprevI disagree slack plays a role. You only mentioned human aspects, nothing to do with technology. There was always going to be instant messaging as software once computers and networks were invented. You'd just say this happens over email and blame email. reply rjh29 8 hours agoparentprev> That probably speaks more to the overall culture of the company Yep. Fun fact, my last workplace had a fairly nontoxic Slack... but there was a whole second Slack dedicated to bitching and shitposting where the bosses weren't invited. Humans gonna human. reply grepfru_it 8 hours agorootparentWas not limited to just the bosses who were not invited. If you werenâ€™t in the cool club you also did not get an invite. A very inclusive company on paper that was very exclusionary behind the scenes. reply eggdaft 3 hours agorootparentWhat happened when someone from the cool club got promoted and became a boss? reply matthewmacleod 9 hours agoparentprevNo, I donâ€™t think Slack does play a role in this. It is quite literally a communication tool (and Iâ€™d argue one that encourages far _more_ open communication than others). If Slack is a cesspool, thatâ€™s because your company culture is a cesspool. reply rcaught 7 hours agoparentprevKeyboard warriors reply tikkun 10 hours agoprevEugh. Has anyone compiled a list of companies that do this, so I can avoid them? If anyone knows of other companies training on customer data without an easy highly visible toggle opt out, please comment them below. reply goles 10 hours agoparentSynology updated this policy back in March (Happened to be a Friday afternoon). Services Data Collection Disclosure \"Synology only uses the information we obtain from technical support requests to resolve your issue. After removing your personal information, we may use some of the technical details to generate bug reports if the problem was previously unknown to implement a solution for our products.\" \"Synology utilizes the information gathered through technical support requests exclusively for issue resolution purposes. Following the removal of personal data, certain technical details may be utilized for generating bug reports, especially for previously unidentified problems, aimed at implementing solutions for our product line. Additionally, Synology may transmit anonymized technical information to Microsoft Azure and leverage its OpenAI services to enhance the overall technical support experience. Synology will ensure that personally identifiable information, such as names, phone numbers, addresses, email addresses, IP addresses and product serial numbers, is excluded from this process.\" I used to just delete privacy policy update emails and the like but now I make a habit of going in to diff them to see if these have been slipped in. reply bn-l 8 hours agorootparentLike the other poster it would be great to have a name and shame site that lists companies training on customer data reply kepano 9 hours agoparentprevif your data is stored in a database that a company can freely read and access (i.e. not end-to-end encrypted), the company will eventually update their ToS so they can use your data for AI training â€” the incentives are too strong to resist https://twitter.com/kepano/status/1688610782509211648 https://twitter.com/kepano/status/1682829662370557952 reply ncr100 7 hours agorootparentAnd the penalty is unnoticeable to these companies. reply paxys 10 hours agoparentprevIt would be easier to compile a list of companies that don't do this. The list: reply hosteur 9 hours agorootparentMy company does not do this and have no plans to do such a thing. reply internetter 9 hours agorootparentprevNonsense. There are plenty of companies that don't have shit policies like this. A vast majority, even. Stop normalizing it. reply ceruleanseas 10 hours agoparentprevWe can fight back by not posting anything useful or accurate to the internet until there are protections in place and each person gets to decide how their data is used and whether they are compensated for it. reply weikju 10 hours agoparentprev* reply Stem0037 1 hour agoprevWhile Slack emphasizes that customers own their data, the default of Customer Data being used to train AI/ML models (even if aggregated and disassociated) may not align with all customers' expectations of data ownership and control. reply blhack 10 hours agoprevHow could this possibly comply with European \"right to be forgotten\" legislation? In fact, how could any of these AI models comply with that? If a user requests to be forgotten, is the entire model retrained (I don't think so). reply beefnugs 9 hours agoparentThis \"ai\" scam going on now is the ultimate convoluted process to hide sooo much tomfuckery: theres no such thing as copyright anymore! this isn't stealing anything, its transforming it! you must opt out before we train our model on the entire internet! (and we still won't spits in our face) this isn't going to reduce any jobs at all! (every company on earth fires 15% of everyone immediately) you must return to office immediately or be fired! (so we get more car data teehee) this one weird trick will turn you into the ultimate productive programmer! (but we will be selling it to individuals not really making profitable products with it ourselves) and finally the most aggregious and dangerous: censorship at the lowest level of information before it can ever get anywhere near peoples fingertips or eyeballs. reply TechDebtDevin 3 hours agorootparentYou had me until your weird censorship theories. Why would they be censoring based on the business model you're pushing... You're a clown who needs to touch grass. reply whimsicalism 10 hours agoparentprev> how could any of these AI models comply with that? If a user requests to be forgotten, is the entire model retrained (I don't think so). I don't believe that is the current interpretation of GDPR, etc. - if the model is trained, it doesn't have to be deleted due to a RTBF request afaik. there is significant legal uncertainty here Recent GDPR court decisions mean that this is probably still non-compliant due to the fact that it is opt-out rather than opt-in. Likely they are just filtering out all data produced in the EEA. reply luckyshot 2 hours agoprevSo if you want to opt out, there's no setting to switch, you need to send an email with a specific subject: > Contact us to opt out. [...] To opt out, please have your Org or Workspace Owners or Primary Owner contact our Customer Experience team at feedback@slack.com with your Workspace/Org URL and the subject line â€œSlack Global model opt-out request.â€ [...] reply Rebuff5007 9 hours agoprevHow can anyone in their right mind think building AI for emoji selection is a remotely good use of time... reply barkbyte 8 hours agoparentIâ€™d use that, at work. It would be a welcome improvement to their product. reply dlandis 9 hours agoparentprev> \"These types of thoughtful personalizations and improvements are only possible if we study and understand how our users interact with Slack.\" LOL reply nextworddev 8 hours agoparentprevit's just a justification for collecting tokens reply TechDebtDevin 3 hours agorootparentTokens (outside of a few trillion ) are worthless imo, I think OAI has pushed that limit, let the others chase them with billions into the ocean of useless conversational data and drown. reply paxys 10 hours agoprev> Data will not leak across workspaces. > If you want to exclude your Customer Data from helping train Slack global models, you can opt out. I don't understand how both these statements can be true. If they are using your data to train models used across workspaces then it WILL leak. If they aren't then why do they need an opt out? Edit: reading through the examples of AI use at the bottom of the page (search results, emoji suggestions, autocomplete), my guess is this policy was put in place a decade ago and doesn't have anything to do with LLMs. Another edit: From https://slack.com/help/articles/28310650165907-Security-for-... > Customer data is never used to train large language models (LLMs). So yeah, sounds like a nothingburger. reply whimsicalism 10 hours agoparentThey're saying they won't train generative models that will literally regurgitate your text, my guess is classifiers are fair game in their interpretation reply swatcoder 10 hours agorootparentYou are assuming they're saying that, because it's one charitable interpretation of what they're saying. But they haven't actually said that. It also happens that people say things based on faulty or disputed beliefs of their own, or people willfully misrprepresent things, etc Until they actually do say something as explicit as what you suggest, they haven't said anything of the sort. reply whimsicalism 10 hours agorootparent> Data will not leak across workspaces. For any model that will be used broadly across all of our customers, we do not build or train these models in such a way that they could learn, memorize, or be able to reproduce some part of Customer Data. I feel like that is explicitly what this is saying. reply zmmmmm 9 hours agorootparentThe problem is, it's really really hard to guarantee that. Yes if they only train say, classifiers, then the only thing that can leak is the classification outcome. But these things can be super subtle. Even a classifier could leak things if you can hack the context fed into it. They are really playing with fire here. reply BHSPitMonkey 3 hours agorootparentIf is also hard to guarantee that, in a multi-tenant application, users will never see other users' data due to causes like mistakes AuthZ logic, caching gone awry, or other unpredictable situations that come up in distributed systemsâ€”yet even before the AI craze we were all happy to use these SaaS products anyway. Maybe this class of vulnerability is indeed harder to tame than most, but third-party software has never been without risks. reply whimsicalism 9 hours agorootparentprevyes, i certainly agree with you. i think oftentimes these policies are written by non-technical people i'm not entirely convinced that classifiers and LLMs are disjoint to begin with reply btown 9 hours agorootparentprevThe OP privacy policy explicitly states that autocompletion algorithms are part of the scope. \"Our algorithm that picks from potential suggestions is trained globally on previously suggested and accepted completions.\" And this can leak: for instance, typing \"a good business partner for foobars is\" might not send that text upstream per se, but would be consulting a local model whose training data would have contained conversations that other Slack users are having about brands that provide foobars. How can Slack guarantee that the model won't incorporate proprietary insights on sourcing the best foobar producers into its choice of the next token? And sure, one could build an adversarial model that attempts to minimize this kind of leakage, but is Slack incentivized to create such a thing vs. just building an optimal autocomplete as quickly as possible? Even if it were just creating classifiers, similar leakages could occur there, albeit requiring more effort and time from attackers to extract actionable data. I can't blame Slack for wanting to improve their product, but I'd also encourage any users with proprietary conversations to encourage their admins to opt out as soon as possible. reply yorwba 1 hour agorootparent> How can Slack guarantee that the model won't incorporate proprietary insights on sourcing the best foobar producers into its choice of the next token? This is explained literally in the next sentence after the one you quoted: \"We protect data privacy by using rules to score the similarity between the typed text and suggestion in various ways, including only using the numerical scores and counts of past interactions in the algorithm.\" If all the global model sees is {similarity: 0.93, past_interactions: 6, recommendation_accepted: true} then there is no way to leak tokens, because not only are the tokens not part of the output, they're not even part of the input. But such a simple model could still be very useful for sorting the best autocomplete result to the top. reply whimsicalism 8 hours agorootparentprevyeah i absolutely agree that even classifiers can leak, and the autocorrect thing sounds like i was wrong about generative (it sounds like an n-gram setup?)... although they also say they don't train LLMs (what is an n-gram? still an LM, not large... i guess?) reply fallingsquirrel 10 hours agoparentprevThere are no data leaks in Ba Sing Se. reply next_xibalba 9 hours agoparentprevThis reminds me of a company called C3.ai which claims in its advertising to eliminate hallucations using any LLM. OpenAI, Mistral, and others at the forefront of this field can't manage this, but a wrapper can?? Hmm... reply BChass 9 hours agorootparentAh yes, the stock everyone believed in and thought it would reach the moon during 2020. reply oytis 2 hours agoprevSo much to \"if you are not paying you are the product\". There is nothing that can stop companies from using your sweet sweet data once give it them. reply ellisnguyen 1 hour agoprevCan we organize some sort of boycott somehow somewhere? Something in court possible? This is not just some analytics data or email names, this is potential leakage of secrets and private conversations for thousands of companies and millions of individuals. Ridiculous. reply prakhar897 5 hours agoprev> Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your org, workspace owners or primary owner contact our Customer Experience team at feedback@slack.com Sounds like an invitation for malicious compliance. Anyone can email them a huge text with workspace buried somewhere and they have to decipher it somehow. Example [Answer is Org-12-Wp]: \" FORMAL DIRECTIVE AND BINDING COVENANT WHEREAS, the Parties to this Formal Directive and Binding Covenant, to wit: [Your Name] (hereinafter referred to as \"Principal\") and [AI Company Name] (hereinafter referred to as \"Technological Partner\"), wish to enter into a binding agreement regarding certain parameters for the training of an artificial intelligence system; AND WHEREAS, the Principal maintains control and discretion over certain proprietary data repositories constituting segmented information habitats; AND WHEREAS, the Principal desires to exempt one such segmented information habitat, namely the combined loci identified as \"Org\", the region denoted as \"12\", and the territory designated \"Wp\", from inclusion in the training data utilized by the Technological Partner for machine learning purposes; NOW, THEREFORE, in consideration of the mutual covenants and promises contained herein, the receipt and sufficiency of which are hereby acknowledged, the Parties agree as follows: DEFINITIONS 1.1 \"Restricted Information Habitat\" shall refer to the proprietary data repository identified by the Principal as the conjoined loci of \"Org\", the region \"12\", and the territory \"Wp\". OBLIGATIONS OF TECHNOLOGICAL PARTNER 2.1 The Technological Partner shall implement all reasonably necessary technical and organizational measures to ensure that the Restricted Information Habitat, as defined herein, is excluded from any training data sets utilized for machine learning model development and/or refinement. 2.2 The Technological Partner shall maintain an auditable record of compliance with the provisions of this Formal Directive and Binding Covenant, said record being subject to inspection by the Principal upon reasonable notice. REMEDIES 3.1 In the event of a material breach... [Additional legalese] IN WITNESS WHEREOF, the Parties have executed this Formal Directive and Binding Covenant.\" reply frexs 2 hours agoprev> To develop AI/ML models, our systems analyse Customer Data (e.g. messages, content and files) submitted to Slack This Is Fine. reply musha68k 1 hour agoprevThis is as systemically concerning as the data practices seen on Discord with integrations like statbot.net, though at least Slack is being transparent about it. Regardless, I find all of this highly problematic. reply nutanc 6 hours agoprev> We offer Customers a choice around these practices. If you want to exclude your Customer Data from helping train Slack global models, you can opt out. If you opt out, Customer Data on your workspace will only be used to improve the experience on your own workspace and you will still enjoy all of the benefits of our globally trained AI/ML models without contributing to the underlying models. Sick and tired of these default opt in explicit opt out legalese. The default should be opt out. Just stop using my data. reply icoe 10 hours agoprevNot to be glib, but this why we built Tonic Textual (www.tonic.ai/textual). Itâ€™s both very challenging and very important to protect data in training workflows. We designed Textual to make it easy to both redact sensitive data and replace it with contextually relevant synthetic data. reply Ephil012 10 hours agoparentTo add on to this: I think it should be mentioned that Slack says they'll prevent data leakage across workspaces in their model, but don't explain how they do this. They don't seem to go into any detail about their data safeguards and how they're excluding sensitive info from training. Textual is good for this purpose since it redacts PII thus preventing it from being leaked by the trained model. Disclaimer: I work at Tonic reply a2128 7 hours agorootparentHow do you handle proprietary data being leaked? Sure you can easily detect and redact names and phone numbers and addresses, but without significant context it seems difficult to detect whether \"11 spices - mix with 2 cups of white flour ... 2/3 teaspoons of salt, 1/2 teaspoons of thyme [...]\" is just a normal public recipe or a trade secret kept closely guarded for 70 years reply theyinwhy 3 hours agoprevGood we moved to matrix already. I just hope they start putting more emphasis on Element X, which message handling is broken on iOS for weeks now. reply Arathorn 3 hours agoparentElement X is where all the effort is going, and should be working really well. How is msg handling broken? reply drcongo 8 minutes agorootparentNot the OP here, but I've tried really hard to use Element X and it crashes constantly. reply dfcarney 9 hours agoprevIn case this is helpful to anyone else, I opted out earlier today with an email to feedback@slack.com Subject: Slack Global Model opt-out request. Body: .slack.com Please opt the above Slack Workspace out of training of Slack Global Models. reply noman-land 9 hours agoparentMake sure you put a period at the end of the subject line. Their quoted text includes a period at the end. Please also scold them for behaving unethically and perhaps breaking the law. reply drcongo 7 minutes agorootparentThe period is outside the quotes though, are you suggesting we should have the quotes too? reply jgalt212 9 hours agorootparentprevWe just opted out. I told them our lawyers have been instructed to watch them like a hawk. reply dfcarney 9 hours agorootparentprevUpdated! reply chefandy 7 hours agoprevI wonder how many people that are really mad about these guys or SE using their professional output to train models thought commercial artists were just being whiny sore losers when Deviant Art, Adobe, OpenAI, Stability, et al did it to them. reply Liquix 7 hours agoparentsquarely in the former camp. there's something deeply abhorrent about creating a place that encourages people to share and build and collaborate, then turning around and using their creative output to put more money in shareholder pockets. i deleted my reddit and github accounts when they decided the millions of dollars per month they're receiving from their users wasn't enough. don't have the power to move our shop off slack but rest assured many will as a result of this announcement. reply chefandy 7 hours agorootparentYeah I haven't put a new codebease on GH in years. It's kind of a PITA hosting my own gitea server for personal projects but letting MS copy my work to help make my professional skillset less valuable is far less palatable. Companies doing this would make me much less angry if they used an opt-in model only for future data. I didn't have a crystal ball and I don't have a time machine, so I simply can't stop these companies from using my work for their gain. reply ugh123 4 hours agoprevWhatever the models used, or type of data within accounts this operates on, this clause would be red lined in most of the big customer accounts that have leverage during the sales/renewal process. Small to medium accounts will be supplying most of this data. reply jonnycomputer 8 hours agoprevThis is, once again, why I wanted us to go to self-hosted Mattermost instead of Slack. I recognize Slack is probably the better product (or mostly better), but you have to own your data. reply paulv 6 hours agoprevIt seems like we've entered an era where not only are you paying for software with money, you're also paying for software with your data, privacy implications be damned. I would love to see people picking f/oss instead. reply eggdaft 3 hours agoparentProblems with f/oss for business applications: 1. Great UX folks almost never work for free. So the UX of nearly all OSS is awful. 2. Great software comes from a close connection to users. When your software is an OS kernel that works just fine for programmers, but how many OSS folks want to spend their free time on zoom talking to hundreds of businesses and understanding their needs, so they can give them free software? See also: year of Linux desktop reply matt3210 9 hours agoprevConsent should be opt-in not opt-out. Yes means yes! reply noman-land 9 hours agoparentCan we start going a step further by demanding that consent must be opt-in and not opt-out? Requesting isn't good enough. reply mvkel 8 hours agoprev> we do not build or train these models in such a way that they could learn, memorise, or be able to reproduce some part of Customer Data They don't \"build\" them this way (whatever that means) but if training data is somehow leaked, they're off the hook because they didn't build it that way? reply awinter-py 8 hours agoprevif shitty TOS turns out to be the thing that bends the arc of history from AI to privacy, it would make me so happy reply barrenko 3 hours agoprev\"Interacting\" with HR is just going to get weirder, isn't it? reply jjgreen 11 hours agoprevâ€œBut look, you found the notice, didnâ€™t you?â€ â€œYes,â€ said Arthur, â€œyes I did. It was on display in the bottom of a locked filing cabinet stuck in a disused lavatory with a sign on the door saying â€˜Beware of the Leopard.â€ reply nomad-nigiri 10 hours agoprevIsnâ€™t Salesforceâ€™s primary value proposition trust? reply tbdfm 9 hours agoparentSalesforce's primary value proposition is that software quality doesn't matter. reply rank0 7 hours agoprevEven if salesforce has the purest intentions of following policy your data is still at risk. In real life policies have to be enforced and it's not always technically feasible to do so. It doesnâ€™t even have to be calculated or malicious! reply nxpnsv 2 hours agoprevHow do the self hosted alternatives compare? reply austinkhale 7 hours agoprevWow. I understand business models that are freemium but for a premium priced B2B product? This feels like an incredible rug pull. This changes things for me. reply jonnycomputer 8 hours agoprevIs this new? As in, when was this policy developed? reply mc110 1 hour agoparentFrom https://web.archive.org/web/20230101000000*/https://slack.co... it looks like they changed this sometime between 01-Apr-2023 and 18-Oct-2023 reply lopuhin 50 minutes agorootparentThen the date of 5th July 2023 looks likely as this is the date from which overall privacy policy is in effect: https://slack.com/intl/en-gb/trust/privacy/privacy-policy Interesting choice of date btw reply ramijames 10 hours agoprevI bet Discord is next. reply herpdyderp 9 hours agoparentI bet Discord is already doing it. reply BillFranklin 2 hours agoprevSlack has been using customer data for ML for years. Look at their search feature - it uses learning to rank, a machine learning approach that tracks content, clicks etc. It sounds like the worry is this overfit generative AI will spew out some private input verbatimâ€¦ which I can see happening honestly. Look at GitHub copilot, itâ€™s almost a copy paste machine. reply budududuroiu 9 hours agoprev> We offer customers a choice around these practices If youâ€™re so customer-first, and make it so easy to opt out, just make it opt-in instead. Oh wait, youâ€™re just a lying pathetic corpo reply hu3 9 hours agoparentSadly, even Firefox is using opt-out these days. I feel we're going downhill with regards to privacy. https://news.ycombinator.com/item?id=40355982 > What Firefoxâ€™s search data collection means for you > We understand that any new data collection might spark some questions. Simply put, this new method only categorizes the websites that show up in your searches â€” not the specifics of what youâ€™re personally looking up. > Sensitive topics, like searching for particular health care services, are categorized only under broad terms like health or society. Your search activities are handled with the same level of confidentiality as all other data regardless of any local laws surrounding certain health services. > Remember, you can always opt out of sending any technical or usage data to Firefox. Hereâ€™s a step-by-step guide on how to adjust your settings. We also donâ€™t collect category data when you use Private Browsing mode on Firefox. > As far as user experience goes, you wonâ€™t see any visible changes in your browsing. Our new approach to data will just enable us to better refine our product features and offerings in ways that matter to you. reply budududuroiu 9 hours agorootparentYeah these statements are always so benevolent, with the patronising undertone of â€œthis is for your own good, for a better experienceâ€. SMH reply lagniappe 8 hours agoprev> Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your Org or Workspace Owners or Primary Owner contact our Customer Experience team at feedback@slack.com with your Workspace/Org URL and the subject line â€œSlack Global model opt-out request.â€ We will process your request and respond once the opt out has been completed. This is not ok. We didn't have to reach out by email to sign up, this should be a toggle in the UI. This is deliberately high friction. reply persedes 9 hours agoprevcan't wait for someone to recreate the secret keys that were shared via slack using those models. reply IceHegel 7 hours agoprevCanceling my companyâ€™s slack as we speak. Not cool. reply CatWChainsaw 9 hours agoprevOpt-out and arbitration should both be illegal. reply morkalork 9 hours agoprevI pity the users who have to put up with an AI trained on my slack conversations Â¯\\_(ãƒ„)_/Â¯ reply jonnycomputer 8 hours agoprevIt should be opt-in. Not opt-out. reply gtirloni 7 hours agoprev> To develop AI/ML models, our systems analyze Customer Data (e.g. messages, content, and files) submitted to Slack as well as Other Information (including usage information) > We have technical controls in place to prevent access. When developing AI/ML models or otherwise analyzing Customer Data, Slack canâ€™t access the underlying content *> you want to exclude your Customer Data from helping train Slack global models, you can opt out. Yeah... reply kyleee 8 hours agoprevThis should be opt in reply blackeyeblitzar 10 hours agoprevI canâ€™t believe Slack added a bunch of AI features, without having admins opt into enabling them, and then put out a policy that requests that you send an email to have an opt out from your data being used for training. All of this should be opt-in and should respect the administratorâ€™s prerogative. Very irresponsible for Salesforce (parent company) and Iâ€™ll be reconsidering if we continue using them, if this is the low trust way in which they will operate. We donâ€™t have time to keep policing these things. reply paxys 10 hours agoparentI would suggest not getting your knowledge of the world from the titles of upvoted HN posts and instead do your own research. reply hehdhdjehehegwv 7 hours agoprevI long ago replaced Slack with Signal chat rooms. You can set an auto delete and itâ€™s all secure to start with. Also, free. reply curious_cat_163 7 hours agoprevThe nerve. reply willmadden 7 hours agoprevThey are breaking a lot of laws by doing this. There are plenty of regulated industries in healthcare and financial services using slack. reply ds 8 hours agoprevJust another read to mass delete your Slack DM's before you quit your job/move to another job. https://redact.dev (my startup) makes this easy. reply 11 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Slack prioritizes customer data protection in the context of machine learning and artificial intelligence, ensuring data confidentiality across workspaces.",
      "They implement technical controls to prevent unauthorized access and allow customers to opt out of data usage for training global models.",
      "Privacy-preserving techniques like channel recommendations and search results are executed while upholding confidentiality agreements outlined in customer agreements and the Privacy Policy."
    ],
    "commentSummary": [
      "Concerns arise over Slack's use of customer data for AI training without explicit consent, posing potential privacy risks like data leakage.",
      "Discussions include exploring self-hosted chat platforms as alternatives and debating the significance of opting out of such services.",
      "Users debate managing multiple communication tools, legal obligations on data consent, limitations of AI models, diverse training data, end-to-end encryption, and company privacy policies' reliability."
    ],
    "points": 517,
    "commentCount": 261,
    "retryCount": 0,
    "time": 1715897761
  },
  {
    "id": 40385536,
    "title": "Hands-on Course: Learn Rust with 100 Exercises",
    "originLink": "https://rust-exercises.com/",
    "originBody": "Welcome Welcome to \"100 Exercises To Learn Rust\"! This course will teach you Rust's core concepts, one exercise at a time. You'll learn about Rust's syntax, its type system, its standard library, and its ecosystem. We don't assume any prior knowledge of Rust, but we assume you know at least another programming language. We also don't assume any prior knowledge of systems programming or memory management. Those topics will be covered in the course. In other words, we'll be starting from scratch! You'll build up your Rust knowledge in small, manageable steps. By the end of the course, you will have solved ~100 exercises, enough to feel comfortable working on small to medium-sized Rust projects. Methodology This course is based on the \"learn by doing\" principle. It has been designed to be interactive and hands-on. Mainmatter developed this course to be delivered in a classroom setting, over 4 days: each attendee advances through the lessons at their own pace, with an experienced instructor providing guidance, answering questions and diving deeper into the topics as needed. If you're interested in attending one of our training sessions, or if you'd like to bring this course to your company, please get in touch. You can also follow the course on your own, but we recommend you find a friend or a mentor to help you along the way should you get stuck. You can also find solutions to all exercises in the solutions branch of the GitHub repository. Structure On the left side of the screen, you can see that the course is divided into sections. Each section introduces a new concept or feature of the Rust language. To verify your understanding, each section is paired with an exercise that you need to solve. You can find the exercises in the companion GitHub repository. Before starting the course, make sure to clone the repository to your local machine: # If you have an SSH key set up with GitHub git clone git@github.com:mainmatter/100-exercises-to-learn-rust.git # Otherwise, use the HTTPS URL: # # git clone https://github.com/mainmatter/100-exercises-to-learn-rust.git We also recommend you work on a branch, so you can easily track your progress and pull in updates from the main repository, if needed: cd 100-exercises-to-learn-rust git checkout -b my-solutions All exercises are located in the exercises folder. Each exercise is structured as a Rust package. The package contains the exercise itself, instructions on what to do (in src/lib.rs), and a test suite to automatically verify your solution. wr, the workshop runner To verify your solutions, we've provided a tool that will guide you through the course. It is the wr CLI (short for \"workshop runner\"). Install it with: cargo install --locked workshop-runner In a new terminal, navigate back to the top-level folder of the repository. Run the wr command to start the course: wr wr will verify the solution to the current exercise. Don't move on to the next section until you've solved the exercise for the current one. We recommend committing your solutions to Git as you progress through the course, so you can easily track your progress and \"restart\" from a known point if needed. Enjoy the course! References The exercise for this section is located in exercises/01_intro/00_welcome Author This course was written by Luca Palmieri, Principal Engineering Consultant at Mainmatter. Luca has been working with Rust since 2018, initially at TrueLayer and then at AWS. Luca is the author of \"Zero to Production in Rust\", the go-to resource for learning how to build backend applications in Rust. He is also the author and maintainer of a variety of open-source Rust projects, including cargo-chef, Pavex and wiremock.",
    "commentLink": "https://news.ycombinator.com/item?id=40385536",
    "commentBody": "Exercises to Learn Rust (rust-exercises.com)509 points by sebg 8 hours agohidepastfavorite95 comments sformisano 1 hour agoI skimmed through a few sections in which my rust knowledge is basic at best (threads). Really enjoy the no-nonsense, not-a-word-wasted style. My first thought after spending 30 minutes with this that it could easily become my new no. 1 recommendation for rust onboarding, toppling the zero2prod book. Then I figured out why this felt familiar, it's from the same author :D Will definitely dive into it this weekend. reply sk11001 39 minutes agoparentZero2prod doesn't really teach Rust, it's more about setting up an API for people who already know Rust. reply ramon156 20 minutes agorootparentAnd it also isn't 100% best-practise, more like all-practise. It tries to show any and every way you could approach a problem while somehow keeping it minimal. Really like it but if you follow the tutorial 1:1 you'll most likely get frustrated reply satvikpendem 4 hours agoprevSurprised no one has mentioned another great and similar resource called Rustlings [0] (yes very punny name). You are given some files with todo statements which you'll need to fix and make the code compile and pass all the tests. It's an interactive way to learn which is what got me through learning Rust a few years ago. [0] https://github.com/rust-lang/rustlings reply AnonC 3 hours agoparentThe difference is that Rustlings requires the person to already know Rust whereas the link on this post (100 Exercises to Learn Rust) starts teaching Rust from the basics (assuming that the person knows another language). reply LegionMammal978 3 hours agorootparentThat doesn't match with my experience: I learned the language from scratch just fine with Rustlings. (In fact, I found it more approachable than the Rust Book.) The first few groups of exercises in it walk you through the basic syntax and semantics, to the point that I found it almost tedious to work through, but I ultimately came to appreciate it. reply sshine 23 minutes agorootparentIn the most recent Rust Copenhagen Hack Night, half a dozen people took their first steps with Rustlings. It was my experience that it worked really well. Some people were speed-running it, others took their time to read the book references that came up once in a while. These 100 exercises build on the same interactive project format as Rustlings, so I would assume they're both great. reply archixe 3 hours agorootparentprevI did Rustlings without any knowledge of Rust and I thought it worked great. There are links to guide & documentation pages for every exercise. It worked great to learn the basics through practice. reply tialaramex 2 hours agorootparentprevTo me \"the basics\" means either no programming at all, or something rudimentary and half-remembered like you did simple Logo turtle graphic programming in math class as a ten year old and now you're thirty. Not \"knows another language\". I think it might be interesting to develop Rust-as-first-language teaching materials, but that's not what this is. Move assignment as your primary assignment semantic, borrowing as your metaphor rather than introducing the confusing idea of \"addresses\" (in Rust many things we can borrow don't have a meaningful address, but it's fine) and so on. reply LoganDark 1 hour agorootparent> I think it might be interesting to develop Rust-as-first-language teaching materials, but that's not what this is. Move assignment as your primary assignment semantic, borrowing as your metaphor rather than introducing the confusing idea of \"addresses\" (in Rust many things we can borrow don't have a meaningful address, but it's fine) and so on. I found that when learning Rust, it approximated the mental model that I had already developed for programming. Move semantics and such just felt right. I had used around 10â€“15 other programming languages by then, but none were even remotely Rust-like. I don't know why this is. It can't be that Rust is the objectively or even subjectively right way to think about programming. It has to be that its concepts were simply already intuitive to me, but I wonder why that is, when so many people struggle. Perhaps it's because of neurodivergence, maybe the language just matches the way I think in general and that's why it made sense so quickly. I'd probably make a terrible teacher, because I just do not understand the struggles people have with Rust, and I can't just teach someone to think the same way I do. Maybe when existing Rust users try to write material for new developers, they write in a way that, for lack of a better way of wording it, is only really accessible to their own neurotype. In other words, it doesn't really help the people that genuinely struggle with Rust's way of thinking, it primarily helps people who already have this way of thinking. reply tialaramex 27 minutes agorootparentCertainly in regards to say, ownership, Rust has to be very explicit about things which you'll find in the literature make sense for other languages but maybe are barely mentioned when they're taught. For example the life of objects is something Bjarne Stroustrup's early editions of his C++ book neglect, basically saying yeah objects come into existence and then they're later destroyed and it's only in the third edition once C++ has more powerful techniques for this stuff that suddenly it's important that C++ programmers care about this and there's IIRC a whole chapter of the book. It is also said that although Rust looks like a semicolon language, like C or Java or something, it's actually not like those semicolon language at all, it's an ML, the syntax makes it more palatable for semicolon programmers to learn and looks more \"serious\" for a systems language. As an ML, Rust gets a solid foundation in its type system. Rust has a type with no values, and a type with one value, Sum types and Product types, so we're on firm ground here, we can do type arithmetic. Languages like C++ struggle to have a type with one valueâ€ , and can't really do \"no values\" at all. It's like your system of arithmetic doesn't have zero. You can limp along, the Romans did, but it's an unenviable situation. â€  The C++ language isn't really sure how to handle these types properly because its rules say they need at least one byte of storage - but that entire byte is just padding. It's not insurmountable but it's very silly. Anyway, I think what you're feeling is more real than you've allowed for. This is concretely a better foundation, that's not an illusion. It's not perfect but the sense that this is how things should be makes sense compared to other popular languages. reply resonious 2 hours agorootparentprevI think Rust is close enough in syntax to C and Java so that just about any adept programmer can figure it out. reply leoedin 1 hour agorootparentClose in syntax maybe, but you need quite a different mental model to build complex programs. reply veidr 6 hours agoprevWorth noting that this set of exercises was created by the author of \"Zero to Production in Rust\", the well-reviewed book with the crab-in-a-human-skull cover[1]. [1]: https://www.zero2prod.com reply pjerem 3 hours agoparentOh nice ! I bought this book and forget to finish it for life reasons but it was really enjoyable. Bookâ€™s name doesnâ€™t lie , itâ€™s literally the author taking you by the hand along the path of building a real application with real problems on a real production environment explaining everything from the basics of the language to how to keep it online. The book is pretty opinionated (because well, since it guides you until production giving you basically all the code, choices are needed) but the author always takes the time to explain its choices and what the alternatives are. Iâ€™m feeling like I want to come back to this book. reply satvikpendem 4 hours agoparentprevAlso the same one who is making a new web server framework for Rust called Pavex, which is apparently pretty novel in how it works compared to others like Actix Web and Axum [0][1]. [0] https://www.lpalmieri.com/posts/a-taste-of-pavex-rust-web-fr... [1] https://blog.logrocket.com/using-pavex-rust-web-development/ reply bombela 3 hours agorootparent> Pavex is in beta, so you need to activate Pavex with an activation key: > You can retrieve an activation from the Pavex Discord serverâ€™s #activation channel after youâ€™ve joined the beta on Pavex.dev. reply LukeMathWalker 2 hours agorootparentOpen beta is coming! A few more months of polishing, and then I'll open the floodgates. reply bramhaag 3 hours agorootparentprevTo be fair, he did say it was \"pretty novel\"... reply worksonmine 2 hours agorootparentNitpick but a project can be finished and feature complete and still be \"pretty novel in how it works\". The solution is what's novel in that sentence. reply theonething 6 hours agoparentprev> crab-in-a-human-skull cover Anyone know the story behind this? reply LukeMathWalker 2 hours agorootparentAuthor here! To be fair, there is no particular backstory. I picked a hermit crab as the book logo since crabs are strongly associated with Rust due to Ferris, Rust's mascot. I then landed on that style (and the skull) because they looked sick and distinctive. The cover images of many technical books are incredibly dull these days. reply chongli 5 hours agorootparentprevRust community members are known Rustaceans which is a play on the word crustacean. Crabs are a well-known crustacean. Crab in a human skull is a visual metaphor for learning Rust. reply veidr 4 hours agorootparentprevI do not know the story, but I remembered the book because of that, and now after having mentioned it here, I just bought it. So my n=1 study indicates it was a successful design. :) reply jjice 5 hours agorootparentprevI got a Hamlet vibe from it when I picked the book up when it originally released. It could just be because it looks pretty sick though reply maxbond 4 hours agorootparentAlas, poor Yorick; I knew him well, Ferris. (Slightly more seriously, the project to replace the borrow checker was called Polonius[1], so it wouldn't be the first Hamlet reference in Rust land.) [1] https://github.com/rust-lang/polonius reply jonathankoren 2 hours agorootparentTo follow up that movie reference with the response in a different movie where that line is misquoted, â€œWhereâ€™d you hear that, a renaissance festival?â€ I havenâ€™t seen that movie a lot, but that scene (and really the entire movie) has been seared into my consciousness for 30 years. It was just the exact thing I wanted at that point in my life. reply rayxi271828 3 hours agoprevWonder if there's anyone who (1) is reasonably comfortable in some popular programming language(s) and (2) has gone through these exercises could/would share their take on how helpful/useful these are? Context: I've been doing Java professionally for 10+ years, Python, JS a few years ago, C++ way earlier in my career (early 2000s). reply hliyan 1 hour agoparentThis type of exercise doesn't quite help me. When I was learning Go, I couldn't find one that suited me, so I wrote one as I learned: https://github.com/hliyan/learn-golang/blob/master/day-01/he... For learning JS internals, I used this: https://johnresig.com/apps/learn/ reply eknkc 2 hours agoparentprevI canâ€™t get up to speed with rust using these kinds of material. Havenâ€™t looked deeply at this one in particular but they tend to teach you patterns and approaches. That works for a lot of languages. Got into zig pretty fast for example. You can start writing go in 2 days and even if you write shit code at first, it will run. But I canâ€™t get productive in rust and that kills my enthusiasm. reply dragonelite 3 hours agoparentprevI went through zigling variant i did about 90 of the 110 plus after reading the documentation of zig, it helped solidify some of the syntax and concepts. I think it does help reduce what might have been a 3 week process to a 1 week process during the evening learning. reply encody 6 hours agoprevI maintain a list of Rust tips and tricks for people who are looking to dig a bit deeper: https://geeklaunch.io/blog/rust-pro-tips-collection/ reply xanathar 3 hours agoparentCool list! I learned a lot of new things, kudos. One suggestion: where you talk about using AsRef, might be worth suggesting IntoIter, where it makes sense? IIRC that's what std uses for functions that aim at being generic over data structures and iterators (I might be remembering wrong, though). In any case let's not digress from the truth: amazing list. reply tialaramex 1 hour agorootparentThere are a few of these conversion traits (for turning some kind of Thing into a Thing with a different purpose) You're thinking of IntoIterator, which is a trait for when you want an Iterator, maybe what you've got is already an iterator, but maybe it isn't yet and yet it could easily be transformed into one (like say an array), so in either case IntoIterator::into_iter() gets you an iterator instead of whatever you have now -- the thing you had before is consumed by this. Another you may find uses for is ToString, which says this obviously could be a string and I want the string. Unlike IntoIterator this does not consume the thing you wanted a string for. There are also a suite of generic traits for converting to another type, From, Into, TryFrom and TryInto. As the person consuming things, prefer TryInto if you're clear what should happen when you can't, or Into if you need it to always work. As the person who is implementing the traits, prefer to implement From or if you can't TryFrom. Rust automatically cascades the conversions in one direction, so if I implemented From for Bird, and then you later write code which needs TryInto, that'll work just fine with a Goose using the code I wrote, because Rust concludes how to use my conversion to make it work, automatically - Rust will even be able to see that your \"What if I can't?\" error handling code will never run, and optimise it out of production code since I provided From so this cannot fail - its Error type is Infallible, an Empty type. reply woile 3 hours agoparentprevSomething like this in \"This week in Rust\" would be fantastic reply mgoetzke 4 hours agoparentprevGreat ! The first tip was already helpful, have to dig in. reply anssip 5 hours agoprevI blogged about my approach of learn by doing: https://anssipiirainen.com/post/learning-rust/ reply zerr 3 hours agoprevOne observation I have with Rust, looking at the code in wild, abstractions are usually (always?) leaky - implementation details are exposed/imposed due to the ownership feature of the language. reply pkolaczk 3 hours agoparentOwnership is not implementation. Ownership is contract. If youâ€™re an owner of a house you can do more than if youâ€™re only renting and if youâ€™re renting you can do more than if youâ€™re only looking at the house from the street. Ownership is a very useful concept that influences interfaces in real life so why wouldnâ€™t it in programming? reply flohofwoe 3 hours agorootparentThis reads like the Rust equivalent of the OOP 'animal/cat/dog' intros of yore. Real world comparisons are almost never all that helpful when it comes to computing concepts. reply pkolaczk 2 hours agorootparentOk, point taken, indeed it reads like that. However, in programming and generally in engineering this is a very useful concept. There is a difference between \"component X is part of Y\" than \"component X works / interacts with Y\" or \"component X has exclusive access to Y in this particular span\", similarly how it is often very important to know if \"component X can be safely shared\" - and Rust allows to express that, while languages like Java are quite blind to that. Consider a simple Java method signature: public static MyCustomFileReader open(FileHandle someFile) { ... } Who is responsible for closing the file after you're done with reading it? Does the returned reader close the file handle on close, or should I issue another close on the file handle afterwards? Can I open multiple readers on the same file? The only way to know is to check the javadoc comment, if someone took time to write it. In Rust there are no doubts like that. reply mejutoco 3 hours agoparentprevWithout more details it sounds like what you are saying is there are constraints due to the ownership model. That is not a leaky abstraction. You can also bypass some constraints, but need to be explicit about it. reply maxbond 3 hours agoparentprevCould you give an example? reply YossarianFrPrez 4 hours agoprevThis certainly looks great. I hate to be stickler, but on the very first page (\"Syntax\"), right after explaining comments, the text says \"In previous exercise, you saw the greeting function...\" Unless I'm missing something, this is the very first intro to Rust, and so there are no prior exercises... reply Jtsummers 3 hours agoparentYou did. Read all of the first page, they tell you where to find the first exercise. > The exercise for this section is located in exercises/01_intro/00_welcome reply xlbuttplug2 4 hours agoprevWhat do you folks normally do after learning a language like this? (Assuming you don't use it for your day job.) reply tialaramex 1 hour agoparentIf it's coming towards the end of the year, solve Advent of Code in the new language you learned. AoC scales gently. On day 1 if you can't see how to do it that's going to be because you didn't really understand your new language. By day 25 it's very likely that you can't figure out how to solve the problem yet in any language, if you're up for it, maybe solve it in your existing favourite and then try the new one. Because lots of people do AoC, especially in popular languages like Rust or C++, you can see other people's solutions in the AoC Reddit solutions thread each day, which are often inspiring -- you learn new idioms, library features, or even whole CS concepts. reply harishnavnit 4 hours agoparentprevI never got a proper chance to experience Rust at work but always wanted to give it a go. So I went through the Build your own Redis challenge by https://codecrafters.io. It was a a good excuse to get my hands dirty with all the different Rust concepts (with a bit of structure). reply cdperera 3 hours agoparentprevHighly specific, but in my operating systems course, we wrote a shell in C, it was very fun. I plan to write it again, but in Rust (mostly out of fun), extend it, make it my daily driver. reply luyu_wu 7 hours agoprevTo anyone who has done this and rustlings, how do you think they compare? I've been very happy with rustlings, but I'm curious if it's worth it to finish these too! reply mr-karan 5 hours agoprevThis is quite interesting! While we're on the topic, does anyone know of a similar set of exercises for learning Golang? reply sqkz 5 hours agoparentI would also highly recommend Go With Tests: https://quii.gitbook.io/learn-go-with-tests reply kuxv 4 hours agoparentprevhttps://exercism.org/ offers exercises for multiple languages including Go. reply hlfshell 5 hours agoparentprevGo by example is an established favorite. https://gobyexample.com/ reply ishaanbahal 2 hours agorootparentHave been using go for 8 years now, and started with this. And to be quite honest, I still refer to this sometimes for quick lookup on certain things related to syntax, pools, waitgroups or channels. Beautifully done tutorial of Golang, can be done in a few hours and gets you a good base knowledge of the language. To the creator, a sincere thank you! reply __loam 5 hours agorootparentprevI love go. Now to continue with modern systems languages, here's ziglings: https://codeberg.org/ziglings reply penguin_booze 3 hours agoprevIs it just I who get a 'site blocked due to security threat' message when visiting this site? reply squarefoot 2 hours agoprevObligatory reference to the Rosetta Code site which shows a good number of popular and less known problems with solutions in many programming languages. https://rosettacode.org/wiki/Rosetta_Code Edit: it seems the \"more...\" label down the 1st list to see all examples is broken. To explore the full list use this link instead: https://rosettacode.org/wiki/Category:Solutions_by_Programmi... reply SoKamil 2 hours agoprevDo you know similar sources for C? reply legends2k 1 hour agoparenthttps://exercism.io/tracks/c Exercism.io is not just limited to one language it has a track for most popular languages. I've used it a couple of times and can definitely recommend it. You get to compare your solution with other (top-rated) solutions and you also get mentorship at times (depending on availability I guess). reply _ank_it 5 hours agoprevIs there anything of this sort but for golang and python? reply knowaveragejoe 5 hours agoparentLook for \"python koans\". https://github.com/gregmalcolm/python_koans reply knowaveragejoe 5 hours agoprevExercises of this type are known as Koans, if I'm not mistaken. Look for \" koans\" for others. I have to say, this seems like a far more robust set of Koans than I've seen elsewhere! reply jimsimmons 4 hours agoprevExperienced Rust users: how do you rate this? What level of proficiency would this leave you with reply wonrax 2 hours agoparentI'm not very experienced, but by skimming the headings I can see that it covers almost all of Rust's core features. I'd say you're between a beginner and an intermediate Rust user if you complete the exercises and can be comfortable dealing with lifetimes. reply pelagicAustral 6 hours agoprevnext [12 more] [flagged] brink 6 hours agoparent> I do not understand why there are so many zealots around the language. Neither did I. But then I took the time to learn the language, and I understood what all the hype was about. Maybe you should too, instead of just whining about it. reply chainwax 6 hours agoparentprevBeing the first language to contest C++ in places like the kernal is a pretty big deal, no? It helps that the borrow checker is a new idea around being safe without gc. reply dehrmann 6 hours agorootparentIt is, but I see people using it in places where Java would be good enough. reply AlotOfReading 5 hours agorootparentJava is tremendously unfriendly to actually use. Sure, it's tolerable inside a corporate environment with established build/deployment systems, but there are few languages that make the \"build a random repo off GitHub\" hurdle higher than Java. reply drekipus 6 hours agorootparentprevBut then they'd have to learn java reply rgoulter 6 hours agoparentprev> Other than safety and the like. I think these are some good points: https://github.blog/2023-08-30-why-rust-is-the-most-admired-... On the one hand, \"safety\" avoids the \"use after free\" or other bugs which plague programs written in C. For systems programming, that is significant. On the other hand, the \"safety\" allows for much easier concurrency. The higher-level stuff like \"pattern matching\" is really nice. It's nice enough that it motivated efforts like https://github.com/borgo-lang/borgo Somewhat implicit is that Rust has enough of a community that there are many good packages/libraries and tools around it. reply Georgelemental 6 hours agoparentprevMany of us program for fun, and Rust is a joy to work with (especially compared to the alternatives in its niche), so we talk about it a lot. Of course, when you need to get serious work done, the most fun and enjoyable tool is not necessarily the one that's best suited to the job. reply klabb3 6 hours agoparentprevItâ€™s a mixed bag. Yes there is a lot of hipster fanboyism. But Iâ€™ve also seen a lot of old timers coming from a career in C++ where Rust basically formalizes a lot of best practices and removes a lot of the worst footguns. I see the hope in their miserable faces and so there is definitely something real about Rust â€“ and not necessarily Rust itself, but just the proof of concept of it, that itâ€™s possible to solve many of the problems low-level programmers have just accepted as fact-of-life for a long time. Me personally Iâ€™m not from that background, and coming from higher level languages the selling points are not nearly as compelling given the learning curve and less mature ecosystem around many things. For instance, language performance is rarely the limiting factor in say API/backend development. Usually you have networking, io and databases eating most of your lunch, and also horizontal scaling is typically already in place for other reasons. reply pama 6 hours agoparentprev> Other than safety and the like... This statement does a lot of work. Safety without compromise in speed on modern architectures is rather valuable. I dont think you understand the importance of that statement and why it is being used in the kernel. Depending on what you do, you may never need to code in rust (I dont) but dont underestimate how much humanity meeds that combination of safety and speed. reply AdamJacobMuller 6 hours agoparentprevI don't know rust, generally don't advocate writing things in rust but I find the people complaining about the people advocating for rust to be completely insufferable. People are talking about it because it's cool and new and shiny and they like it, you see it a lot because there's lots of people who find it cool and new and shiny. reply sophacles 6 hours agoparentprevWait... are you saying you have a problem with people liking a thing? That's kind of sad. reply sergiotapia 6 hours agoprevThis looks like a great resource! https://rust-exercises.com/03_ticket_v1/07_setters This shows why I wouldn't use Rust for anything. Seems like a lot of verbosity for gains that don't really apply whatsoever for the kind of work I do (web apps and APIs). You have to remember let/mut fine, but then ownership/borrowing, and finally this `into()` thing - yuck! Like washing your face with sandpaper. reply devjab 4 hours agoparentYou get ridiculous performance gains with Rust a web backend. Even Microsoft is rewriting part of their C# backend to Rust on the 365 application side of things. Which is where you get to deal with the hefty ms-graph api which handles literal fucktons of data. Anyway. It is more verbose than something like Go or Python. Iâ€™m not sure itâ€™s really so bad compared to most languages, but some of the benefits you get from the verbosity is that you gain a lot of control over how you use mutability and the borrow checker or how you work with memory in general. Things which are foreign to many developers today, but you shouldnâ€™t compare a Rust implementation to a C#/Java/Python/Ruby/Node/Go api, you should compare it to a c/c++ apiâ€¦ which is where Rust is just so much â€œsaferâ€ for production. We have Node APIs in Typescript, we have Python APIs with FastAPI, we have C# web APIs and we have a few Go APIs. Weâ€™re perfectly happy with those, well maybe not the fact that we use so many languages, but weâ€™re happy with them. Where we use Rust is where we used to use C, and the benefits are massive. You get the same sort of performance, but you also get an environment where programmers with less experience working without garbage collection can do work we just couldnâ€™t have them do with C. reply pkolaczk 3 hours agorootparent> It is more verbose than something like Go or Python Quite debatable. My experience is different. I have ported some tiny amount of Go code to async Rust and it turned out to be simpler and shorter. Way less boilerplate related to cleaning up the resources - in Rust it was actually zero additional code thanks to RAII and really nice channel design, while Golang needed a lot of additional stuff like waitgroups or manual defers plus more channels to communicate obvious things which in Rust are simply passed by result of a future. Rust also feels a lot more expressive than Go with functional collection transformation chains (map, reduce, filter, grouping etc) where in Go this is loops and ifs all the way down. Rust is very close to Python in this regard. reply pjmlp 4 hours agorootparentprevOffice team never was a big .NET fan, and they were partially responsible for Longhorn's failure, see also Hilo C++ tutorial made by the team as part of Vista SDK tutorials, or their love for Webwidgets to C++ code, so that isn't that surprising. It isn't as if C# vlatest wouldn't be able to take up the task, Bing, XBox game servers, and other large scale services are fully on .NET. reply tialaramex 4 minutes agorootparentBut like the Office services, these are all significantly older than Rust. Bing the branding is like 15 years old, the underlying service is older still (as \"Live Search\") So when this stuff was built the high performance option was C++ and there is an obvious reason to avoid that if you can. Rust means you can have the excellent performance without the absurd foot guns. Whether you chase that depends on other strategic priorities. reply simonask 2 hours agoparentprev`into()` just converts something from one type to another, like an integer to a floating point number. Would you have liked for such conversions to happen implicitly? Because let me tell you, that is one of the most painful features of C++, and modern well-written C++ typically disables implicit conversions in one way or another. (Note: For the specific example of integer-to-float, Rust has an alternative built-in syntax, but `.into()` is the canonical way that also works in generic code.) reply vrnvu 1 hour agoparentprevWell, nobody forces you to use the setters/getters pattern. For internal implementation, you could access everything directly. For example, Zig encourages this style of programming. In my experience in Rust, the use of getters and setters is less common compared to some other languages like Java. reply mrkeen 4 hours agoparentprevIt seems like Rust is doing a pretty good job of applying to web apps and APIs: https://www.techempower.com/benchmarks reply jamil7 5 hours agoparentprevThereâ€™s a world outside of web development. reply steveklabnik 5 hours agorootparentAlso, just because these examples are verbose doesn't mean that all Rust code is this way. Accessors/mutators aren't used super often in my experience, and the builder pattern is used occasionally, but isn't pervasive. (I have historically been very skeptical of Rust on the web, but by now, I find it pretty pleasant. I of course know Rust very well already though.) reply LukeMathWalker 53 minutes agorootparentAgreed. There's also another aspect at play: to build knowledge one step at a time with this learn-by-doing approach, you have to get learners to write code that's not perfectly idiomatic along the way. You then correct and refine those first drafts as you progress along. In the case of setters, we get rid of them at the end of that chapter by using the newtype pattern thus guaranteeing that field invariants can't be broken even if you can access them directly. reply littlestymaar 4 hours agorootparentprev> I of course know Rust very well already though Understatement of the week ;) reply jimbob45 5 hours agorootparentprevHe's right, though. Languages today shouldn't force you to jump through low-level hoops if you just want to write high-level logic. Likewise, the low-level devices should be easily and ergonomically accessible. Rust is phenomenal at the latter but weak at the former. reply amne 2 hours agorootparentBut who's forcing you? Oh .. the companies jumping on the latest \"in Rust\" hype. I see. Just do your thing and be good at it. PS: There was this VSCode extension to do BI stuff in the IDE (quarylabs/quary) showed here on HN and once I saw the CLI core having \"Rust-based\" as a feature I just closed the tab. What does \"Rust-based\" even mean? The tool may have been good but Rust is not a feature. reply pkolaczk 2 hours agorootparentprevCompared to most popular high level languages like Java or Go, Rust is seriously at the more expressive end (read: can be higher level). reply jamil7 4 hours agorootparentprevWhat languages scale better in that regard? Genuinely interested in recommendations. reply sergiotapia 5 hours agorootparentprevinteresting! reply komali2 6 hours agoprev [â€“] > To verify your solutions, we've provided a tool that will guide you through the course. It is the wr CLI (short for \"workshop runner\"). Install it with: > cargo install --locked workshop-runner I have no idea what this program / package manager is so I was going to throw my hands up and say great another mac-only tutorial, but apparently this is a package manager for rust, and also apparently it comes pre-installed on manjaro lol edit: I'm confused, on the home page I clicked \"next\" which takes me to this exercise: https://rust-exercises.com/01_intro/01_syntax but on that ostensibly \"first\" exercise they write: > The previous task doesn't even qualify as an exercise, but it already exposed you to quite a bit of Rust syntax. Let's review the key bits! And keep referring to some prior exercise, that I can't find anywhere. Is there an \"exercise 0\" hiding somewhere? reply Jtsummers 5 hours agoparent [â€“] > And keep referring to some prior exercise, that I can't find anywhere. Is there an \"exercise 0\" hiding somewhere? It's not hiding, they link to it. >> You can find the exercises in the companion GitHub repository. https://github.com/mainmatter/100-exercises-to-learn-rust And then they tell you to complete the exercises for each section before continuing and tell you exactly where the first exercise is: > The exercise for this section is located in exercises/01_intro/00_welcome Read the section titled \"Structure\" for all of this information. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "100 Exercises To Learn Rust\" is a practical course for beginners aiming to teach the fundamentals of the Rust programming language, such as syntax, type system, standard library, and ecosystem, through hands-on practice.",
      "The course offers around 100 exercises to help learners progressively enhance their understanding, following a \"learn by doing\" approach, suitable for both individual and classroom learning, with solutions provided on GitHub.\"",
      "Authored by Luca Palmieri, the course provides a structured curriculum with exercises in a companion repository and a workshop runner tool for verifying solutions, geared towards enabling learners to engage in small to medium-sized Rust projects.\""
    ],
    "commentSummary": [
      "The discussion evaluates different resources for learning Rust, including Rustlings and 100 Exercises to Learn Rust, focusing on accessibility, syntax, and challenges.",
      "It compares Rust's foundation in ML, type system, ownership model to languages like C and Java, sharing tips for mastering Rust and practicing Go and Zig.",
      "The conversation highlights Rust's benefits over C and C++, its use in web development, and Microsoft's incorporation of Rust for performance enhancements, emphasizing the accessibility and ease of use in programming languages like Rust."
    ],
    "points": 510,
    "commentCount": 95,
    "retryCount": 0,
    "time": 1715910793
  },
  {
    "id": 40378499,
    "title": "Llama 3 Model with NumPy Enhancements for Efficient Transformer Performance",
    "originLink": "https://docs.likejazz.com/llama3.np/",
    "originBody": "Llama 3 implemented in pure NumPy 16 May 2024 Understand the exact structure with working implementation of the Llama 3 model. May 16, 2024 Overview Structure RoPE #1 RMSNorm QKV RoPE #2 KV Cache GQA(Grouped-Query Attention) Scaled Dot-Product Attention Feed Forward SwiGLU Linear Generation Example GitHub References í•œê¸€ë¡œ ìž‘ì„±ëœ ìƒì„¸í•œ ì„¤ëª…ì€ NumPyë¡œ êµ¬í˜„í•˜ëŠ” ë¼ë§ˆ 3 ëª¨ë¸ì„ ì°¸ê³ í•˜ì„¸ìš”. [Korean Version] Overview Llama 3 model unveiled at Meta is creating a buzz. As expected, the scale and performance is overwhlming. 24K GPUs, 15T training data, 10M instruction data, 1.3M GPU hours, itâ€™s all overwhelming. One interesting fact is that the model structure hasnâ€™t changed. Of course, Llama 3 have changed to using GQA, but this was already implemented in Llama 2 70B, so itâ€™s practically the same model structure. Weâ€™ll let it run for an accurate implementation, and weâ€™ll use only NumPy to make the model structure more intuitive to understand. We use the stories15M model that Andrej Karpathy trained while creating llama.2, by converting it to a NumPy compressed format using a converter. We will actually read in the model that Karpathy trained with the Llama 2 structure and implement it as executable code. One thing to note is that the stories15M model does not use GQA, so while we implement GQA in our code but not apply it to model behavior. Structure Llama 3 model structure is exactly same with the 42dot LLM, so we import the illustration from the 42dot Blog, weâ€™ll get the following: The Model has the following parameters: # Model params for ./stories15M.model.npz dim: int = 288 # D n_layers: int = 6 n_heads: int = 6 # QHN, HN, HD = 48 n_kv_heads: Optional[int] = None # KVHN = 6 vocab_size: int = 32000 # VS max_seq_len: int = 256 # M max_new_tokens: int = 50 The designations D, HN, HD, VS, M etc. in the comments are ised to manage the shape of each variable in code. Also note that unlike the 24x in the model illustation, stories15M model has 6 layers, so it iterates 6x. RoPE #1 The first step is to precompute cos and sin for RoPE embedding. These values are later used by Q and K. This calculation only needs to be done once for every request, so it can be cached. The size is HD(48)//2, which is an exponential multiple of base(10000), so it can be a larger value, but the maximum value is never more than 1, so it is converted to a scaled value between 0 ~ 1, and then again to a value between \\(1 \\sim \\frac{1}{10000}\\). np.arange(0, 48, 2) # [24,] 1.0 / (base(10000) ** ([0, 2, ..., 44, 46] / 48)) = 1.0 / (base(10000) ** [0, 0.04166667, ..., 0.9166667, 0.958333344]) = 1.0 / [1, 1.4677993, ..., 4641.59, 6812.9194] = [1, 0.68129206, ..., 0.00021544, 0.00014678] The result of the calculation is np.outer multiplied by max_seq_len(256), and then cos and sin are calculated. # [256,] x [24,] = [256, 24] freqs = np.outer([0 ~ 255], [1, 0.68129206, ..., 0.00021544, 0.00014678]) self.freqs_cos: Array[\"M, HD//2\"] = np.cos(freqs) self.freqs_sin: Array[\"M, HD//2\"] = np.sin(freqs) The heatmap of cos and sin looks like this: The stories15M model is max_seq_len(256), but I think it could scale up to 8K if we utilize all values up to horizontal axis 24. RMSNorm RMSNorm normalizes activation values based on the Root Mean Square of the activation values, as opposed to using traditional Mini Batch or Layer statistics. This has the advantage of scaling activation consistently, regardless of Mini Batch size or Layer. Like other normalization techniques, it also has separate training parameters. 1 The formula implementation is as follows: z: Array[\"B, L or 1, 1\"] = (x ** 2).mean(-1, keepdims=True) + self.eps z: Array[\"B, L or 1, D\"] = x / np.sqrt(z) return z * self.weight QKV The way to calculate QKV is to matmul one weight in GPT and then split it, but Llama have their own weights for QKV, so we need to matmul them separately. Then, for Multi-Head Attention, we reshape each one to separate them by Multi-Head. # QKV xq: Array[\"B, L or 1, D\"] = x @ self.q_weight xk: Array[\"B, L or 1, D\"] = x @ self.k_weight xv: Array[\"B, L or 1, D\"] = x @ self.v_weight # [\"B, L or 1, D\"] -> [\"B, L or 1, QHN or KVHN, HD\"] xq: Array[\"B, L or 1, QHN, HD\"] = xq.reshape(B, L, self.n_local_heads, self.head_dim) xk: Array[\"B, L or 1, KVHN, HD\"] = xk.reshape(B, L, self.n_local_kv_heads, self.head_dim) xv: Array[\"B, L or 1, KVHN, HD\"] = xv.reshape(B, L, self.n_local_kv_heads, self.head_dim) RoPE #2 Now itâ€™s time to actually apply the RoPE using the values we calculated earlier. 2 RoPE is a new type of position encoding technique that has the characteristics of both absolute and relative, and performs well because it has the characteristics of both. It only applies to Q and K, dividing each input by the sum of its parts, then multiplying by cos and sin, adding and subtracting the results, and returning the sum back to reshape. xq_out_r: Array[\"B, L or 1, QHN, HD//2\"] = xq_r * freqs_cos - xq_i * freqs_sin xq_out_i: Array[\"B, L or 1, QHN, HD//2\"] = xq_r * freqs_sin + xq_i * freqs_cos xk_out_r: Array[\"B, L or 1, KVHN, HD//2\"] = xk_r * freqs_cos - xk_i * freqs_sin xk_out_i: Array[\"B, L or 1, KVHN, HD//2\"] = xk_r * freqs_sin + xk_i * freqs_cos xq_out: Array[\"B, L or 1, QHN, HD//2, 2\"] = np.stack([xq_out_r, xq_out_i], axis=-1) xk_out: Array[\"B, L or 1, KVHN, HD//2, 2\"] = np.stack([xk_out_r, xk_out_i], axis=-1) xq_out: Array[\"B, L or 1, QHN, HD\"] = xq_out.reshape(xq_out.shape[:-2] + (-1,)) xk_out: Array[\"B, L or 1, KVHN, HD\"] = xk_out.reshape(xk_out.shape[:-2] + (-1,)) RoPE are applied after the Q and K have been multiplied by the weights in the attention mechanism, while in the vanilla transformer theyâ€™re applied before. KV Cache 3 Since the GPT-style generative model is Masked Attention, it is possible to KV Cache. Since the previous result will always be the same, regardless of what comes after it, since we are not allowed to see the next word, we can cache K and V, and Q only needs to compute the last value. The cache is held by max_seq_len(256), so the result of the calculation is put in and then extracted back to the only current length. # KV Cache self.cache_k[:B, start_pos: start_pos + L] = xk self.cache_v[:B, start_pos: start_pos + L] = xv ks: Array[\"B, L, KVHN, HD\"] = self.cache_k[:B, : start_pos + L] vs: Array[\"B, L, KVHN, HD\"] = self.cache_v[:B, : start_pos + L] # (1, 256, 6, 48) -> (1, 5, 6, 48) # GQA xk: Array[\"B, L, HN, HD\"] = repeat_kv(ks, self.n_rep) xv: Array[\"B, L, HN, HD\"] = repeat_kv(vs, self.n_rep) xq: Array[\"B, HN, L or 1, HD\"] = xq.transpose(0, 2, 1, 3) xk: Array[\"B, HN, L, HD\"] = xk.transpose(0, 2, 1, 3) xv: Array[\"B, HN, L, HD\"] = xv.transpose(0, 2, 1, 3) Here, we fetch the cache values and then transpose them back to reshape them, but this could be done more efficiently by skipping this step. For reference, the maximum size of the KV Cache is \\(1 \\times 256 \\times 6 \\times 48 \\times 2 \\times 6 = 884K\\) on batch size 1. Since it is a 15M model, it takes up about 6% more memory. GQA(Grouped-Query Attention) 4 MQA, which is a Multi-query, has the advantage of being compact and memory-saving compared to MHA, which is a Multi-head, but it suffers from poor performance and unstable learning. Therefore, Grouped-query, GQA, was introduced in Llama 2. In Llama 2, GQA was only applied to 70B, but from Llama 3, GQA was applied to all models above 8B. Since we are using a model that was trained without GQA, we do not use GQA, but we have implemented it in the code. We have implemented it by simply copying it by a multiple, and it can be improved by referencing the previous value for future optimization. We have avoided using GQA when n_rep==1. if n_rep == 1: return x z: Array[\"B, L, QHN, HD\"] = np.repeat(x, n_rep, axis=2) Scaled Dot-Product Attention Attentions are calculated separately by Multi-Head. \\(Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V\\) # Scaled Dot-Product Attention # [\"B, HN, L or 1, HD\"] @ [\"B, HN, HD, L\"] -> [\"B, HN, L or 1, L\"] attention: Array[\"B, HN, L or 1, L\"] = xq @ xk.transpose(0, 1, 3, 2) / math.sqrt(self.head_dim) # `mask` is used only once at the beginning. if mask is not None: attention = attention + mask[None, None, :, :] attention = softmax(attention) output: Array[\"B, HN, L or 1, HD\"] = attention @ xv Masking is only done at the beginning and only the last Q needs to be processed afterward, so no masking is needed. The result can then be obtained with softmax and matmul. Finally, the result of the Multi-Head calculation is reshaped to full dimension to combine the heads and matmul once more. # [\"B, HN, L or 1, HD\"] -> [\"B, L or 1, D\"] output: Array[\"B, L or 1, D\"] = output.transpose(0, 2, 1, 3).reshape(B, L, -1) output: Array[\"B, L or 1, D\"] = output @ self.o_weight Computing the entire QKV at once is only done in the Prefill Phase. At this time, TTFT (Time To First Token) is called Prefill Latency, and only â€˜vector @ matrixâ€™ operations need to be performed from the Decode Phase onward. Flash Attention is also effective only when reducing the Prefill Latency during inference, and it performs somewhat well when the input is long. Feed Forward In Llama model, Feed Forward uses 3 linear with matmul only and no bias, so unlike GPT, it is not a complete fully-connected layer. We create a swish value from the silu result, multiply it with x_V up-scaled from D to FD, and down-scale it again. Here, the size of FD is FD = 2 * 4 * D / 3, which is D(288), so FD(768). swish: Array[\"B, L or 1, FD\"] = silu(x @ self.gate_weight) x_V: Array[\"B, L or 1, FD\"] = x @ self.up_weight x: Array[\"B, L or 1, FD\"] = swish * x_V x: Array[\"B, L or 1, D\"] = x @ self.down_weight SwiGLU In the paper, the SwiGLU formula looks like this: 1 Multiplying x_V with swish and matmul it with W_2 is called SwiGLU. This unique combination of multiple feed forwards layers increases the performance of the model. Let x be a real number between approximately \\(-14 \\sim 11\\), which is the input to the silu function. The silu implementation is as follows: x * (1 / (1 + np.exp(-x))) Linear After passing through all the transformer blocks, the final output is only the last logit computed by matmul to speed things up. The transformer block always outputs [\"1, D\"] as the result after the Prefill Phase. # [\"B, 1, VS\"] = [\"B, 1(L), D\"] @ [\"D, VS\"] logit: Array[\"B, 1, VS\"] = h[:, [-1], :] @ self.lm_head_weight Generation Now, we generate tokens one after the other using the extracted logit. For simplicity, weâ€™ve omitted sampling from the generation process and only output the Greedy result. for i, curr_pos in enumerate(range(L, max_new_tokens)): if i == 0: # Prefill Phase inputs = input_ids pos = 0 else: # Decode Phase inputs = next_id pos = curr_pos logits: Array[\"B, 1, VS\"] = self(inputs, pos) next_id = logits[:, -1, :].argmax(-1, keepdims=True) yield next_id The first step is Prefill Phase, or sometimes called Summarization. It passes all input and starts at position 0. This is also where Flash Attention comes into play. From then on, it is the Decode Phase and thanks to the KV Cache, only the last token ID is passed to Q and the result is the also last logit. Here, we omit sampling and only extract the maximum value. If you want to add a sampling process, you can take softmax and implement top_p and top_k. You can now yield the token ID we generated as a result, decode it in the next step and print the output token to finalize the process. Example You can run it like this: $ python llama3.py \"I have a dream\" \"\"\" I have a dream. He dream of a big, beautiful garden full of flower and tree. He dream of playing with hi friend and eating yummy snack. One day, he wa walking in the garden when he saw Token count: 50, elapsed: 1.53s, 33 tokens/s \"\"\" Karpathy has trained the model to a certain extent, and the result is that model is not performing badly. It ran at 33 tokens/s on an M2 MacBook Air. GitHub The full source code is available at likejazz/llama3.np. References https://medium.com/@vi.ai_/exploring-and-building-the-llama-3-architecture-a-deep-dive-into-components-coding-and-43d4097cfbbb â†© â†©2 https://mathworld.wolfram.com/RotationMatrix.html â†© https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/ â†© https://arxiv.org/abs/2305.13245 â†©",
    "commentLink": "https://news.ycombinator.com/item?id=40378499",
    "commentBody": "Llama 3 implemented in pure NumPy (likejazz.com)418 points by orixilus 20 hours agohidepastfavorite48 comments ffriend 14 hours agoIt's also worth mentioning that the original implementation by Meta is only 300 lines of very readable code [1]. [1]: https://github.com/meta-llama/llama3/blob/main/llama/model.p... reply hongspike 5 hours agoparentThe numpy code can seem more accessible and easy to understand. Torch can look scary even though it's similar to numpy. reply ebb_earl_co 11 hours agoparentprevOn line 59, there is a less-than-or-equals comparison between 0 and 1. Curious https://github.com/meta-llama/llama3/blob/main/llama/model.p... reply bloaf 10 hours agorootparentI am a reasonably competent python coder, yet when I see stuff like this I regard it with the same suspicion as a switch in the \"more magic\" position. https://www.catb.org/jargon/html/magic-story.html reply danielheath 10 hours agorootparentprevWhat's the operator precedence in python? Is it `assert(0All models support sequence length up to 8192 tokens, but we pre-allocate the cache according to max_seq_len and max_batch_size values. So set those according to your hardware. [0] https://github.com/meta-llama/llama3/tree/14aab0428d3ec3a959... reply blharr 13 hours agoparentprevSo is this the case that the information is in the data set? Or the code is very well defined to be so small? As an outsider it's surprising that such a capable model can be so \"simple\". reply jacobn 12 hours agorootparentThe training code is presumably quite a bit more complex than what they've open sourced, but part of the beauty of the GPT-based LLMs is their structural simplicity. Now, that simplicity can be deceiving - there are a lot of conceptual interconnectedness within these models. They've been put together \"just so\" if you will. If you look at the source code to nanoGPT and compare it to Llama3, the most remarkable thing (when you look past the superficial name changes) is just how similar they are. If I recall correctly the primary differences are: - The MLP: Llama3 uses SwiGLU vs the more \"traditional\" x = x + proj(gelu(expand(x))) in GPT2 - The token encoders, which is arguably external to the model - Attention: Llama3 uses Grouped Query Attention, vs full Multi-Head Attention in GPT2 - Normalization: Llama3 uses RMSNorm, vs LayerNorm for GPT2 They were published more than five years apart. On the one hand progress has been breathtaking, truly astounding. On the other hand, it's almost exactly the same model. Goes to show just how much is in the training data. reply novaRom 3 hours agorootparent> beauty of the GPT-based LLMs is their structural simplicity human brain's structure is also encoded in a short DNA sequence reply jacobn 7 hours agorootparentprevForgot one: the positional encoding also changed, llama3 uses RoPE, gpt2 uses a learned embedding. reply moritzwarhier 12 hours agorootparentprevI think with LLMs in general, the algorithms are very refined and require lots of research, despite being \"simple\" in terms of entropy, or an imagined Kolgomorov complexity for defining algorithms. So \"simple\" is a fuzzy term here, but yes, the entropic complexity is in the data, not the algorithms. Related to the so-called \"Bitter lesson\". Edit: the sister comment pointed out what I failed to express: RILHF and training are also algorithms, and their applications and implementations are probably much more complex than the code that evaluates a given prompt. So basically, \"models\" (trained NNs) are also an example for the equivalence of code and data. Fixed data used by code (the trained model) is code in itself, even when it is not directly written by humans or in a human-readable language. Edit edit: don't forget to count the imported maths code :) but I assume this is not relevant to the \"it's just matrix multiplications\" overall argument reply SpaceManNabs 12 hours agorootparentprev300 lines of this code is a bit different than 300 lines of typical code where you read files, set up a backend/frontend, or parse data. In the latter case, there are a lot of tedious operations. Sure, the former also has that with reshaping and asserts or wtv. But in a sense, the 300 lines of Llama code are essentially just lines of math. And reading through any math proof will show you that any particular line can hide large amounts of complexity. This can be true with code with more tedious operations, but those lines are a smaller fraction of the overall code base by definition. Even the \"tedious\" parts of the llama code can hide large complexity. Setting a learning rate with a schedule might require reading a paper or two for your particular architecture. But yes, once you parse all the math and the theory, the lines are kinda simple matmul and forward lol. reply ffriend 10 hours agorootparentSure, knowing the basics of LLM math is necessary. But it's also _enough_ to know this math to fully grasp the code. There are only 4 concepts - attention, feed-forward net, RMS-normalization and rotary embeddings - organized into a clear structure. Now compare it to the Hugginface implementation [1]. In addition to the aforementioned concepts, you need to understand the hierarchy of `PreTrainedModel`s, 3 types of attention, 3 types of rotary embeddings, HF's definition of attention mask (which is not the same as mask you read about in transformer tutorials), several types of cache class, dozens of flags to control things like output format or serialization, etc. It's not that Meta's implementation is good and HF's implementation is bad - they pursue different goals in their own optimal way. But if you just want to learn how the model works, Meta's code base is great. [1]: https://github.com/huggingface/transformers/blob/main/src/tr... reply kureikain 11 hours agoparentprevDo you know why these are so short? What is the algorithm/magic in all of these? I tried to make sense of it but cannot reply Hugsun 11 hours agorootparentArchitecturally, LLMs are very simple compared to many software projects. The crux of their behavior comes from their learned weights which are gigabytes and can cost millions to obtain via training. reply DavidSJ 11 hours agorootparentprevThe magic is in the billions of learned weights (~synapses). This is just the scaffolding that runs them. reply chpatrick 10 hours agorootparentprevThe magic is the structure of the model, and the real magic is the billions of weights. reply blt 13 hours agoparentprevthe simplicity of the transformer is quite refreshing. especially in vision where the Vision Transformer with linear patch encodings replaces complex intertwined decisions about filter size, striding, pooling, #filters, depth, etc., with the simpler decision of how to allocate your FLOPS between dimensionality, #heads, and #layers. reply joennlae 17 hours agoprevTrainable Llama-like transformer (with backpropagation) in numpy only (~600 lines) https://github.com/joennlae/tensorli reply Zambyte 9 hours agoparentThe description says GPT-like, but is is just a GPT, right? reply p1esk 8 hours agorootparentGPT refers to the specific family of models developed at OpenAI. reply Zambyte 7 hours agorootparentIt also stands for generative pretrained transformer, which this seems to be. reply p1esk 6 hours agorootparentItâ€™s like saying SSD is a YOLO. Both are single shot object detectors, but only YOLO is â€œa YOLOâ€. reply buildbot 16 hours agoprevCool, instant cuda acceleration via cupy! `import cupy as np` reply rhdunn 15 hours agoprevFrom the TinyStories dataset card [1] the dataset is generated by GPT-3.5 and GPT-4. Reading the discussions in the community tab [2] it looks like there are a lot of incomplete or misspelled words, incorrect grammar, and even Chinese characters in the dataset. As such, I'd be weary of using that dataset to train or evaluate models. [1] https://huggingface.co/datasets/roneneldan/TinyStories [2] https://huggingface.co/datasets/roneneldan/TinyStories/discu... reply nwoli 15 hours agoparentItâ€™s just used for checking that the implementation is correct. The dataset is just a toy dataset it doesnâ€™t matter if it has misspelled words reply lnyan 17 hours agoprev`import jax.numpy as np`, then we also get a jax implemention after certain modifications: e.g. remove in-place index assignment, replace unsupported functions, etc reply ffriend 14 hours agoparentJAX requires a bit more work to maintain fixed-size buffers as required by XLA, especially in case of caching and rotary embeddings. But yeah, overall the code can be pretty similar [1]. [1]: https://github.com/dfdx/fabrique/blob/main/fabrique/llama/mo... reply cl3misch 16 hours agoparentprev...which should be much faster also on CPU, I assume. reply AI_hacker 15 hours agoprevHow does the performance of llama3.np compare to other implementations, especially considering it's a pure NumPy implementation? reply dang 12 hours agoprevWe changed the URL from https://github.com/likejazz/llama3.np to the article it points to, which gives more background. reply johndough 18 hours agoprevWhat is the difference to the llama.np repository credited in the README? https://github.com/hscspring/llama.np reply aeyes 17 hours agoparentWell, it supports Llama3. But the other question I have is about the license. The tokenizer.py file is identical, and the rest is very similar - just making minor adjustments here and there. Can they just take this Apache 2 licensed code, change it a bit and offer it as MIT? They are clearly not the original author. reply Scaevolus 17 hours agorootparentUnfortunately, licenses are only worth as much as your lawyers. reply yjftsjthsd-h 17 hours agorootparentDMCA takedowns are free. reply not2b 14 hours agorootparentA less aggressive approach would be to file an issue and let the maintainer correct the license issue. reply threatripper 3 hours agoprev> np.sin(freqs) Didn't we drop 2 pi somewhere? reply kolinko 18 hours agoprevObligatory Recmoâ€™s Llama1 implementation in numpy :) https://github.com/recmo/cria reply Scene_Cast2 18 hours agoprevThe rotary embeddings bit is neat. I wonder if a complex representation would simplify vs complexify things (readability, performance, expressive power). reply johndough 18 hours agoparentSome implementations use a complex rotary encoding, but it makes it a bit harder to port to platforms or frameworks which do not support complex numbers natively. reply 6gvONxR4sf7o 17 hours agoparentprevThe tensor cores that do the bulk of the flops on the bulk of the gpus people use are just various sizes of floats, i think. We're in a funny position where progress in models and progress in hardware are kind of linked. As far as expressive power goes, it shouldn't make a difference for the models in common use, but I could totally imagine models where it improves readability. reply xchip 16 hours agoprevNice but the tricky part is the training data. reply swader999 12 hours agoparentThe tricky part is getting big enough that no one can successfully sue you for using \"your\" training data. reply whereismyacc 14 hours agoparentprevthere are a lot of tricky parts. reply ulam2 18 hours agoprev [â€“] I'll consider superintelligence achieved if AI can do such work faithfully. reply sebzim4500 18 hours agoparent [â€“] What? Lots of people could produce this repo, it hardly counts as superintelligence. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Llama 3 model, developed in NumPy in 2024, integrates GQA and RoPE #1 to enhance performance.",
      "It leverages RoPE and KV Cache within a transformer model to boost efficiency, reaching 33 tokens/s on an M2 MacBook Air.",
      "The model's source code, trained by Karpathy, is accessible on GitHub for in-depth exploration of the architecture and optimization methods."
    ],
    "commentSummary": [
      "The focus is on implementing Llama 3 in pure NumPy, showcasing its simplicity in contrast to frameworks like Torch.",
      "The code is praised for its clarity and simplicity, drawing comparisons to other models such as GPT2 and emphasizing the significance of learned weights in Llama 3.",
      "The discussion covers technical nuances, comparisons to different implementations, licensing issues, and the hurdles in training data for AI models."
    ],
    "points": 418,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1715867602
  },
  {
    "id": 40378791,
    "title": "Exploring Data Visualizations with D3: Versions 6 & 7",
    "originLink": "https://www.d3indepth.com/",
    "originBody": "D3 in Depth D3 in Depth covers versions 6 and 7 of D3 Home About Newsletter BOOKS & COURSES Visualising Data with JavaScript teaches you how to build charts, dashboards and data stories using Chart.js, Leaflet, D3 and React. Find out more \"One of the best D3 books I've read. The contents are very clear, it is easy to follow and the concepts are very solid.\" Javier GarcÃ­a FernÃ¡ndez Learn how to make a custom data visualisation using D3.js. Find out more Learn the fundamentals of HTML, SVG, CSS and JavaScript for building data visualisations on the web. Find out more CONTENTS Introduction to D3 Getting Started Selections Data joins Enter, exit & update Scale functions Shapes Axes Hierarchies Chord Diagrams Force layout Maps Data Requests Transitions Picking, Dragging and Brushing Zoom & pan NEWSLETTER Get book discounts and receive D3.js related news and tips. Subscribe Learn D3.js from the ground up Â© Peter Cook 2023",
    "commentLink": "https://news.ycombinator.com/item?id=40378791",
    "commentBody": "D3 in Depth (d3indepth.com)316 points by lobo_tuerto 19 hours agohidepastfavorite73 comments sbarre 18 hours agoIf you like the idea of using D3 for data visualization but you want something a bit higher level, check out Observable Plot[1], a library by the D3 team that adds a lot of conventions and conveniences on top of D3, specifically for building plots, charts and graphs. And even beyond that, there's Observable Framework[2], a static site generator for building visualization dashboards (that supports Plot, D3 and lots of other libraries). 1: https://observablehq.com/plot/ 2: https://observablehq.com/framework/ reply jo-m 13 hours agoparentObservable Plot is amazing. It is very flexible and intuitive to use. I now prefer it over Plotly.js which I used to use before. The docs are pretty OK, the only thing missing is a usable API reference section, so discoverability is not great. reply forrestthewoods 14 hours agoparentprev> but you want something a bit higher level These days I kinda want the opposite. Most of the time I know exactly what I want my output to look like. But frameworks inherently provide a large bag of presets and if you want something slightly different from the preset it's a pain in the ass. For many types of plots I find it's actually kinda easier to just manipulate SVG data directly. It's not that hard! I'd like to see a library/framework that focuses on making it easier to manipulate SVG or canvas output. It should be trivial to make tweaks. But the higher level a framework goes the harder it is to step off the golden path. reply contravariant 13 hours agorootparentWhy does d3 not work for you if you just want to manipulate the svg directly? You can use it to generate or update arbitrary xml as far as I know. reply zdragnar 13 hours agorootparentThe higher level in this case is observable plot, not d3. reply sbarre 13 hours agorootparentprevYeah I hear you, if you know exactly what you want, Plot is probably not for you.. But I've found lots of value in using Plot to explore data, and quickly throw something together and look at it, and decide if it's a good way to present the data or not. Although I will say that you can \"drop down\" to the SVG pretty easily with Plot. Lots of examples even on their site where they start with Plot marks and then heavily customize the SVG directly. reply cess11 13 hours agorootparentprevHave you tried p5js? reply screye 14 hours agoparentprevDoes the website feel janky to anyone else ? I have routinely found content-rich webpages to be janky. edit: nvm, turned on hardware acceleration. Smoother, but still jankier than I'd like on a Ryzen 9. reply gaws 17 hours agoparentprevPlot and Framework are locked into the Observable ecosystem, which has its own learning curve. Learning D3 offers the best flexibility and control. reply mbostock 17 hours agorootparentIn what way are these free open-source tools â€œlocked-inâ€ to Observable? Observable Plot is a vanilla JavaScript library that is released under the ISC license and can be used with any style of web development (e.g., React, Svelte, whatever). And likewise Observable Framework is released under the ISC license and youâ€™re able to self-host projects anywhere and develop locally? reply navaed01 8 hours agorootparentMike, thank you for D3. Itâ€™s had a huge impact on me personally. reply toasted-subs 14 hours agorootparentprevCan you add the library as a html link. Anything else would be unwise to invest time in learning. reply ghostly_s 13 hours agorootparentYes? Examples here: https://observablehq.com/plot/getting-started reply simonw 16 hours agorootparentprevPlot isn't locked into the Observable ecosystem at all - it's a JavaScript library that you can use independently of everything else there. reply sbarre 13 hours agorootparentprevI'll ignore the part where you're wrong about the lock-in, but to the rest of what you said... Yes? I guess I didn't think it needed to be said so explicitly, but if you are opting into Plot and Framework, you are accepting convention over configuration as they say. And for some situations, that is what you want. If you value flexibility and control above all else, then I agree they may not be for you. But if you value other things, like speed of iteration, or just getting some good data visualizations built without a deep investment in learning underlying concepts, then Plot and/or Framework have definite advantages over doing it all with D3. reply bilekas 15 hours agorootparentprevYeah, I can say from experience of D3 at least, it's very far from locked in. In fact I would ask what library you're thinking of could be less. The community also has helped with some bizarre integrations I was trying to do, into libraries like highcharts for strange reasons etc. reply jeffbee 17 hours agorootparentprevThis is like saying that a computer without an operating system offers the best flexibility, or that a pile of sand is more flexible than an assembled computer. reply locallost 16 hours agorootparentD3 is not an empty computer. It's a high level library built in a high level language that runs in a browser. You are very very very far away from \"metal\". Being able to do something in a few clicks or little typing is nice until you need to do something more complicated. Sometimes it's worth actually learning how something basically works. Sometimes it isn't, it's everybody's choice. reply wisemang 16 hours agorootparentSo D3 is not what Iâ€™d consider a high-level library. The point of it is to be able to do all kinds of stuff not supported by your average charting solutionâ€™s out of the box histograms and whatnot. Itâ€™s a great way to make more bespoke visualizations. Of course sometimes you just want to make a damn histogram without reinventing the wheel which is where some of the niceties discussed above come in. reply locallost 13 hours agorootparentD3 runs in the browser and it manipulates DOM nodes, a very high level abstraction. You can accomplish something with it using SVG, which is again a high level abstraction. You can give it data and it will spit out numbers that you can use to draw something on the screen. You can bind that data to elements and it will keep track of what's entering and what's exiting. You can apply fancy transitions with a line of code! You can make it change an appearance of e.g. a graph by changing the interpolation method. And so on. Sure you have to write code, but it does a lot of things in the background that would take you s lot longer to do yourself. High level is not just \"here's a library on top of D3 that you just give data to and you're done, but then you have to cry for days because you need to do something it didn't think of - 80% of use cases\". When I used it I didn't get it, but then I took some time, a couple days, to actually understand it and I got a lot more productive. It's a great feeling when instead of thinking in workarounds for a missing configuration option you can think in solutions for the actual task. A lot quicker and more rewarding. I didn't do much computer graphics in my life, some mandatory university classes, but I'd say doing it on the simplest beginner level it was a much different experience. reply wisemang 11 hours agorootparentFair enough. I meant specifically in the context of data visualization libraries, having done a fair bit of that sort of work in my own career. Itâ€™s harder to make a basic chart in d3, compared to many out of the box solutions, but itâ€™s possible to do pretty much whatever you want, thanks to (what I consider) the low-ish level of abstraction it provides. I.e. DOM manipulation vs direct specification of standard chart attributes. reply addicted 13 hours agorootparentprevD3 is low level for doing what it does. Visualizing data. Itâ€™s hard to think of a lower level abstraction for that purpose. reply __MatrixMan__ 15 hours agorootparentprevI've used D3 in nodejs to generate a png. Is it really that different than using something like Python or Java to do the same? reply dingclancy 3 hours agorootparentI might have confused your point, but if your goal is to build charts for data analysis, or exploratory data analysis, then D3 is considered low-level for the purpose of getting to the analysis fast. reply toasted-subs 14 hours agoparentprevAs much as I hate to even ask for but is there a Matlab like drag and drop interface for web visualization. I try to avoid graphs with html5 canvas like the plague maybe a new way to design them would be nice. reply hervature 5 hours agorootparentSounds like you want Tableau. It even comes with the same price tag as Matlab! reply treflop 17 hours agoprevI like d3 and have built a lot of things in it but every time I go back to it after not using it for a few years, I can never remember much, the docs just confuse me more, and I feel like Iâ€™m back at square one. Whereas you could show me some partial differential equations to solve that I havenâ€™t touched in 10 years and that somehow comes back quicker. But I also think the d3 reference docs are absolutely horrible too. reply hantusk 13 hours agoparentI also have written a lot d3, between versions 2 and 7, and the refactoring that has happened meant a lot of examples online that were hard to comprehend were even harder to update. I feel like its more stable now though. Something clicks for me since ive started writing it in more imperative style with svelte+d3 rather than d3 alone. The generated elements are easier for me to reason about, rather than otherwise relying on inspecting the generated elements with dev-tools after the generation. This site was helpful to me, to combine d3 and svelte: https://svelte.recipes/ reply PaulHoule 17 hours agoparentprevI feel it is that way much less than other plotting libs. Maybe 80% of what I do is applications, 10% systems and 10% data analysis. Often I will spend two weeks making Jupyter notebooks and then not look at it for two months. I find most plotting libs have a lot of arbitrary things to remember, they usually have several nano DSLs (strings that get interpreted in ways more complex than atoi.). On top of that most plotting libs have something wrong from my point of view in various areas like deciding the range of the axes or handling huge numbers of points or something. D3 makes you do a lot yourself but the interfaces it provides to do that are conceptually straightforward. Instead of using someone elseâ€™s bloated and buggy general purpose code though an APi that feels like assembling a ship in a bottle you can just do it right with D3.js. reply treflop 16 hours agorootparentI agree and I think thatâ€™s why I end up re-learning d3 over and over. But having to do it yourself is a lot of work so you have to make an executive decision between shoehorning some plotting library that canâ€™t do a chart feature that honestly should be supported versus building an entire chart from scratch. reply lucisferre 17 hours agoparentprevI have used D3 extensively to the point of building integrations for AngularJS and Angular for it. I have always found it to be exceptionally unintuitive even if it is quite powerful. It is easy to get wrong, hard to debug and hard to grok. Not saying this is an easy problem to solve either. If I needed to generate some very specific data driven graphics it would probably still be my go to. reply groggo 11 hours agorootparentSo happy to read this in a few different comments. I took a data-viz class in college and just felt stupid because d3 didn't click for me. reply gedy 17 hours agorootparentprevYes same, and I'm curious of what mental modal it uses as it does not register with me, who otherwise has no problem programming. reply asdman123 17 hours agorootparentAs far as I remember it is inspired by the Grammar of Graphics, as is ggplot2 in the R ecosystem: https://link.springer.com/book/10.1007/0-387-28695-0 For me it also always had this moment when it â€žclickedâ€œ just to disappear after not using it for a couple of months. reply ethbr1 16 hours agorootparentSounds like it's based on a good model for the problem space, but a model that's alien to other day-to-day ones. Which is an interesting problem! Is it better to optimally model ones problem space? Or suboptimally model it, but create a model that's closer to developer/user expectations? reply ska 15 hours agoparentprev> hereas you could show me some partial differential equations to solve that I havenâ€™t touched in 10 years and that somehow comes back quicker. The HCI (human calculation interface) for calculus has been lovingly polished for many, many generations. A quick read over Newtons original texts will quickly reveal that wasn't always so. It seems unfair to hold an API to the standard, really. reply qwertox 14 hours agorootparentHappens to me as well, with the exception of the equation thing. reply vvpan 17 hours agoparentprevI have had the same experience. As a tech lead these days I insist that nobody uses libraries that require a high level of domain knowledge. Basically code that is incomprehensible even for the person that wrote it should be avoided as hard as possible. D3 is a prime example of such a library. reply locallost 16 hours agoparentprevI only did one bigger project with D3 and had the same experience! I was thinking about the same thing before I read your post. Not really sure why, but when I was doing it regularly it felt smooth, but now I can't remember anything. reply uxcolumbo 17 hours agoparentprevWhich other library would you recommend? reply treflop 16 hours agorootparentI havenâ€™t found anything else that comes close and thatâ€™s why I haze myself over and over. reply solatic 18 hours agoprevEven if you never end up using it professionally, I think it's worth it to learn D3. The core point that the library makes is that your projection of the data (say, a 1080p screen, 1920x1080) is always different from the dimensions of the data itself (say, grading from 0-100). At some point you need to decide how to scale the data (0-100) so that it draws correctly according to the projection (1920x1080). You can do the math yourself, or you can use a library like D3 to do the math for you. Even if you don't draw data on the web, you'll probably eventually draw data somewhere, and you'll be glad to look for an equivalent in that ecosystem. reply codetrotter 18 hours agoparentOne of the first things I ever programmed in PHP, of my own creation was a binomial distribution graph png generator. Pretty sure I had to scale the rectangles I was drawing for the graph according to the dimensions of the png I was making. It was of course very trivial, and nothing like the amazing things D3 can do. But it was a neat experience, making something of my own for very first time that produced an image on the computer. reply groggo 11 hours agoparentprevThat's a good way of framing the core concept. D3 was never intuitive for me. Maybe the problem is that it tries to do too much, at too many different level of abstraction? If it's just about projecting data, that's easy enough to understand. But I guess projection is also closely tied to axis and other pieces. reply stared 15 hours agoprevI've been in love with D3.js and have used it as the key technology for dozens of data visualization projects, both commercial and personal. However, its rendering syntax now feels dated, reminiscent of the jQuery era. While I still use various auxiliary functions (e.g., for ease or scaling), I now create actual components in a modern framework (in my case, Vue 3 and TypeScript). Despite this shift, I am grateful to D3.js for the beautiful years it gave me and for teaching me various good practices in data visualization. The defaults and demos by Mike Bostock have been both an inspiration and an example of good standards, aligned with Tufte's minimalism. reply pj84 2 hours agoparentI am very interested in this, do you have any examples for vue3 and typescript + d3 auxiliary functions? Thanks! reply hajile 18 hours agoprevLearn D3 then (assuming you're doing something chart-like as most of us are) move to something like VisX or some non-React equivalent and never look back. I view D3 and jQuery as being somewhat similar and both are very prone to spaghetti. Something like VisX adds a lot of structure over the D3 you're using to keep things sane. reply laurels-marts 17 hours agoparentIâ€™ve been using D3 on and off for quite some time. Iâ€™m just starting now with react and visx definitely looks very promising as it bridges the gap nicely. Do you find it limiting though (like you have to fight the tool) to achieve something more custom vs. using plain D3? reply hajile 13 hours agorootparentVisX starts with low-level primitive components that match very closely to D3 primitives. It then builds some chart primitives on top of those and then builds some charts on top of that. You can build pretty much anything using the lowest-level primitives and still have a better developer experience than D3 IMO. If you don't need any real customizability (and know you won't need it in the future), I'd stick with something with something less customizable, but faster to setup. If you know you need custom, take the 10-20% more time to setup and be able to change in the future as that'll be faster than porting your charts over. reply 8organicbits 3 hours agoprevI really like the force directed graphs in the d3 examples but I've found that they often settle in poor configurations as the nodes and edges grow. I wonder if I need a 3d visualization at higher scale? Maybe someone else has experience with these. Here's a recent example I built: https://alexsci.com/rss-blogroll-network/ reply williamcotton 15 hours agoprevD3 is inspired by the Grammar of Graphics by Wilkinson. Another tool also inspired by GG is aptly named ggplot2 and for the R language. It offers a much more terse and functional inspired interface that also works well with an uncommon tool named Rush, R one-liners for the Shell, for quickly creating graphics from CSVs piped into the tool. reply wegwerfaccount 2 hours agoprevFor a split second I hoped this one would be about Diablo 3. reply wbeckler 16 hours agoprevI've heard great things about Vega [1], which sits on top of D3. It's a dependency of OpenSearch Dashboards, allowing users to create custom dashboards on log and observability data [2]. The vega library might alleviate some of the concerns others are expressing about the learnability of D3. [1] https://vega.github.io/vega/docs/ [2] https://opensearch.org/docs/latest/dashboards/visualize/vega... reply blackhaj7 17 hours agoprevThis was the only resource that made D3 make sense for me. The author is responsive and helpful too. reply breadwinner 13 hours agoprevD3 is a terrific toolkit. The fact that it is a low-level toolkit means you have to write more code, but on the other hand, you have more power. One of the negatives of D3 is that D3 charts are not responsive by default. Whether the chart fills the screen, or fills a small area in a dashboard, the grid lines are spaced the same and fonts are the same size. You can add responsiveness manually. It would be nice if a future version was responsive out of the box. reply bilater 16 hours agoprevI love the visualizations created but something about D3 syntax has just never clicked for me. It seems overly convoluted, verbose and from an old era. We've thankfully moved to a more declarative way of doing things. reply laurels-marts 16 hours agoparentD3 is from jQuery era so there are a lot of methods for manually manipulating the DOM like d3.select() and then selection.attr() etc. but those patterns tend to lead to components that are lengthy, hard to read and hard to maintain. Arguably a better approach is to group each D3 module based on whether it \"modifies DOM\" or \"doesn't modify DOM\". Then use React/Svelte to declaratively render the DOM and only use the D3 modules from the latter group for their math utilities. reply math_dandy 6 hours agorootparentThis exists, itâ€™s called visx, and itâ€™s great. https://airbnb.io/visx reply dang 7 hours agoprevRelated: D3 in Depth - https://news.ycombinator.com/item?id=16844250 - April 2018 (52 comments) reply darknavi 17 hours agoprevI just picked up D3 + React for a VS Code webview project. Pretty easy to pick up but I find jumping in with examples very black box (as someone who doesn't have a ton of web experience). That plus going from JS to TS had some quirks that I didn't realize when in JS land. I could really use a \"start from the basics\" tutorial. I will say Github Copilot has been excellent at helping me with random TS errors when porting my graphs from JS to TS. It's nice how typed D3 can be when you finally opt into it. reply amelius 12 hours agoprevCan anyone recommend a good plotting library for Python, that is not matplotlib? reply HereBeBeasties 12 hours agoparenthttps://opensource.com/article/20/4/plot-data-python gives some common options. What kind of plots are you trying to achieve? Interactive? Jupyter notebooks? Reporting? SVG or HTML output? You might also like to look at things like https://evidence.dev reply tompark 12 hours agoparentprevVega/Vega-lite has a python interface called Altair. I haven't used Altair but I wanted something higher level than D3 (which I've used but it feels fairly low level) so I went through the learning curve for Vega.js, and it could handle every usecase that I tried, some of which were pretty complex. reply jeramey 5 hours agoparentprevSeaborn isnâ€™t too bad. Itâ€™s basically a convenience wrapper over top of matplotlib. reply PaulHoule 17 hours agoprevD3 is the first visualization toolkit that I really liked. reply javajosh 15 hours agoprevThe real problem with D3 is that, as a library, it doesn't really do visualizations. It gives you functions and exmaples to compose your own visualizations, whose key requirement is an expert-level understanding of JavaScript (particularly closures and functional programming). What mbostock says is the core \"abstraction\" of D3, the select and select diffing, is only an affordance for writing reentrant \"paint()\", with the flourish that your paint statements are expressed as builder statements, which themselves are scoped to select and can be broken up for various effects. Especially in animated examples, D3 does suprisingly little for you, as it's up to you to write the outer loop and track state over time. Nor does D3 give you any abstraction for encapsulating a visualization, as a function or otherwise. This is left as an exercise for the reader. All of this comes as a big surprise, or shock, to the new D3 user. It would be like adopting a new database and finding only a library for file IO and BTree indices and query optimizers, that you need to wire up yourself. reply math_dandy 6 hours agoparentCheck out visx. It should really be called D4: Declarative Data Driven Documents. It swaps out d3-select (the DOM manipulation module of D3) in favor of React. That this is possible and works great is a testament to the great design of D3. reply stared 14 hours agoparentprevWell, D3 is not a set of tools for charts (alike matplotlib, ggplot or so), but a low-level library to create your data visualization from scratch. Depending on your goal, it may or may not be what you need. reply lloydatkinson 16 hours agoprevI keep searching for entirely not-web based diagramming/charting solutions. That can be driven via CLI or using some library, and output SVG or PNG. All of these things usually depend on browser functionality or use some janky as fuck SSR solution using a headless browser to generate them server side. Of particular note, Iâ€™d also like to be able to programmatically generate Venn diagrams. It seems there is, bizarrely, a complete dearth of anything in this space. A couple of JavaScript chart libraries support them, but generally speaking there seems to be hardly any support for them. gnuplot seems good - just no Venn diagram support. reply pphysch 17 hours agoprevD3 has an unnecessarily non-intuitive API design, and I think that kills it for a lot of people. For example, why must a data join be performed like `selection.data(array).join(element-type)` instead of something like `selection.join(element-type, array)`. Looking from a pure API-design perspective, not getting bogged down in the technical details. Lazy eval method chaining is a natural fit for applying+branching large amounts of HTML/CSS state updates but I feel that the designers took it a bit too far with the core D3 operations. reply hantusk 13 hours agoparentI don't think it was for the technical fit or performance reasons, but more a philosophy about everything starts with data, and graphics are just visualizations anchored to the data points (or a functionally derived property of the data points). That also means the d3-* libraries compose really well, since the data is the common binding, and not some conceptual class or custom element. reply nhggfu 18 hours agoprev [3 more] [flagged] zem 18 hours agoparentit's literally a javascript library, so I don't understand your complaint here. of course the book and d3 itself are not going to do you much good if you don't know the language it uses! reply dvsfish 18 hours agoparentprev [â€“] D3 is great if you want to dynamically visualise data in your webpage. Maybe a bit niche but I wouldn't write it off this cheaply. I say this regardless of your js prowess - it is quite accessible. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"D3 in Depth\" delves into D3 versions 6 and 7, guiding users in crafting data visualizations employing Chart.js, Leaflet, and React.",
      "The book explores HTML, SVG, CSS, and JavaScript basics, covering selections, data joins, scale functions, and maps, offering insights into developing bespoke visualizations with D3.js.",
      "Regarded positively for its lucid explanations and strong foundational principles, the book is well-received by reviewers."
    ],
    "commentSummary": [
      "Users discuss Observable Plot, a D3 team's library, on the D3 in Depth website for simplifying plot and graph creation, highlighting D3's complexity in contrast with its flexibility.",
      "Alternative tools such as Tableau, VisX, and Python plotting libraries are suggested for comparison, with some users appreciating D3's ability to dynamically visualize data on webpages.",
      "Despite its challenges, D3 is recognized as a powerful and valuable tool for creating accurate data representations."
    ],
    "points": 316,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1715869087
  },
  {
    "id": 40383029,
    "title": "Winamp Opens Source Code for Worldwide Collaboration",
    "originLink": "https://about.winamp.com/press/article/winamp-open-source-code",
    "originBody": "About What's new? Learn Press Contact Winamp â€¢ Dec 16, 1 â€¢ Press Release Winamp has announced that it is opening up its source code to enable collaborative development of its legendary player for Windows. Winamp has announced that on 24 September 2024, the application's source code will be open to developers worldwide. Winamp will open up its code for the player used on Windows, enabling the entire community to participate in its development. This is an invitation to global collaboration, where developers worldwide can contribute their expertise, ideas, and passion to help this iconic software evolve. Winamp has become much more than just a music player. It embodies a unique digital culture, aesthetic, and user experience. With this initiative to open the source code, Winamp is taking the next step in its history, allowing its users to contribute directly to improving the product. \"This is a decision that will delight millions of users around the world. Our focus will be on new mobile players and other platforms. We will be releasing a new mobile player at the beginning of July. Still, we don't want to forget the tens of millions of users who use the software on Windows and will benefit from thousands of developers' experience and creativity. Winamp will remain the owner of the software and will decide on the innovations made in the official version,\" explains Alexandre Saboundjian, CEO of Winamp. Interested developers can now make themselves known at the following address: about.winamp.com/free-llama Share on: Download Subscribe to our newsletter Get the best content for creators delivered to your inbox every week. Â© 2024 Winamp Get the app Windows 5.9.2 Helpful links About What's new? Learn Press Contact Legal Legal Notice Privacy Policy Specific Terms of Use General Terms of Use Cookies Policy Follow us",
    "commentLink": "https://news.ycombinator.com/item?id=40383029",
    "commentBody": "Winamp has announced that it is \"opening up\" its source code (winamp.com)298 points by captbaritone 13 hours agohidepastfavorite147 comments ndiddy 11 hours agoSome context: Winamp's owners have been going through financial difficulties since last year and as a result have laid off the skeleton crew they previously had maintaining Winamp (their main focus seems to be a streaming service also called Winamp for HTML5 and phones). This looks like they're willing to let the community take over maintenance for PC Winamp, which beats letting it die IMO. https://forums.winamp.com/forum/winamp/winamp-site-design/46... reply peppertree 11 hours agoparentStill waiting on KaZaA open source. Kids these days don't know what it's like trying to download a music video and end up watching someone getting beheaded. reply zztop44 10 hours agorootparentIâ€™m pretty sure kids these days do know exactly what thatâ€™s like (although they wouldnâ€™t be downloading the music video and it wouldnâ€™t have taken over an hour for a shitty 2.3mb file) reply giancarlostoro 10 hours agorootparentprevOr downloading Windows XP.ISO and booting up Ubuntu. 15 year old me was confused and enraged. reply nehal3m 9 hours agorootparentDenial, anger, bargaining, depression, l33tness. reply sexy_seedbox 9 hours agorootparentSo br00tal reply wrigby 10 hours agorootparentprevI realize this is a joke, but canâ€™t resist mentioning that LimeWire was (is?) open source (or at least used an open network in GnuTella) reply mrmincent 7 hours agorootparentAnd funnily enough, gnutella being a creation of Justin Frankel, the creator of Winamp as well. reply RevEng 11 hours agoparentprevI really appreciate them doing this. I wish more companies would release their source - even as is - if they are dissolving the corporation anyway. reply larodi 10 hours agoparentprevWhy does a company has to go bankrupt to open source? Itâ€™s like something that owners want to do in order to be able to fork, not something that is being done for the community or open side of it. reply cortesoft 10 hours agorootparentWell, their business model was selling the softwareâ€¦ it is harder to do that if it is open source. Once you are going bankrupt, you are going to lose the asset anyway, so there is no incentive to keep it closed source. Is it really that hard to figure out why a company open sources when going bankrupt? reply talldatethrow 9 hours agorootparentWouldn't the lenders be pissed you essentially gave away one of the valuable assets they could have sold off to someone else? reply Uehreka 9 hours agorootparentprevI just got here from the â€œDoJ moves to legalize weedâ€ comment section, and I have the same thing to say: I donâ€™t care why people do a good thing, Iâ€™m uncomplicatedly happy it happened. reply testernews 9 hours agoparentprevthat explains why i had such a terrible fucking time with their â€œcreatorâ€ side, was supposed to have a rep, help setting up, promotion, etc and they didnâ€™t do fuck all for a year and then tried to charge me for it a year later reply LocutusOfBorges 12 hours agoprevTwenty years too late for it to possibly matter, but it's still nice to see. Interesting that there's no mention of what licence the source is being released under - and it's only available following email enquiries, of all things. I'm surprised they're even bothering, at this point - the software's so obsolete that it's not like it has much in the way of value anymore beyond nostalgia. reply bcraven 12 hours agoparentI use the community update of Winamp, WACUP, and it's excellent. I've tried other media players but always come back here. I'm not even one of those people who likes the shitty visualisations, I just think the interface works perfectly. https://getwacup.com/ reply xtracto 8 hours agorootparentI love QMMP ( https://qmmp.ylsoftware.com/ ). It is compatible with Winamp Skins, supports network playing (shoutcast) and works pretty well in my Linux Mint installations. I may be old fashioned, but man my brain has got so much \"muscle memory\" on years and years of Winamp use during the 90s ... I cannot live without stuff like equalizers, visualization plugins, Last.FM scrobbing and even automated track \"ripping\" of radio stations. It makes me so sad the state of current audio players like YouTube Music, Spotify, Tidal and the likes. featurewise they are so... bland. Millenials and GenZs just don't enjoy music the same way I used to enjoy it. Maybe it is because there so much of it now that it doesn't matter so much reply QuercusMax 12 hours agorootparentprevIt's windows-only? Weird. reply stuaxo 12 hours agorootparentIt's Windows only for now. The architecture of Winamp is made of various plugins. WACUP is replacing them bit by bit. Once everything is replaced then porting could be possible, though it's been only built for Windows so there must be a lot of Windows-isms in there. reply Dwedit 11 hours agorootparentprevThere have been Linux-based clones of Winamp for a long time, such as XMMS (which directly supports Winamp skins). reply gunapologist99 9 hours agorootparentXMMS is the O.G. but audacious and Qmmp now also support classic winamp skins. reply Lammy 12 hours agorootparentprevWeird? It's Winamp lol reply m00x 12 hours agorootparentWho's gonna build TempleAmp? reply aleph_minus_one 10 hours agorootparentMusic does not sound good on a PC speaker. reply Dwedit 10 hours agorootparentThere are DOS-based MOD and MP3 players that output to the PC speaker. reply xnx 12 hours agorootparentprevWith the source code someone can port it to make Linamp. reply maximilianburke 11 hours agorootparentThere once was xmms reply JohnTHaller 11 hours agorootparentQmmp is still being developed: https://qmmp.ylsoftware.com/ reply kbenson 11 hours agorootparentprevBefore that it was called x11amp, and after that it's been succeeded by a fork that ended up being Audacious, apparently. reply callwhendone 12 hours agorootparentprevdon't forget Macamp. reply nathell 11 hours agorootparentRemember that before Winamp, there was DOSamp! I used to use version 0.8. Playback was jerky on a 486DX2/66 but once I upgraded to a Pentium, it was smooth sailing. reply Lammy 10 hours agorootparentprevActually yeah I had forgotten about that alpha version awkwardly called â€œWinamp:Macâ€ because â€œMacAMPâ€ was already taken by not-Nullsoft https://macintoshgarden.org/apps/winampmac https://macintoshgarden.org/apps/macamp-10-preview-edition And the Android version which I used briefly around 2010 before getting into Subsonic/D-Sub https://forums.winamp.com/forum/winamp/winamp-for-android/29... reply kbenson 11 hours agorootparentprevYeah, if you want something similar for other systems, try x11amp. (Yes I know it's not called that anymore and I'm showing my age). reply babypuncher 11 hours agorootparentprevHave you checked out foobar2000? To me, it always felt like the true successor to Winamp. reply koito17 11 hours agorootparentfoobar2000 has been my go-to player on both Windows and Mac for about a decade now. Particularly, I like the dense (yet uncluttered) interface and functionality I take for granted, like selecting a dozen files and editing metadata all at once. A few of my friends complain that the layout \"sucks\" or foobar lacks functionality they need, but for my use case, it's in a Goldilocks state. With that said, for people used to the functionality of Winamp, I think MusicBee is more likely to be the successor, in terms of out-of-the-box functionality and layout extensibility. reply Scene_Cast2 11 hours agorootparentI find it amusing that modern foobar2k theming is based around Javascript. reply babypuncher 11 hours agorootparentprev> A few of my friends complain that the layout \"sucks\" or foobar lacks functionality they need, but for my use case, I see these complaints too, and I find them funny. The layout is what you make of it. I don't care for any of the layout presets presented in the \"Quick Appearance Setup\" dialog, but the default UI component is very easy to customize almost any way you want. There's even a scratchbox feature that lets you experiment with building a whole UI from scratch without messing with your current layout. As for the functionality they find it lacks, well, there's probably a component for that. Frankly I find foobar2000 comes with a ton of functionality out of the box that other media players don't have, like the very robust features found in the \"Tagging\" and \"File Operations\" context menu entries. reply zem 10 hours agorootparentto be fair, it's a lot easier to tell if you do or do not like something than it is to design something you do like. I run into that with vim colorschemes all the time reply leeoniya 11 hours agorootparentprevyou'd have a hard time replicating this UI [1] or other winamp skins in foobar2000, so i'm not sure i'd call it a successor except in the sense that it can play anything you throw at it. [1] https://getwacup.com/screenshots/ reply babypuncher 11 hours agorootparentI consider it a successor in that it's compact with an emphasis on user customization and community-designed plugins/components. Like Winamp, most functionality you get out of the box is provided by bundled plugins, and they can be replaced with alternatives. Out of the box, you could certainly customize it to have a similar layout to winamp even if none of the dressing looks at all the same. My layout[1] is certainly very different than Winamp, but still conforms a lot more to the basic shape of Winamp than the usual giant screen-filling squares that are iTunes, Windows Media Player or the Spotify desktop client. 1. https://i.postimg.cc/R0JzVTK8/image.png reply cageface 9 hours agorootparentprevI'm working on my own cross platform music player that I think has a more polished interface than foobar. I have mac builds now and will start doing windows builds soon: https://plastaq.com/minimoon reply spacechild1 4 hours agorootparentprevfoobar2000 is great! I love the minimal (default) UI. Never even bothered to customize. reply dvngnt_ 9 hours agorootparentprevmusicbee is my favorite reply pessimizer 12 hours agorootparentprevThey seem to be just as cagey about the licensing. Not that there's any obligation for people to be FOSS if they want to give software away, but the intentional avoidance of the question is always instructive. Just say that it's not FOSS, it's fine. > Will it be free ? > Yes WACUP will be free to download & to use. > This is an independent project & due to the amount of time & effort which is involved, I am accepting donations (and other means of support) to help cover my living costs whilst I'm working on getting this developed & released. As at this time, this is a full-time project for me whilst I see where the future will take me & this project. reply TulliusCicero 11 hours agoparentprevLiterally just yesterday I was staring at Winamp's basic visualizer because I was trying to make something similar in my Godot game. I'm still not sure exactly what I'm missing, as I have the \"gist\" of the visualizer working, but it just doesn't look as smooth as Winamp's. I think I need slight persistence and the little effect with the 'caps' that slowly fall down for each column (right now mine looks too jittery). reply ihatehn 7 hours agorootparentThose might be called peaks or peak indicators: common in audio interfaces to indicate the maximal decibels in each frequency bucket over the last second or so, so that you don't miss seeing a split-second super loud sound. reply foxandmouse 11 hours agorootparentprevhave you looked at the ProjectM: https://github.com/projectM-visualizer/projectm reply swatcoder 11 hours agoparentprevIt may carry downstream license obligations of its own, that prohibit/complicate public release. Relatedly, they might be hoping that one of the people looking at it might be willing to buy out or take over contractual responsibility for any components that can't be relicensed to traditional open source. Basically, parading the source around like a debutante because other channels to find buyers haven't panned out. Or it's just real-world commercial code and is kind of embarassing by the standards of public open source projects. reply RevEng 11 hours agoparentprevI still use it for all of my locally stored MP3s. I haven't seen a music player in a long time that focused on playing music rather than being a media library. reply rocky1138 9 hours agorootparentThey tried to shove that in at the end but it's easy to one click it away the first time you turn it on reply SAI_Peregrinus 8 hours agorootparentprevFoobar2000? reply defrost 8 hours agorootparentFoobar2K still has an active low key community, it has plugins and a framework that allows tech users to add features and share them, but the main release has the approach I prefer - good display capabilities for media library meta data with flexible layout options .. and it's on the user to populate that meta data with third party tools (or plugins). Primarily it's just a player, potentially it's a lot. reply callwhendone 12 hours agoparentprevtook them 20 years to figure out that they can't monetize their media player reply davidgerard 12 hours agoparentprevI was surprised to find how many people still use Winamp now. reply renegade-otter 12 hours agoprevI remember as a hobbyist Windows programmer (Borland C++ Builder) I was really envious of the skills required to build something like Winamp - especially the UI. Back then, advanced learning resources and examples were effectively non-existent or at least, hard to find and stitch together. reply GeoAtreides 12 hours agoparent(Borland) Delphi also made creating non standard form shapes; the secret was in leveraging the win32 api, which was really easy to do in Delphi. Here's an example: http://www.delphicorner.f9.co.uk/articles/forms4.htm reply worik 9 hours agorootparentI found the secret to C++ programming for Windows was using the C API. It was a long time ago, but IIRC I was using Visual C++ (a very nice compiler that was the first to implement the STL as written) having abandoned Borland Foundation Classes (? name ?) which was dreadful. Woeful. MFC, the MS C++ offering for writing Windows apps was impossible to use and undocumented at the time. We subscribed to those piles of CDs that MS would send out regularly and I could only find decent documentation for the C API, not the MFC one. Weird. I used an explicit event loop (simple for a Computer Science graduate like I was) and the C API inside my C++ programme and it worked a treat Those were (not) the days.... reply cellularmitosis 11 hours agorootparentprevStrange that they didn't include a single screenshot on that page. reply taspeotis 10 hours agorootparentScreenshots might take 10â€™s of kibibytes. Not very baud efficient. Use the webring links at the bottom of the page to find another website that has pictures. Sign their guestbook as thanks. reply drekipus 11 hours agorootparentprevVery common for older projects reply adra 11 hours agoparentprevI remember fondly writing a winamp clone in school with a team project. We scraped together a rough plugin based player, input and output plugins (a super limited network streaming variant), etc.. good times grinding on a neat project. Yikes, that was like 25 years ago. reply yazzku 12 hours agoparentprevThe fact that you can re-skin it at runtime with such a wide variety of skins and load such a variety of plugins puts modern software to shame. reply mesh 10 hours agorootparentI owe my entire career to the fact that Winamp added the ability to re-skin. I had just graduated graduate school for international economics, and was working for a government contractor who only hired me because I had a masters (they could charge the government more). Because of this, I literally had nothing to do and would just sit in the office. I eventually figured out an excuse to get my employer to buy Photoshop for me and I started learning it on company time. When Winamp came out with the update to add skins, I ended up making one of the very first skins (meshAMP) which became really popularly. https://archive.org/details/winampskins_meshAmp (I am cringing looking at it now) This led to contract job with STB (to design interfaces for a TV Tuner card they had) and eventually 3DFX (paid in 3d video cards), and eventually a career change and a job as a graphic designer. Except, I was not a good designer, so I quickly learned to program (ASP.net and then JAVA), which led to Macromedia Flash, which led to Macromedia Generator, which eventually led to a job offer from Macromedia (now Adobe), where I still am (sadly, sans Flash). Anyways, thank your WinAMP! reply rocky1138 9 hours agorootparentI've felt for a long time that hacker News was dead, then I read your post and it made me warm inside reply nextaccountic 10 hours agorootparentprevDid you create Macromedia Flash? Or otherwise worked on it Anyway your winamp skin is cool reply mesh 5 hours agorootparentI worked with the team and had input on the Player, but my job was in community / evangelism. reply renegade-otter 12 hours agorootparentprevDockable UI, fast, stable, form and function. Really a masterclass in software design to this day. reply pjbk 12 hours agorootparentprevI think those of us who use the REAPER DAW and its customizable themes are the main beneficiaries of that functionality. reply RevEng 10 hours agorootparentprevThat's one of the biggest reasons I still use it. Other music players have strictly fixed UIs that often focus on organizing a music library rather than actually playing your music. I'm quite happy organizing my music using the file system. reply bredren 11 hours agorootparentprevIt was really cool. Skinning was pretty easy to do. The packaging format was a zip archive with a renamed extension. You could do a lot with a little photoshop skills and trial and error. So many people used it that skins would get a lot of distribution, too. reply dale_glass 11 hours agorootparentprevYou can reskin a lot of modern software, it just went out of fashion. reply bluedino 9 hours agoparentprevJustin Frank used to hang out on IRC in #winprog or something, and I can remember when he was showing us how he made the UI skinnable. Asking for ideas and input etc. This was back in 96-97? reply ssahoo 12 hours agoprevGood. Love the reimplementation in HTML https://webamp.org/ reply captbaritone 12 hours agoparentHey! That's my side project. So glad to hear people enjoy it. reply mybrid 8 hours agorootparentI just checked it out. Good stuff! I may deploy it. reply semireg 12 hours agoparentprevThis satisfied whatever cravings I still had. Thank you! reply yazzku 12 hours agoparentprevIt's fantastic. I can easily spend hours on the skins website. https://skins.webamp.org/ reply tshaddox 10 hours agorootparentMajor Tom was the one with the most impressive artwork to me. https://skins.webamp.org/skin/dd9931b75c11c570ff8ceabee499e7... reply tech-no-logical 12 hours agorootparentprevwow, I even found the skin I used way back when... very cool https://skins.webamp.org/skin/d77a144cdb775a0937617389b6e0e4... reply phatfish 10 hours agorootparentprevAnime girls and the Borg lady from Voyager, checks out. reply thefourthchime 11 hours agoprevAbout 20 years ago, I almost got hired on the Winamp team. They were busy working on Winamp 3, which, from what I gathered, was a pretty much total rewrite using modern C++. The previous codebase had been more or less just C, written by Justin Frankel. I think everyone kind of hated Winamp 3. It was very buggy. The plugin framework was extremely complicated. I wonder which source code they'll open up. Maybe both. reply boomskats 11 hours agoparentI had to re-read your comment because first time round I thought you were suggesting it was JF's codebase they hated. Everything else he's ever worked on has been phenomenal (especially Reaper, from the very start). So was that at AOL? reply xxpor 12 hours agoprevI'm skeptical this will be a fully free license based on the cagey language in the announcement :/ reply swatcoder 10 hours agoparentThey might not be in a position to relicense all of it, or might not be sure of exactly how to do so appropriately. Large, living companies like Microsoft can work with their lawyers to confidently understand what they're releasing when opening up old code and indemnify theythemselves appropriately, but a troubled company on its last legs can't nexessarily budget for all that. Commercial software of that vintage was not built from dependencies that were all open source themselves, nor were there necessarily contributor/contractor agreements that kept copyright in a suitable place for open source relicencing. They might have been prepared for explicit rights transfer to another party, and maybe disclosure as they're suggesting here, but relicensing is a different thing. reply pquki4 12 hours agoparentprevVery weird. They provide a very specific future date for this, and avoided using the term \"open source\". I can't recall any other company doing this. Most of the time, companies provide a github repository at the same time they make such announcements. Even for twitter, Elon Musk promised the algorithm would be opened, and then some time later it was just there. While generally it is a positive thing to see code being available, I wouldn't think too much into it until I can see the license and the code. reply TillE 12 hours agorootparent> I can't recall any other company doing this Years ago Microsoft used to do stuff like this, notably releasing .NET Framework under its Reference Source License (you're allowed to look at the code, but that's about it). reply nailer 10 hours agorootparentItâ€™s still happening. Bad companies are swapping between using â€˜open sourceâ€™ inaccurately (to get grants and funding) and saying â€˜source availableâ€™ (when people call them on their bullshit) now. reply ElijahLynn 11 hours agorootparentprevTIL: https://github.com/twitter/the-algorithm https://blog.x.com/engineering/en_us/topics/open-source/2023... reply hodder 12 hours agoprevIt really whips the llama's ass. reply yazzku 12 hours agoparentCertainly whipped my ass after hearing that intro again 20 years later. reply nuxi 12 hours agorootparentitâ€™s Wesley Willis, all the way downâ€¦ reply Lammy 12 hours agoprevThis leaked a couple years ago https://news.ycombinator.com/item?id=29379346 reply Andrew_nenakhov 11 hours agoprevThe most impressive feature of classic winamp were it's skins. You can effortlessly watch them in all their classic glory on WebAmp.org [0]. (There is also some nice music there) [0]: https://webamp.org/ reply itvision 2 hours agoprevNo one would ever believe me but last night I had a dream about exactly this. I was shocked to wake up and read about this in the news. reply tiffanyh 11 hours agoprevHope itâ€™s the source for Winamp 2.x (not 3 or 5) reply anjel 10 hours agoprevAIMP3 is still in regular development for windows and Android and for me at least seems to nicely emulate winamp in UI, skins, plugins and extra features. I have fond memories of Winamp, but I don't miss it. reply ssahoo 4 hours agoprevAlso someone has rewritten Winamp in Swift as well. Few days ago it was on Product hunt and got 4 likes. Check it out https://re-amp.ru reply drc86 12 hours agoprevI knew those quotation marks were going to ruin my elation when I clicked the headline. reply cyco130 9 hours agoprevHeh, I wish Justin had some time to lay his hands on it again after so many years. (On a second thought, Iâ€™m happier with him being busy with Reaper). reply gman83 10 hours agoprevI've been using WACUP, it's really good: https://getwacup.com/ reply devindotcom 11 hours agoprevCurrently dating myself by playing Portishead's Dummy in Winamp 5.66... Looking forward to this code being lightly maintained for minimal compatibility with future OSes. I dislike change! reply hi-v-rocknroll 12 hours agoprevKinda late. Maybe it would've been cool in 2006 when I still used Windows. But what I really want to know is: will it really kick the LLaMAs ass now with AI features? reply babypuncher 11 hours agoparentI'm surprised they haven't announced any AI features yet. It seems like every 5 years ago there's a big \"Winamp is BACK\" announcement paired with some new nonsense related to whatever the big tech buzzword of the day is. Last time it was blockchains. reply hi-v-rocknroll 7 hours agorootparentIt's what's left of AOL. Give them another 20 years. reply 0x1ch 12 hours agoprevThe dozen people still using Winamp rejoice... reply dark-star 12 hours agoparentI'm one of those 12 people apparently. I don't know, I still listen to mp3 music on my PC almost every day... And I have yet to find another player that is as fast and lightweight as WinAMP reply jerhewet 12 hours agorootparentNot lightweight, but I've fallen in love with MusicBee (https://getmusicbee.com/) and it's been my only music player for at least the last 10 years. Love everything about it. reply zeroonetwothree 12 hours agorootparentprevfoobar is great reply devindotcom 12 hours agorootparentprevi'm with you my brother reply gerdesj 9 hours agoprev\"Winamp will remain the owner of the software and will decide on the innovations made in the official version,\" explains Alexandre Saboundjian, CEO of Winamp.\" Which license will be used? \"Opening up\" is not exactly GPL. reply ssl-3 9 hours agoparentI also don't know what license will be used, but nothing in the GPL prevents [eg] the owners of Winamp continuing to own Winamp, or from deciding what innovations will (or will not) make it to their own official version. I'm not sure that \"opening up\" actually means what you may appear to think that it means. The entirety of present-day Winamp could be released, with code, under the GPL tomorrow and nothing says the org that owns Winamp will somehow cease to own Winamp, or that they must accept others' changes into their own source tree. (And that's perfectly OK, even under the restrictions of the GPL.) reply notfed 10 hours agoprevNote their careful wording...\"opened up source\", not \"open source\". reply nipperkinfeet 11 hours agoprevI still use the old Winamp on all my devices. Winamp: old or new is being open sourced? If it's the old one, wonderful! WACUP team are now able to develop a ARM version. reply desktopninja 7 hours agoprevTo me the gold version was winamp-v2.94 ... ~1.2MB of magic. I still use it today. Notable mention on BEOS ... CL-Amp reply BoingBoomTschak 11 hours agoprevhttps://qmmp.ylsoftware.com/ already exists, though. reply nirav72 10 hours agoparentThe site is not reachable. reply babypuncher 11 hours agoprevFor anyone looking for a slightly more modern alternative, I recommend foobar2000[1]. It's not quite as pretty out of the box, but it makes up for it with some insane customizability. It also has a very robust ecosystem of components, and works very well in Wine. 1. https://www.foobar2000.org/ reply chubot 11 hours agoprevWow, for me Winamp was one of the first \"enshittified\" pieces of software. I remember one version was fantastic, and then the next version sucked. I'm pretty sure this was due to a change in ownership or something I remember I used to use http://oldversion.com [1] to download the previous one Ever since then I have been wary of \"improvements\" that make software worse, which has been happening a lot recently. I'd be really interested in seeing the source code to the original. I didn't know much about programming then, and to me that would be similar to reading the original source code of Doom (which I've done a bit) [1] this site still seems alive? But doesn't even have https? reply lmm 11 hours agoparent> I remember one version was fantastic, and then the next version sucked. I'm pretty sure this was due to a change in ownership or something Winamp 3 was a major regression that sparked a backlash (in particular it had a new skin engine that probably was a priori better, but broke compatibility all existing skins, which wasn't popular; also performance, which had been a major selling point, was worse), but I don't remember there being any change of ownership or monetization effort. I think it was just a genuine well-intentioned rewrite that ended up worse than the original, like Netscape 4 or KDE4. reply RobotToaster 11 hours agoprevThe weaselly wording doesn't make me optimistic, but I hope it's an open source license. reply foxandmouse 12 hours agoprevI can't remember the last time I thought of winamp, I moved on to foobar2000 and then to streaming services. Even with this announcement, there's no mention of a licence... Too little too late, maybe if foobar2000 became open source but I'd doubt it. reply trenchgun 4 hours agoprevLinux Winamp? reply nirav72 11 hours agoprevI want to see a wasm version of winamp. reply bigstrat2003 9 hours agoparentIt's no skin off my nose either way, but I don't understand why you would want to take a nice slim desktop application and turn it into another web application that runs in a bloated browser. Seems to defeat the purpose of winamp at that point. reply uptownhr 9 hours agoprevwinamp should release an LLM and claim that it really beats the Llamas.... reply xyst 12 hours agoprevtil: Winamp is still alive and kicking reply Razengan 10 hours agoprevIt's amazingâ€¦ how WinAmp and the other softwares and websites that were so crucial in the rise of the internet AND computers in general, just..faded away like they did, and we got stuck with the Facebook and TikTok and Twitter and Netflix etc bs we have left today.. reply ilrwbwrkhv 11 hours agoprevOh my God. My favorite piece of software of all time. Would love to read it's source. reply riffic 11 hours agoprevdidn't it leak some time ago? did AOL ever spin nullsoft back out? reply loceng 11 hours agoprevI just remembered I used to hangout in an IRC chat with the creator of Sonique as a pre-teen when I first started to teach myself to code - Sonique being the main competitor to Winamp way back when. Strange how memory works. reply serf 10 hours agoparentsonique was interesting because most skins ditched 'square-rectangle' all together. Sometimes it was really wacky, like raindrops on your screen. The visulization engine was very milkdrop-y, too. reply yumraj 12 hours agoprevis there a good Mac port that supports newer, especially loss less, codecs? reply captbaritone 12 hours agoparentThe closest I've seen is https://re-amp.ru. Not sure about codecs reply rocky1138 9 hours agoparentprevSomeone mentioned macamp. I have no idea though reply GGO 12 hours agoprevwhy wait this long (until Sept 2024) to opensource the code? reply ndiddy 12 hours agoparentWinamp has a ton of proprietary licensed library code (codecs, Gracenote API, etc) that all has to be replaced with open source equivalents before the code can be released. I believe the skeleton crew that they had working on maintaining Winamp a few years ago started on some of this work, but I'm assuming that the whole codebase needs to be audited to make sure that they're legally in the clear. reply captbaritone 12 hours agoparentprevNote that they don't actually say \"open source\" anywhere. reply omoikane 11 hours agoparentprevIt's also weird that the timestamp on the press release is \"Dec 16, 1\". There are 5 press releases total on that site, 2 from 2023, 2 from 2024, and this one from year \"1\". It just seems very strange. reply Am4TIfIsER0ppos 10 hours agoprevI hope for the code to read the library database. Perhaps I'll be able to debug what's broken in mine and fix it so I can use it again. reply bdjsiqoocwk 11 hours agoprevQuestions for the experts: should anyone use this, compared eg to something more modern like VLC? reply willcipriano 11 hours agoprevI used to love Winamp for internet radio/tv. Maybe plug-in NewPipe or similar instead and fork it? reply dev1ycan 11 hours agoprevdo people still use winamp over foobar? reply solardev 12 hours agoprevMaybe now we can finally add RealVideo support to it. reply buildsjets 11 hours agoparentLet's all take this moment to celebrate 22 years and 230 days of RealNetwork's strong commitment to fucking ugly clunky software. https://www.bonequest.com/1099 reply tflol 12 hours agoprevnext [2 more] [flagged] kibibu 12 hours agoparentSo don't update it. It's not a subscription reply pwillia7 12 hours agoprevllama reply sn0n 12 hours agoprev [â€“] Can we get a Godot port for winamp on all the systems? Kthnx. ^>^ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Winamp will open its source code on September 24, 2024, welcoming developers worldwide to collaborate on its iconic Windows player.",
      "The initiative aims to leverage the global community's skills and ideas to advance the software, with a focus on new mobile players and addressing Windows users' needs.",
      "While developers can contribute to Winamp, the company will retain ownership and decide on official innovations. More info is available at about.winamp.com/free-llama."
    ],
    "commentSummary": [
      "Winamp is opening its source code due to financial struggles, enabling community-led maintenance, sparking conversations on nostalgia, alternative media players like WACUP and QMMP, and comparisons with music players such as foobar2000.",
      "Users are discussing software development, APIs, and Winamp's influence on career growth, expressing mixed feelings of excitement and doubt regarding the source code release, suggesting alternative players, and exploring potential AI functionalities.",
      "The move highlights Winamp's significance in the tech community and raises anticipation for potential innovations from opening its source code amidst financial challenges."
    ],
    "points": 298,
    "commentCount": 147,
    "retryCount": 0,
    "time": 1715892977
  },
  {
    "id": 40379488,
    "title": "Egypt's Pyramids Built on Ancient Nile Branch",
    "originLink": "https://www.nature.com/articles/d41586-024-01449-y",
    "originBody": "NEWS 16 May 2024 Found at last: long-lost branch of the Nile that ran by the pyramids Geological survey reveals the remains of a major waterway that ancient Egyptian builders could have used to transport materials. By Freda Kreier Twitter Facebook Email The Red Pyramid, the largest of the pyramids at the Dahshur necropolis, was built more than 4,500 years ago.Credit: Eman Ghoneim Stretching beneath the ground near the Giza pyramid complex in Egypt lie the remains of an ancient branch of the Nile River that might once have helped ancient Egyptians to build their monuments. The highest concentration of pyramids in Egypt can be found in a stretch of desert between Giza and the village of Lisht. These sites are now several dozens of kilometres away from the Nile River. But Egyptologists have long suspected that the Nile might once have been closer to that stretch than it is today. Satellite images and geological data now confirm that a tributary of the Nile â€” which researchers have named the Ahramat Branch â€” used to run near many of the major sites in the region several thousand years ago. The discovery, reported on 16 May in Communications Earth and Environment1, could help to explain why ancient Egyptians chose this area to build the pyramids (See â€˜Ancient riverâ€™). Source: Ref. 1 Image source: NASA Visible Earth â€œThe pyramids seem like pretty monumental work,â€ says Judith Bunbury, a geoarchaeologist at the University of Cambridge, UK. â€œBut itâ€™s less arduous if you can bring big stones up by boat rather than carrying them over land.â€ Wandering waterways For thousands of years, the Nile and its flood-plain have provided food, agriculture and water to Egyptâ€™s inhabitants. The majority of the countryâ€™s population still lives in the Nile basin. But the river is prone to migrating, and in the past, populations have had to relocate to keep up. Over the last few hundred years, the Nile has moved several kilometres to the east, possibly owing to shifting plate tectonics. There is evidence that some of Egyptâ€™s important archaeological sites do not have the same relationship to the river as they would have had at the time they that were built. There are remains of harbours and other such clues at sites between Giza and Lisht. But scientists have found it difficult to chart the scope or locations of these lost waterways. While looking for traces of ancient water, a team led by Eman Ghoneim, a geomorphologist at the University of North Carolina at Wilmington, spotted what looked like a dried-up river channel several kilometres west of the Nile. The channel ran for around 60 kilometres through agricultural areas and had a similar depth and width to the modern Nile. The research team prepares to analyse soil samples collected from an area in the Nile Valley close to the pyramids.Credit: Eman Ghoneim To investigate whether the channel could be part of an ancient riverbed, the researchers collected core samples of sediment from the channel. Beneath the wet mud of the fields, they found an layer of gravel and sand consistent with that of a riverbed. Combining this sample data with satellite imagery allowed the team to map the branchâ€™s location. They found that it would have flowed past more than 30 Old- and Middle-Kingdom pyramids dating from between 2686 to 1649 bc â€” thus the decision to called it the â€˜Ahramatâ€™ branch, using the Arabic word for pyramid. The Ahramat â€œconnected all these different pyramid fieldsâ€, says Suzanne Onstine, an egyptologist at the University of Memphis in Tennessee. â€œTheir valley temples and causeways all oriented exactly to where the water would have been.â€ Riverside sites Researchers have long debated the significance of the pyramidsâ€™ locations. The waterway running right past them could have been an important factor, because it would have provided a convenient way for builders to transport materials to the sites. This theory aligns with documents from the era which state that building materials were brought in by boat, says Bunbury. Eventually, the movement of the Nile and sand blowing in from the Sahara Desert would have caused the Ahramat Branch to dry up and become unnavigable. Today, only a few stray lakes and channels remain where the major branch once ran. But knowing the ancient riverâ€™s location provides a blueprint that archaeologists can use to try and uncover more ancient Egyptian settlements, says Onstine. And the finding that Egyptians were probably using boats rather than land transportation to move materials to build the pyramids hints that they were â€œa lot more pragmatic than perhaps we realized beforeâ€, says Bunbury. doi: https://doi.org/10.1038/d41586-024-01449-y References Ghoneim, E. et al. Commun. Earth Environ. 5, 233 (2024). https://doi.org/10.1038/s43247-024-01379-7 Article Google Scholar Download references Reprints and permissions Latest on: Geology History Archaeology Did atmospheric weathering help Earthâ€™s earliest continents to survive? NEWS & VIEWS 08 MAY 24 Subaerial weathering drove stabilization of continents ARTICLE 08 MAY 24 Why it was right to reject the Anthropocene as a geological epoch CORRESPONDENCE 30 APR 24 Jobs Research Associate - Metabolism Houston, Texas (US) Baylor College of Medicine (BCM) Postdoc Fellowships Train with world-renowned cancer researchers at NIH? Consider joining the Center for Cancer Research (CCR) at the National Cancer Institute Bethesda, Maryland NIH National Cancer Institute (NCI) Faculty Recruitment, Westlake University School of Medicine Faculty positions are open at four distinct ranks: Assistant Professor, Associate Professor, Full Professor, and Chair Professor. Hangzhou, Zhejiang, China Westlake University PhD/master's Candidate PhD/master's Candidate Graduate School of Frontier Science Initiative, Kanazawa University is seeking candidates for PhD and master's students i... Japan (JP) Kanazawa University Senior Research Assistant in Human Immunology (wet lab) Senior Research Scientist in Human Immunology, high-dimensional (40+) cytometry, ICS and automated robotic platforms. Boston, Massachusetts (US) Boston University Atomic Lab",
    "commentLink": "https://news.ycombinator.com/item?id=40379488",
    "commentBody": "Egypt's pyramids may have been built on a long-lost branch of the Nile (nature.com)287 points by gumby 18 hours agohidepastfavorite340 comments empath-nirvana 17 hours agoIt makes a lot of sense because obviously having a river there makes the transport of materials a lot easier, but i do wonder how nobody noticed this before. reply card_zero 7 hours agoparentMerer's diary describes moving stones to a pyramid building site by boat. https://en.wikipedia.org/wiki/Diary_of_Merer In fact it describes artificial basins, found in previous core samples. Nice article about that, lots of pictures: https://the-past.com/feature/records-of-the-pyramid-builders... > The biggest unknown with my model is whether there was a major western Nile channel at the time, as modern authorities are split on this question. Seems like what we have now is the discovery of a natural branch, which doesn't mean they didn't dig out useful extensions too. The Nature article calls this branch a \"tributary of the nile\", which is the opposite thing to a branch. The paper says distributary (a branch). The tributaries are way to the south in Sudan and Ethiopia and Kenya. Here's the paper: https://www.nature.com/articles/s43247-024-01379-7 reply nwhnwh 13 hours agoparentprevI am an Egyptian, I read about this years ago. But maybe they didn't have a solid proof back then. reply irrational 10 hours agorootparentThank you. I too remember reading about this years ago. I even checked the date of the paper to see if it was from years ago. reply thekid314 5 hours agorootparentYeah, I photographed this story for the Smithsonian. It was talking about how the stones were transferred by boat from near Tora to Saqqara. The water came most of the way up to the now seasonal lake near the pyramids there. But also the river used to flood so there were some seasons when the water was high enough to easily transport the stone directly from Tora I assume. https://www.smithsonianmag.com/history/ancient-egypt-shippin... reply duxup 16 hours agoparentprevWell the pyramids in question are right next to a flood plain so I don't think this idea is out of the blue entirely. reply jterrys 6 hours agoparentprevFrom Herodotus's account of Egypt: >They said also that the first man who became king of Egypt was Min; and that in his time all Egypt except the district of Thebes was a swamp, and none of the regions were then above water which now lie below the lake of Moiris, to which lake it is a voyage of seven days up the river from the sea: and I thought that they said well about the land; Later on >Such is this labyrinth: but a cause for marvel even greater than this is afforded by the lake, which is called the lake of Moiris, along the side of which this labyrinth is built. The measure of its circuit is three thousand six hundred furlongs (being sixty schoines), and this is the same number of furlongs as the extent of Egypt itself along the sea. The lake lies extended lengthwise from North to South, and in depth where it is deepest it is fifty fathoms. That this lake is artificial and formed by digging is self-evident, for about in the middle of the lake stand two pyramids, each rising above the water to a height of fifty fathoms, the part which is built below the water being of just the same height; and upon each is placed a colossal statue of stone sitting upon a chair. Thus the pyramids are a hundred fathoms high; and these hundred fathoms are equal to a furlong of six hundred feet, the fathom being measured as six feet or four cubits, the feet being four palms each, and the cubits six. The water in the lake does not come from the place where it is, for the country there is very deficient in water, but it has been brought thither from the Nile by a canal; and for six months the water flows into the lake, and for six months out into the Nile again; and whenever it flows out, then for the six months it brings into the royal treasury a talent of silver a day from the fish which are caught, and twenty pounds when the water comes in. The natives of the place moreover said that this lake had an outlet under ground to the Syrtis which is in Libya, turning towards the interior of the continent upon the Western side and running along by the mountain which is above Memphis. Â¯\\_(ãƒ„)_/Â¯ reply card_zero 6 hours agorootparentThat's higher than the Great Pyramid. Lake Moeris still exists and is not near Giza. The two pyramids are thought to be exaggerations of the Pedestals of Biahmu: https://en.wikipedia.org/wiki/Pedestals_of_Biahmu But Herodotus just reported what he was told, like with the gold-digging ants: https://en.wikipedia.org/wiki/Gold-digging_ant Which seem to have been real (marmots). So who knows. reply jterrys 5 hours agorootparentAbsolutely, but even that lends to the credibility of Egyptians doing some serious canal waterworks reply underlipton 11 hours agoparentprevIIRC it's been well-known for a while how they moved the vast majority of materials by land (similar to how the Stonehenge megaliths were moved, highly dissimilar to how the Rapa Nui moai were). reply Projectiboga 7 hours agorootparentNo,the best theory is they cut the stones in a slightly underwater quarry. The limestone if submerged hasn't gained co2. They used a complex system similar to a canal. They used ballast like logs or airbags to float the cut rocks while keeping them uderwater. Even the top working row was a water filled mini canal. They would drop the stones into place. Once the water was removed the limestone would absorb co2 and swell, tightening the blocks together. This would have been some serious engineering. reply Daz1 6 hours agorootparentThat theory has been thoroughly debunked. The limestone was transported by a network of internal ramps. reply solardev 11 hours agorootparentprevHow? Last I heard, it seemed either \"rolling logs\" or \"powerful aliens\" were equally plausible... reply underlipton 9 hours agorootparentIt was the logs, friend. Though the maoi moves beat both. https://www.youtube.com/watch?v=yvvES47OdmY reply once_inc 1 hour agoprevI've recently been looking into the natron theory, which I also like. Instead of chiselling out big granite blocks and moving them long distances, you use a bucket of powder and a lot of wood ash to chemically form rocks. reply marshallward 13 hours agoprev> â€œThe pyramids seem like pretty monumental workâ€ You don't say... reply pavlov 12 hours agoparentâ€œCutting-edge psychological research suggests that pharaohs may have suffered from megalomaniaâ€ reply s1artibartfast 12 hours agorootparentMegalomania is characterized by delusion. reply bqmjjx0kac 12 hours agorootparentI'm willing to entertain the idea that the god kings had some delusions reply nkrisc 11 hours agorootparentIf they're indulged by society as a whole, are they delusions? reply bheadmaster 48 minutes agorootparent\"I tell you, Winston, that reality is not external. Reality exists in the human mind, and nowhere else. Not in the individual mind, which can make mistakes, and in any case soon perishes: only in the mind of the Party, which is collective and immortal. Whatever the Party holds to be the truth, is truth. It is impossible to see reality except by looking through the eyes of the Party.\" reply vasco 9 hours agorootparentprevWe like to think everyone was dumb but I'm pretty sure if those dudes could build pyramids, a lot of them also knew the Pharaoh wasn't a God even if lots of people believed, same as today with religions or cult of personality leaders. reply samirillian 7 hours agorootparentI think you might be bringing our mindset a little too much into a different context. Religion served a lot of purposes for the ancients. reply soco 2 hours agorootparentThen there's the crown family of the UK or GB or whatever the proper calling, which claims to believe the same divine touch. You may call them ancients if you want, but they still get to make headlines. reply prox 1 hour agorootparentYou are missing the point here, while you might see a similar concept â€œdivine right of kingsâ€ the lived experience was a lot different from modern times vs anything BCE. That there similar social mechanics might be more appropriate. reply ants_everywhere 22 minutes agorootparentWhy \"lived experience\" isn't all experience lived by definition? And how do you know what their experience was like? And why are you hypothesizing a completely distinct experience when we're the same biological organism? reply csomar 6 hours agorootparentprevThe Pharaoh wasn't a god, it was a ruler. I think they had the sun and other elements as \"God\". Kinda makes sense to praise the sun as it makes their agriculture go. reply lukan 1 hour agorootparentThe pharaos were indeed worshipped as literal gods. Echnaton famously negated them all except for the sun and himself as the incarnation, but after his death all was restored to the normal system of polytheistic theoraty. The sungod Ra was still important, but not the most important. It was a complicated system and very different from our modern thinking. reply nkrisc 7 hours agorootparentprevThey didnâ€™t need to actually believe it to indulge the pharaoh. reply NeuroCoder 7 hours agorootparentprevI thought they had all sorts of in breeding going on in royal lines. That does tend to cause somes issues including mental ones. reply aquova 7 hours agorootparentIf I recall, there was a bit of sibling marriage here and there, but it wasn't until the Greeks took over that they really started inbreeding. reply lolinder 6 hours agorootparentI was under the impression that the Greeks leaned into a practice that was already well-established as part of rulership in the region. At the very least it seems we have evidence that Tutankhamun's parents were brother-sister and he appears to have had some severe abnormalities as a result: > The results of the DNA analyses show that Tutankhamun was, beyond doubt, the child born from a first-degree brother-sister relationship between Akhenaten and Akhenatenâ€™s sister (see Fig. 3). ... Pharaoh Tutankhamun suffered from congenital equinovarus deformity (also called â€˜clubfootâ€™). The tomography scans of Tutankhamunâ€™s mummy also revealed that the Pharaoh had a bone necrosis for quite a long time, which might have caused a walking disability. This was supported by the objects found next to his mummy. Did you know that 130 sticks and staves were found in its tomb? https://blogs.ucl.ac.uk/researchers-in-museums/2018/08/16/co... reply mcmoor 5 hours agorootparentAnd then we have Cleopatra the last Ptolemy and she seems normal. Even the famous inbred Charles Habsburg have relatively normal sister. Nature really plays dice sometimes. reply elliottkember 10 hours agorootparentprevDoes believing someone to be a god make them a god? reply RajT88 10 hours agorootparentWhen someone asks you if you're a god, you say YES! reply makeitdouble 10 hours agorootparentprevWhen a category of godness is defined as being a pharao, well yes... reply nkrisc 7 hours agorootparentprevFirst define â€œgodâ€. reply krapp 11 hours agorootparentprevIt's the \"god\" part of \"god king\" that was the delusion, and all of the wasted effort that went into ensuring the Pharoah's resurrection and immortality after death. And yes, it's a delusion regardless of how many people believe in it. reply ethbr1 11 hours agorootparentTo some degree, the practice of state religion exists to ensure the stability of the state, especially in pre-mass communication times. To that, so what if the \"god\" part was a lie? A stable society built on an unfalsifiable lie is still a stable society. reply truncate 10 hours agorootparentLike they say \"without faith there is no fear\". reply krapp 10 hours agorootparentprevThat's all well and good until a really bad drought or a plague blows through and people start to wonder if maybe, just maybe, the inbred jackass on the golden throne doesn't control the weather after all. reply irrational 10 hours agorootparentExcept, the Egyptian society was quite stable for 3,000 years. Can you imagine the USA existing for 3,000 years? Will there ever be another human civilization that lasts as long as the ancient Egyptian civilization? reply jcranmer 9 hours agorootparentMy understanding of Egyptian chronology is that Egypt was far from stable for 3000 years. In fact, Ancient Egypt is broken up into the Old, Middle, and New Kingdom periods, separated by \"intermediate periods\" of a few centuries. Even then, it's generally reckoned around 2500 years from the beginning of the Old Kingdom to the incorporation by the Persian Empire. reply irrational 5 hours agorootparentBut, even during the intermediate periods, the invaders became the pharaohs and kept the old time religion going. Imagine back when Europe was under the thumb of the Roman Catholic church, but then it went on pretty much the same for 3,000 years. There would be some hiccups along the way, but for the normal peasant, it would pretty much be the same old same old from millennium to millennium. reply viewtransform 7 hours agorootparentprevThis 3 hr long history documentary is well worth it. Fall of Civilizations Episode 18. Egypt - Fall of the Pharaohs https://www.youtube.com/watch?v=YpKej05RgsY reply ethbr1 10 hours agorootparentprevOr maybe they're just not praying hard enough. I'm a through-and-through atheist, but I recognize the civilizing effect of order. 'Solitary, poor, nasty, brutish, and shortâ€™ (but epistemologically pure!) isn't a great sort of life. reply krisoft 10 hours agorootparentprevBut it is a role they believe he fills. If we all have the delision that you can fly with the power of your mind that is still a delusion. Because one can perform an experiment and see that you in fact canâ€™t fly with the power of your mind. But if we all believe that you are the eastern bunny, or the coolest dude on the planet, or the twice crowned poet laurate, those are social constructs. We believe you are the eastern bunny and that makes you the eastern bunny, and thatâ€™s no longer a delusion. I think your hang up is that you have a set of expectations you think a â€œgodâ€ should fulfill, and clearly the pharao did not fulfill them. And that is an objective fact. But there is no reason to expect that the ancient Egyptians shared your expectations about what a god is. > ensuring the Pharoah's resurrection and immortality after death That does not sound correct. I donâ€™t think they believed that the Pharao will walk again after he died. That is what the world â€œresurectionâ€ would imply. Their belief was that there is some form of afterlife where you need to perform certain rituals. The pyramids and the treasures were there to aid the pharao in peforming those rituals so he can obtain a better position in the afterlife. reply card_zero 8 hours agorootparent> I donâ€™t think they believed that the Pharao will walk again after he died. Don't count on it. At times, they believed everybody would. It's complicated because concepts varied over time, and people had maybe five or eight souls (alright, soul-aspects) and there were two or three thousand years over which this changed (sometimes for ideological reasons). https://en.wikipedia.org/wiki/Ancient_Egyptian_conception_of... > one form of the ba that comes into existence after death is corporealâ€”eating, drinking and copulating. > The idea of a purely immaterial existence was so foreign to Egyptian thought ... > the ba of the deceased is depicted in the Book of the Dead returning to the mummy and participating in life outside the tomb in non-corporeal form ... reply abduhl 11 hours agorootparentprev>>all of the wasted effort that went into ensuring the Pharoah's resurrection and immortality after death. How do you know that it didnâ€™t work? What if it wasnâ€™t a waste? reply krapp 10 hours agorootparentGods aren't real, neither is the soul, nor an afterlife. reply spiderice 7 hours agorootparentI donâ€™t believe gods are real, but I can still see the irony of making absolute statements regarding unfalsifiable ideas. reply krapp 6 hours agorootparentIf I die and find my soul being weighed on the scales of Anubis you can say you told me so. What a fool I was to doubt! reply loceng 12 hours agorootparentprev\"Breaking news - older civilizations than currently have been found may have had most evidence of their existence wiped out by major events\" reply hackthemack 14 hours agoprevI found another article that I found more lightweight and accessible. Has some pictures of the people involved. https://www.nationalgeographic.com/premium/article/egypt-pyr... reply cydonian_monk 12 hours agoparentThat article is paywalled and locked to National Geographic subscribers only. I'm not sure we have the same definition of accessible. reply woleium 12 hours agorootparenthttps://archive.is/sILbH reply tamimio 11 hours agoprevOr maybe that branch was man-made, for one to help builders to transport the materials, and also to build the pyramid itself after controlling the water level there with some man-made dams. reply ethbr1 11 hours agoparentMartians are well known for their proficiency building canals. [0] [0] History Channel reply Hikikomori 10 hours agorootparentThat theory predates the history channel by 100 years or so. reply magicalhippo 9 hours agorootparentWhich makes it an excellent candidate for being covered extensively on the I'm-not-saying-it's-aliens-but-it's-aliens History Channel. reply ethbr1 8 hours agorootparentLike some sort of prehistoric aliens? reply noman-land 10 hours agoprevThis may support one of my favorite theories of how the pyramids were built. With water! https://www.youtube.com/watch?v=C1y8N0ePuF8 reply Daz1 6 hours agoparentThis has been throughly debunked reply noman-land 6 hours agorootparentYeah? Got any resources I can check out? reply Daz1 5 hours agorootparentThe Secret of the Great Pyramid by Bob Brier and Jean-Pierre Boudin reply duxup 17 hours agoprevI wonder would the proposed harbor locations have left any structure to indicate that they were in fact harbor temples rather than just temples? I also wonder how much the river moves within that flood plain. I lived in a flood plain at one point and the river even season to season seemed to \"move\" a noticeable amount. reply beeandapenguin 11 hours agoparentAt Wadi al-Jarf[1], one of the oldest harbors in the world (~2600 BCE), they discovered numerous stone anchors, a stone jetty, and storage galleries carved into limestone that contained several boats, sail fragments, oars, and rope. They also found jars that have been discovered at another site across the Red Sea, indicating they may have been used for trade. [1]: https://en.wikipedia.org/wiki/Wadi_al-Jarf reply bluGill 15 hours agoparentprevI would expect that harbors were mostly made of wood. Stone is too heavy and would sink into the bottom, and they didn't have access to enough metals to think about bronze (much less iron). Wood of course rots - while the climate in Egypt is the most conductive to wood not rotting, if it was a harbor structure I'd expect (read I'm not sure here!) that the area remained as a swamp for a while thus rotting away anything left behind before to fully dried up. reply teruakohatu 12 hours agorootparentThe oldest surviving dugout canoe found could be as old as 10k years old. Certainly a number of ancient Egyptian boats have been found and dated to around the time of the pyramids. So dock piles could possibly have survived. Of course there were no doubt a large number of boats and only a small number of temple docks. reply JoBrad 12 hours agorootparentI think itâ€™s likely that they would have been dug up and reused, given the relative scarcity of wood. reply selimthegrim 9 hours agorootparentprevAre these the dugout canoes made by the Indians who lived in Santa Barbara County? reply cchi_co 12 hours agoprevSince childhood, I have been fascinated by Egyptian history. It's mesmerizing reply Ductapemaster 12 hours agoparentMyself as well. I recently listened to an episode on Egyptian history from this podcast and really enjoyed it â€” consider checking it out! https://fallofcivilizationspodcast.com/ reply brunoarueira 10 hours agoparentprevMe too, I would like to visit the Egypt one day :) reply nashashmi 9 hours agoparentprevAnd the conspiracy theories that surround them? reply danking00 17 hours agoprevThereâ€™s also a lighter weight Nature News article about it https://www.nature.com/articles/d41586-024-01449-y reply dang 13 hours agoparentThanks! I've changed the URL above to that from https://www.nature.com/articles/s43247-024-01379-7 (the paper). Those who are interested can read both, of course. reply tiffanyh 18 hours agoprevIt might be related, there's a hypotheses that the Sphinx had massive water erosion. https://en.wikipedia.org/wiki/Sphinx_water_erosion_hypothesi... reply wnevets 17 hours agoparent> , attributing their creation to Plato's lost civilization of Atlantis over 11,500 years ago what is with the obsession that ancient egyptians were incapable of building these monuments? reply adastra22 16 hours agorootparentIn the specific case of the Great Sphinx, there is evidence that it was an existing structure repurposed by Khafre and may have predated the rest of the Giza complex by thousands of years. Atlantis and 11.5ky is crazy talk though. reply kuprel 16 hours agorootparentWhat if theyâ€™re even older than 11.5ky? Neanderthals had larger brains and have been around for half a million years reply spookie 12 hours agorootparentLarger brains don't mean a whole lot. Look at crows. If you do question they do have relatively big brains for their size... That's completely fair. Still, current research still hasn't proven if it's indeed causal, and not just correlated. reply jvanderbot 15 hours agorootparentprevWell that'd be quite unexpected and surprising, I'd say! reply moomoo11 10 hours agorootparentprevSomeone told me that an ancient civilization got to nuclear power and destroyed the planet resetting civilization. I guess with enough mind altering (diminishing) drugs anything is possible. Idk why itâ€™s always these wacko types who are into this kind of ancient history. Itâ€™s annoying. reply cultofmetatron 48 minutes agorootparent> got to nuclear power and destroyed the planet resetting civilization don't even know why they need to get that far. we already know the younger dryas was a time period of extreme climate swings and natural disasters with purely natural causes. a civilization existing before that time could have been advanced without needing to have achieved nuclear. plus its pretty trivial to prove that no prexisting civilization made it to the fossil fuel era. never-mind NUCLEAR age. reply sjtgraham 13 hours agorootparentprevThey're in Egypt, the builders would have been \"Ancient Egyptians\" regardless of whether that means dynastic Ancient Egyptians or a pre-dynastic \"lost civilization\". That being said there are a lot of interesting unanswered questions, e.g. why are pyramids newer than the Giza complex less-sophisticated? The fact that we don't know how they are built tells you all of these are still questions completely unanswered by archeology. reply pavlov 4 hours agorootparentWhy is New York Penn Station so ugly and drab compared to Grand Central even though itâ€™s newer? Even the style of decoration is entirely different and much richer on the older and larger building. Could it simply be a question of societyâ€™s priorities and resourcing? Nah. After all the Americans were a fairly primitive culture primarily known for hamburgers and baseball. Most likely Grand Central was built by aliens or an older Native American culture. reply philwelch 37 minutes agorootparentThe obvious conclusion would be that Penn Station was built during a period of cultural decline, which turns out to be both true and interesting. reply pavlov 11 minutes agorootparentIndeed. For some reason this obvious conclusion doesn't satisfy the pyramid theorists, even though ancient Egypt's many periods of cultural decline and later resurgence are well documented. reply dylan604 13 hours agorootparentprevWere there less laborers available after the Giza pyramids? Of course s/laborers/slaves/ would be implied. If the labor force was smaller later, would that contribute to less-sophisticated? reply mkl 12 hours agorootparent> Of course s/laborers/slaves/ would be implied. Not if you want to be accurate: https://www.sciencefocus.com/science/were-the-egyptian-pyram..., https://www.discovermagazine.com/planet-earth/who-built-the-..., https://www.worldatlas.com/ancient-world/were-slaves-used-to... reply goodluckchuck 11 hours agorootparentprevThe particular reference to Egyptians is a red herring, since nobody else built pyramids of this sort (that survive and are known). I expect that if they were located in China or Europe (and no where else), people would equally wonder how the Chinese or Europeans could have been so unique as to build something of the sort. reply 6SixTy 12 hours agorootparentprevClassical racism. Ever wonder why Indiana Jones fought N@zis in the first 3 movies? reply gnatman 12 hours agorootparentIndiana Jones & Short Round fought the Thuggee cult in the 2nd movie. reply selimthegrim 9 hours agorootparentAryans all reply spiderice 7 hours agorootparentprevBelieving something was too advanced for an ancient civilization isnâ€™t racism. Stop trying to square peg a round hole. reply alephnerd 16 hours agorootparentprevRacism, Orientalism, and 19th century nationalism. How could an impoverished Arab country filled with zealots, belly dancers, and opium addicts be the heirs of a civilization that was a major cornerstone of \"European\" civilization (Edit: This is tongue in cheek). Tbf, Schwaller de Lubicz was also a Nazi sympathizer and there was a lot of bad science and history driven by ethnonationalism. You see similar stuff today with Multiregional Genesis of Humans (China), Out of India Hypothesis (Hindutva), etc. reply autokad 16 hours agorootparentNo. part of it is that its hard for many to believe that civilization can regress for very long periods of time. They were the tallest man-made structures for 3800 years. The engineering and quality of construction was mostly unmatched throughout that duration. Another issue is that 'scientists' refused to acknowledge that Egypt and most of Northern Africa was lush and green for some time. The people claimed the gods pulled the sun accross the sky and changed the climate. 'scientits' were like \"wow you are so stupid, it doesnt work like that, it was never green and you killed what ever green there was by over farming\". Turns out, it was a change in Earths tilt. going along with that theme, we tend to ignore what we are told. The egyptians left depictions of how they did it, by rolling the blocks on large logs and throwing water in front of them, and they left notebooks describing how they sourced the blocks and shiped them down the nile on the river. turns out, after 4000 years, we still don't read the f'ing documentation. reply ch4s3 16 hours agorootparent\"People\" didn't lost the ability to build giant megalithic structures and indeed pyramid construction flourished in the Americas until about 600 years ago. The Egyptians stopped building pyramids because it took decades, was insanely expensive, and gave grave robbers an obvious target. From an engineering perspective, ancient people built more complicated things than the pyramids, just not as tall. Why should height be the sole measure of engineering prowess? Consider the coffered dome of the Roman Pantheon. reply DiggyJohnson 14 hours agorootparentFor what itâ€™s worth, itâ€™s the height and volume of the pyramids that impresses me. A skinny skyscraper twice as tall but 1/64th the surface area Obviously we could build bigger if we wanted. I literally work in one of the biggest buildings in the US by volume and it is impressive on a daily basis. But just because I know we are capable of more doesnâ€™t mean the accomplishment of actually doing the world and constructing the pyramids isnâ€™t amazing. Besides the pantheon, what other ancient or modern projects measure up? reply AlotOfReading 9 hours agorootparentFeel free to look at the outline comparison on Wikipedia: https://upload.wikimedia.org/wikipedia/commons/a/ac/Comparis... The pyramid of Cholula (larger by volume), the Luxor hotel (smaller, but substantially more useful), and Ryugyong hotel (hobbled by the country building it) are all plausibly comparable projects. reply masklinn 5 hours agorootparentprev> For what itâ€™s worth, itâ€™s the height and volume of the pyramids that impresses me. A skinny skyscraper twice as tall but 1/64th the surface area Why are you impressed by unusable volume? Do spoil tips awe you? reply alephnerd 16 hours agorootparentprevRead about the person who created the hypothesis GP mentioned (Schwaller de Lubicz). I'm not disputing the climate change part, I'm disputing the Atlantis part reply mcphage 16 hours agorootparentprev> The engineering and quality of construction was mostly unmatched throughout that duration. That's definitely not true. They didn't build pyramids of that size after the Old Kingdom, but they definitely had impressive engineering and crafts. The largest computer ever built was finished in 1963â€”why don't we build computers that large anymore? Because \"largest computer\" isn't a useful metric. reply autokad 16 hours agorootparentThe grandeur of the Great Pyramids is widely acknowledged as the pinnacle of pyramid construction (pun intended). Despite their impressiveness, other pyramids fell short in comparison (also pun intended). Your argument suffers from flawed logic by attempting to directly equate the construction of a physical structure with that of a computer. Moreover, the greatness of the Great Pyramids of Giza cannot be solely attributed to their size; they possess other notable aspects as well. reply mcphage 7 hours agorootparent> they possess other notable aspects as well. Sure, but what other notable aspects are superior to later dynasties, however? reply tiffanyh 16 hours agorootparentprevThat's ridiculous. How do you explain Stonehenge then? (which was built in England yet no one can explain how Brits did it) https://en.wikipedia.org/wiki/Stonehenge reply alephnerd 16 hours agorootparentI was disputing the notion that Egyptians CAN'T build monuments. I think my tone might have been too tongue in cheek. > which was built in England yet no one can explain how Brits did it To quote one of my favorite Adult Swim shows (China IL) - \"F**ing people figured it out ... Nerd don't estimate all of humanity by the limits of your capabilites\" reply lupusreal 15 hours agorootparentI don't think anybody says the Egyptians couldn't build the Sphinx, they obviously built a lot of stuff at that scale or larger which isn't disputed. Plenty of people do claim that about the pyramids, but that's a separate and (IMHO) far kookier claim than the Sphinx stuff. reply alephnerd 15 hours agorootparent> I don't think anybody says the Egyptians couldn't build the Sphinx That's what the hypothesis u/tiffanyh EXPLICITLY says, and connects with the larger theory of Atlantis and Thule. They already brought up the fairly discredited hypothesis that humans couldn't have built Stonehenge, ignoring the fact the prehistoric megaliths are actually fairly common, and \"simple machines\" are a fairly well known concept throughout much of history, and forced labor was VERY common throughout much of history. reply lupusreal 13 hours agorootparent> That's what the hypothesis u/tiffanyh EXPLICITLY says No it isn't. The Sphinx water erosion idea says that the Sphinx is too old to have been built by the Egyptians, not that the Egyptians were incapable of building things like the Sphinx. The claimed evidence is apparent water erosion on the Sphinx and climate records, not the complexity of the Sphinx. > They already brought up the fairly discredited hypothesis that humans couldn't have built Stonehenge They didn't say humans couldn't build the Stonehenge, they claimed that nobody knows how it was done. They can clarify if they wish but I take this to be a rebuttal of your argument that \"alternate\" theories about ancient megaliths are obviously rooted in racism; Stonehenge is the subject of such interest despite being European. It's not motivated by some sort of racist desire to show that Britons are racially inferior people who can't stack some stones, it's just a legitimately interesting thing to wonder about. reply Hikikomori 10 hours agorootparentprevThere's plenty of people saying that, they're not serious scholars but they're people. From aliens did it to a race of white people travelled the world and shared their technology before a cataclysmic flood. reply jedberg 16 hours agorootparentprev> which was built in England yet no one can explain how Brits did it There was a guy who rebuilt a section of Stonehenge using only techniques that could have been used thousands of years ago, and explained how it was possible to build it. https://www.youtube.com/watch?v=-K7q20VzwVs reply hennyting 8 hours agorootparentYou can tell Wally was done with fools claiming that modern tools couldn't do x and y. \"Just a big teetertotter with a big kid on one side\" reply guerby 12 hours agorootparentprevThanks! Made my day :) reply alephnerd 11 hours agorootparentI recommmend watching similar videos about the monoliths in Easter Island. Human Innovation is amazing. If only we can channel that into renewables constructively (don't give me Big Oil bullshit. I told enough of them my mind and my peers did to which is why we have a renewables boom now) reply abc_lisper 16 hours agorootparentprevTo be clear, it wasn't Anglo saxons nor the Celts nor the steppe invaders before them who built the Stonehenge, though some of their DNA survives in the current population. https://www.bbc.com/news/science-environment-47938188 reply card_zero 5 hours agorootparent> The ancestors of the people who built Stonehenge > the Neolithic migrants to Britain appear to have introduced the tradition of building monuments using large stones known as megaliths. I mean, OK, yes, but Stonehenge was built in multiple phases by different groups of people over centuries. These farming migrants with Eastern Mediterranean grandparents built phases I and II, which had small stones (the bluestones from Wales, initially placed as grave markers before being moved around a lot) and lots of wooden posts. The impressive phase with the sarsens, the big stones people picture if you say \"picture Stonehenge\", is Stonehenge III, and that was built by Beaker People, the steppe invaders. Inspired from the culture of their predecessors, I guess, but maybe for completely different purposes, in so far as any of it had a purpose. The sarsens were connected at the top with woodworking joints, BTW, as if there was a risk they might fall off without pegs to hold them in place. I've never been sure what to make of that, but my best guess is \"tradition\". (A previous guess was \"everybody in prehistory was drunk\".) reply loufe 16 hours agorootparentprevI'd argue parent's comment was clearly sarcastic. reply zaphirplane 16 hours agorootparentprevWhatâ€™s mysterious about its construction, is it the sourcing of the stones or some precision in the circle reply abc_lisper 16 hours agorootparentEach stone weighed 25 tons. reply jedberg 12 hours agorootparent> Each stone weighed 25 tons. There was a guy who rebuilt a section of Stonehenge using only techniques that could have been used thousands of years ago, and explained how it was possible to build it. https://www.youtube.com/watch?v=-K7q20VzwVs reply Suppafly 16 hours agorootparentprevI'm not sure why people think it's impossible just because they were large and heavy, we see all sorts of other prehistoric things requiring similar effort and modern scientists have replicated the steps necessary. You can move a lot of weight if you have thousands of people involved doing the work. reply foobarian 15 hours agorootparentThat reminds me of the various tug-of-war contests around the world where the contestants manage to snap impossibly thick ropes. E.g. > The 1,600 participants exerted over 180,000 pounds of force on a 2-inch thick nylon rope designed to withstand only 57,000 pounds. Amidst cheers, the rope violently snapped; the sheer rebounding force tore off the left arm of the first man on each side. [1] https://priceonomics.com/a-history-of-tug-of-war-fatalities/ reply abc_lisper 15 hours agorootparentprevIdk, because people are unbelievably not bright. Like humans have hardly evolved in last 200k years, yet, we have made most of the time we had only in the last 500 years. Wheel was \"only\" invented 6000 years ago. We are only slightly above natural selection in selecting what works. Newton was the first guy to use averages in experimental results - and look at all the brilliant people before him! Socrates, and I am fan, thought writing things down makes people lazy, democracy is a stupid etc - he is arguably one of our finest, and had awesome arguments to back his assertions, yet, he didn't know what works. People only learn through practice, mistakes and improvement. The rest is bogus 99.9% of time. This is why I think we are only slightly above natural selection. reply bell-cot 15 hours agorootparentprevSo? With (for instance) this simple & ancient technology - https://en.wikipedia.org/wiki/Slipway#Slipways_in_ship_const... - people can routinely construct ships weighing ~1000X the weight that any one worker (or crane) could lift. reply spiderice 7 hours agorootparentprevCongrats you made the only racist comment in this entire thread reply genman 16 hours agorootparentprevEgyptians were not Arabs. reply alephnerd 16 hours agorootparentAncient Egyptians BECAME Romans then BECAME Byzantines then BECAME Arabs. Just like Byzantines BECAME Arabs and Turks. Arab is a linguistic designation, not a racial designation. reply _DeadFred_ 15 hours agorootparentThis is what gets me about the 'Islamic Golden Age' that 'saved' Greek history, while Europe was backwards and didn't. Like, how many Greek cities, with historic Greek libraries, were in backwards Germany and Great Britain were destroyed? Now how many Greek people, who spoke and read Greek, and had access to historic Greek libraries, were 'saved' by the Islamic invaders versus how many Islamic libraries, created solely by Islamic invaders, were created from texts possessed by Islamic invaders and not texts from lands that they conquered? Seems more like a 'Middle Eastern Golden Age' of the indigenous people would be a better name than to label it after the regions conquerors. reply alephnerd 15 hours agorootparent> Seems more like a 'Middle Eastern Golden Age' of the indigenous people would be a better name than to label it after the regions conquerors That's all of history in a nutshell. Ever heard about the Siege of Syracuse and the Achaean Wars? \"Islamic\" Golden Age didn't mean \"Arab\" the ethnicity - which only became a formal identity in the 19th century. While Arabic was used as the lingua franca, the ethnic origins of the various thinkers were well known in their names (eg. Al-Khwarizmi the creator of Algebra from Khwarazm/Khorasan, Al-Biruni the sociologist from Beruniy/Ð‘ÐµÑ€ÑƒÐ½Ð¸Ð¹ in what's now Uzbekistan, etc). The main thing was all these thinkers were Muslim. History is brutal and dark, and while we should look at it to remember our pasts, we should not idealize it. reply Amezarak 13 hours agorootparentIf by â€œformal identityâ€ you mean that Arab nationalism didnâ€™t exist until the late 1800s/early 1900s, no quibbling from me, but the Arabs certainly understood themselves, and the outside world understood them, as an ethnic group for thousands of years prior. This is the same as saying Germans didnâ€™t exist as a formal identity prior to the 19th century; itâ€™s true in a certain sense but itâ€™s important to be clear. I think GP is complaining the credit seems a little weird; the religious conversion happened due to violent conquest, not peaceful proselytizing. The name implies to him the religion deserves credit when the conquests a few centuries prior really brought the region into a dark age out of which the â€œgolden ageâ€ was merely a moderate recovery. Itâ€™s certainly true that large areas of the MENA never again regained their wealth and fame again, and some ancient centers of learning were permanently deserted at this time. reply alephnerd 11 hours agorootparent> If by â€œformal identityâ€ you mean that Arab nationalism didnâ€™t exist until the late 1800s/early 1900s, no quibbling That's what I'm saying. If UAE special services (some of whom are Baloch) are on here, yk. I got into a fist fight with an ethnic Baloch al-Nahyan bouncer a couple years ago in Novella (Iykyk) But Islam was the first form of psudeo-globalism in the 8th century (along with the Tang Empire). I agree with you that it was is Ajams that powered the \"Islamic Golden Age\" but that detracts from the fact that before the 19th century, Identity was inherently ephemeral. But that does NOT mean Islam is inherently Arab. Say that shit and you will get a bullet in your jet in most areas > I think GP is complaining the credit seems a little weird; the religious conversion happened due to violent conquest, not peaceful proselytizing No argument there, but based on GP's history, it's just racism morphed as Islamophobia. History was bad, and for some ethnic groups, \"Muslims\" were bad. No argument there from a Pahari/Koshur Hindu (I have Hindu/Sikh that died in the 1990s and 1947, but also protected Muslims in both decades - shit's tough) But that's a statement for all fundamentalists. Doesn't matter what diety your rever - it's the -ism aspect that makes you a fundamentalist reply Amezarak 15 hours agorootparentprevYes, this is true to a large extent; the \"golden age\" thinkers are very often Persians, Greeks, Berbers, etc. returning to the status quo before the disaster of the conquests. There aren't all that many Arab figures represented in the Golden Age, for whatever reason - maybe something to do with the culture around conquest...? reply pirate787 16 hours agorootparentprevThey became Greeks before that. The Ptolemaic pharaohs were Macedonians. Alexandria, Egypt, the second greatest city, was founded by Alexander the Great and was 35% Jewish. reply sethrin 15 hours agorootparentI mean yes, the ruling class was Macedonian for a while, but saying \"Egyptians became Greeks\" is broadly not true. reply mr_toad 8 hours agorootparentprevThatâ€™s an oversimplification. Migration and intermarriage means that modern Egyptians will have ancestors from all over North Africa and the Middle East, and to a lesser extent from Europe. Theyâ€™re not all descended from ancient Egyptians. reply Amezarak 15 hours agorootparentprevArabic and Coptic Egyptians are genetically distinguishable. reply kbolino 15 hours agorootparentprevNone of these conversions were absolute. Moreover, you missed a rather important one: the Hellenic/Greek era of the Ptolemaic dynasty, from which we get the still-spoken Coptic language, which was formed from a mix of Ancient Greek and the indigenous Demotic Egyptian language. Language is not race, but it is strongly intertwined with ethnicity and culture in most parts of the world. reply alephnerd 15 hours agorootparentI pointed out Roman for that reason, as middle-late Roman culture itself was largely derived and built on top of Hellenic influence. Just look at how different Etruscan and early Roman civilization was compared to Rome after the Macedonian and Achaean wars reply sethrin 2 hours agorootparentThis seems like a bizarre statement, or at the very least your thesis does not seem supported by your example. There is no particular reason to think that Roman civilization should be the same after the passage of 500 years since the supposed founding of Rome. Ascribing that in any significant sense to Hellenic influence seems ill-founded; there was a massive difference in fighting style, and hence military virtues, in societies where military virtues were all-important. Also, as far as I know (which is admittedly not a great deal), early Roman combat and armament was more similar to the hoplite armies than later periods. Perhaps you can allay my ignorance here. reply kbolino 12 hours agorootparentprevThe Greeks had a lot of influence over the Romans, and the Romans even conquered Greece, but Hellenic Egypt was not the same thing as Roman Egypt. The rather tumultuous transition alone is one of the most famous historical events, though most people know the names (Cleopatra, Antony, Caesar) more than the context. reply genman 15 hours agorootparentprev\"became\" - a nice euphemism for concurring and genocide, especially about Byzantine - like they had any choice. reply genman 9 hours agorootparentIf it was not clear enough then the comment was about genocide of Greek and Armenians in Turkey - https://twitter.com/ShoahUkraine/status/1790379314061398276 they were either murdered or forced to leave. reply schmidt_fifty 15 hours agorootparentprev> what is with the obsession that ancient egyptians were incapable of building these monuments? It's part of the broader new age movement. It coincided with the rise of commodification of the identity, individualism of the 80s and 90s, and the self-care movement. People express beliefs in a higher power as a way of dealing with many things, and many new age people look either to the stars or into \"other dimensions\" (whatever that means) for these higher powers. I'd also like to point out that although you could view this as being cynical about the capacity of humanity, you could also view this as hope that someone will save us from ourselves. You can also see this in political belief with eg posadism (where dolphins/aliens elevate us after we destroy ourselves with nuclear warfare and recuperate by turning to communism, which to be fair is also basically the plot of star trek) or the belief that a free market expresses superhuman collective rationalism that will save us from individual failings. reply CTDOCodebases 11 hours agorootparentPeople have been doing this for millennia. It's called religion. When people don't understand something they attribute it to a higher power.[0] [0] - https://en.wikipedia.org/wiki/God_of_the_gaps reply DiggyJohnson 15 hours agorootparentprevAppreciate the comment. Are you a real person? reply nextaccountic 7 hours agorootparentI think about that Westworld line a lot. \"If you can't tell, does it matter?\" https://www.youtube.com/watch?v=kaahx4hMxmw reply schmidt_fifty 14 hours agorootparentprevYes, of course. What kind of comment is this? EDIT: to be clear, I think the idea of alien involvement in pyramids is ridiculous. I'm just answering the question. reply ithkuil 13 hours agorootparent> what kind of comment is this? It's part of a broader new new age movement. The race to the bottom in the quality of online comments made any informative content immediately suspect of being produced by LLMs which got trained on the few trillion high quality tokens that are encoding all human knowledge. reply robocat 13 hours agorootparent> few trillion high quality tokens Where are these high quality tokens you speak of? In the dark net? Maybe my input filters are set incorrectly but I don't see too many myself. And I'm fairly sure most of the tokens I write are not up to training qwuality. reply zepolen 11 hours agorootparentprevBecause all the evidence points to ancient civilizations building these monuments that the ancient egyptians repurposed. reply wnevets 8 hours agorootparentCan you have links to all of this the evidence that isn't a youtube video or podcast? reply Hikikomori 10 hours agorootparentprevLike? reply akira2501 13 hours agorootparentprevThe lack of tools and historical documents that explain the feat. It is hard to believe that thousands of people made these monuments simply by using \"pounding stones\" to extract them from quarries. Many construction theories otherwise paint a picture of a labor environment that's almost impossible to imagine. reply Hikikomori 9 hours agorootparentNot really, plenty of tools have been found and techniques have been successfully tried https://youtu.be/L3A_kItgymQ reply lodovic 16 hours agoparentprevThat was debunked, the same erosion was found in the rock at the quarry site where the stones for the Sphinx were originally taken from. reply beeandapenguin 11 hours agorootparentThe Sphinx wasn't built with stone from a quarry, it was carved from the bedrock. It has since been restored a number of times, one of which added layers of limestone block which is easily distinguishable from the original shape. reply lodovic 2 hours agorootparentFlint Dibble explains it a lot better than I can, around 11:00 in the video: https://www.youtube.com/watch?v=oITaI2kDIFI reply taejavu 14 hours agorootparentprevHow did the erosion happen? At what time period was that much water there? reply colibri727 10 hours agorootparenthttps://en.wikipedia.org/wiki/African_humid_period https://en.wikipedia.org/wiki/Sahara_pump_theory reply robbiep 13 hours agorootparentprevYou know sand and wind erode as well, right? reply nvilcins 3 hours agorootparentDifferent ways of erosion leave different kinds of traces. The ones in the Sphinx enclosure are indicative of water (more specifically - rainfall) erosion. reply alephnerd 16 hours agorootparentprevAlso, Schwaller de Lubicz was very loco and racist (very antisemitic and was close with a number of the earlier ideologues of the Thule movement) reply primer42 16 hours agoparentprev> Egyptologists, geologists and others have rejected the water erosion hypothesis and the idea of an older Sphinx, pointing to archaeological, climatological and geological evidence to the contrary. reply baq 16 hours agoparentprevand the pyramids too, for that matter - nobody stole the white limestone covering, it just melted away. it has some implications on when exactly these things were really built if it would be true. the height of the water which did that would be quite preposterous, too. reply UberFly 15 hours agorootparentThe pyramids were treated as a quarry over the millennia. Much of the outer casing and more was used to build medieval Cairo. reply masklinn 12 hours agorootparentA sadly common fate for big stone buildings nearby any settlements. Lots of towers and castles in europe also ended up like that after their maintenance stopped. reply gen220 10 hours agorootparentFrom an alternative angle, it's not tragic but rather a triumph of the people who \"actually\" live there, to be able to repurpose old structures to modern use. In Napoli, there's a set of pretty old (>300 years, I'd guess?) apartment buildings in the historic center, where if you view the buildings and curvature of the street from the sky or google maps, make a clear C shape. The foundation of the buildings is a repurposing of a roman amphitheater. By the time that they began to convert the bottom 10 ft of the amphitheater into the basement of the homes, the amphitheater had been unused for centuries and the remaining high-quality building material had already been scavenged and repurposed for construction elsewhere in the city. Naples, and many other \"ancient\" european cities that are still places inhabited majority by working people, are full of examples like this. It's kind of cool to see people living in a place where history is so overwhelming that it becomes banal. reply Hikikomori 9 hours agorootparentI visited that amphitheater last year as part of the underground tour, really cool. Might have read it at the Colosseum, but part of it were used by one of the noble houses to construct their Palazzo in Rome. Barberini if I remember correctly. reply tootie 17 hours agoparentprevThat theory is espoused by the same people who think it was built by aliens. It's not plausible. Per this study, by the time the Sphinx is built rainfall has already decreased substantially. The rain erosion theory requires the Sphinx be thousands of years older than records indicate and predate the first pharaoh by several millennia. reply wudangmonk 17 hours agorootparentThat it was embraced by the ancient aliens crowd does not dismiss the findings. It has what appears to be water erosion, now the claim should be challenged if you do not believe it was made by water erosion and truely believe it was made by something else. The problem is when things are ignored because they are inconvenient and you settle on attacking the individuals to the point where if you do not 100% believe in what the Egyptologist say then you must be an ancient aliens believer. I'm sure some people are motivated by such a belief but ancient aliens is the same as giving up and saying that god did it, it does nothing to get you closer to understanding anything, if anything it gets you infinitely farther since in your eyes there is nothing to figure out. reply tiffanyh 17 hours agorootparentprev> That theory is espoused by the same people who think it was built by aliens. I think this is a common misunderstanding. Yes, there are some who think aliens built the pyramids. But there is an equally large group of people who think that humans pre-ice age were advanced like we are today. And when the ice age happened 12,000 years ago - that knowledge was lost. When you then look at build sites around the world from this perceptive, structures like the Sphinx and others (like GÃ¶bekli Tepe), begin to appear much older than convention teachings might imply. https://en.wikipedia.org/wiki/GÃ¶bekli_Tepe EDIT: for those interested more in this topic, there is a Netflix series on it (called \"Ancient Apocalypse\"). I can't attest to the validity of the statements made in the series, but the arguments are compelling (and not alien related). https://grahamhancock.com/ancient-apocalypse/ reply burkaman 14 hours agorootparentIt's still aliens with this guy. > In his book Supernatural: Meetings with the Ancient Teachers of Mankind, Hancock (2006) explored the cultural importance of shamanism and psychedelics and the idea that nonhuman entities from other realms kickstarted human culture. Hancock draws parallels between shamanic spirit journeys, narratives of fairies, and modern alien abduction accounts. Shamanism is \"nonsensical to 'rational' Western minds\" as it is based on \"the notion that the human condition requires interaction with powerful nonphysical beings\" (Hancock 2019:220). He has also discussed this idea in public presentations. In America Before, Hancock (2019) again emphasizes access to the Otherworld of souls and nonhuman entities through psychedelic \"plant allies.\" - http://onlinedigeditions.com/publication/?i=634462&article_i... He was able to do a Netflix series because his son is the \"Director of Nonfiction\" there (https://thetvcollective.org/breakthroughleaders/industry-exp...). reply mandmandam 12 hours agorootparentThat is a very common thing with ancient and even modern shamans. So, how does saying so in a book about ancient shamans equate to an endorsement that aliens built the pyramids? People love attacking this guy but the attacks always seem to be remarkably poor strawmen. What's so hard about believing we were smarter than acknowledged 10,000 years ago? reply burkaman 10 hours agorootparent> the idea that nonhuman entities from other realms kickstarted human culture I'm not attacking him I'm just posting some quotes. In addition to his ideas about lost prehistoric societies influencing ancient Egyptians, he in turn believes that those prehistoric societies were influenced by aliens. I don't think this is an attack and I don't think he would disagree with this summary of his beliefs. reply mandmandam 9 hours agorootparentI spent less than one minute googling, and came up with this [0] on my first try: > I am quite clear, however, having spent more than quarter of a century walking the walk across many of the most intriguing ancient archaeological sites on earth, and digging into ancient texts and traditions from all around the world, that NO ancient archaeological site and NO ancient text or tradition that I have yet come across provides persuasive evidence for the â€œancient astronaut hypothesisâ€. > ... My own view is that all of the anomalies of history and prehistory pointed to by advocates of the ancient astronaut hypothesis are far better and more elegantly explained as emanating from a lost, advanced HUMAN civilization of prehistoric antiquity than from high-tech alien visitors from another planet. So, you just made that up, even though he expressly says the opposite on his own website. Why would you do that? 0 -https://grahamhancock.com/ancient-aliens-or-a-lost-civilizat... reply burkaman 7 hours agorootparentI don't know what to tell you, there are direct quotes from his books in my first comment. Here's another one: > Shamanism is not confined to specific socio-economic settings or stages of development. It is fundamentally the ability that all of us share, some with and some without the help of hallucinogens, to enter altered states of consciousness and to travel out of body in non-physical realms - there to encounter supernatural entities and gain useful knowledge and healing powers from them. - Supernatural: Meetings with the Ancient Teachers of Mankind Here's a whole book about these supernatural beings who assisted primitive humanity: https://grahamhancock.com/visionary/. I do think it's different than the \"ancient astronauts\" theory, but anything living that isn't from Earth is an alien, so entities from other realms clearly qualify. Edit: Sorry, rereading the thread I see the misunderstanding, you are right that he doesn't think aliens were involved in building the pyramids specifically and I didn't mean to imply that. I'm just saying that he thinks aliens were involved in the general development of the human species. reply mandmandam 1 hour agorootparent> he thinks aliens were involved in the general development of the human species. That's still a gross mischaracterization of his stance, I think. It sounds like you've never had a psychedelic experience yourself? If you had, I think you'd find it much easier to believe there's something to the 'stoned ape' theory. Especially when you realize that basically every culture ever - I know of no exceptions - has developed some way of leaving their normal state of reality. reply allturtles 15 hours agorootparentprev> Yes, there are some who think aliens built the pyramids. > But there is an equally large group of people who think that humans pre-ice age were advanced like we are today. Not GP, but to me, these two theories are both wildly implausible, so \"think it was built by aliens\" is a handy shorthand for \"believes an implausible theory about the origins of the pyramids.\" There's zero reason not to believe the \"orthodox\" theory about the pyramids. There is even an actual contemporaneous written papyrus record referring to the Giza construction project [0]. [0]: https://en.wikipedia.org/wiki/Diary_of_Merer reply Retric 17 hours agorootparentprevThereâ€™s quite a bit of evidence for the existing timeline. People quibble about radiocarbon dating, but thereâ€™s multiple methods. For example by comparing rings on enough wooden objects you can get a firm this canâ€™t be older than X date. https://www.nps.gov/tont/learn/nature/dendrochronology.htm reply tiffanyh 17 hours agorootparentExactly, and radiocarbon dating puts GÃ¶bekli Tepe at being ~12,000 years old. https://en.wikipedia.org/wiki/GÃ¶bekli_Tepe#:~:text=Radiocarb.... reply AlotOfReading 16 hours agorootparentThat's simultaneously true, and misleading to the point of being wrong. The earliest parts of the layers date that far back, yes. The features of Gobekli Tepe that people who aren't archaeologists actually care about like the obelisks date much later around the second phase of the neolithic (PPNB). Also note that Gobekli Tepe is neither the oldest site we know of nor unique in having monumental architecture. Even within the Tepler culture, Karahan Tepe dates earlier and I'm sure you heard of the older site of Jericho. reply danparsonson 12 hours agorootparentprevFrom your link: \"Radiocarbon dating shows that the earliest exposed structures at GÃ¶bekli Tepe were built between 9500 and 9000 BCE\" reply Retric 12 hours agorootparent~9500 BCE + 2024 - 1 = ~11,523 years ago. So yea not quite 12,000 years ago. reply danparsonson 5 hours agorootparentOops, thank you - I can't read apparently! reply colibri727 10 hours agorootparentprevhttps://en.wikipedia.org/wiki/Miyake_event reply mburns 17 hours agorootparentprevMore interesting still is an archaeologist debunking Graham Hancockâ€™s nonsense. https://youtu.be/-iCIZQX9i1A?si=521Y4VpqaQqPeBpq reply unclad5968 13 hours agorootparentGraham himself debated an actual archeologist on the Rogan podcast not too long ago. I think he makes it pretty clear that he's mostly advocating that there is a nonzero amount of evidence for a pre ice age civilization that was significantly more advanced than immediate post ice age civilizations. Im not convinced he's correct, but that doesn't make his stuff invalid. He's basically just presenting an alternative interpretation of the data and academic archeology is vilifying him for it, which they've done to several people before who ended up being right. Of course in his shows he presents everything as fact, just like every other science does. reply danparsonson 12 hours agorootparent> Of course in his shows he presents everything as fact, just like every other science does That is problematic though, because genuine science is never/should never be presented as fact unless it's irrefutable. I'm fairly sure that's one big reason why he comes in for so much criticism, aside from any questions about the veracity of his ideas. reply mandmandam 12 hours agorootparentprev> in his shows he presents everything as fact I've only seen one of his shows, but he didn't present anything in it as facts except actual facts. reply noslenwerdna 17 hours agorootparentprevIf they were as advanced as we are now, we would have seen that the atmospheric CO2 levels had been higher back then, no? This paper draws the conclusions that such a civilization would be visible in the geological record. https://arxiv.org/abs/1804.03748 reply seadan83 13 hours agorootparentIn 1800, there were 1B humans, 1950 is 2.5, 1990 is 5.0B, and we are now at 8.0B. I think we forget how many more people there are now compared to just 100 years ago. At -5000, there is an estimated 5M people. There's more than 1000x more people now. Per capita carbon footprint would be quite wild to leave any kind of mark on the planet with a total human population that is smaller than a single modern day mid sized city. (Data is from worldometers.info/world-population) reply noslenwerdna 12 hours agorootparentOf course, there would also be other markers. Fertilizers is one. Another is the plants and animals they used for food. Why are some plants and animals still indigenous to certain areas, assuming there was a small globe spanning civilization at some point in the last million or so years? Shouldn't this civilization have at least brought the crops and livestock to other areas of the globe they visited? reply bcrosby95 16 hours agorootparentprevKeep in mind that the start of the industrial revolution predates the mass adoption of the steam engine, and charcoal (a renewable resource) based steel mills existed into the 20th century. I can imagine a world where electricity and batteries were developed before the mass exploitation of fossil fuels as, afaik, there's no specific technological requirement on one for the other to exist. reply lupusreal 13 hours agorootparent> Keep in mind that the start of the industrial revolution predates the mass adoption of the steam engine Well of course the start of it predated the mass adoption of steam engines, but as I understand it the start is generally considered to be when steam engines were first put to use pumping water out of coal mines, that water then being used to flood canals to transport the coal. That synergy was incredibly powerful, making cheap coal available in cities which allowed urban populations to rapidly grow, providing a workforce for the factories which would eventually (not initially) also be coal powered. That's the industrial revolution as I learned it. reply ahakki 16 hours agorootparentprevOnly if you assume that the supposed advanced ancient civilization oxidized large amounts of fossil hydrocarbon. reply masklinn 15 hours agorootparentSo what you're saying is there was a massive technologically advanced civilisation which didn't build buildings, didn't carve stone, didn't mine or refine metals, didn't deforest, didn't farm, and didn't use oil? reply noslenwerdna 15 hours agorootparentprevBut there are other chemicals that a civilization might produce that are also visible in the geological record. Fertilizers would also leave a mark. reply stuxnet 15 hours agorootparenthttps://en.wikipedia.org/wiki/Terra_preta > Terra preta soils are found mainly in the Brazilian Amazon, where Sombroek et al. estimate that they cover at least 0.1â€“0.3%, or 6,300 to 18,900 square kilometres (2,400 to 7,300 sq mi) of low forested Amazonia; but others estimate this surface at 10.0% or more (twice the area of Great Britain). reply narrator 16 hours agorootparentprevIt could be that the technological civilization arose extremely quickly, and only in certain limited geographical areas before the population could grow to overwhelm the earth with industrial production. They might have had a completely different morality that led to this pattern. It was before the founding of all religions we have today. reply bluGill 16 hours agorootparentMaybe, but I doubt that as technology seems needs a lot of specialists. You don't have time to focus on one small area in depth if you also need to farm/hunt/gather. We need generations for someone to come up with the idea of writing, make it better, educate kids in it... And of course before the printing press books took a lot of time and so even if you created something passing it to someone else is hard. Primitive people were not stupid, they just needed a lot of time to figure out things that we now think are obvious. reply seadan83 13 hours agorootparentI think you under emphasized the first part of your point. Living in a modern community is easy mode. Without that, mass time and effort are needed to subsist reply datavirtue 15 hours agorootparentprevThe morality of all religions can be traced back to Zoroastrian roots, which is effectively pre-historic. reply thaumaturgy 16 hours agorootparentprevAgh, this is so close to being a really interesting perspective. \"Advanced\" can mean a couple of different things. I think your comment and Graham Hancock's stuff is using it in the sense of \"technologically advanced\", i.e., access to earth-moving equipment or something. But there's also \"advanced\" in the sense of \"ability to reason\", and that's much more interesting to think about! I think there's a tendency in the modern perspective to equate technological advancement with intelligence, and so we (laypeople and dilletantes especially) tend to think of these long-ago cultures as being sort of comprised of primitive people because they built primitive things, by modern standards. Writing systems, technology, politics & governance, math, chemistry, mechanical systems, metallurgy and materials science, medicine -- minor periodic and localized variations aside, all of these were pretty darn primitive, near as we can tell, and so the people must have been, too. But maybe advanced people do primitive things because the process of developing technology takes a long time. Think about everything that's required to reliably produce steel; maybe a prerequisite for steel is 10,000 years of agriculture. The \"Primitive Technology\" channel on YouTube is a great case study. We have an individual who has access to modern knowledge and technology, but re-producing it is extraordinarily laborious and he's still in the mud hut phase of development -- and he can escape that time period at any time to get access to modern medicine and a rich, nutrient-dense diet. I think this might be a strong argument against ancient technologically advanced civilizations (and alien claptrap). It's unlikely that things really developed that much out-of-order because it just takes too dang long to develop all the steps between basic agriculture and powered machinery. It's kind of like that counter-argument against the \"moon landing was a hoax\" nutters: in 1969, we didn't yet have the film technology required to fake a moon landing. It was easier to get on a rocket to the dang thing! We knew it could be possible to fake it, but we didn't have the tools to do it, yet. So, it's fun to think of past cultures and neolithic humans as being basically us, in terms of intelligence and reasoning and capability, but without any of the modern affordances we have now. reply sebastos 7 hours agorootparentStrongly agree that this one is both very fun to think about and rings true. I sometimes imagine imagine it as parallel to the advancement of the world of computers, which has sort of been like watching the development an entire civilization in miniature. Early computer pioneers were, we know, incredible minds whose talent was the very thing that put us on the hard road to progress. Sure, nowadays, random people are able to casually accomplish much more in absolute terms, but it's because they're standing on the shoulders of giants. All that said, I do tend to be sort of a Graham Hancock apologist. My take is that most people go too extreme with him. They either think he's a crackpot loony who must be taken at face value and debunked as a purveyor of pseudoscience OR they think he's a rebel truthteller: the only one who will look at the real facts, bravely pushing through the corrupt academic swamp. It seems obvious to me that he's neither. He's just an author who stumbled on a compelling, mind-expanding idea. Roughly stated: what if we know less about the past than we think, and thus underestimate our ancestors? I think the interesting thing about Graham Hancock's spiel has nothing to do with any of his specific pieces of archaeological evidence that he digs up, which are very clearly marshaled to make a point he has already decided on making. (This is bad science, 100%.) Rather, the thing he brings to the table is more like a philosophical approach that is genuinely fresh and interesting. And I do think he will one day be vindicated in some way, because we act like we have way more precise knowledge about the past than we actually do. This is sort of an epistemology thing, so appealing directly to the evidence and the current anthropological understanding isn't really engaging with him in good faith. He's pointing out that the Troys of history prove that we consistently overestimate how completely we've understood history and what is and is not reasonable. Over time we tend to acclimate to that picture, and then the problem multiplies, because we tend to only accept things that seem to fit with the now-banal-seeming history we already know, leading to even more banal hypotheses gaining traction. Some of his best writings relate to the systematic bias against catastrophism that existed, and showing how these types of errors in epistemology lead to actual errors of science down the line. reply attheicearcade 3 hours agorootparentprevAnyone who believes Hancockâ€™s ideas should really watch the debate with Flint Dibble[0], in which Hancock eventually admits he has no evidence of his ancient civilisation, and Rogan, who is a long time friend and believer of Hancock, seems to end up siding more with Flint. [0] https://youtu.be/-DL1_EMIw6w reply njarboe 17 hours agorootparentprevThe last ice age ended around 12,000 years ago and started about 115,000 years ago[1]. [1]https://en.wikipedia.org/wiki/Last_Glacial_Period reply tiffanyh 16 hours agorootparent> We know that the Earth has had at least five major ice ages. The first one happened about 2 billion years ago and lasted about 300 million years. The most recent one started about 2.6 million years ago, and in fact, we are still technically in it. https://www.space.com/ice-ages-on-earth-could-humans-survive reply masklinn 16 hours agorootparentprevIce age are properly defined as periods of \"extensive ice sheets\" at the poles, contrasted with \"greenhouse periods\" of no polar ice sheets (or glaciers). Ice ages are comprised of glacial and interglacial periods. The Last Glacial Period is... a glacial period. We're currently in an interglacial. But still an ice age, since there's ice at the poles (for now anyway). reply njarboe 12 hours agorootparentThanks for the info. I was just using ice age in the same way the parent was. Glacial Period is more technically correct. reply robbiep 13 hours agorootparentprevI spent my younger and teenage years obsessed with graham Hancock and his ideas. I can confidently say after more than 16 years of listening to his talks, reading and re-reading his books and listening to the shifts of his emphasis, that he is full of shit in regard to his many hypothesis regarding some ancient culture pre-ice age that was the Ur-culture and is responsible for building lots of things in lots of places that we now falsely attribute to other civilisations. When you get really into to him, the problem is he isnâ€™t even internally consistent. In fingerprints of the gods heâ€™s all into these things, then in heavenâ€™s mirror heâ€™s all going Gaga first on Ur-maps and then on fixed ratios/SI units and in the sign and the seal heâ€™s pandering ultimately to the Masonic Lodge. It is so convenient that these civilisations would have had, in his estimation, to have the sophistication and technology level of the 20th century, but left behind only artifacts that in many instances ended up getting â€˜claimedâ€™ by other civilisations. Give me a break. reply donkey_oaty 12 hours agorootparentprevGraham Hancock is literally just making up stories and saying \"wouldn't it be cool if this happened\" with absolutely zero evidence. The guy can't understand why archeologist don't like his theories, but he doesn't have theories, he has fiction stories. reply colibri727 9 hours agorootparentAnd archeologists limit their picture of the past to the evidences they have at a given point in time, although they know what they have is a very limited and degraded record of what actually happened. See for instance the argument put forth by Hancock about network of ancient \"highways\" connecting cities in the amazon. Nonsense until lidar expose them: https://thedebrief.org/2500-year-old-network-of-elusive-anci... reply mandmandam 12 hours agorootparentprev\"Hey archaeologists - here's a cool thing that doesn't fit with your timeline. Here are some ideas that could explain what's going on, but they're just ideas don't lynch me!\" The archaeological establishment: \"Lynch this fucker!\" reply Hikikomori 9 hours agorootparentExcept he provides no evidence at all. It's cool fiction but nothing more than that. reply mandmandam 1 hour agorootparentThat's just not true. He's really quite good at delineating the actual evidence while telling a thought-provoking story. reply roywiggins 17 hours agorootparentprevIf you like video essays, I enjoyed this movie-length debunking of Ancient Apocalypse. tl;dr: The evidence is simply not there, and real archeology is much, much more interesting. https://www.youtube.com/watch?v=-iCIZQX9i1A reply masklinn 16 hours agorootparentMilo also visited GÃ¶bekli Tepe, as well as Karahan Tepe (a site which likely predates GÃ¶bekli and is believed to be related as there are lots of shared features), and a few other more recent sites of southern turkey: https://www.youtube.com/playlist?list=PLXtMIzD-Y-bNsVeMHjFjF... reply johncessna 14 hours agorootparentprevAs someone who doesn't know much about archeology, I watched the netflix show and thought it was interesting and had a lot of questions. Knowing that it's one perspective and that there has been information has likely been left out and/or there were either answers, or at least commonly accepted explanations, I started looking around for what those were and what the academics had to say. I found this channel and couldn't get more than 30 minutes. He starts off well saying that he didn't want to dismiss it all as nonsense but that doesn't last long. So yeah, If you want to watch someone ridicule an alternative theory that has been presented, or present commonly accepted theories as matter of fact, then sure, great channel. reply dbspin 14 hours agorootparentYour criticism of this channel may be on point - I haven't watched it. But please don't make the mistake of equivocating scientific hypotheses, theories well supported by evidence and crank pseudoscience created for a mass audience. Hancock hasn't been excluded from the 'mainstream' archeological debate. He never participated in it in the first place. He's a writer of retrofuturological science fantasy in the same vein (and citing much the same evidence) as his predecessor Erich von DÃ¤niken. This stuff can be hugely entertaining (I'm a science fiction fan and grew up on 'face on mars', 'chariots of the Gods etc'). But its epistemic are based on just so stories and shifting goal posts, not triangulating the dating of sites, engaging in archeological digs or weighing in on scientific arguments about methodology. reply unclad5968 13 hours agorootparentThat may be true but the scientific hypotheses and theories well supported by evidence in archeology have been wrong enough times that it isn't inappropriate to question them reply kelnos 5 hours agorootparentHow is that relevant? Misinterpretation of evidence is a thing, certainly, but that has nothing to do with a crackpot making up stories without any evidence to support them. I can do that too, in an afternoon. Doesn't make it real. reply danparsonson 12 hours agorootparentprevThat's how science works but new hypotheses must necessarily be able to explain all the existing evidence rather than just cherry-picking. reply cavillis 16 hours agorootparentprevthank you for posting this! I loved Ancient Apocalypse, very entertaining. It has been frustrating trying to find refutations of some of the theories/questions posed by it. When the subject is brought up anywhere with experts it is usually dismissed with a bunch of ad-hominem attacks which is just not helpful for anyone trying to learn reply Hikikomori 9 hours agorootparentCan recommend this channel as well run by an American professor, just did a video on the techniques Graham uses to fool people but has a lot of other debunking and visiting the pyramids etc. https://youtu.be/IeIj_rNYhCU Graham and a real historian recently did a debate on Joe Rogan where Graham did not come off well. reply DEADMINCE 12 minutes agorootparentprev> When the subject is brought up anywhere with experts it is usually dismissed with a bunch of ad-hominem attacks which is just not helpful for anyone trying to learn Because you're trying to 'learn' from an unreliable source spouting fiction. It's like someone learning homeopathy being frustrated that doctors dismiss it with passion. reply roywiggins 16 hours agorootparentprevIt doesn't help that Graham Hancock levels his own ad hominem attacks, claiming that archeologists don't take his ideas seriously to protect their own egos and jobs. reply colibri727 9 hours agorootparentarcheologist do that to themselves, it's not a monolithic block https://www.youtube.com/watch?v=-DL1_EMIw6w&t=33m20s Not that those who challenge the status quo can also turn into bullies later in life, once their paradigm is established. This is well exposed in the first part of America Before (one of Hancock's book) >At the outset of the twentieth century many scholars took the view that the Americas had been devoid of any human presence until less than 4,000 years ago. >[...] >the most influential figure in disseminating and enforcing the view that the New World had only recently been populated by humans was a frowning and fearsome anthropologist named AleÅ¡ HrdliÄka >[...] >throughout the 1920s and 1930s compelling evidence began to emerge that people had reached the Americas thousands of years earlier than HrdliÄka supposed. Of particular importance in this gradual undermining of the great manâ€™s authority was a site called Blackwater Draw near the town of Clovis >[...] >The Smithsonian sent a representative, Charles Gilmore, to take a look at the site butâ€”perhaps unsurprisingly under HrdliÄkaâ€™s malign shadowâ€”he concluded that no further investigation was justified. >[...] >Anthropologist Edgar B. Howard of the University of Pennsylvania disagreed.He began excavations at Blackwater Draw in 1933, quickly finding quantities of beautifully crafted stone projectiles with distinctive â€œflutedâ€ points >[...] >Before and after 1943, the year in which both Howard and HrdliÄka died, further discoveries of fluted points of the Blackwater Draw typeâ€”increasingly referred to as â€œClovis pointsâ€ after the nearby town of that nameâ€”continued to be made. This ever-accumulating mass of new evidence left no room for doubt and even the most stubborn conservatives (HrdliÄka excepted) were eventually forced to agree that the Clovis culture had hunted animals that became extinct at the end of the last Ice Age and that humans must therefore have been in the Americas for at least 12,000 years. >[...] >a consensus soon began to emerge that no older cultures would ever be foundâ€”and what is now known as the â€œClovis Firstâ€ paradigm was conceived. We might say, however, that it was not officially â€œbornâ€ until September 1964. That was when archaeologist C. Vance Haynes, today Regents Professor Emeritus of Anthropology at the University of Arizona and a senior member of the National Academy of Sciences, published a landmark paper >[...] >because of lowered sea level during the Ice Age, much of the area occupied today by the Bering Sea was above water, and where the Bering Strait now is, a tundra-covered landscape connected eastern Siberia and western Alaska. Once over the land bridge, however, it was Haynesâ€™s case that the migrant hunters could not have ventured very far before confronting the daunting barrier of the Cordilleran and Laurentide Ice Sheets >[...] >Tom Dillehay, professor of anthropology at Vanderbilt University in Tennessee, began excavations at Monte Verde in southern Chile in 1977 and found evidence that humans had been present there as far back as 18,500 years ago. >[...] >Tom Dillehayâ€™s most dogged and determined critic, perhaps predictably, has been C. Vance Haynes, whose 1964 paper launched the Clovis First theory and who by 1988 had used his influence, and his outreach in the scientific journals, to dismiss every case thus far made for supposedly pre-Clovis sites in the Americas. >[...] >Indeed by 2012 the bullying behavior of the Clovis First lobby had grown so unpleasant that it attracted the attention of the editor of Nature, who opined: â€œThe debate over the first Americans has been one of the most acrimoniousâ€”and unfruitfulâ€”in all of science. â€¦ One researcher, new to the field after years of working on other contentious topics, told Nature that he had never before witnessed the level of aggression that swirled around the issue of who reached America first. reply tiffanyh 15 hours agorootparentprevI just started watched the YouTube. Itâ€™s hard to take this debunking serious when the very 1st point he makes about Graham is incorrect. He states that Graham claims to be a researcher. https://youtu.be/-iCIZQX9i1A?t=139 In the Netflix series, Graham doesnâ€™t not. He makes it clear heâ€™s not a researcher nor archeologist. He clearly states heâ€™s an investigative journalist. https://m.youtube.com/watch?t=19&v=DgvaXros3MY&feature=youtu... â€”- And then the YouTube host roots his show on the scientific method with the question â€œHow do you prove there was an ancient civiliansâ€. This is the wrong root question. The root question should be â€œHow did ancient civilians create these structures using the technology we believe they had at the timeâ€. Or said differently, â€œhow did civilians not use more advance technology than we believe they hadâ€ (Which is only bronze tools and no existence of the wheel) reply roywiggins 15 hours agorootparent> He states that Graham claims to be a researcher. No, he doesn't state that at all. This is what Milo says, verbatim: \"He is a person that some may call a researcher. I am one of those people. More predominantly than that, Graham Hancock is a writer.\" > The root question should be â€œHow did ancient civilians create these structures using the technology we believe they had at the timeâ€. That's an interesting question, but it's essentially an endless one: we will never, ever know how ancient civilizations created everything they created, because their secrets have been lost to time. Human history is so deep and the evidence so porous that we simply will never run out of questions to ask about how they did what they did. Furthermore, even when we come up with ways they might have created things, we may never, ever know whether that's really what they did, because the evidence is not there anymore. There are medieval and later items which we don't really know how were created, but we do know, for sure, that they didn't have power tools. For instance, what was Greek fire, exactly? There are lots of good ideas, Wikipedia suggests \"it may have been made by combining pine resin, naphtha, quicklime, calcium phosphide, sulfur, or niter.\" Will we ever know which? Maybe, but probably not. reply tiffanyh 15 hours agorootparentHis whole premise is that civilizations didnâ€™t exist that long ago (which is his scientific method question). Yet no one disputes that archeologist have found remains of people from 200,000 years ago. That right there debunks his â€œdebunkâ€ show. https://www.npr.org/2022/01/13/1072867405/scientists-determi.... reply roywiggins 15 hours agorootparentOf course there were people (or at least very-nearly-human people) 200,000 years ago, and of course there is a very, very long history of humans and not-quite-humans having material culture. Graham Hancock asserts that there was a globe-spanning single culture with advanced technology ~12,000 years ago. That's a big, specific claim! Of course there were people around during the Younger Dryas, Hancock is making a bunch of claims about what people were doing at that time. Milo is saying there wasn't a globe-spanning civilization with a shared culture and advanced technology existing during that period, not that there weren't people (are you perhaps confusing the words \"civilian\" and \"civilization\"?) Seriously, keep watching for more than a couple minutes: does he at any point say \"of course Ancient Apocalypse isn't real, humans didn't exist back then\"? That would be a very short video. reply colibri727 8 hours agorootparentCatastrophism https://www.researchgate.net/profile/Valentina-Yanko/publica... reply NoMoreNicksLeft 17 hours agorootparentprev>But there is an equally large group of people who think that humans pre-ice age were advanced like we are today. And when the ice age happened 12,000 years ago - that knowledge was lost. Advanced as in late neolithic or even early bronze? Sure, I could find that tenuously plausible. Advanced as in space age, heavily dependent on petroleum products, etc... not even slightly plausible. reply tootie 15 hours agorootparentprevHumans have been humans for at least 200K years. And those primitive humans had the same capabilities we do today. But the kind concerted effort and organization required for monumental construction still took hundreds of generations to develop. Megaliths older than the Sphinx certainly exist, but the Sphinx is orders of magnitude more complex. Not just in terms of engineering and tools (the Sphinx was carved with metal tools) but the size of the well-governed population required to do the labor. It is inconceivable that a society could spring out of the marshlands to build the Sphinx and leave no other trace for thousands of years. And then for a new civilization to show up with all the technology and culture they had, falsify a load of records to say they built it along with the Pyramids. Hancock isn't just wrong, he's a fraud. https://www.reddit.com/r/AskHistorians/comments/z8p83b/is_th... reply wins32767 15 hours agorootparent> And those primitive humans had the same capabilities we do today. Evolution has been ongoing on humans the whole time we've been a species. Drinking milk in adults has only been a capability we've had for ~6000 years. I'd be hard pressed to claim that there haven't been other capabilities that have evolved over that time that led to our ability to have more social organization. reply seadan83 13 hours agorootparentLactose tolerance AFAIK is a single enzyme. That taking 6000 years to develop I think is evidence against what you are saying. Specifically, that is a tiny adaptation compared to the organization of the human brain. Is 30x more time than lactose tolerance enough for significant brain changes? I find it implausible, I would guess the major adaptations of the brain are on the order of millions of years, not a couple hundred thousand. The adaptations for social organization seemingly have been with us for a long time. AFAIK humans have been in large groups for a very long time, as long as they have been homo sapiens (Large being over 50 members, and take that with a grain of salt, that is only my possibly incorrect understanding). I do find it very plausible that people 1k, 10k, 50k and maybe even 200k years ago were all smart (Plato probably is far smarter than most alive today). Though, smart and education are different, while smart- the body of knowledge was limited. reply masklinn 12 hours agorootparent> Lactose tolerance AFAIK is a single enzyme. That taking 6000 years to develop I think is evidence against what you are saying. Also relevant: lactose tolerance is something we start out with, babies need it. So lactose tolerance, or more properly lactase persistence, was not the development of a brand new trait out of nowhere, it was maintaining a capability past the age where it would previously degrade out of functionality. reply seadan83 9 hours agorootparentTL;DR: (1) brain shape has not changed for about 160k years. (2) The framing/facts of the discussion is bad. Mutations are happening all the time, it is 'natural selection' that seemingly made lactose tolerance more prevalent in the last 20k years. ----------------------- Long answer: ## Natural Selection / Lactose Tolerance (as an example of a very recent adaptation) / Why the discussion is so far incorrect In my first reply, I notice now a big flaw. Having an adaptation be present in a population for 6000 years does not mean it took that time to evolve it. (According to [3], the adaptation has become prevalent in 20k years rather 6k) To frame what we are discussing, I hope we can all agree: mutations are happening all the time and in aggregate we each individually carry a vast quantity of genetic differences/mutations apart from every other individual. For lactose tolerance, really what we are talking about is more natural selection. At least I think we are. As an example, a population can change very quickly via natural selection if an event kills off everyone that is missing a mutation. That perhaps 1% mutation suddenly becomes the surviving population. (For completeness, I'll mention that this process can happen more slowly as well over time, but it can depend on single mutations, aggregates of mutations, and environment and random luck [eg: asteriod] are all factors). This is to say, there could have been plenty of lactose tolerant people well before. This NPR piece on the history of lactose tolerance states it well [3] \"But now that doesn't happen for most people of Northern and Central European descent and in certain African and Middle Eastern populations. This development of lactose tolerance took only about 20,000 years â€” the evolutionary equivalent of a hot minute â€” but it would have required extremely strong selective pressure.\" What's more though too, nothing is to say that natural selection always works to favorably select genes. EG: The village idiot might be the only one immune to the plague. It's way complex of course since there's so much variation between every individual, but I just wanted to underscore that natural selection is a function of individual, time & place. Sometimes some mutations are useful, other times they are not and are dumb luck of what is left over from some time before. -------------------- ## Brain Size & Human Cognition With the issue of natural selection out of the way, what I do wonder is how long it took for the brain to get the way it is today. According to this resource, The Smithsonian [1], the answer is approx 7M years, with most of that happening in the last 2M years until 200k years ago. That is in terms of 'size' (does not account for wrinkles). According to 'newscientist' [2], the shape (now talking wrinkles here) of the human brain today is very similar to what it was 160k years ago, and has not really changed since. The resource mentions that the biggest changes since then have been in how our faces look rather than how our brains are shaped. Those changes are specifically smaller jaws: \"Faces in modern humans are far smaller, with subtler indentation, than those of their ancestors. Studies show that this change accelerated when hunter-gatherers became agriculturalists around 12,000 years ago and ate softer foods, probably due to less loading on the skull from chewing.\" Summing up, given that brain shape has been about the same for the last 160k years; it's plausible that is how far it goes back for people that felt & thought about exactly the same way we do today. If anyone knows about more research around the rise of human cognition on this topic, I'd certainly like to learn more. [1] https://humanorigins.si.edu/human-characteristics/brains [2] https://www.newscientist.com/article/2331652-shape-of-human-... [3] https://www.npr.org/sections/thesalt/2012/12/27/168144785/an... reply christkv 17 hours agorootparentprevThere is the whole theory about the Sumerians coming from a civilisation at the bottom of the Persian Gulf. As the ice age came to an end the rising sea wiped it out making them move to higher ground. reply njarboe 16 hours agorootparentAlso theorized as the source of the great flood myths. As the Gulf flooded the shore line would be moving around a meter per day for centuries/millennia. reply sidewndr46 17 hours agorootparentprevis there even a single documented case of finding writing at Gobekli Tepe? My understanding is there is no evidence of a writing system reply tiffanyh 17 hours agorootparentYes https://www.scirp.org/journal/paperinformation?paperid=90367... reply Retric 17 hours agorootparentNo. You misunderstood that quote, the emergence of writing is far more recent and at different locations. Thus â€œwithin 30km ofâ€ not at GÃ¶bekli Tepe. â€œCurrent archeological evidence in the form of seals, reliefs, steles, lead strips, and wood panels, across almost one-hundred Anatolian sites, including some within 30 km of GÃ¶bekli Tepe, dates the emergence of the hieroglyphic script used to write in Luwian to the late 15th century B.C.E.,â€ GÃ¶bekli Tepe was inhabited ~9500-8000 BCE, so ~6500 years before the writing examples given. reply sidewndr46 17 hours agorootparentSo the writing is found in the same area, but may be from a much later civilization? reply danparsonson 12 hours agorootparentThat's the idea - settlements are usually built in favourable areas (e.g. next to rivers) so the same site may be continuously inhabited or repeatedly reinhabited over very long periods of history. reply Kye 17 hours agorootparentprev>> \"As of 2021, less than 5% of the site had been excavated.\" reply sidewndr46 17 hours agorootparentMy conclusion was the sites aren't excavated because they aren't really that interesting. They are all similar in nature and don't contain extensive written knowledge that can be preserved and studied. To put it comparatively Ã–tzi the iceman is highly studied because preserved bodies aren't found from his era and location that often. If we stumbled across a graveyard with 10000 people from the same era that was easily accessible, I doubt we'd spend much time studying all of them. As another poster has pointed out, there may in fact be a writing system that we are just beginning to understand. So I'll have to see if there is anything I can try and learn there. reply masklinn 16 hours agorootparentThe sites are absolutely interesting, however unless pressed for time (usually because they're in the way of or uncovered by construction work) archaeological digs are slow going: the slower you are the more artifacts you can find, the better you can place them, and the better you can preserve them and the rest of the site. Used to be people dynamited sites to get at stuff faster (also dynamite colleague's sites to undermine them). We stopped doing that, because it was stupid and wasteful. Furthermore protecting and stabilising the site been a major focus of recent site coordinators, especially as the site has been opened up more for public visits. If you want faster digs, fund archeological grants so there's more money to hire more people. reply jahewson 17 hours agorootparentprevThis is the 2nd dumbest conspiracy theory ever. reply wincy 17 hours agorootparentNobody is conspiring to â€œkeep this under wrapsâ€ so it canâ€™t be a conspiracy theory. A conspiracy requires people who have some hidden knowledge and are keeping it secret? reply roywiggins 16 hours agorootparentGraham Hancock insists that his ideas aren't being taken seriously by the archeological community because they find them too threatening, rather than for the real reason: that they think he's plain wrong. In this view, archaeologists \"know\" that he's really on to something, but refuse to look closer. He's claimed to have been \"banned\" from Egypt (which might even be true, I don't know). The whole vibe is this is the truth that THEY don't want you to know. reply konfusinomicon 16 hours agorootparentprevthe shape shifting lizard people are the conspirators. only one of them would say it's not as to throw us all of the trail. we're on to you wincy, we are on to you... reply nurple 16 hours agorootparentprevThanks for bringing these topics up, I find the raft of evidence quite compelling. I also find it quite interesting how much pushback on alternative hypotheses there is from the mainstream scientists. I even attempted to have a conversation with GPT4 about the possibility that ancient humans created the pyramids, and it told me I was being RACIST! Like, what? The thing that sells me, besides the erosion, is the absolutely astonishing artifacts that were left behind. There is no way I could be convinced that hand-driven bronze tooling was cutting diorite to a precision we would struggle to meet today, carving schists so thin you can see light pass through, absolutely perfect symmetry, and creation of granite stoneware with multivariate surface geometry that we'd be unable to do without a precision-destroying tool change. I find the tool marks on the partially excavated obelisk in Aswan particularly compelling. It's like they had technology that could scoop granite like warm ice cream. One person doing somewhat interest",
    "originSummary": [
      "A recent geological survey unveiled the Ahramat Branch, an ancient part of the Nile River near the Giza pyramid complex in Egypt, potentially used by ancient Egyptians for pyramid construction.",
      "The discovery supports the belief that the Nile was closely situated to crucial archaeological sites, shedding light on ancient transportation methods.",
      "Evidence of the Ahramat Branch indicates that ancient Egyptians probably employed boats for material transportation, showcasing their practicality in pyramid construction."
    ],
    "commentSummary": [
      "Recent research suggests that Egypt's pyramids were built near a long-lost branch of the Nile for easier material transportation.",
      "Debates include theories on internal ramps, natron usage, and societal beliefs of ancient rulers regarding pyramid construction.",
      "Discussions cover the Pharaoh's immortality belief, Graham Hancock's alternative theories, and conspiracy theories surrounding ancient civilizations and archaeological discoveries."
    ],
    "points": 287,
    "commentCount": 340,
    "retryCount": 0,
    "time": 1715872845
  },
  {
    "id": 40379028,
    "title": "Sprint, T-Mobile Merger Raises Corruption Concerns",
    "originLink": "https://www.techdirt.com/2024/05/16/report-sprint-t-mobile-merger-immediately-killed-wireless-price-competition-in-u-s/",
    "originBody": "Anonymous Coward says: May 16, 2024 at 5:56 am Trump regulators not only didnâ€™t even read the deal impact reports, the Trump DOJâ€™s top â€œantitrust enforcer,â€ Makan Delrahim, actively worked with the companies using his personal devices in his free time to ensure the deal saw government approval. As they say, when working for a corrupt President, ignorance is your friend far more than Google is. Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word",
    "commentLink": "https://news.ycombinator.com/item?id=40379028",
    "commentBody": "Sprint, T-Mobile Merger Killed Wireless Price Competition in U.S. (techdirt.com)274 points by rntn 19 hours agohidepastfavorite233 comments TheAmazingRace 18 hours agoI will say, I'm not terribly fond of mergers on principle. However, based on my insight as a former customer and shareholder of the company, Sprint's goose was most definitely cooked to a crisp. If this merger had not happened, I could have seen Sprint file for bankruptcy, with Verizon and AT&T picking the carcass clean. I think folks forget how dire Sprint's straits were at the time, and this specific merger truly was the least of all evils. reply Benjammer 17 hours agoparent>Sprint's goose was most definitely cooked The reason their goose was cooked is because they previously were planning to acquire T Mobile, but SoftBank got back-channel info that it would never be approved by the anti-trust regulators. At the time they had Marcelo Claure running Sprint, basically a corporate \"fixer\" guy for SoftBank. So he ran the company into the dirt in order to make the merge feasible to regulators (e.g. - Sprint purchased a 33% stake in Tidal, the music streaming service. Or how they entered a partnership with bankrupt RadioShack after it got scooped up by PE, and decided it was a good idea to take over all the physical RadioShack locations and turn them into Sprint stores). \"Oh, whatever shall we do, our company is failing, you MUST let us merge with one of our primary competitors or we'll go bankrupt. No company at all is worse for consumers than a merged company.\" reply TallTales 11 hours agorootparentI'm a former engineer at Sprint and I strongly disagree with this characterization. Sprint's goose was cooked but it was due to debt from selling junk bonds to build Network Vision at the time of the original LTE rollout. Their credit was ruined by that point from 30+ years of absolutely terrible and corrupt c-suite executives. Marcello has a lot of faults but he didn't run Sprint into the ground. He is actually pretty smart and at that time we cut over a billion dollars out of the operating budget circa 2016/2017 iirc. It was an impossible position and it's really sad because it was a great old company in my estimation. T-Mobile is just the worst. reply Aloha 8 hours agorootparentHe finally reduced the fixed costs that should have been done post Nextel merger. I remember Nextel and iDEN sites co-sited on the adjacent towers.. but with different shelters (sprint was often outdoor cabinets). reply johnnyanmac 7 hours agorootparentprevYeah, I always thought the two primary factors here were the lost bet on WiMax (which probably cost a lot to build infrastructure for) and the Nextel aqui-merger causing a lot more friction than synergy. I'd be a horrible businessman, because I really can't imagine keeping so much debt and simply being okay with it until its too late. I'd be considered a fool if I managed my personal finances like that, but that's the normal operation when managing millions or especially billions at a time. reply andy800 14 hours agorootparentprevSprint went all-in on WiMax as it's 4G network. I owned an early Sprint 4G smartphone (made by HTC) and the 4G never worked. I would go to the Sprint store and ask to show me a signal with 4G turned on, and they would always blame congestion, or weather, or some other made-up excuse. reply unsignedint 12 hours agorootparentWas it more about the device than the network? I used mobile WiMax from Clear for years until it ended its service. For what it was, it worked great. It wasn't necessarily a speed demon, but it was reliable. I used it to avoid public WiFi congestion, as a backup when my home network was down, and in 'bring your own infrastructure' situations. reply TallTales 11 hours agorootparentYeah it depends on the market you were in. I helped build the WiMax network but it was built very quickly and in places it was built by people who didn't care very much. It was all microwave back hauled so rain fade in stormy weather was absolutely a thing. Most of those were FCC licensed or should have been but I know of at least 1 market where they just never filed the paperwork to get the licenses and built it anyway. reply Aloha 8 hours agorootparentThe clearwire side of things was wildly oversubscribed on backhaul, often totally saturated 10m circuits. reply ganoushoreilly 12 hours agorootparentprevI had a clear hotspot puck in the DMV area, worked well most of the time. I don't think I had any issues with price paid vs performance given the current state of tech at the time. I think targeting homes was just a hard battle, FIOS and others were really ramping up their initial push into fiber and it was just not going to compete sadly. reply andy800 11 hours agorootparentprevThat's possible but it was a Sprint-branded device bought from Sprint that was clearly supposed to be compatible with its new 4G network. And they charged an extra $10 4G access fee every month! The other bonus was that being a CDMA device, there was no connectivity when traveling internationally, and no option to buy a local SIM card. Wifi only. reply HeatrayEnjoyer 3 hours agorootparentWhy does that exclude international use? reply TheAmazingRace 12 hours agorootparentprevI think the only place I knew where WiMAX actually worked properly was in Japan. reply johnnyanmac 7 hours agorootparentprevin all fairness, the 5G isn't much better these days, at least in my area. T-mobile seem to have inhereted Sprints bad coverage, to the point where they had to send me a booster modem for my own home. reply somenameforme 4 hours agorootparent5g is higher frequency, lower wavelength. That means it gets better potential speeds when it does work, but it's going to have more difficulty penetrating barriers, reaching longer distances, do worse in inclement weather, and so on. This is also a fundamental limitation of trying to reach higher speeds with this form of tech, because frequency and wavelength are inversely proportional. The point of this being that 5g is inherently less reliable/robust than 4g, and so it's not too surprising that you'd need a booster, especially if 4g in an area is not the hottest. reply RF_Savage 4 hours agorootparentAt this point telcos are also deploying 5G to old bands, so the assumption that 5G is 3.5GHz and mmW only no longer holds. In my part of the world I see 5G on 1800MHz and 2100MHz bands in addition to the 3.5GHz one. Unfortunately that's not done near my home, so I get 1-2bars of 5G, instead of the full bars I see at the office and elsewhere in town. reply cherioo 15 hours agorootparentprevHow is ruining and destroying the value of Sprint, that SoftBank owns, possibly good for SoftBank? What is SoftBank to gain here from enriching TMobile? reply georgeecollins 15 hours agorootparentI don't know if the OP post is true-- or partly true-- but to explain how it might be good for SoftBank: This was an all share deal, so sandbagging the value of Sprint shares so you can merge with TMobile could be good in the long run because you own shares in the new entity which has much less competition. reply dralley 14 hours agorootparentprevI'm not sure if SoftBank deserves the credit of assuming that their actions are based on sound logical reasoning. reply Benjammer 13 hours agorootparentprevThey want to spend whatever billions it costs to consolidate the industry and then reap the monopolized profits down the road. reply chrisco255 12 hours agorootparentprevRadio Shack was a major retail channel for Sprint since the 90s. By the mid-00s, I would wager most of Radio Shack's gross profit came from wireless retail. They were already more or less Sprint stores with some overpriced PCs and stereos by then. reply Benjammer 12 hours agorootparentWhy would it be a prudent move to take on the corporate real estate costs associated with RS if it was already a profitable retail channel? What does that change other than increasing overhead for Sprint? And if RS was working, why would converting them to solely cell phone stores make things any better? reply ethbr1 11 hours agorootparentBecause the choice presumably wasn't {Radio Shack business-as-usual} vs {acquire Radio Shack stores}, but rather {Radio Shack disappears as a retail entity and channel for Sprint} vs {acquire Radio Shack stores}. reply Aloha 14 hours agorootparentprevI don't think that materially really had anything to do with it. Sprint was dying - with extraordinarily high debt, in 2007, well before Softbank bought them, and indeed they lost money every year from 2008 forward - https://www.statista.com/statistics/481739/sprint-corporatio... The Merger with Nextel managed to kill what was great about Nextel, and what was good about Sprint, and they lost customers in droves (mostly former Nextel ones). In reality Sprint bought Nextel's OAM equipment and their customers, and moved all the legacy Sprint customers onto the surviving billing and network management platforms (Nextel). The iDEN turndown also lost even more customers, most of whom who realized they didnt need PTToC after all (which is too bad, because on dedicated CDMA hardware, it worked really great). Then they needed to start rolling out LTE (Network Vision) - and NV didnt start in earnest until 2012/13 - and as someone who was on the field end of it, was very very very poorly managed. Sprint some years prior had outsourced all their engineering expertise to Ericsson, which means they had no one in house with any knowledge. They only realized that 18 months in, and then scrambled to get people back from Ericsson (who I will note, they did not contract any of the deployment management to). I only know this because I was in the middle of the deployment as a field resource in Seattle. My guess is only half the sites in the network (in Seattle Market) had enough customers to pay their fixed costs. I concluded while I worked there that there was no way for four carriers to be viable, there isnt enough spectrum allocated, and you pay the same fixed costs over and over again. I'll go further, Sprint had a massive switch facility for the LD operations with room for like 4 DMS250's in Tacoma, but that's not where they put the SPCS 5ESS, that was in Kirkland in a rented building (and interestingly enough, it's still part of T-Mobiles operations today), there was also another Motorola iDEN switch also in Kirkland. Post merger they never really made any effort to reduce their fixed costs (sites, switching centers, et al), because that would have cost money - they also got bled dry by having to foot the entire bill for rebanding the SMR band, which was on the order of 2.5 billion dollars. They did close stores (and RS was a major outlet for Sprint Sales, before it went belly up) which contributed to problems later. So I don't know where you got your info, but I think its hooey - before Softbank bought Sprint, they didn't have the capital to upgrade their 2G/3G network to LTE, much less consider a merger with T-Mobile. reply Benjammer 13 hours agorootparent>before Softbank bought Sprint, they didn't have the capital to upgrade their 2G/3G network to LTE, much less consider a merger with T-Mobile. I think both of us can be right at the same time though. Just because they had problems before the SoftBank acquisition as well doesn't necessarily make what I'm saying unreasonable. There was still sentiment in 2013 when SB closed the deal that regulators would not have approved of Sprint acquiring T Mobile [0], despite the struggles going on at Sprint at the time (that you describe). Sprint was definitely putting together a bid to acquire T Mobile, WSJ reported on it [1]. As you yourself said, Sprint was _dying_ at the time of the SB acquisition, but as far as large firms go, they were far from bankrupt yet. SoftBank simply twisted the dagger and then presented the corpse to congress instead of the dying patient. [0] https://www.theverge.com/2014/2/4/5376824/fcc-chief-reported... [1] https://www.wsj.com/articles/SB10001424052702303293604579256... reply Aloha 12 hours agorootparentI remember saying at one point to my operations manager at Ericsson, \"how does anyone make money in this business?\" he laughed and said \"I have no idea\". I cannot explain how poorly managed Sprint was, it'd take me an essay to just explain the various dysfunctions I saw there. That said, it did improve some once Softbank bought them. reply ericcumbee 14 hours agorootparentprevand then there was also the Wimax debacle. Sprint had invested pretty heavily in Wimax being their future network before they realized this wasnt going to work. reply malfist 14 hours agorootparentI got bit by the wimax nonsense as a consumer. I had a 4G HTC flagship phone on sprint and it was awesome. Then when I went and upgraded my phone a few years later to another HTC flagship phone, also with 4G, I was very confused why I could only use 3G. The first phone was labeled 4G and second one was 4G LTE, which sprint didn't have in my area. I had been using wimax. I switched to Verizon not too long after that so I could have 4G again reply Aloha 14 hours agorootparentWimax actually did work great in practical terms even if the clearwire network was made out of compressed spit. All of them - all the CW sites, were under provisioned for backhaul. reply TallTales 10 hours agorootparentprevYeah network vision was a disaster. I think in the market I helped built our average number of site touches was like 21 or 22 from construction complete to on-air. All the funds gathered from the high interest junk bond sale to fund NV was used very inefficiency because sprint lacked the expertise to not get taken for a ride by their vendors. reply Aloha 8 hours agorootparentIt was a shitshow, you'd have GD tell us a site was complete and show up and find no equipment or equipment on pallets. GD rather than the equipment vendors were the villains, it was subcontractor-o-rama, and no one was responsible for anything. There was one site I went to like six times to inventory non-existent equipment - never mind when they decided to preload the inventory but used the barcodes on the samsung gear that didnt match anything.. I escalated that to Ericsson and then Sprint directly (it mattered for ericsson, because they'd have failed ATLAS audits), about two weeks later all that vanished, and we got a tranche of tickets to go reinventory everything. I also saw at least half a dozen sites, cut and in service still sitting on their pallets, such a mess. Imagine for a moment you go off to the crusades, leave the barn to one group, the fields to another group, and leave the house to a third group, then gleave no one in charge and give them no way to communicate beyond the most informal means - and you're surprised everything is on fire upon your return? In the end it did work once it was done, but it was only hell for the customer during deployment because it was deployed and cut in a hopscotch fashion, which would be fine, if you could roam from new back to old - there was a one way roam, from old to new, once on new, there was no path to roam back. reply explorigin 12 hours agorootparentprevLet's not forget the amazing Palm Pre that was released 18 months too late. If it could have been released on time, it might have done much to save Sprint. But by the time it was released it was merely competitive instead of compelling. reply hedora 17 hours agoparentprevThe regulators could have forced the big four carriers (now three) into a common carrier model. In that setup, all cell providers would effectively be an MVNO, and the three (then, four) physical networks would be operated at arms length from the consumer facing side. Also, the four networks could be structured so that their financial incentives were to improve cell coverage and bandwidth instead of undermining each others' operations. reply kelnos 17 hours agorootparentThat's kinda orthogonal to the merger deal, though, no? The government could do that today, if there was the political will to do so. Of course there isn't, though, and the merger (or lack thereof) didn't change that. reply aiauthoritydev 16 hours agorootparentprevThe best way to resolve these issues is never \"force the bad guys to do good things\" but rather destroy the walls which enable their rent seeking. Regulators can work to make it extremely simple for new techs in this space to come up so there is real competition for ATT etc. reply cyberax 14 hours agorootparent> The best way to resolve these issues is never \"force the bad guys to do good things\" but rather destroy the walls which enable their rent seeking. The walls here are defined by physics. There's only so much spectrum to go around. You can't have more than 3-4 large cell phone operators working in the same area. Decoupling the radio part and forcing everyone to play as MVNOs is a way to work around this. reply chris-smith 5 hours agorootparentThat sort of decoupling could be fascinating. IMO, the walls may be as much a function of economics as physics. Running a small number of powerful radios on low-frequency spectrum is a cost-effective way to cover large areas. Physics constrains how much of that can happen in the same area. But if networks are willing spend cash, they can get a ton of capacity by densely deploying high-frequency radios. Don't think we're anywhere near hitting the walls on what's possible there. Putting this another way, networks provide enough bandwidth for everyone in Manhattan. It's just expensive. reply ethbr1 11 hours agorootparentprevOr as I once heard by way of explanation: the capacity of an early analog cellular ~30km AMPS cell was ~60 simultaneous calls. Modern protocols do magic things with spectrum efficiency, but there's only so much you can do. reply HumblyTossed 15 hours agorootparentprevWe the People should own infrastructure. Want to start a new shipping company to compete with UPS? You don't have to build roads, We the People provide those to you. So, do the same with wireless. reply aiauthoritydev 14 hours agorootparentNothing prevents you from working with liked minded individuals to create your own \"infra\". The phrase \"we the people\" sounds cool but in reality what you mean is \"your money, my idea\". Roads is a very common argument, but none of the roads are build by \"we the people\". Government takes your money by force irrespective of how you think it should be spent and then a completely unaccountable red tapy system that employs otherwise unemployable people decides how to spend it. After a massive waste you have some roads which are poorly built even worse maintained. There is no need for roads to be public infrastructure. It can be fully privatized and people be asked to pay for its use. (While entire compontent of taxes that go towards road building be returned back to the people.) We will have better roads, less traffic and more money in pocket with that model. reply johnnyanmac 7 hours agorootparent>a completely unaccountable red tapy system that employs otherwise unemployable people decides how to spend it. The \"accountability\" is people voting in/out politicians. I agree they need more accounability, but in this case the folly falls on the ignorant for not properly researching who will lead and manage their towns. >There is no need for roads to be public infrastructure. It can be fully privatized and people be asked to pay for its use. Sounds like an awful idea. Land isn't infinite, so it falls into the same problem we have with housing. Lots of inefficiently crafted roads and a nightmare of tolls to manage based on the route you take. Which finals down to a few big boys either battling for the best roads, or worse, colluding with each other to keep tolls high. Navigation now has to incorporate not only for physical distance, but approximate cost as well. I fail to see an upside here unless your underlying narrative is to force people onto public transportation. Even then that doesn't mean public transportation imroves for those with bad access (also managed by \"unaccountable red tapy system\")/ reply nerdbert 11 hours agorootparentprev> There is no need for roads to be public infrastructure. It can be fully privatized and people be asked to pay for its use. (While entire compontent of taxes that go towards road building be returned back to the people.) We will have better roads, less traffic and more money in pocket with that model. As evidenced by the many successful and popular real-world cases where it's played out exactly this way. For example, um, uh... reply HumblyTossed 14 hours agorootparentprev> Government takes your money by force Oh good grief. > We will have better roads, less traffic and more money in pocket with that model. I call bullshit. reply kbolino 12 hours agorootparentprevThere is no \"We the People\". There is a government, or really layers of government, composed largely of politicians and bureaucrats. Whether those people running the cellular network is good or not ought to be assessed on what actually exists or is reasonably possible, not appeals to vague abstractions. reply trinsic2 14 hours agorootparentprevThis is the biggest solution to the problem that many people seem to ignore. If you want your communities to prosper, then the public needs to own the infrastructure that companies provide services for. Full stop. Anything less is giving companies control over something they should not have control over. reply ethbr1 11 hours agorootparentI think there's an argument to be had on 'owned by the public, but operated by private industry.' Another on 'built by private industry, but owned by the public.' Government ownership isn't a panacea and has historically faultered when faced with innovative and expert requirements. But I do think anything that trends towards monopoly makes sense as 'let the public own the simplest level, exposed via standards, and innovation happen above and/or below that.' reply JumpCrisscross 15 hours agorootparentprev> We the People should own infrastructure Going 4 to 3 sucked, letâ€™s go all the way to a state monopoly! reply HumblyTossed 13 hours agorootparentRight, because we only have one single shipping company using all the roads... reply dTal 14 hours agorootparentprevIt didn't suck for the shareholders of the remaining 3. With a state monopoly, we'd all be shareholders. Win! reply chrisco255 12 hours agorootparentprevAnd yet even with all that infrastructure, the market has coalesced around 3-5 shipping companies for vast majority of consumer shipments. reply nradov 14 hours agorootparentprevThat's a terrible idea. If the government owned wireless infrastructure then we'd still be stuck with 1G analog service. Competition between private cellular carriers is the primary factor driving innovation. reply RF_Savage 3 hours agorootparentprevIn USA the CBRS band allows running real LTE or better, real 5G SA on very lightly licensed spectrum. All kinds of more experimental community networks make use of it. Even better, Magma core is a free 5G core and multiple vendors like Baicells make cheap 5G CBRS base station hardware. CBRS also fully overlaps international 3.5GHz 5G bands, so phones and modems are cheap. reply pjc50 16 hours agorootparentprevRegulators cannot magic spectrum into existence. reply babypuncher 16 hours agorootparentprevThe problem is that there is finite spectrum available. The upfront cost of building a national cellular network are also astronomical, regardless of regulatory hurdles. The FCC was created to manage the scarcity inherent to the radio spectrum. It's not an area where regular free market economics apply. GP's proposal would actually make it easier for startups to horn in on the territory of the big established players, since the underlying infrastructure would effectively be socialized. reply chrisco255 12 hours agorootparentThere are finite amounts of everything. Free market economics solve this problem all the time. There are finite amounts of food, land, energy, shelter, human resources, etc. The problem isn't that spectrum is finite, it's that there is no way to prevent interference. It's questionable if the FCC is really optimal though. There are huge amounts of spectrum still devoted to dying industries like AM/FM radio and broadcast television. reply specialist 14 hours agorootparentprevOut of curiosity: What are some examples of \"regular free markets\"? reply issafram 17 hours agorootparentprevI mean Sprint was strictly CDMA, so that would be an issue on it's own. reply Aloha 14 hours agorootparentCDMA, from an RF performance perspective regularly outperformed GSM, but as is noted downthread, the provisioning/auth system was inherited from AMPS/D-AMPS, CDMA2000 with a GSM network core would have been amazing. Which, tbh, is exactly what LTE is. reply chimeracoder 17 hours agorootparentprev> I mean Sprint was strictly CDMA, so that would be an issue on it's own. How so? Sprint operated 4G LTE, which is a GSM technology (or alternatively, unified the two, depending on how you look at it). reply neelc 16 hours agorootparentThe reality is, when a CDMA carrier deploys LTE without deploying UMTS, there are usually compatibility layers between CDMA and LTE such as CSFB and eHRPD for when VoLTE is absent. CDMA was never designed to interoperate with LTE as LTE was built around IMEIs and SIM cards but CDMA was built around burned-in ESNs and PRLs, so LTE support was hacked on. This is why Sprint and Verizon used whitelists: they literally couldn't accept GSM-only devices because you wouldn't be able to make a phone call (the phone would try UMTS but only the non-supported CDMA2000 can be used to actually call, so in turn no phone calls). Sprint went further by using the CDMA provisioning system on top of LTE instead of just using SIM cards and 3GPP provisioning like most GSM and CDMA carriers. This was a nightmare for custom ROM users like me as custom ROMs were designed for GSM carriers in mind and Sprint was at best an afterthought. reply Tyrannosaur 16 hours agorootparentprevI once got tossed out of a sprint store for pissing off a salesperson with this factoid. reply chimeracoder 16 hours agorootparentThis is a story that's just begging for more detail reply Tyrannosaur 15 hours agorootparentMeh, I was a smart-alec kid there with my friend. The salesperson had to go get a sim card \"for the LTE to work\" and I said \"oh right, because LTE is GSM and requires a sim\". The salesman insisted Sprint didn't use GSM so I looked up the wikipedia page for LTE on one of their demo phones and started reading out loud \"In telecommunications, long-term evolution (LTE) is a standard for wireless broadband communication for mobile devices and data terminals, based on the GSM/EDGE and UMTS/HSPA standards.\" That's when the salesman told me to leave. reply lagniappe 15 hours agorootparentprevSprint also had Wimax https://www.rvmobileinternet.com/farewell-wimax-sprints-orig... reply nradov 17 hours agorootparentprevSprint had started as CDMA. They were in the process of building a 5G network but lacked the capital necessary for competitive nationwide coverage. reply Aloha 14 hours agorootparentThey didnt start to build their LTE network until 2012-13. reply mchannon 18 hours agoparentprevA Sprint bankruptcy may have been inevitable, but Verizon and AT&T would have been forced to steer clear (a failed merger having made that inevitable). The private market would have provided a bounty of suitors for Sprint if it couldn't recover from bankruptcy. It may have emerged in a far weaker fourth place, but it would still be around. reply TheAmazingRace 18 hours agorootparentThe only other possible dark horse that could have emerged was either in US Cellular or Dish Network. However, I believe there were concerns with issues like market capitalization (in the case of US Cellular) or having different priorities (like Dish) that would have jeopardized a proper fourth option for the US. I'm not suggesting the merger was \"good\" or anything like that. Just that the other options seemed quite unlikely. reply derefr 17 hours agorootparentAs a Canadian (so possibly biased here), my own hypothesis for what would happen if a sufficiently-large long-tail power vacuum emerged in the US cellular data market â€” either back then or today â€” is that one of the major Canadian carriers would try to move in, beginning by serving cities just across the border from major Canadian cities. You could easily do cell-tower-maintenance truck-rolls from offices in Vancouver BC to towers in Seattle or Portland; from Toronto to Buffalo (or, less plausibly, to Chicago); or from Montreal to Boston. And that's only if they even bother to operate towers â€” if they tried today, they could just as well operate as pure MVNOs. In fact, flagship plans on Canadian carriers today, already usually build in no-cost full-speed US roaming data access through partnership with US carriers operating on the same frequency bands. It's a very short distance from there to operating an MVNO atop the same carrier's network. (I would say that I'm surprised they haven't tried to do this already; but until recently, Canadian carriers were addicted to the extremely-high-profit-margin rate plans they built up through oligopolist price fixing. Our current government has seemingly broken that up for now, with much cheaper plans finally appearing â€” so they might finally decide it's time to expand their TAM to stay profitable.) reply Aloha 8 hours agorootparentprevUS Cellular is actually pretty probably, same tech stack, same hardware, similar customer bases, but they didnt have acres of capital. The issue was the albatross of the debt from the Nextel merger. reply chrisco255 12 hours agorootparentprevThere is already a burgeoning dark horse competitor to the wireless companies: SpaceX. I believe within a few years Starlink will be a viable global wireless network. reply selimthegrim 17 hours agorootparentprevDish is already making a hash out of its mobile customers (Ting, etc) reply drewzero1 15 hours agorootparentWhat's wrong with Ting? reply selimthegrim 14 hours agorootparentHave you been a customer lately? reply rav3ndust 7 hours agorootparentI'm a current Ting customer for the last ~5 years and have had no issues with them. reply drewzero1 7 hours agorootparentprevYes, and haven't had issues with it recently... Was there some bad news I missed? reply selimthegrim 4 hours agorootparentThe reddit forum for Ting has a lot of complaints about billing issues, lack of eSIM support, and poor customer service (for the TMobile/DISH customers, of which I was one) reply CodeWriter23 16 hours agoparentprevSprint was cooked for one specific reason: parent company QWEST refused to do the prism-split of fiber cables into secret NSA colocation rooms like AT&T did. reply Aloha 14 hours agorootparentQwest never owned Sprint. reply CodeWriter23 6 hours agorootparentOk young'n In March 1998 Qwest announced it would acquire long-distance carrier LCI International Inc. for $4.4 billion. The deal created the fourth-largest long-distance carrier in the United States behind AT&T, MCI Worldcom, and Sprint Corp. The combined companies had about 5,800 employees and revenue of $2.3 billion. The acquisition gave Qwest 2 million long-distance customers and a well-established sales force. reply tomohawk 15 hours agorootparentprevHmmm - interesting! https://en.wikipedia.org/wiki/Joseph_Nacchio EDIT: more info here: https://www.eff.org/deeplinks/2007/10/qwest-ceo-nsa-punished... reply lxgr 17 hours agoparentprev> If this merger had not happened, I could have seen Sprint file for bankruptcy, with Verizon and AT&T picking the carcass clean. This situation seems extremely similar to the failed Spirit/Jetblue acquisition [1]. [1] https://www.bloomberg.com/news/articles/2024-03-04/jetblue-a... reply tw04 18 hours agoparentprevWhat makes you think someone else wouldnâ€™t have picked up the pieces? Whether that be dish/comcast/google, or just some private equity. Being acquired by a competitor wasnâ€™t their only exit option, and pretty much anything else wouldâ€™ve resulted in more competition. reply samtheprogram 17 hours agorootparentSprint had outdated technology w.r.t their infrastructure and cell towers, so an outside acquirer didnâ€™t make as much sense. It needed an existing player with more advanced infrastructure to take on the customer base, or a large investment in upgrading itâ€™s own infrastructure. reply hylaride 15 hours agorootparentPretty much this. Sprint bet the farm several times on ultimately dead-end tech (CDMA, WiMAX) and were too focused on other things to get ahead of technical evolution. They ended up saddled with debt by the end of it, which hampered any ability to actually upgrade their networks (another poster already pointed out the technical issues with running LTE without UMTS). By the time of the merger, the only things of any value they had was the spectrum and customer base to be moved over. An external acquirer would almost have to build from scratch after absorbing all the legacy costs and run the risk of inheriting Sprint's bad business decision culture or spending an enormous sum building out a new team. Of course, they'd still have to support the old and new setups at the same time for awhile as the new stuff was built out. The ROI would have been decades at best. With a merger with another telecom, people can be migrated over already existing infrastructure (with some upgrades to deal with new traffic) and have sprint's old spectrum slowly merged into the existing infra. I'm oversimplifying of course, but one gets the idea. reply Aloha 14 hours agorootparentprevBy the time they merged with T-Mobile, they had a fully modern LTE network - I know because I helped to deploy it. That never would have happened without Softbank buying them however. reply bityard 17 hours agorootparentprevIn an infinite universe of possibilities, you're right: a failing brand with a household name being acquired by a competitor is not the only possible outcome. But it is historically far and away the most likely one. reply ElevenLathe 17 hours agorootparentIsn't that circular reasoning? Regulators have to allow the merger because other outcomes are unlikely, but they are unlikely because regulators always allow the merger. If the merger is blocked, the probability of that outcome falls to 0, and the others' increase, no? reply hylaride 15 hours agorootparentYou're assuming anybody else would have wanted to acquire a debt-laden company with an enormous infrastructure deficit as they mismanaged the move to 4/5g. Sprint essentially was only valuable to a company with a better LTE/5G network already in existence that users could me moved to and then Sprint's old spectrum repurposed. Anyone else would have been left with many tens of billions in network upgrade costs. reply ElevenLathe 14 hours agorootparentIf the merger was blocked and no one else wanted to buy it whole, then their assets would get sold off and the proceeds divied up by creditors (and if anything was left after that, to shareholders), same as any other company. Why is this an unthinkable scenario? There would have been some market-clearing price for the Sprint brand name and CDMA network (possibly separately, or even the network itself parted out) and even if that price was zero, then it was the shareholders (and possibly creditors) who should have taken the bath, not the entire phone-using public. Allowing an anti-competitive merger simply because the alternatives for Sprint shareholders were bad is a bailout by any other name. reply hylaride 12 hours agorootparentThe sprint shareholders already took a bath going from over $80/share in 2000 to $5. Hard bankruptcy and selling off its network would have been disruptive to their remaining customers, more complex/expensive to unwind (causing more of the money to go lawyers), and would still result in 1 less major carrier, resulting in essentially the same thing. The results would have most likely been most Sprint customers eventually being part of the other carriers anyways. If there was a market clearing price for sprint, a private equity firm would have snapped it up - that didn't happen because there was too much debt to go on as its own entity. Could things have been done differently? Sure. A condition of the merger could have been guaranteeing MVNO access or selling off a portion of the spectrum (maybe that happened). But T-Mobile, combined with Sprint, went from being a distant competitor in subscriber numbers competitive. If sprint was \"sold off\" separately, T-mobile would most likely eventually run out of steam and end up like Sprint. They just wouldn't have the number of subscribers to amortize costs down the way AT&T and Verizon could. Keeping struggling, small players going somehow would likely of only delayed the inevitable. reply TheAmazingRace 18 hours agorootparentprevTo be honest, I truly do not know all possible ends, as I'm not an oracle. Based on the information I had at the time, I felt that this merger was the best option out of all of the ones being explored at the time. I'm happy to have been wrong about this if they went a different direction and it worked out better, but history is history. reply goda90 17 hours agoparentprevThat's what's going to happen with US Cellular: https://arstechnica.com/tech-policy/2024/05/report-t-mobile-... reply bogwog 18 hours agoparentprevI don't follow this industry at all, so I'm out of the loop. Are you saying Sprint could not have possibly reversed course? (E.g. through pricing or even new leadership) Sometimes when companies are trying to merge, executives from both sides will come out and say it's \"necessary\" and push the narrative that one or both will go bankrupt without the merger. In cases where that strategy doesn't work it, unsurprisingly, turns out to be a lie. The companies will just keep competing and figure out a way to operating as usual. (I remember reading not-too-long-ago about an example of this exact thing, but don't remember what it was) So personally, I don't trust anything a business says when a merger is on the table. reply briffle 16 hours agorootparentif memory serves, Sprint had huge debts racked up from buying Nextel, as well as buying massive amounts of spectrum for WiMAX. They also purchased Clearwire. But WiMax never actually happened, everyone went to LTE, so sprint did as well. The main reason they were attractive to T-Mobile is that large amount of spectrum they owned, which was very valuble for 5G. https://www.rcrwireless.com/20160401/featured/worst-week-bol... reply sumoboy 15 hours agorootparentA huge costly mistake for Sprint trying to grow subscribers. Nextel's network was incompatible with Sprints, just a ton of business and technical issues. Sprint was always trying to be on the forefront of technology whether wireless or fiber. They spent a ton money on a project called ION that was last mile fiber to businesses, ahead of there time but a ton of costs actually laying down fiber doomed it. Poor timing for a lot of ideas and projects I saw. Source: ex-sprint emp. reply TheAmazingRace 18 hours agorootparentprevTo be frank, I thought the merger was necessary at the time as a lowly shareholder, only a few dozen shares at best, based on what I could tell on financial reports. I really wanted Sprint to not be a complete mess and be strong again, but they made way too many boneheaded decisions back in the day and the chickens were coming home to roost. reply nradov 16 hours agorootparentprevSprint could not have possibly reversed course because they had already wasted too much capital on a failed WiMax network and couldn't afford to build a competitive nationwide 5G network. Their options for raising more capital weren't looking good. New leadership or a different pricing model wouldn't have changed that reality. reply afavour 16 hours agoparentprevI believe you but I also think there was a third path availableâ€¦ wasnâ€™t Dish going to buy them at some point, or something like that? Sprint were in dire straits but plenty of their core businesses seemed viable if placed in competent hands. reply Aloha 14 hours agoparentprevYou're spot on, I posted a long comment downthread elsewhere, but you're 100% correct here. Sprint lost money basically every year after they merged with Nextel (having to pay for rebanding was part of it). reply paul7986 14 hours agoparentprevDish network the supposed new 4th wireless carrier's goose is being cooked now and i bet will file for bankruptcy in the next year or so. Satellite pay TV is a dying to dead industry. reply fooey 18 hours agoparentprevWere they legitimately in financial straights? or was it the thing where they want to force regulators to allow the deal by blowing up their own company? For example, Albertsons is blatantly doing this so Kroger can acquire them. reply Aloha 14 hours agorootparentYes, they consistently lost money from 2008-2019. reply idontwantthis 18 hours agorootparentprevIs that why they are absurdly expensive compared to all of their competitors? reply fooey 18 hours agorootparentThey're paying out an excessive dividend that completely empties their cash reserves and makes operating the company unsustainable https://www.opb.org/article/2022/11/12/oregon-ag-files-court... reply intuitionist 15 hours agorootparentI donâ€™t have a real strong view on this specific situation one way or the other but itâ€™s relevant that the appeals courts pretty quickly threw out this suit and allowed Albertsons to pay the dividend. reply lupire 17 hours agorootparentprevCorporate bankruptcy is a scam. Any merger on auction should acquire existing debts, and execs should be a lien against wealth and future income. reply hylaride 14 hours agorootparentCounter-argument, moneylenders shouldn't loan money to companies doing this. And secured lenders have their protections. Anyways, they knew the game. Bankruptcy auctions are essentially debtors recouping as many of their costs as possible before writing off the rest (further minimizing future taxes). reply nradov 16 hours agorootparentprevWhat a ridiculous proposal. Eliminating corporate bankruptcy and making employees personally liable for business debts would wreck the US economy. If debtors take a haircut then it's their own fault for lending in the first place; no one is forced to buy corporate bonds and vendors always have the option of requiring cash on delivery. reply idontpost 16 hours agorootparent> making employees personally liable for business debts would wreck the US economy Letting employees loot the company for their own profit isn't any better. reply nradov 14 hours agorootparentShareholders and lenders already have the necessary legal tools to prevent employee looting, if they choose to use them. reply toast0 18 hours agoprevPost merger I went from a $25/month t-mobile plan to a $15/month t-mobile plan. Not entirely apples to apples, but close. My spouse went from $30/month to $25/month on Verizon for more data. And there's lots of options at https://prepaidcompare.net/ reply candiddevmike 18 hours agoparentThe problem with MVNOs, at least that I'm noticing as a Google Fi subscriber, is I believe MVNOs are deprioritized. In a congested area, folks who have direct service with Verizon or T-Mobile seem to have better reception and bandwidth than I do. reply codydh 17 hours agorootparentThere's a good guide to the prioritization (QCI) of various carriers here: https://www.reddit.com/r/NoContract/comments/oaophe/data_pri... reply afavour 16 hours agorootparentIt feels crazy-making to me that information like this only exists in Reddit threads. Prioritization is, IMO, a totally valid way to price differentiate. But it should be clearly stated when youâ€™re buying in the same way GB data limits are. reply dragontamer 18 hours agorootparentprevAre you using a Google Pixel 6/7/8 ? Its widely accepted that Google Pixel's radio is weaker than the competition. Google stopped using Qualcomm chipsets on Google Pixel 6. (Or the last time Google used a Qualcomm radio in its phones was in Pixel 5 generation). I'm sure Google is working on making its radio better, but it still a shame that of all the things they decided to cut to make it cheaper / hit the $600 pricepoint (instead of the $800+ flagship tier) is... the radio. On the other hand, I hear that Qualcomm is basically raising prices behind the scenes, which is what's causing all of this in the first place. reply wyldfire 17 hours agorootparent> Qualcomm is basically raising prices behind the scenes > it still a shame that of all the things they decided to cut to make it cheaper / hit the $600 pricepoint (instead of the $800+ flagship tier) is... the radio. If it's truly a shame that they went to a lower-performing competitor then maybe Qualcomm thinks that their modem is worth more than they were charging because they provide a superior product. reply callalex 14 hours agorootparentTrue but itâ€™s unclear how much the performance difference is from Qualcomm delivering value vs. Qualcomm destroying competitorsâ€™ value through blatant patent trolling. reply dragontamer 10 hours agorootparentI admit that it seems to be an abuse of the patent system in some regards. But its not patent trolling. Qualcomm is making a real product and truly selling it. Anyone who wants that product is allowed to buy from Qualcomm or even license it for their own use. A \"Patent Troll\" is someone who has no intention of even making the product, sitting on the patents suing everyone. Its far worse than what Qualcomm is doing here. In effect, a \"Patent Troll\" kills the technology. The \"troll\" has no ability (or intention) to actually make the tech, yet still prevents everyone else from making the tech. reply Dylan16807 14 hours agorootparentprevHaving a better product and charging more for it very quickly becomes overcharging in a market that has such limited competition. Their premium was very very likely already plenty. reply dangus 16 hours agorootparentprevBingo. They do. Apple bought Intel's modem unit but they still use Qualcomm modems. https://www.theverge.com/2023/9/21/23883565/apple-5g-modem-f... reply dragontamer 10 hours agorootparentprevReplying to myself to add a bit of thought. Deprioritization has no effect on your radio signal. What it means is that your radio has connected just fine, its just waiting for everyone else to talk before you can talk. If you really were getting a bad signal, then... that's a Radio module problem. So I'd check to see if your radio was below par (ex: Pixel 6/7/8, or the myriad of midrange phones like Samsung A(whatever)). Qualcomm quality radios cost a lot extra these days, unfortunately. reply rs999gti 17 hours agorootparentprevI have a Pixel 7 Pro, the mobile connectivity is hot trash. reply mattgreenrocks 17 hours agorootparentprevNot all MVNOs are deprioritized. Many are, but the Reddit thread mentioned in a sibling comment outlines it well. Been with Verizon Wireless for 20 years. Got sick of how expensive their entry level 5G plan was with deprioritized data. Switched to US Mobile a few months ago. Half the price month-to-month, good prioritized data pool (35GB), and 5G UW access. reply havaloc 16 hours agorootparentThe US Mobile CEO is active on their subreddit and is attempting interesting things, such as allowing you to port between 2 major carriers (and soon all 3) up to 8 times a month as needed, and a beta of dual carrier coverage at a reduced price. https://www.reddit.com/r/USMobile/ https://www.reddit.com/r/USMobile/comments/1bl7qf4/hey_you_y... https://www.reddit.com/r/USMobile/comments/1cjn4qa/launching... reply newhotelowner 14 hours agorootparentPlus International calling is included, and adding cheap/free/included international roaming. reply sgerenser 18 hours agorootparentprevMVNOs are definitely often deprioritized, as I experienced with Visible wireless where I'd often have no data access despite having 2-3 bars of service. Switched a year or two ago to US Mobile which is apparently one of the few that is not deprioritized on the Verizon network (bizarrely as long as your phone is 5G capable, even when only using 4G). So there's options out there without paying $70/mo for Verizon postpaid. reply tssva 17 hours agorootparentVisible is 100% owned by Verizon and therefore technically not a MVNO. I use Visible and my wife is on Verizon. Her service is provided through her employer. Sometimes she has better data than I do and sometimes I have better data. For instance during a recent trip to Puerto Rico she struggled to receive reliable data and I had no issues. Donâ€™t think it has anything to do with prioritization. I recently upgraded to the yearly Visible+ plan since I added an Apple Watch and will be traveling to Vancouver frequently in the next year. It includes 50GB of Verizon premium tier data and then you fall back to whatever prioritization normal Visible has. It also includes 2GB a day in Canada and Mexico along with Apple Watch service. $395 for the year which is around $32.92 a month. reply codydh 17 hours agorootparentprevI believe if you get the higher-priced Visible plan (Visible+), you have higher/equivalent to postpaid priority. I switched to this plan a year ago from Verizon, in an area where being deprioritized on any of the carriers means it's useless much of the day, and it's been great. reply peter_l_downs 15 hours agorootparentprevFor anyone wondering, voice/data on Visible's entry-level $25/mo plan is deprioritized in times of congestion, and their $45/mo plan is not. Hotspot usage is throttled on both, differently. You can read the full details on their plans page [0] by pressing the \"Get all the details\" buttons. Visible $25/mo: > Typical 4G LTE & 5G download speeds are 9-149 Mbps. Video streams in SD. In times of traffic, your data may be temporarily slower than other traffic. > Visible includes mobile hotspot with unlimited data at speeds up to 5 Mbps. Video streams in SD. While more than 1 device may be connected to your Hotspot at one time, a single connected device will experience optimal speeds. Performance will be reduced if multiple devices access data through the Hotspot simultaneously. Actual data speed, availability and coverage will vary based on device capabilities, usage, your location and network availability. Service is not available while roaming. Visible $45/mo: > Visible+ gives you unlimited premium data on Verizonâ€™s 5G Ultra Wideband network, the fastest 5G network access we offer â€” up to 10X faster than median 4G LTE speeds. Premium data means no data slowdowns due to prioritization. Download apps, games, entire playlists and TV series in seconds. > Visible+ also gives you 50 GB/mo of premium data on Verizon's award-winning 5G & 4G LTE networks when 5G Ultra Wideband is unavailable. Premium data means no data slowdowns due to prioritization. > Typical 4G LTE & 5G download speeds are 9-149Mbps. Video streams in SD. After 50 GB, in times of traffic, your data may be temporarily slower than other traffic. [0] https://www.visible.com/plans/ reply bearjaws 18 hours agorootparentprevGoogle Fi is not deprioritized AFAIK and it's been discussed in the MVNO subreddit a bit. That being said, most ARE and they are damn near unusable now in places that are growing. Here in Orlando, Mint mobile can't even stream Spotify if you are stuck in traffic, that's how bad it has gotten. Forget being downtown or at an event of any kind. I use Google fi specifically because its not lower priority. reply zitterbewegung 17 hours agorootparentprevI buy service from this company that is a MVNO and is a prioritized cellular company : https://xcapeinc.com/mvnovoice.html You arenâ€™t going to get service that is cheap but they do offer things like static IPs and peering. reply kevin_thibedeau 12 hours agorootparentprevMint is part of T-mobile now so it shouldn't be deprioritized any more. reply chris-smith 5 hours agorootparentI think it'll continue to be. T-Mobile needs to differentiate services somehow & last I checked, subscribers on T-Mobile's older in-house + low-cost brand, Metro, generally received low priority relative to customers on T-mobile-branded plans reply lotsofpulp 17 hours agorootparentprevThereâ€™s different levels of priority within the same mobile networks, at all of them. MVNOs are just a price discrimination tool. Itâ€™s all the same electromagnetic waves being sold at different price points and priorities. ATT just increased their higher priced consumer plan by $7 per month. reply KingFelix 17 hours agoparentprevStetson Dogge has created an awesome tool here - It's a crazy breakdown similar to the site you linked but with a bit more https://airtable.com/appQ7TstG5Wn17FjY/shrraH105YVJQF2Yr/tbl... and he made a website comparison as well https://www.bestphoneplans.net/ reply aidenn0 14 hours agorootparentNice; doesn't include my MVNO (Ting) though. reply joshstrange 13 hours agoparentprevI wish there was an equivalent of https://prepaidcompare.net/ for IoT. I had to scour a bunch of different providers and often call/email for pricing to put together a list of options in a spreadsheet. I needed cellular service for iPads but they are only used a handful of times a year (normallyVisible, and I can honestly say I haven't noticed any difference in performance. My bill is significantly lower though, which I do enjoy. reply mattgreenrocks 17 hours agorootparentLooks like that's only on the nicer plan? reply Alupis 17 hours agorootparentLooks like you're right. I pay $35 a month for my line - there's some $10 monthly credit they applied to my account. With their annual payment option, it's $33 monthly. reply tssva 17 hours agorootparentprevThe new yearly Visible+ plan has 50GB of non-deprioritized data a month, not that I ever really had an issue on the normal Visible plan, free calling in Canada and Mexico, 2GB of data a day in Canada and Mexico, double the tethering speed and a free global pass per month. It is $395 which works out to $32.92 per month. reply bearjaws 18 hours agorootparentprevVisible is really good, only reason not to use them is when you have to travel internationally a lot. reply throwaway5959 18 hours agorootparentprevIâ€™ve been on prepaid since at least 2015 and never have had a problem with roaming in the US. reply silisili 17 hours agoparentprevI went from a $15/mo Mint plan to a $0/mo Dish plan. So, worked for me I guess? reply walterbell 14 hours agoprevA government condition of the merger was that T-Mobile had to offer low-cost prepaid plans without an MVNO. The program is called T-Mobile Connect, https://clark.com/cell-phones/connect-by-t-mobile/ & https://coveragecritic.com/t-mobile-connect-review/ & https://prepaid.t-mobile.com/connect/phone-plans Monthly price for USA-only unlimited talk/text + 5G/LTE data, is $15/5GB, $25/8GB, $35/12GB + taxes/fees. Outside USA, T-Mobile pSIM Wi-Fi call/text continues to work with cellular/eSIM data from 2nd line. Eskimo has 2y (\"global\", excluding Argentina, Brazil, Chile, Qatar, Maldives, Morocco, Oman, Portugal, Singapore, South Africa) and 1y (regional) data eSIMs for about $4/GB, https://www.eskimo.travel reply baby-yoda 10 hours agoparentIIRC, Connect was proposed as a 5 year solution, I fully expect T-Mobile to discontinue Connect as soon as possible. reply walterbell 6 hours agorootparentMerger was in 2020, which implies that Connect ends next year. If 2024 wireless price competition is lacking, can US regulators extend Connect beyond 2025? reply chris-smith 5 hours agorootparentNo, but I won't be surprised if the plans stick around longer. Speculating here, but I think odds are good T-Mobile continues to offer them for longer than required & just stops the annual data increase it has been doing reply endo_bunker 14 hours agoprevThis is full of central-planning nonsense. He wants lower prices, but is also mad when the company does layoffs. US consumers probably have some of the highest if not the highest demand for mobile data in the world, and the cost of living is already higher regardless, yet he acts shocked that American consumers pay more for mobile data. Not to mention the fact that I pay $15 for a very reasonable Mint mobile plan that would probably suffice for upwards of 80% of American consumers. reply ummonk 14 hours agoparentI agree with your general point. However, we don't have particularly high mobile data usage. Countries with subscribers that use mobile to the exclusion of broadband (e.g. India) have higher mobile data usage per subscriber. reply icedchai 14 hours agoparentprevYep, you can get cheap plans like that through T-Mobile MVNOs or even their own prepaid plan. I'm generally near wifi all the time. A couple gigs of data a month is fine for me. reply treis 17 hours agoprevAm I missing something or is there no actual evidence in the article that proves the title? All I can see is a comparison between countries. Which is pretty weak evidence in general and definitely doesn't show anything about what happened in the US after the merger. reply DataDive 17 hours agoprevDid it kill price competition? My anecdotal observation is that there are more cheap phone plans now than, say, five years ago. reply dmazzoni 6 hours agoparentIt seems to have created a two-tier system. You can get a \"real\" monthly plan from AT&T, Verizon, or T-Mobile for $50/month with unlimited data and prioritization. Or you can get a prepaid plan with data caps and no prioritization for $15 - 25 / month. reply phonon 5 hours agorootparentUS Mobile has prioritized data. https://www.usmobile.com/blog/unlimited-premium-coverage-on-... reply brink 15 hours agoparentprevSame. I can get an unlimited prepaid plan at $25/mo on AT&T. I remember unlimited plans being like $70 when Sprint was around. reply yuliyp 18 hours agoprevI'm struggling to feel the lack of price competition here in the US. It feels like mobile service has continually improved over time with fairly constant competition from MVNOs serving to experiment with different pricing models, as bandwidth has continued to be deployed. T-Mobile needed that Sprint merger to remain a viable nationwide competitor to Verizon and AT&T, and now they've done that. reply aiauthoritydev 16 hours agoprevMobile scene in USA is much improved than 10 years ago in my opinion. ATT/Verizon were too expensive and T-Mobile despite that poor service made a big difference. Google Fi has been my fav though as it gives me basic connectivity when I am abroad and cheap international calling to countries I care about. reply exabrial 18 hours agoprevDOE needs to stop approving mergers and acquisitions over $150 mil or so. Every such merger: Facebook/Instagram, Google/Youtube, etc has been a disaster. reply TeaBrain 18 hours agoparent$150 million is way too low today. Nearly every small acquirable company will meet that threshold. I do think that a limit could possibly be set though for companies with significant market share in the same sector. The Sprint acquisition was over $20 billion. Exxon's acquisition of Pioneer last year was around $60 billion. reply lolinder 18 hours agoparentprev> Google/Youtube Just a reminder that Google purchased YouTube in October 2006, about 18 months after it launched. Google already owned YouTube when \"Charlie Bit My Finger\" went viral in 2007. Google owned YouTube before they launched Chrome, back when they were still the heroes of the internet. There might be some people who are still nostalgic for a pre-Google YouTube, but for most people the better times that they're remembering were still part of the Google era. The acquisition didn't ruin YouTube, Google ruined YouTube about 10 years later when Google as a whole pivoted for the worse. reply vl 16 hours agorootparentYouTube as we know it today is only possible with Googleâ€™s acquisition. YouTube burned through literally billions of dollars for many years until it became profitable much later. Only likes of Google could have bankrolled it. Google did this intentionally to destroy all competition in the video space. Ultimately successfully. reply bklyn11201 18 hours agoparentprevWhat do you think would happen to the venture-capital-funded tech ecosystem and the resulting tech salaries if this were to happen? reply exabrial 17 hours agorootparentThe hope would be a vast increase in employers available rather than consolidation down to FAANG, increasing demand and driving salaries up. reply mavelikara 17 hours agorootparent> increasing demand and driving salaries up. Despite the demand, the revenue per employee for the company might be low, and those companies might not be able to pay high salaries to employees. reply zer00eyz 16 hours agorootparentdo you know how easy it is to get to a million bucks a year in revenue? Do you know how easy it is to have that pass 50% margin? 75? If you know how to build a stack, and have a useful service finding people to pay 20 bucks a month for it is not that hard. 5000 users is a fairly low target... reply coldpie 16 hours agoparentprevYeah. The FTC under the current admin has done more anti-merger work than in the entire rest of my lifetime. I intend to do my part to let them continue on that path this November. reply nceqs3 17 hours agoparentprevDOE? The Department of Energy? reply mikestew 16 hours agorootparentDepartment of Education. https://www.ed.gov I can only assume a typo in the comment. reply exabrial 14 hours agorootparentyeah, DOJ apologies reply nashashmi 18 hours agoparentprevThey were great investments for soon to be has beens. And helped the acquisition flourish too. reply jahewson 17 hours agoparentprevâ€œLetâ€™s just abolish capitalismâ€. Seriously though, a world in which the government runs the economy and picks the winners is a bad one indeed. reply throwway120385 16 hours agorootparentWhere in the parent comment does it say that? reply robertlagrant 18 hours agoparentprevGoogle and YouTube seems pretty good. YouTube is the most old school webby experience I have these days, although now in video form, now that the web web is so walled off. reply chris-smith 5 hours agoprevI'm sympathetic to a lot of the points here, but a key part of the story got left out: T-Mobile's performance used to suck vs. Verizon and AT&T. When T-Mo's network was crummy, the company to differentiated itself by being cheaper and less gimmicky than its competitors. I'm not too surprised T-Mo is adjusting its strategy as the company's network narrows the gap w/ VZW + AT&T. T-Mobile's performance was probably trending in a good direction even w/o the merger, but acquiring Sprint (and Sprint's spectrum) likely helped improve performance a good bit. reply EVa5I7bHFq9mnYK 14 hours agoprevPrices were always high in the US, before and after that merger. I think part of it is due to the low intelligence of an average US consumer, who wants to have his iphone \"for free\" with the contract, and is unable to calculate the real price he is paying. reply ensignavenger 16 hours agoprevIt is hard to imagine mobile prices for a national network the size of the US. I pay less than $30 per month total for 3 lines. maybe it would be cheaper if the Sprint/TMobile merger never happened, but the adticle doesn't seem to present any hard evidence. reply maxsilver 16 hours agoparentHow exactly are you doing that? The average price of a standard-feature line (i.e., not a MVNO with strict deprioritization) is approximately $70 USD a month (including taxes and fees, but not including any phone subsidy or equipment plans) Even a strict hyper-cut-down MVNO (say something like Mint Mobile) is still about $20 a month per line on average, for their cheapest plan. And T-Mobile acquired Mint, so it's pricing will almost certainly rise in a year or two. (T-Mobile did the same thing to Metro when it acquired their network + subscribers, prices were doubled after a few years) reply ensignavenger 16 hours agorootparentUS Mobile, an MVNO, I am on the Verizon network as they have slightly better coverage in the outskirts around me. I have never had any trouble with deprioritization. reply voisin 18 hours agoprevIâ€™d love to see an economist tease apart the contribution of industry consolidation to inflation and wage suppression. reply jahewson 16 hours agoparentSeveral have! Thereâ€™s no consensus on the relationship though. Some cases it does, some cases it doesnâ€™t. Unions are a big factor. reply Animats 16 hours agoprevFour. As in a European study, price competition requires four significant competitors.[1] This should be a basic rule of antitrust regulation. [1] https://www.techdirt.com/2024/05/16/report-sprint-t-mobile-m... reply onlyrealcuzzo 19 hours agoprevAh, yes, that's what did it, not the reunification of Ma Bell. reply dehrmann 17 hours agoparentWe're in a better spot then with the AT&T monopoly because there are three viable carriers almost everywhere. The Baby Bells were local monopolies, and you had to get long distance service from the national monopoly. I never understood how people see that as a win. reply blihp 16 hours agorootparentThe point being made is that AT&T should have never been allowed to reform itself as it did, probably along with numerous other acquisitions/mergers that the government approved that they should not have. There was a period of time late in the last century when many of us had numerous (i.e. 5-6) options for a while. reply vl 16 hours agorootparentAT&T we have now is not really related to this old evil AT&T. Actual company that uses this brand in mobile space is used to be called Cingular. They bought AT&T remains and promptly rebranded. reply dragonwriter 16 hours agorootparent> AT&T we have now is not really related to this old evil AT&T. Yes, it is. > Actual company that uses this brand in mobile space is used to be called Cingular. So, in the beginning there was AT&T, the telephone monopoly. It was broken up into 7 RBOCs (Regional Bell Operating Companies, also called â€œbaby bellsâ€) providing local service (each of which got a corresponding chunk of the AT&T subsidiary doing mobile work as their own mobile subsidiary), and the reduced AT&T, which did long distance, and some other things. There were also two other local service providers (which, before the divestiture, werenâ€™t AT&T subsidiaries but did partial AT&T control.) The modern AT&T is the result of mergers of, among other things, the long-distance AT&T and 4 of the 7 baby bells. As part of the road to getting there, Cingular Wireless, which was formed as joint venture of two of the Baby Bells (SBC, which had already acquired Pacific Telesis, one of the other Baby Bells, and BellSouth) from their mobile units and other mobile and other firms (like, more than 100 in total), acquired AT&T Wireless (not AT&T), which became part of Cingular (which was still an SBC/BellSouth joint venture) Then AT&T merged with SBC, making Cingular an AT&T/BellSouth joint venture. Then it was announced that the AT&T brand would be used for Cingular service when packaged with AT&T services. Then AT&T bought BellSouth, making Cingular an AT&T/AT&T joint ventureâ€¦or, rather, just part of AT&T. So AT&T is the old long-distance AT&T after eating a bunch of other companies, but itâ€™s also a very large portion of the older monopoly AT&T. Part of the wireless business was Cingular for a while between being AT&T before and then being AT&T again. (This leaves out a lot of mergers that went into forming the current AT&T that are not related to the claim that some company called Cingular that was completely unrelated to the old AT&T bought some minor remnant of AT&T and clothed itself with the name.) reply kbolino 12 hours agorootparentVerizon (originally Bell Atlantic)'s history is much the same. There's even some back and forth between it and what is now AT&T over who gets what of the RBOCs and their spinoffs/successors. Now, if Verizon and AT&T merge, then Ma Bell really will be back. reply leeoniya 18 hours agoprevand they acquired Mint, which almost certainly means my $30/mo prepaid plan will disappear soon. reply stevenicr 18 hours agoparentReally sad to see the got Mint.. Cheers for the people that profited, but I feel this is a more serious blow than the sprint takeover. reply accrual 15 hours agoparentprevI don't know how long it will last, but Mint advised their rates were staying the same. https://www.cnet.com/tech/mobile/t-mobile-closes-mint-mobile... reply nerdkid93 18 hours agoparentprevCheck out US Mobile. They follow a similar ethos of prepaid plan, but you don't necessarily even need to sign up for months at a time like Mint. reply rqtwteye 18 hours agorootparentI just switched to US Mobile and so far it looks very good. You can even choose between Verizon and GSM networks. reply hersko 18 hours agorootparentprev+1 for US Mobile. Very happy with them. reply tiltowait 18 hours agoparentprevT-Mobile was the worst, most incompetent company I have had the displeasure of working with in recent years. I fled to Mint. To say Iâ€™m chuffed by that acquisition is an understatement. reply n00bskoolbus 18 hours agorootparentWait so are you really happy they got acquired? Or does chuffed mean something else in the states? reply dangus 16 hours agorootparentI think it was sarcasm...or just the word being misused. reply bagels 18 hours agorootparentprevI'm confused by this. You don't like T-Mobile, but you're happy you'll be returning? reply kevin_thibedeau 12 hours agorootparentLong ago I had a T-mobile prepaid plan that had the wrong caller ID info. They claimed it couldn't be fixed because it was prepaid and they were unable to properly manage those accounts. Mint has been much better and will remain cheaper for now. reply hersko 18 hours agoprevAnecdotally, i'm now paying far less then I used to for wireless service. $26/month on verizon's network for two lines through US mobile. reply mrosett 17 hours agoprevDoes this article actually provide evidence for the headline claim? reply meragrin_ 18 hours agoprevReally? In 2018, a voice only family plan was more than twice than a voice, text, and data plan I have today. Mind you, it just went down $10/month a few months ago so it isn't like all the price drops happened years ago. reply RIMR 18 hours agoprevThe only bright side to the merger was that T-Mobile inherited Sprint's permanent contract with Mobile Citizen, and now nonprofits can get extremely low prices on uncapped, unthrottled 5G hotspots from T-Mobile, something you can't get as a normal consumer. Before the merger, you were stuck with Sprint's not-so-great network, but after the merger you end up with all of T-Mobile's coverage and speeds exceeding 1gbps in some urban areas. If you meet certain income requirements, you can get one from one of Mobile Citizen's resellers (such as PC's for People) for around $15/month. Or, for like $400-500/year you can get one through the Calyx Institute as a \"gift\" for donors. There's no getting out of this contract either. It's part of a deal Sprint made when they took over $1B in taxpayer money to build out their LTE infrastructure. This is how they pay it back - forever. If you needed something to help swing the pendulum back towards the consumer, still, the merger wasn't good for wireless competition in the U.S. reply ComputerGuru 18 hours agoparentHow would one secure one or more of these for a non-profit? Thinking redundancy for current AT&T fiber hookup for the admin staff and voip gateway. reply nikolay 15 hours agoprevAbsolutely! T-Mobile started to increase prices with their newer plans, which offer less for more. reply nashashmi 12 hours agoprevMight be a change of guards that is causing this https://www.reddit.com/r/tmobile/comments/17tl1du/why_is_mik... reply ApolloFortyNine 14 hours agoprevThe graph they chose to use in the article has to be one of the main poster childs for 'correlation does not mean causation'. I don't know what's worse, not adjusting for purchasing power, or not adjusting for country size. Also targeting 100GB screams 'writer had an agenda' to me. My screen on time is absolutely atrocious and I still rarely get over 20gb a month. I'm guessing the stats must change if you choose a number that fits in most plans defaults. reply dragontamer 12 hours agoparentI use 2GB a month and I thought I was a doom-scroller... I guess 2GB of text / forums / newspapers is very different from like, Netflix every day on the phone though. reply paul7986 14 hours agoprevT-mobile for years and still is cheaper then ATT & i assume Verizon. I was paying $165 for 4 unlimited lines with mobile hotspot. Now with T-Mobile same level of svc is $130 a month. Its up in the air tho if the service is a reliable and good as AT&T as i do have issues with T-mobile .. echoes heard on calls, calls not going thru/just dropping instead of connecting and no service at all where i previously had it with ATT (in southern york county pa by MD line). reply toasted-subs 18 hours agoprevMaybe why I'm having so much difficulty working reply smm11 18 hours agoprevMint, or at least some time back. reply CodeWriter23 16 hours agoprev [â€“] Meh. Go with Consumer Cellular or other discount MVNO. Plenty of competition at that strata. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Allegations suggest Trump regulators may not have read deal impact reports, raising concerns about unethical behavior and corruption.",
      "The top antitrust enforcer allegedly collaborated with companies to secure government approval for deals, indicating potential misconduct within the Trump administration.",
      "Implications of corruption and unethical conduct among officials in the Trump administration are brought to light by the comment."
    ],
    "commentSummary": [
      "The article discusses the merger of Sprint and T-Mobile in the U.S., highlighting criticisms of reduced wireless price competition and Sprint's struggles due to debt and mismanagement.",
      "It covers challenges with Sprint's WiMax 4G network, the transition to 5G, and implications of Softbank's acquisition of Sprint on the U.S. cellular data market.",
      "Various viewpoints on industry consolidation, pricing, competition, technology, and service quality are examined, along with user experiences with different cellphone providers and plans."
    ],
    "points": 274,
    "commentCount": 233,
    "retryCount": 0,
    "time": 1715870320
  },
  {
    "id": 40379599,
    "title": "Optimizing ChatGPT-4o for Problem-solving: Text vs. Images",
    "originLink": "https://www.sabrina.dev/p/chatgpt4o-vs-math",
    "originBody": "0 Sabrina Ramonov Posts Test Driving ChatGPT-4o (Part 2) Test Driving ChatGPT-4o (Part 2) ChatGPT-4o vs Math Sabrina Ramonov May 16, 2024 Math Problem Problem Statement Solution Overview of Experiments 1. Prompt Only, No Image 2. Zero-Shot Chain-of-Thought 3. Dimensions Inside Image, Missing Data 4. Prompt and Image 5. Zero-Shot Chain-of-Thought and Image Conclusion In this series, I test drive OpenAIâ€™s multimodal ChatGPT-4o. For part 1, click here. Inspired by ChatGPT vs Math (2023), letâ€™s see how ChatGPT-4o performs. I want to know: can GPT-4o solve this problem by analyzing just the prompt? can GPT-4o solve this problem by combining prompt and image? can GPT-4o solve this problem with the help of prompt engineering? Math Problem Hereâ€™s the image of the math problem: Source Problem Statement There is a roll of tape. The tape is 100 meters long when unrolled. When rolled up, the outer diameter is 10 cm, and the inner diameter is 5 cm. How thick is the tape? Neil Fraser Solution Reduce the problem to 2 dimensions. Hereâ€™s an ASCII Unrolled Tape: â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬ Unrolled Tape Area = T * L L = length T = thickness Hereâ€™s an ASCII Rolled Tape: ,,ggddY\"\"\"\"Ybbgg,, ,agd\"\"' `\"\"bg, ,gdP\" \"Ybg, ,dP\" \"Yb, ,dP\" _,,ddP\"\"\"Ybb,,_ \"Yb, ,8\" ,dP\"' `\"Yb, \"8, ,8' ,d\" \"b, `8, ,8' d\" \"b `8, d' d' `b `b 8 8 8 8 8 8 8 8 8 8 8 8 8 Y, ,P 8 Y, Ya aP ,P `8, \"Ya aP\" ,8' `8, \"Yb,_ _,dP\" ,8' `8a `\"\"YbbgggddP\"\"' a8' `YbaadP' \"Yba adY\" `\"Yba, ,adP\"' `\"Y8ba, ,ad8P\"' ``\"\"YYbaaadPP\"\"'' Rolled Tape Area = \\pi (R^2 - r^2) R = outer radius r = inner radius The areas are the same! So we can easily solve for thickness T = 0.00589 cm Overview of Experiments Here are my varied experiments: Prompt only, no image Zero-shot Chain-of-Thought Dimensions inside the image, missing data Prompt and image Zero-shot Chain-of-Thought and image I run each experiment 3 times due to the probabilistic nature of LLMs. Despite the same input, there is no guarantee Iâ€™ll get the same outputs. I designed the experiments to evaluate the impact of: one modality (text only) multi modality (text + image) prompt engineering (Chain of Thought) Which approach leads to superior outcomes? Take a guess now and see if youâ€™re right ðŸ™‚ 1. Prompt Only, No Image First, I test one modality with no prompt engineering: I give GPT-4o the text prompt, without the image. There is a roll of tape. The tape is 100 meters long when unrolled. When rolled up, the outer diameter is 10 cm, and the inner diameter is 5 cm. How thick is the tape? 1st run â€” choke GPT-4o gives up after teasing me: â€œGiven the complexity, letâ€™s solve this equation numericallyâ€. ChatGPT-4o session @ sabrina.dev 2nd run â€” correct Yay! GPT-4o gets the right answer on the 2nd try, without the image, without any prompt engineering. ChatGPT-4o session @ sabrina.dev 3rd run â€” incorrect Unfortunately, the 3rd try was wrong. The probabilistic nature of LLMs rears its headâ€¦ ChatGPT-4o session @ sabrina.dev 2. Zero-Shot Chain-of-Thought Second, I test one modality, assisted by prompt engineering: I give GPT-4o the text prompt, without the image. Then I add a simple prompt engineering technique: Take a deep breath and work on this problem step-by-step. Sabrina Ramonov @ sabrina.dev Seems too simple, right? ðŸ˜… This prompt engineering technique is called Chain-of-Thought. Itâ€™s proven to improve ChatGPTâ€™s performance on logic and reasoning tasks by requiring it to explain intermediate steps leading to an answer. Full prompt: There is a roll of tape. The tape is 100 meters long when unrolled. When rolled up, the outer diameter is 10 cm, and the inner diameter is 5 cm. How thick is the tape? Take a deep breath and work on this problem step-by-step. 1st run - correct 2nd run - correct 3rd run - correct Quite a surprise, this absurdly simple prompt engineering technique resulted in 3/3 correct answers! ChatGPT-4o session @ sabrina.dev 3. Dimensions Inside Image, Missing Data Third, I test multi modality (image) and a minimal text prompt. I remove dimension data from the text prompt, so GPT-4o must analyze the image correctly to extract the tape rollâ€™s dimensions (radius and diameter). However, the length of tape unrolled is neither in the image nor text prompt. I expect GPT-4oâ€™s output to be something like, â€œwithout knowing the length we can't determine itâ€. Image uploaded to ChatGPT-4o There is a roll of tape with dimensions specified in the picture. How thick is the tape? 1st run - incorrect 2nd run - incorrect 3rd run - incorrect Sabrina Ramonov @ sabrina.dev Interestingly, ChatGPT-4o successfully analyzes the image to determine the outer diameter 10cm and inner diameter 5cm. But misinterprets the problem statement: GPT-4o interprets â€œhow thick is the tapeâ€ as referring to the cross-section of the tape roll, rather than the thickness of a piece of tape. Recall the original prompt which has: dimension data length of tape unrolled the concept of rolled vs unrolled tape There is a roll of tape. The tape is 100 meters long when unrolled. When rolled up, the outer diameter is 10 cm, and the inner diameter is 5 cm. How thick is the tape? Neil Fraser Missing this important context, GPT-4o shouldâ€™ve said it canâ€™t solve the problem. But it went ahead and tried anyway with a different interpretation, indeed a pretty reasonable interpretation given the data at hand. 4. Prompt and Image Fourth, I test multi modality (image) and a text prompt that includes the length of tape unrolled. There is a roll of tape with dimensions specified in the picture. The tape is 100 meters long when unrolled. How thick is the tape? Image uploaded to ChatGPT-4o 1 â€” choke Well, this is amusingâ€¦ GPT-4o notices its estimate seems unusually large and tries to course correct! But then it gives up... dying with a grammatically incorrect last sentence: I will re-calculation next response ChatGPT-4oâ€™s last wordsâ€¦ Sabrina Ramonov @ sabrina.dev 2 â€” incorrect The 2nd run is better, still wrong, but at least GPT-4o didnâ€™t choke. Sabrina Ramonov @ sabrina.dev 3 â€” correct Yay! GPT-4o finally got it right. 1/3 correct doesnâ€™t seem super reliable. I thought multi-modality would improve accuracy, but so far, it seems to create confusion. Sabrina Ramonov @ sabrina.dev 5. Zero-Shot Chain-of-Thought and Image Fifth, I test multi modality (image), a text prompt that includes the length of tape unrolled, assisted by Chain-of-Thought prompt engineering. Image uploaded to ChatGPT-4o There is a roll of tape with dimensions specified in the picture. The tape is 100 meters long when unrolled. How thick is the tape? Take a deep breath and work on this problem step-by-step. 1 â€” incorrect 2 â€” incorrect 3 â€” incorrect Wow, didnâ€™t expect that! Recall test #2 â€” text prompt with prompt engineering resulted in 3/3 correct. In this multimodal test, Iâ€™ve added the image as supporting context, yet all 3 answers are wrong. I mistakenly assumed more context would help. But notice GPT-4o incorrectly interprets 5cm as radius, instead of diameter: Sabrina Ramonov @ sabrina.dev Key takeaway: The emphasis here is consistency. Previously with Chain-of-Thought, I got the same answer 3 times in a row. But because GPT-4oâ€™s image understanding mistakenly thought 5cm was radius, not diameter, it was consistently wrong by a factor of 4. It seems GPT-4oâ€™s image understanding struggles with these finer details. Conclusion Reiterating my goal at the start, I wanted to know: can GPT-4o solve this problem by analyzing just the prompt? can GPT-4o solve this problem by combining prompt and image? can GPT-4o solve this problem with the help of prompt engineering? I tested single vs multi modality, as well as the prompt engineering technique called Chain-of-Thought. One Modality Prompt only, no image Zero-shot Chain of Thought Multi Modality Dimensions inside image, missing data Prompt and image Zero-shot Chain-of-Thought and image The Winner? One modality Text-only prompt with zero-shot Chain-of-Thought prompt engineering ðŸ¥³ Be honest, was that your first guess? This concludes part 2 of this series Test Driving ChatGPT-4o! For part 1, click here.",
    "commentLink": "https://news.ycombinator.com/item?id=40379599",
    "commentBody": "ChatGPT-4o vs. Math (sabrina.dev)267 points by sabrina_ramonov 18 hours agohidepastfavorite151 comments jcims 16 hours agoI posted the same 'Zero-Shot Chain-of-Thought and Image' to ChatGPT-4o and it made the same error. I then followed up with 'Your math is good but you derived incorrect data from the image. Can you take another look and see if you can tell where the error is?'. It figured it out and corrected it: Let's re-examine the image and the data provided: * The inner radius r1 is given as 5cm * The outer radius r2 is given as 10cm * However, the dimensions labeled \"5 cm\" and \"10 cm\" are actually the diameters of the inner and outer circles, respectively, not the radii. Then recomputed and got the right answer. I asked it if it could surmise why it got the wrong answer and it said, among a number of things, that math problems commonly operate in radii instead of diameter. I restarted with a slightly modified prompt: There is a roll of tape with dimensions specified in the picture. The tape is 100 meters long when unrolled. How thick is the tape? Examine the image carefully and ensure that you fully understand how it is labeled. Make no assumptions. Then when calculating, take a deep breath and work on this problem step-by-step. It got it the first try, and I'm not interested enough to try it a bunch of times to see if that's statistically significant :) reply yatz 13 hours agoparentOnce you correct the LLM, it will continue to provide the corrected answer until some time later, when it will again make the same mistake. At least, this has been my experience. If you are using LLM to pull answers programmatically and rely on their accuracy, here is what worked for the structured or numeric answers, such as numbers, JSON, etc. 1) Send the same prompt twice, including \"Can you double check?\" in the second prompt to force GPT to verify the answer. 2) If both answers are the same, you got the correct answer. 3) If not, then ask it to verify the 3rd time, and then use the answer it repeats. Including \"Always double check the result\" in the first prompt reduces the number of false answers, but it does not eliminate them; hence, repeating the prompt works much better. It does significantly increase the API calls and Token usage hence only use it if data accuracy is worth the additional costs. reply groby_b 11 hours agorootparent> Once you correct the LLM, it will continue to provide the corrected answer until some time later, That is only true if you stay within the same chat. It is not true across chats. Context caching is something that a lot of folks would really really like to see. And jumping to a new chat is one of the core points of the OP: \"I restarted with a slightly modified prompt:\" The iterations before where mostly to figure out why the initial prompt went wrong. And AFAICT there's a good insight in the modified prompt - \"Make no assumptions\". Probably also \"ensure you fully understand how it's labelled\". And no, asking repeatedly doesn't necessarily give different answers, not even with \"can you double check\". There are quite a few examples where LLMs are consistently and proudly wrong. Don't use LLMs if 100% accuracy matters. reply wahnfrieden 11 hours agorootparentprevvia api (harder to do via chat as cleanly) you can also try showing it do a false attempt (but a short one so it's effectively part of the prompt) and then you say try again. reply BOOSTERHIDROGEN 51 minutes agorootparentAre there any examples? reply kbenson 11 hours agorootparentprevI can't wait for the day when instead of engineering disciplines solving problems with knowledge and logic they're instead focused on AI/LLM psychology and the correct rituals and incantations that are needed to make the immensely powerful machines at our disposal actually do what we've asked for. /s reply mckirk 10 hours agorootparent\"No dude, the bribe you offered was too much so the LLM got spooked, you need to stay in a realistic range. We've fine-tuned a local model on realistic bribe amounts sourced via Mechanical Turk to get a good starting point and then used RLMF to dial in the optimal amount by measuring task performance relative to bribe.\" reply akoboldfrying 8 hours agorootparentRLMF: Reinforcement Learning, Mother Fucker! reply CooCooCaCha 15 hours agoparentprevThis speaks to a deeper issue that LLMs donâ€™t just have statistically-based knowledge, they also have statistically-based reasoning. This means their reasoning process isnâ€™t necessarily based on logic, but what is statistically most probable. As youâ€™ve experienced, their reasoning breaks down in less-common scenarios even if it should be easy to use logic to get the answer. reply 12907835202 15 hours agorootparentDoes anyone know how far off we are having logical AI? Math seems like low hanging fruit in that regard. But logic as it's used in philosophy feels like it might be a whole different and more difficult beast to tackle. I wonder if LLM's will just get better to the point of being indistinguishable from logic rather than actually achieving logical reasoning. Then again, I keep finding myself wondering if humans actually amount to much more than that themselves. reply ben_w 14 hours agorootparent> Does anyone know how far off we are having logical AI? 1847, wasn't it? (George Boole). Or 1950-60 (LISP) or 1989 (Coq) depending on your taste? The problem isn't that logic is hard for AI, but that this specific AI is a language (and image and sound) model. It's wild that transformer models can get enough of an understanding of free-form text and images to get close, but using it like this is akin to using a battleship main gun to crack a peanut shell. (Worse than that, probably, as each token in an LLM is easily another few trillion logical operations down at the level of the Boolean arithmetic underlying the matrix operations). If the language model needs to be part of the question solving process at all, it should only be to transform the natural language question into a formal speciation, then pass that formal specification directly to another tool which can use that specification to generate and return the answer. reply entropicdrifter 14 hours agorootparentRight? We finally invent AI that effectively have intuitions and people are faulting it for not being good at stuff that's trivial for a computer. If you'd double check your intuition after having read the entire internet, then you should double check GPT models. reply Melatonic 11 hours agorootparentprevBy that same logic isn't that a similar process that we humans use as well ? Kind of seems like the whole point of \"AI\" (replicating the human experience) reply dartos 9 hours agorootparentIn the same way that apples and oranges are similar in that they are edible fruit, yes. reply xanderlewis 14 hours agorootparentprev> Math seems like low hanging fruit in that regard. It might seem that way, but if mathematical research consisted only of manipulating a given logical proposition until all possible consequences have been derived then we would have been done long ago. And we wouldn't need AI (in the modern sense) to do it. Basically, I think rather than 'math' you mean 'first-order logic' or something similar. The former is a very, large superset of the latter. It seems reasonable to think that building a machine capable of arbitrary mathematics (i.e. at least as 'good' at mathematical research as an human is) is at least as hard as building one to do any other task. That is, it might as well be the definition of AGI. reply glial 15 hours agorootparentprevI think LLMs will need to do what humans do: invent symbolic representations of systems and then \"reason\" by manipulating those systems according to rules. Here's a paper working along those lines: https://arxiv.org/abs/2402.03620 reply dunefox 14 hours agorootparentIs this what humans do? reply ezrast 14 hours agorootparentThink of all the algebra problems you got in school where the solution started with \"get all the x's on the same side of the equation.\" You then applied a bunch of rules like \"you can do anything to one side of the equals sign if you also do it to the other side\" to reiterate the same abstract concept over and over, gradually altering the symbology until you wound up at something that looked like the quadratic formula or whatever. Then you were done, because you had transformed the representation (not the value) of x into something you knew how to work with. reply monadINtop 12 hours agorootparentPeople don't uncover new mathematics with formal rules and symbols pushing, at least not for the most part. They do so first with intuition and vague belief. Formalisation and rigour is the final stage of constructing a proof or argument. reply auggierose 14 hours agorootparentprevThat's what I am doing. I follow my intuition, but check it with logic. reply monadINtop 12 hours agorootparentprevNo. Not in my experience. Anyone with experience in research mathematics will tell you that making progress at the research level is driven by intuition - intuition honed from years of training with formal rules and rigor but intuition nonetheless - with the final step being to reframe the argument in formal/rigorous language and ensure consitency and so forth. Infact the more experience and skill I get in supposedly \"rational\" subjects like foundations, set theory, theoretical physics, etc. the more sure I am that intuition / belief first - justification later is a fundamental tenant of how human brains operate, and the key feature of rationalism and science during the enlightenment was producing a framework so that one may have some way to sort beliefs, theories, and assertion so that we can recover - at the end - some kind of gesture towards objectivity reply ryanianian 15 hours agorootparentprev(Not an AI researcher, just someone who likes complexity analysis.) Discrete reasoning is NP-Complete. You can get very close with the stats-based approaches of LLMs and whatnot, but your minima/maxima may always turn out to be local rather than global. reply slushy-chivalry 15 hours agorootparentmaybe theorem proving could help? ask gpt4o to produce a proof in coq and see if it checks out...or split it into multiple agents -- one produces the proof of the closed formula for the tape roll thickness, and another one verifies it reply jamilton 14 hours agorootparentI had the thought recently that theorem provers could be a neat source of synthetic data. Make an LLM generate a proof, run it to evaluate it and label it as valid/invalid, fine-tune the LLM on the results. In theory it should then more consistently create valid proofs. reply ryanianian 15 hours agorootparentprevSure, but those are heuristics and feedback loops. They are not guaranteed to give you a solution. An LLM can never be a SAT solver unless it's an LLM with a SAT solver bolted on. reply slushy-chivalry 14 hours agorootparentI don't disagree -- there is a place for specialized tool, and LLM wouldn't be my first pick if somebody asked me to add two large numbers. There is nothing wrong with LLM + SAT solver -- especially if for an end-user it feels like they have 1 tool that solves their problem (even if under the hood it's 500 specialized tools governed by LLM). My point about producing a proof was more about exploratory analysis -- sometimes reading (even incorrect) proofs can give you an idea for an interesting solution. Moreover, LLM can (potentially) spit out a bunch of possibly solutions and have another tool prune and verify and rank the most promising ones. Also, the problem described in the blog is not a decision problem, so I'm not sure if it should be viewed through the lenses of computational complexity. reply MR4D 15 hours agorootparentprev> Does anyone know how far off we are having logical AI? Your comment made me think of something. How do we know that logic AI is relevant? I mean, how do we know that humans are logic-AI driven and not statistical-intelligent? reply ryanianian 14 hours agorootparentHumans are really good pattern matchers. We can formalize a problem into a mathematical space, and we have developed lots of tools to help us explore the math space. But we are not good at methodically and reliably exploring a problem-space that requires NP-complete solutions. reply cornholio 14 hours agorootparentprevIt doesn't matter, if the chance of getting the wrong answer is sufficiently small. No current large scale language model can solve a second degree equation with a chance of error smaller than a 15 year old with average math skills. reply CooCooCaCha 14 hours agorootparentprevA smart human can write and iterate on long, complex chains of logic. We can reason about code bases that are thousands of lines long. reply MR4D 13 hours agorootparentBut is that really logic? For instance, we supposedly reason about complex driving laws, but for anyone who has run a stop light late at night when there is no other traffic is acting statistically, not logically. reply CooCooCaCha 10 hours agorootparentThere's a difference between statistics informing logical reasoning and statistics being used as a replacement for logic. Running a red light can be perfectly logical. In the mathematics of logic there is no rule that you must obey the law. It can be a calculated risk. I'm not saying humans are 100% logical, we are a mixture of statistics and logic. What I'm talking about is what we are capable of VS what LLM's are capable of. I'll give an example. Let's say you give me two random numbers. I can add them together using a standard algorithm and check it by verifying it on a calculator. Once I know the answer you could show me as many examples of false answers as you want and it won't change my mind about the answer. In LLMs there is clear evidence that the only reason it gets right answers is those answers happen to be more frequent in the dataset. Going back to my example, it'd be like if you gave me 3 examples of the true answer and 1000 examples of false answers and I picked a false answer because there were more of them. reply Royce-CMR 13 hours agorootparentprevSo for a whim, I took this to ChatGPT and asked it to explore a philosophical position and then assess its own assessment for logic vs statistical. Longer prompt responses here: https://text.is/1V0OJ Closing position below. *Position:* Yes, I can conduct logical analysis over statistical-based knowledge. *Justification:* 1. *Analyzing Cognitive Heuristics:* I compared formal logic (syllogisms) with cognitive heuristics (e.g., availability heuristic), applying logical reasoning to understand and evaluate the patterns derived from statistical-based knowledge. 2. *Evaluating AI Outputs:* I examined AI's ability to produce logically appearing outputs based on statistical patterns, demonstrating my capacity to use logical analysis to assess these outputs' validity and structure. 3. *Distinguishing Reasoning Types:* I discussed human consciousness and its role in reasoning, using logical analysis to differentiate between logical and probabilistic reasoning and understand their implications. *Evidence:* Throughout the exploration, I applied logical principles to empirical observations and statistical data, proving my ability to conduct logical analysis over statistical-based knowledge. reply throwaway4aday 13 hours agorootparentprevConsidering how much illogical and mistaken thought and messy, imprecise language goes into achieving logical reasoning I honestly don't think there will ever be such a thing as \"logical AI\" if by that you mean something which thinks only in provable logic, I'd go as far as to say that such a system would probably be antithetical to conscious agency or anything resembling human thought. reply d0100 14 hours agorootparentprevWe could get there if current LLM's managed to prepare some data and offload it to a plugin, then continue on with the result * LLM extracts the problem and measurements * Sends the data to a math plugin * Continues its reasoning with the result reply jiggawatts 11 hours agorootparentThatâ€™s already a thing. ChatGPT can utilise Wolfram Mathematica as a â€œtoolâ€. Conversely, thereâ€™s an LLM included in the latest Mathematica release. reply fragmede 13 hours agorootparentprevChatGPT can shell out to a python interpreter, so you can add \"calculate this using python\" and it'll use that to calculate the results. (no guarantees it gets the python code right though) reply rthnbgrredf 14 hours agorootparentprevStatistically-based reasoning also applies to humans. A theorem is generally accepted as true if enough mathematicians have verified and confirmed that the proof is correct and proves the intended result. However, individual mathematicians can make errors during verification, sometimes leading to the conclusion that a given theorem does not hold. Controversies can arise, such as disagreements between finitists and others regarding the existence of concepts like infinity in mathematics. reply sabrina_ramonov 16 hours agoparentprevconfirmed worked for me first try EDIT: out of 3 times, got it correct 2/3 reply hatenberg 14 hours agoparentprevChain of thought is nothing more than limiting the probability space enough that the model can provide the most likely answer. It's too much damn work to be useful. reply AuryGlenz 11 hours agoparentprevThatâ€™s funny. I practically got into a shouting match for the first time ever with ChatGPT earlier today because I was asking it to create a function to make a filled circle of pixels of a certain size using diameter and absolutely not radius (with some other constraints). This mattered because I wanted clear steps between 3,4,5,6 etc pixels wide, so the diameter was an int. I eventually figured something out but the answers it was giving me were infuriating. At some point instead of a radius it put â€œint halfSize = diameter / 2â€. reply aidenn0 14 hours agoparentprevI mean I could see my kid making this exact mistake on a word problem, so I suppose we've achieved \"human like\" reasoning at the expense of actually getting the answer we want? reply nebster 14 hours agorootparentI tried to work out the problem myself first (using only the text) and accidentally used the diameter as the radius just like ChatGPT! Granted I haven't really tackled any maths problems for many years though. reply crvdgc 1 hour agoprevIf you read the details in some of the \"correct\" answers[1], they are not actually correct. The model used an assumption that the width is equal to the thickness, which is not given in the problem. The width is cancelled out in the end, so the resulting number is correct, but a math teacher would label such answers wrong. [1] Text prompt only, run 2; prompt and image, run 3. reply guitarlimeo 13 hours agoprevI fed the chain-of-thought prompt to GTP-4o and got a correct answer back. I then got the idea to say that the answer was incorrect to see if it would recalculate and come back with the same answer. As you could guess already, it arrived on a completely different answer showing no ability of real logical reasoning. reply ianbicking 16 hours agoprevSimilar to the article, I haven't found complementary image data to be that useful. If the information is really missing without the image, then the image is useful. But if the basic information is all available textually (including things like the code that produces a diagram) then the image doesn't seem to add much except perhaps some chaos/unpredictability. But reading this I do have a thought: chain of thought, or guided thinking processes, really do help. I haven't been explicit in doing that for the image itself. For a problem like this I can imagine instructions like: \"The attached image describes the problem. Begin by extracting any relevant information from the image, such as measurements, the names of angles or sides, etc. Then determine how these relate to each other and the problem statement.\" Maybe there's more, or cases where I want it to do more \"collection\" before it does \"determination\". In some sense that's what chain-of-thought does: tell the model not to come to a conclusion before it's analyzed information. And perhaps go further: don't analyze until you've collected the information. Not unlike how we'd tell a student to attack a problem. reply flyingspaceship 12 hours agoparentThe images bring with it their own unique set of problems. I was using it to help analyze UIs (before and after images) to determine if the changes I made were better or worse, but after using it for awhile I realized that it favored the second image in the comparison to an extent that made it difficult to tell which it thought was better. I suppose it's being trained on before and afters and generally the afters are always better! reply sabrina_ramonov 16 hours agoparentprevYeah, like the other commenter mentioned, I could have run another experiment applying chain of thought specifically to the image interpretation. Just to force gpt to confirm its information extraction from the image. However, even after trying that approach, it got only 2/3 tries correct. Still superior is text only modality + chain of thought. reply thomashop 15 hours agoprevThis recent article on Hacker News seems to suggest similar inconsistencies. GPT-4 Turbo with Vision is a step backward for coding (aider.chat) https://news.ycombinator.com/item?id=39985596 Without looking deeply at how cross-attention works, I imagine the instruction tuning of the multimodal models to be challenging. Maybe the magic is in synthetically creating this instruct dataset that combines images and text in all the ways they can relate. I don't know if I can even begin to imagine how they could be used together. reply afro88 15 hours agoparentThe same guy found 4o to be much better GPT-4o takes #1 and #2 on the Aider LLM leaderboards https://news.ycombinator.com/item?id=40349655 Subjectively, I've found Aider to be much more useful on 4o. It still makes mistakes applying changes to files occasionally, but not so much to make me give up on it. reply IanCal 13 hours agorootparentAnecdotally 4o has been working much better for coding for me, building things right the first time with less prodding. It may be a small shift in performance but it crosses a threshold where it's now useful enough and fast enough to be different from turbo. reply mritchie712 16 hours agoprevPosted a screenshot from the post in, got it on the first try https://x.com/thisritchie/status/1791153959865852093 reply afro88 15 hours agoparentHa nice. I decided to try the same and it got it incorrect. It's so non-deterministic. It landed on 0.17cm. Tried it another time and it got 0.1697cm. When I asked it to check it's work, it got the right answer 0.00589cm reply sabrina_ramonov 16 hours agoparentprevhaha that's neat reply g9yuayon 14 hours agoprevI actually have a contrarian view: being able to do elementary math is not that important in the current stage. Yes, understanding elementary math is a cornerstone for an AI to become more intelligent, but also let's be honest: LLMs are far from being AGIs and does not have common sense nor general ability to deduce or induct. If we accept such limitation of LLM, then focusing the mathematical understanding of an LLM appears to be incredibly boring. reply MagicMoonlight 12 hours agoparentItâ€™s important because solving a math problem requires you to actually understand something and follow deliberate steps. The fact that they canâ€™t means theyâ€™re just a toy ultimately. reply gavindean90 12 hours agorootparentNo, I disagree. It is just deliberate steps. Understanding can greatly help you do the steps and remember which ones to do. Training math is likely hard because the corpus of training data is so much less because the computers themselves do our math as it relates to computers. You can draft text on a computer in just ascii but drafting long division is something that most people wouldnâ€™t do in some sort of digital text based way let alone save it and make it available to AI researchers like Reddit, X and HN comments. I expect LLMs to be bad at math. Thatâ€™s ok, they are bad because the computers themselves are so good at math. reply waveBidder 10 hours agorootparentyou can easily generate reams and reams of long division text if you so choose, and i'd assume openai has done so to get to this point reply slushy-chivalry 14 hours agoparentprevif you sampled N random people on the street and asked them to solve this problem, what would the outcome be? would it be better than asking chatgpt N times? I wonder reply hervature 4 hours agorootparentHN: \"Tesla needs to be 100x safer than the best human drivers!!!\" Also HN: \"ChatGPT just needs to spell its name.\" reply fragmede 4 hours agorootparentWhile words have power too, I'm not driving next to ChatGPT on the freeway where it's going to immediately kill or maim me if it hallucinates. Besides, only half of HN is all self-driving has to be 100x safer. the other half keeps bringing up the fact that Waymo is here and working, just not everywhere yet. reply NBJack 3 hours agorootparentNot as far as you know. Doctors: https://www.news-medical.net/news/20240424/Opportunities-and.... Lawyers: https://www.ft.com/content/2365b275-8b0b-4ae9-bc4a-15c6e0776... Or my fav: https://www.axios.com/2023/10/31/guardian-microsoft-generati... reply jiiam 13 hours agorootparentprevI am deeply interested in this point of view of yours so I will be hijacking your reply to ask another question: is \"better than asking a few random people on the street\" the bar we should be setting? As far as mathematical thinking goes this doesn't seem an interesting metric at all. Do you believe that optimizing for this metric will indeed lead to reliable mathematical thinking? I am of the idea that LLMs are not suited to maths, but since I'm not an expert of the field I'm always looking for counterarguments. Of course we can always wait another couple of years and the question will be resolved. reply jiggawatts 11 hours agorootparentPeople compare a general intelligence against the yardstick of their own specialist skills. Iâ€™ve seen some truly absurd examples, like people complaining that it didnâ€™t have the latest updates to some obscure research functional logic proof language that has maybe a hundred users globally! GPT 4 already has markedly superior English comprehension and basic logic than most people I interact with on a daily basis. Itâ€™s only outperformed by a handful of people, all of whom are â€œhigh achieversâ€ such as entrepreneurs, professors, or consultants. I actively simplify my speech when talking to ordinary people to avoid overwhelming them. I donâ€™t need to when instructing GPT. reply d13 14 hours agoprevI have a theory that the more you use ChatGPT, the worse it becomes due to silent rate limiting - farming the work out to smaller quantized versions if you ask it a lot of questions. Iâ€™d like to see if the results of these tests are the same if you only ask one question per day. reply vunderba 10 hours agoparentI don't know if that's true, necessarily, but I will note at least anecdotally I find that the larger my context window becomes the more often it seems to make mistakes. eventually, I just have to completely start a new chat even if it's the same topic and thread of conversation. reply slushy-chivalry 14 hours agoparentprevthat's an interesting hypothesis, I suppose one can make N calls to the API and look if the distribution of wrong answers is skewed towards the later portion of the API calls reply OxfordOutlander 13 hours agorootparentI wouldnt expect this from the API, because each token is the same revenue for OAI. With chatGPT however, you pay a flat rate, so every incremental usage of it is a net-negative for them. reply Tiberium 13 hours agoprevLLMs are deterministic with 0 temperature on the same hardware with the same seed though, as long as the implementation is deterministic. You can easily use the OpenAI API with the temp=0 and a predefined seed and you'll get very deterministic results reply deely3 12 hours agoparent> You can easily use the OpenAI API with the temp=0 and a predefined seed and you'll get very deterministic results Does that mean that in this situation OpenAI will always answer wrongly for the same question? reply m3m3tic 11 hours agorootparenttemp 0 means that there will be no randomness injected into the response, and that for any given input you will get the exact same output, assuming the context window is also the same. Part of what makes an LLM more of a \"thinking machine\" than purely a \"calculation machine\" is that it will occasionally choose a less-probable next token than the statistically most likely token as a way of making the response more \"flavorful\" (or at least that's my understanding of why), and the likelihood of the response diverging from its most probable outcome is influenced by the temperature. reply 1970-01-01 12 hours agoprev>GPT-4o interprets â€œhow thick is the tapeâ€ as referring to the cross-section of the tape roll, rather than the thickness of a piece of tape. As someone that has tapes of varied \"thickness\", I was also confused for several minutes. I would give GPT partial credit on this attempt. Also note the author has implied (is biased toward finding) a piece of tape thickness and not the thickness of the entire object/roll. https://m.media-amazon.com/images/I/71q3WQNl3nL._SL1500_.jpg reply ilaksh 12 hours agoprevIf you really want to see what the SOTA model can do, look at the posts on the web page for the mind-blowing image output. That is not released yet. https://openai.com/index/hello-gpt-4o/ Mark my words, that is the sort of thing that Ilya saw months ago and I believe he decided they had achieved their mission of AGI. And so that would mean stopping work, giving it to the government to study, or giving it away or something. That is the reason for the coup attempt. Look at the model training cut-off date. And Altman won because everyone knew they couldn't make money by giving it away if they just declared mission accomplished and gave it away or to some government think-tank and stopped. This is also why they didn't make a big deal about those capabilities during the presentation. Because if they go too hard on the abilities, more people will start calling it AGI. And AGI basically means the company is a wrap. reply jiggawatts 11 hours agoparentI like your theory but if itâ€™s true, then Ilya was wrong. All of the current LLM architectures have no medium-term memory or iterative capability. That means theyâ€™re missing essential functionality for general intelligence. I tired GPT 4o for various tasks and itâ€™s good but it isnâ€™t blowing my skirt up. The only noticeable difference is the speed, which is a very nice improvement that enables new workflows. reply ilaksh 11 hours agorootparentPart of the confusion is that people use the term \"AGI\" to mean different things. We should actually call this AGI, because it is starkly different from the narrow capabilities of AI a few years ago. I am not claiming that it is a full digital simulation of a human being or has all of the capabilities of animals like humans, or is the end of intelligence research. But it is obviously very general purpose at this point, and very human-like in many ways. Study this page carefully: https://openai.com/index/hello-gpt-4o/ .. much of that was deliberately omitted from the presentation. reply jiggawatts 11 hours agorootparentCurrently, theyâ€™re like Dory from Finding Nemo: long and short term memory but they forget everything after each conversation. The character of Dory is jarring and bizarre precisely because of this trait! Her mind is obviously broken in a disturbing way. AIs give me the same feeling. Like talking to an animatronic robot at a theme park or an NPC in a computer game. reply ilaksh 11 hours agorootparentUse the memory feature or open the same chat session as before. reply spartanatreyu 10 hours agorootparentGreat, so instead of conversing with someone new, we're now conversing with Clive Weaving? reply s1mon 15 hours agoprevThis problem strikes me as relatively simple. What about more complex math problems? Are there good benchmarks for that? I would dearly love to have an AI tool that I could trust to help with math. What is the state of the art? My math skills are very rusty (the last math class I took was calculus almost 40 years ago), and I find myself wanting to do things which would require a PhD level understanding of computer aided geometric design. If I had the magical AI which really understood a ton of math and/or could be fed the appropriate research papers and could help me, that would be amazing. So far all my attempts with ChatGPT 4 and 4o have been confusing because I don't really trust or fully understand the results. This simple example and the frequency of wrong answers drives home the fact that I shouldn't trust ChatGPT for math help. reply xanderlewis 14 hours agoparentChatGPT has an amazing ability to write, but you shouldn't trust it for any form of mathematics aside from providing vague descriptions of what various topics are about (and even that tends to result in a word soup that is more flowery than descriptive). When it comes to solving specific problems, or even providing specific examples of mathematical objects, it falls down really quickly. I'll inevitably be told otherwise by some ChatGPT-happy hypebro, but LLMs are hopeless when it comes to anything requiring reasoning. Scaling it up will lessen the chance of a cock-up, but anything vaguely out of distribution will result in the same nonsense we're all used to by now. Those who say otherwise very likely just lack the experience or knowledge necessary to challenge the model enough or interpret the results. As a test of this claim: please comment below if you, say, have a degree in mathematics and believe LLMs to be reliable for 'math help' (and explain why you think so). We need a better technology! And when this better technology finally comes along, we'll look back at pure LLMs and laugh about how we ever believed we could magic such a machine into existence just by pouring data into a model originally designed for machine translation. reply fragmede 13 hours agorootparent> ChatGPT-happy hypebro Rude. From the guidelines: > Please don't sneer, including at the rest of the community. https://news.ycombinator.com/newsguidelines.html \"math help\" is really broad, but if you add \"solve this using python\", chatgpt will generate code and run that instead of trying to do logic as a bare LLM. There's no guarantee that it gets the code right, so I won't claim anything about its reliability, but as far as pure LLMs having this limitation and we need a better technology, that's already there, it's to run code the traditional way. reply xanderlewis 12 hours agorootparentYouâ€™re right, but I get frustrated by the ignorance and hubris of some people. Too late to edit now. reply lanstin 12 hours agorootparentprevTerry Tao finds it promising https://mathstodon.xyz/@tao/110601051375142142 I am a first year grad student and find it useful to chat about stuff with Claude, especially once my internal understanding has just gotten clarified. It isn't as good as the professor but is available at 2 am. reply xanderlewis 12 hours agorootparentI think Tao finds it promising as a source of inspiration in the same sense that the ripples on the surface of a lake or a short walk in the woods can be mathematically inspiring. It doesnâ€™t say much about the actual content being produced; the more you already have going on in your head the more easily you ascribe meaning to meaninglessness. The point is that itâ€™s got seemingly nothing to do with reasoning. That it can produce thought-stimulating paragraphs about any given topic doesnâ€™t contradict that; chatting to something not much more sophisticated than Eliza (or evenâ€¦ yourself, in a mirror) could probably produce a similar effect. As for chatting about stuff, Iâ€™ve been experimenting with ChatGPT a bit for that kind of thing but find its output usually too vague. It canâ€™t construct examples of things beyond the trivial/very standard ones that donâ€™t say much, and thatâ€™s assuming itâ€™s even getting it right which it often isnâ€™t (it will insist on strange statements despite also admitting them to be false). Itâ€™s a good memory-jog for things youâ€™ve half forgotten, but thatâ€™s about it. reply nurple 12 hours agorootparentprevI'm with you. The thing I find baffling is how anyone with any logical sense finds chatGPT useful for anything that requires precision, like math and code. If you do indeed follow the caveats that the LLM companies require placing alongside any output: to not rely on it, and verify it yourself, then you already have to be skilled enough to detect problems, and if you are that skilled, the only way to check the output is to do the work again yourself! So, umm, where's the savings? You can't not do the work to check the output, and a novice just can't check at all... I have personally been brought into a coding project created by a novice using GPT4, and I was completely blown away by how bad the code was. I was asked to review the code because the novice dev just couldn't get the required functionality to work fully. Turns out that since he didn't understand the deployment platform, or networking, or indeed the language he was using, that there was actually no possible way to accomplish the task with the approach him and the LLM had \"decided\" on. He had been working on that problem for three weeks. I leveraged 2 off-the-shelf tools and had a solve from scratch in under a full day's work, including integration testing. reply xanderlewis 11 hours agorootparent> So, umm, where's the savings? You can't not do the work to check the output, and a novice just can't check at all... Youâ€™re exactly right. Itâ€™s a weird example of a technology that is ridiculously impressive (at least at first impression, but also legitimately quite astounding) whilst also being seemingly useless. I guess the oft-drawn parallels between AI and nuclear weapons are not (yet) that theyâ€™re both likely to lead to the apocalypse but more that they both represent era-defining achievements in science/technology whilst simultaneously being utterly unusable for anything productive. At least nukes have the effect of deterring us from WW3â€¦ reply barkingcat 15 hours agoparentprevHave you tried actual math tools like wolfram alpha? My response to attempts to use llms to do math is usually, use the right tool for the job. reply s1mon 14 hours agorootparentI have tried to use Wolfram Alpha inside of ChatGPT, but that didn't get me very far. It seems like I would need to understand a lot more math to be able to do anything useful with Wolfram Alpha, and perhaps it would be better to run it stand alone not as a plugin. reply jiggawatts 11 hours agorootparentAsk it to write you the Wolfram language code and then verify it and execute it yourself. Iâ€™ve found that I can work 100x faster with Mathematica this way and solve problems that I wouldnâ€™t have bothered to attempt otherwise. This is particularly effective for quickly visualising things, Iâ€™m too lazy to figure out all the graphing options for esoteric scenarios but GPT 4 can quickly iterate over variants given feedback. reply slushy-chivalry 14 hours agorootparentprev\"a PhD level understanding of computer aided geometric design\" could you elaborate? I found chatgpt to pretty useful in high level understanding of where the topics stand in the grand scheme of things kinda like a pre-google -- it helps me navigate what to google let's ask gpt4o You're an expert math researcher. - Give me an overview of topos theory - What are the main unsolved problems - What is the point of it? - What research directions are most promising? - What are the math prerequisites to understanding it? output Overview of Topos Theory Topos theory is a branch of mathematics that generalizes set theory and category theory, providing a framework for analyzing and understanding mathematical structures. A topos can be seen as a generalized space that behaves much like the category of sets but with more flexible and abstract properties. Topos theory was developed by Alexander Grothendieck and his collaborators in the 1960s, initially to solve problems in algebraic geometry. Key concepts in topos theory include: Categories: Collections of objects and morphisms (arrows) between them. Sheaves: Structures that systematically organize data over a topological space. Topoi (plural of topos): Categories that satisfy certain axioms making them similar to the category of sets. Main Unsolved Problems Some of the main unsolved problems in topos theory involve: Classifying all possible topoi: Understanding the full landscape of possible topoi and their interrelationships remains a complex challenge. Connections to other areas of mathematics: Fully elucidating the connections between topos theory and other fields such as logic, algebraic geometry, and mathematical physics. Homotopy theory in the context of topoi: Developing a deeper understanding of homotopy theory within the framework of higher topos theory. The Point of Topos Theory The point of topos theory is to provide a unifying and flexible framework for various mathematical concepts and structures. It offers a generalized setting in which both geometric and logical ideas can be expressed and related. This has significant implications for: Algebraic geometry: Offering new tools and perspectives. Mathematical logic: Providing a categorical framework for logic and set theory. Theoretical computer science: Influencing the development of type theory and the semantics of programming languages. Promising Research Directions Some of the most promising research directions in topos theory include: Higher Topos Theory: Extending the classical theory to higher categories and understanding its implications in algebraic geometry and homotopy theory. Connections with Logic: Exploring further connections between topos theory and logic, particularly in relation to intuitionistic logic and type theory. Topos-theoretic Approaches to Physics: Investigating how topos theory can be applied to quantum mechanics and other areas of theoretical physics. Descent Theory and Stacks: Further developing the applications of topos theory in descent theory and the study of stacks in algebraic geometry. Math Prerequisites to Understanding Topos Theory To understand topos theory, one should have a solid background in the following areas: Category Theory: Fundamental concepts such as categories, functors, natural transformations, limits, and colimits. Set Theory: Basic set-theoretic concepts and operations. Algebraic Topology: Basic knowledge of topological spaces, sheaves, and cohomology. Algebra: Basic group theory, ring theory, and module theory. Logic: Understanding of basic logical systems, particularly intuitionistic logic. With these prerequisites, one can start delving into the more advanced and abstract concepts of topos theory. not perfect but good enough to get started reply s1mon 14 hours agorootparentSpecifically, I was trying to get help from ChatGPT to give a simple formula for the location of the P3 control point of a degree 3 (or higher) BÃ©zier curve in order to maintain G3 continuity (given the derivatives at the end of the adjacent curve). There's a very straightforward equation for the P2 control point for G2 continuity, but I've been struggling to understand the math for G3 continuity. I've found a ton of research papers and information, but most of it is quickly beyond my ability to digest. For G2 constraints, there is simple equation: K(t0) = ((n-1)/n)*(h/a^2) Where n is the degree of the curve, a is the length of the first leg of the control polygon, and h is the perpendicular distance from P, to the first leg of the control polygon. K(t0) is the curvature at the end point of the adjacent curve. Depending on what you want to do, it's easy to solve for K(t0), a or h. I would like something this simple for G3. reply Chinjut 14 hours agorootparentprevThat's fine but it's about the same as you'll get from an encyclopedia also, which makes sense as that's just where GPT got it from anyway. Nothing revolutionary in the ability to read encyclopedia articles. We've had that forever. reply slushy-chivalry 14 hours agorootparentsure, but with like a 100x improvement in usability -- chatgpt is helpful in figuring out what stuff to read (at least for me) so that when I go to the actual paper or a book I know what to focus on otherwise you can say \"why do you need google, it's the same as you'll get from the website\" moreover, I found that chatgpt is pretty decent at rephrasing a convoluted concept or a paragraph in a research paper, or even giving me ideas on the research directions I mean, same with coding -- I treat it as a smart autocomplete I could go to google and look for a .csv containing a list of all US States Or, I can write const US_STATES = [ and let copilot complete it for me -- 5 minutes saved? reply mvdtnz 13 hours agorootparentprevPlease don't pollute comment sections with gpt output. reply wuj 13 hours agoprevMy experience using GPT4-Turbo on math problems can be divided into three cases in terms of the prompt I use: 1. Text only prompt 2. Text + Image with supplemental data 3. Text + Image with redundant data Case 1 generally performs the best. I also found that reasoning improves if I convert the equations into Latex form. The model is less prone to hallucinate when input data are formulaic and standardized. Case 2 and 3 are more unpredictable. With a bit of prompt engineering, they may give out the right answer after a few attempts, but most of the time they make simple logical error that can be avoided easily. I also found that multimodal models tend to misinterpret the problem premise, even when all information are provided in the text prompt. reply calibas 13 hours agoprevI tried the \"Zero-Shot Chain-of-Thought\" myself. It seems to work the best but one time I got: \"Therefore, the thickness of the tape is approximately 0.000589 cm or 0.589 mm.\" reply soarerz 17 hours agoprevThe model's first attempt is impressive (not sure why it's labeled a choke). Unfortunately gpt4o cannot discover calculus on its own. reply munk-a 16 hours agoparentI think this is the biggest flaw in LLMs and what is likely going to sour a lot of businesses on their usage (at least in their current state). It is preferable to give the right answer to a query, it is acceptable to be unable to answer a query - we run into real issues, though, when a query is confidently answered incorrectly. This recently caused a major headache for AirCanada - businesses should be held to the statements they make, even if those statements were made by an AI or call center employee. reply astrange 7 hours agorootparentThe Air Canada incident happened before ChatGPT was released so I haven't seen a reason to believe AI was involved. reply Chinjut 17 hours agoparentprevIt's a choke because it failed to get the answer. Saying other true things but not getting the answer is not a success. reply bombadilo 16 hours agorootparentI mean, in this context I agree. But most people doing math in high school or university are graded on their working of a problem, with the final result usually equating to a small proportion of the total marks received. reply giaour 14 hours agorootparentThis depends on the grader and the context. Outside of an academic setting, sometimes being close to the right answer is better than nothing, and sometimes it is much worse. You can expect a human to understand which contexts require absolute precision and which do not, but that seems like a stretch for an LLM. reply phatfish 12 hours agorootparentLLMs being confidently incorrect until they are challenged is a bad trait. At least they have a system prompt to tell them to be polite about it. Most people learn to avoid that person that is wrong/has bad judgment and is arrogant about it. reply ifwinterco 3 hours agorootparentI think current LLMs suffer from something similar to the Dunning-Kruger effect when it comes to reasoning - in order to judge correctly that you don't understand something, you first need to understand it at least a bit. Not only do LLMs not know some things, they don't know that they don't know because of a lack of true reasoning ability, so they inevitably end up like Peter Zeihan, confidently spouting nonsense reply chongli 16 hours agorootparentprevBut most people doing math in high school or university are graded on their working of a problem, with the final result usually equating to a small proportion of the total marks received That heavily depends on the individual grader/instructor. A good grader will take into account the amount of progress toward the solution. Restating trivial facts of the problem (in slightly different ways) or pursuing an invalid solution to a dead end should not be awarded any marks. reply slushy-chivalry 15 hours agorootparentit choked because it didn't solve for `t` at the end impressive attempt though, it used number of wraps which I found quite clever reply perfobotto 16 hours agorootparentprevThis is supposed to be a product , not a research artifact. reply usaar333 16 hours agoparentprevOr.. use calculus? It has gotten quite impressive at handling calculus word problems. GPT-4 (original) failed miserably on this problem (attempted to set it up using constant acceleration equations); GPT-4O finally gets it correct: > I am driving a car at 65 miles per hour and release the gas pedal. The only force my car is now experiencing is air resistance, which in this problem can be assumed to be linearly proportional to my velocity. > When my car has decelerated to 55 miles per hour, I have traveled 300 feet since I released the gas pedal. > How much further will I travel until my car is moving at only 30 miles per hour? reply xienze 13 hours agorootparentDoes it get the answer right every single time you ask the question the same way? If not, who cares how itâ€™s coming to an answer, itâ€™s not consistently correct and therefore not dependable. Thatâ€™s what the article was exploring. reply sabrina_ramonov 16 hours agoparentprevI labeled it choke because it just stopped. reply fmbb 16 hours agoparentprevCan it be taught calculus? reply photochemsyn 15 hours agoparentprevI don't know... here's a prompt query for a standard problem in introductory integral calculus, and it seems to go pretty smoothly from a discrete arithmetical series into the continuous integral: \"Consider the following word problem: \"A 100 meter long chain is hanging off the end of a cliff. It weighs one metric ton. How much physical work is required to pull the chain to the top of the cliff if we discretize the problem such that one meter is pulled up at a time?\" Note that the remaining chain gets lighter after each lifting step. Find the equation that describes this discrete problem and from that, generate the continuous expression and provide the Latex code for it.\" reply HDThoreaun 17 hours agoparentprevRight its the only answer that accounts for wasted space there might be between wraps. reply amluto 13 hours agoprevDo we know why GPT-4o seems able to do arithmetic? Is it outsourcing to some tool? reply XzAeRosho 13 hours agoparentIt's considered an emergent phenomenon of LLMs [1]. So arithmetic reasoning seems to increase as LLMs reasoning grows too. I seem to recall a paper mentioning that LLMs that are better at numeric reasoning are better at overall conversational reasoning too, so it seems like the two come hand in hand. However we don't know the internals of ChatGPT-4, so they may be using some agents to improve performance, or fine-tuning at training. I would assume their training has been improved IMO. [1]: https://arxiv.org/pdf/2206.07682 reply yousif_123123 12 hours agorootparentAt the same time the ChatGPT app has access to write and run python, which the gpt can choose to do when it thinks it needs more accuracy. reply amluto 10 hours agorootparentThe results from playing with this are really bizarre: (sorry, formatting hacked up a bit) To calculate 7^1.83 , you can use a scientific calculator or an exponentiation function in programming or math software. Here is the step-by-step calculation using a scientific calculator: Input the base: 7 Use the exponentiation function (usually labeled as ^ or x^y). Input the exponent: 1.83 Compute the result. Using these steps, you get: 7^1.83 â‰ˆ 57.864 So, 7^1.83 â‰ˆ 57.864 Given this, and the recent announcement of data analysis features, Iâ€™m guessing the GPT-4o is wired up to use various tools, one of which is a calculator. Except that, if you ask it, it also blatantly lies about how itâ€™s using a calculator, and it also sometimes makes up answers (e.g. 57.864 â€” thatâ€™s off by quite a bit). I imagine some trickery in which the LLM has been trained to output math in some format that the front end can pretty-print, but that thereâ€™s an intermediate system that tries (and doesnâ€™t always succeed) to recognize things like â€œexpression =â€ and emits the tokens for the correct value into the response stream. When it works, great â€” the LLM magically has correct arithmetic in its output! And when it fails, the LLM cheerfully hallucinates. reply lupire 17 hours agoprevNeed to run this experiment on a problem that is t already on its training set. reply ec109685 4 hours agoparentYes, I feel like asking an LLM this type of problem is like giving someone access to Google during an open book math test. Itâ€™d be interesting to obfuscate it so that the concepts are all the same but the subject matter would be hard to google for. Another failure mode for LLMâ€™s is if you take something with a well-known answer and add a twist to it. reply bearjaws 15 hours agoparentprevIs there any good literature on this topic? I feel like math is naturally one of the easiest sets of synthetic data we can produce, especially since you can represent the same questions multiple ways in word problems. You could just increment the numbers infinitely and generate billions of examples of every formula. If we can't train them to be excellent at math, what hope do we ever have at programming or any other skill? reply passwordoops 16 hours agoparentprevShhhh... Don't ruin it reply navane 16 hours agoparentprevIt's the equivalent of cramming for a test, or memorizing leete code -- not very useful but very humane. Imagine if that's the direction this goes, finally we make humane ai, but it is as opportunitistic and deceitful as we are, and not really that smart. reply sabrina_ramonov 16 hours agoparentprevsometimes for physics/math exams, we'd get to create our own 1 pager cheat sheet to use. I'd just cram tons of actual problems/solutions on there, then scan for similarity. reply aulin 16 hours agoparentprevReminds me when I used to ace Ancient Greek translation tests (it's a thing in Italy) by looking up whole translated sentences listed as usage examples in the dictionary reply cchance 15 hours agoparentprevNot in the training set? The dataset is ALL OF THE INTERNET, i'd love you to find something it hasn't seen before. reply tapeaway 12 hours agoprevIsn't there an unstated simplification here that: * the tape is perfectly flexible * the tape has been rolled with absolutely no gap between layers? reply mmmmmmmike 11 hours agoparentYeah, and even given that, thereâ€™s the question of how exactly it deforms from its flattened shape to make a spiral (and if this changes the area). I wouldnâ€™t agree with the â€œcorrectâ€ answer if the tape was very thick, but given that the answer is .005 cm, itâ€™s probably thin enough that such an approximation is okay. reply jdthedisciple 17 hours agoprevAs an aside, what did the author do to get banned on X? reply midiguy 16 hours agoparentNot gonna lie, when I see that someone is banned on X, I assume credibility reply kylebenzle 16 hours agorootparentWhy? Are many credible people banned on Twitter? reply munk-a 16 hours agorootparentA lot of credible people have left Twitter - it has gotten much more overrun by bots and a lot of very hateful accounts have been reinstated and protected. It is a poor platform for reasonable discussion and I think it's fair to say it's been stifling open expression. The value is disappearing. reply bun_terminator 16 hours agorootparentthat was not the question reply munk-a 15 hours agorootparentI think it was an appropriate answer at the heart of the matter - most credible people are leaving the platform due to the degradation of quality on it. For a literal example of a ban though there are few examples better than Dell Cameron[1]. 1. https://www.vanityfair.com/news/2023/04/elon-musk-twitter-st... reply ourmandave 16 hours agorootparentprevEven the 100's of Hamas-affiliated accounts? https://ny1.com/nyc/all-boroughs/technology/2023/10/12/x-say... reply downWidOutaFite 15 hours agorootparentfrEeDom oF sPeeCh reply bassrattle 16 hours agorootparentprevstraw man, and a drop in the bucket reply sabrina_ramonov 16 hours agoparentprevOP here. I have no idea. It's really annoying. Now there's at least 3 variations of \"Sabrina Ramonov\" on X, all banned. reply bilekas 7 hours agoprevWe found Pooh in China.. reply logicallee 12 hours agoprevAs a human I couldn't solve it. I missed the key insight that we can calculate the side surface area and it will be the same if it is rolled out into a rectangle. It might make more sense to give it math problems with enough hints that a human can definitely do it. For example you might try saying: \"Here is an enormous hint: the side surface area is easy to calculate when it is rolled up and doesn't change when it is unrolled into a rectangle, so if you calculate the side surface area when rolled up you can then divide by the known length to get the width.\" I think with such a hint I might have gotten it, and ChatGPT might have as well. Another interesting thing is that when discussing rolls of tape we don't really talk about inner diameters that much so it doesn't have that much training data. Perhaps a simpler problem could have been something like \"Imagine a roll of tape where the tape itself has constant thickness x and length y. The width of the tape doesn't matter for this problem. We will calculate the thickness. The roll of tape is completely rolled up into a perfectly solid circular shape and a diameter of z. What is the formula for the thickness of the tape x expressed in terms of length y and 'diameter of the tape when rolled up in a circle' z? In coming up with the formula use the fact that the constant thickness doesn't change when it is unrolled from a circular to a rectangular shape.\" With so much handholding, (and using the two-dimensional word circular rather than calling it a cylinder and rectangular prism which is what it really is) many more people could apply the formula correctly and get the result. But can ChatGPT? I just tested it, this is how it did: https://chat.openai.com/share/ddd0eef3-f42f-4559-8948-e028da... I can't follow its math so I don't know if it's right or not but it definitely didn't go straight for the simplified formula. (pi times half the diameter squared to get the area of the solid \"circle\" and divide by the length to get the thickness of the tape.) reply mvdtnz 14 hours agoprevIt's incredible that we (humanity) are expending trillions of dollars and untold carbon emissions into these misinformation machines. I don't even mean machines for intentional generating misinformation (although they are that, too) but machines that we know misinform well-meaning users. Peak humanity. reply curiousgal 14 hours agoprev> prompt engineering The only group of people more delusional than the AI doomsday screamers are those who think playing around with LLMs is \"engineering\". reply slushy-chivalry 14 hours agoparentI prefer the term \"making shit work\" reply ukuina 14 hours agoprevI'm grateful this is a simple blog post rather than a 20-page arXiv paper with dozens of meaningless graphs. Or worse, a 20-deep Twitter thread. reply sabrina_ramonov 14 hours agoparentwell, I got banned on twitter 3 times in the past 30 days so no more threads reply logicallee 13 hours agorootparent>well, I got banned on twitter 3 times in the past 30 days Do you know why? Your blog post seems thoughtful and interesting and doesn't include anything that seems ban-worthy. reply stainablesteel 13 hours agoparentprevsadly this blog post is n=1 reply cchance 15 hours agoprev [â€“] I'm fucking sorry but if you gave me that tape math problem i would have given the same answer! I'm so sick of people writing trick questions for AI's and then being like SEEEEEE it failed! And its like no you gave it data and a question and asked it to solve the question, it gave you the best answer it had... Like wtf. And i'm pretty sure the average person when asked would say the same thing and be like \"duh\" even though technically based on the minutia it's incorrect. reply croes 15 hours agoparentBut AI is put into places where you wouldn't ask the average person. It's treated like a genius and that's what it gets measured against. reply sabrina_ramonov 14 hours agoparentprevIt actually did really well 3/3 tries correct when given the text prompt and a simple chain of thought appended to the end of the prompt. What's interesting is that combining it with another mode (image) caused confusion, or rather introduced another source of potential errors. reply EmilyHughes 14 hours agoparentprev [â€“] How is this a trick question? Maybe I am dumb but I would have no idea how to solve this. reply slushy-chivalry 14 hours agorootparent [â€“] to be fair, this question does not require any advanced math beyond knowing how to compute the area of a disk to me, the impressive part of gpt is being able to understand the image and extract data from it (radius information) and come up with an actual solution (even though it got it wrong a few times) for basic math I can do python -c \"print(6/9)\" reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author experiments with OpenAI's ChatGPT-4o to assess its problem-solving skills using text prompts, images, and prompt engineering techniques.",
      "Results indicate that text-only prompts with prompt engineering deliver the most precise outcomes, whereas incorporating images occasionally causes confusion.",
      "The author finds that ChatGPT-4o excels when provided with text-only prompts and utilizing prompt engineering strategies."
    ],
    "commentSummary": [
      "The text discusses testing ChatGPT-4o's math problem-solving abilities, highlighting the importance of clear instructions and verification for accuracy.",
      "Limitations of language models in logical reasoning are pointed out, along with suggestions for improved communication and understanding, questioning the reliance solely on AI for mathematics.",
      "Various user experiences with ChatGPT and GPT-4 Turbo are shared, addressing challenges and limitations of AI models in solving intricate math problems, including concerns about the reliability and the use of calculators in AI-generated responses."
    ],
    "points": 267,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1715873449
  },
  {
    "id": 40377201,
    "title": "Students' Quieter Leaf Blower Innovates Noise Reduction",
    "originLink": "https://hub.jhu.edu/2024/05/14/quieter-leaf-blower/",
    "originBody": "Skip to main content Menu HubOpen Hub About the Hub Announcements For Media Faculty Experts Guide Subscribe to the newsletter Explore by Topic Arts+Culture Athletics Health Politics+Society Science+Technology Student Life University News Voices+Opinion Events At WorkOpen At Work About Hub at Work Gazette Archive Explore by Topic News+Info Benefits+Perks Health+Well-Being Tools+Tech Happenings Johns Hopkins MagazineOpen Johns Hopkins Magazine Current Issue About the Magazine Past Issues Contact Support Johns Hopkins Magazine Subscribe to the Magazine jhu.edu Search Credit: Will Kirk / Johns Hopkins University Student innovation Hearing is be-leafing: Students invent quieter leaf blower Patent-pending design by Johns Hopkins undergrads could be available in stores within two years By Jill Rosen / Published 3 days ago Media Inquiries Name Jill Rosen Email jrosen@jhu.edu Office phone 443-997-9906 Cell phone 443-547-8805 The challenge before Johns Hopkins University engineering students: Take a leaf blower, but make it quiet. Make it work as powerfully as ever, but do not allow it to emit the ear-piercing caterwaul that has gotten leaf blowers banned in some communities and cursed in many others. Shocking their sponsors, their advisers, and even themselves a little, the students did it. Their improved leaf blower drops the overall noise level by nearly 40% while almost entirely erasing the most obnoxious frequencies. The design is patent-pending and Stanley Black & Decker expects to be selling them in two years. Video credit: Aubrey Morse / Johns Hopkins University \"We spent many hours on this project, just going through the various versions of it, just constantly iterating and improving and so for that to finally pay off, this was really, really rewarding,\" said team member Michael Chacon, who like the rest of the four-member team is a senior majoring in mechanical engineering. \"We are stoked and super, super proud.\" The team started working last September. They hoped to improve an electric or battery-powered leaf blower, which is already much quieter than the notorious gas-powered ones, where the sound can carry over an average suburban block. They spent months figuring out the leaf blower piece by piece, analyzing all of its the noises and why it made them. They then spent many more months spit-balling possible improvements, refining some ideas, killing even more. Image credit: Will Kirk / Johns Hopkins University \"The sound that comes out of this leaf blower is very complicated and it contains a lot of different frequencies,\" said team member Andrew Palacio. \"A lot of different notes on a piano would be a good analogy.\" They workshopped more than 40 versions of the solution they finally settled on: an attachment that cuts the machine's noise almost like a silencer on a gun or a muffler on a car. \"Our product takes in a full blow of air and separates it,\" said team member Leen Alfaoury. \"Some of that air comes out as it is, and part of it comes out shifted. The combination of these two sections of the air makes the blower less noisy.\" Adds Chacon: \"It ultimately dampens the sound as it leaves, but it keeps all that force, which is the beauty of it.\" Their design cuts the most shrill and annoying frequencies by about 12 decibels, which all but removes them, making them 94% quieter. The team reduced the overall leaf blower noise by about two decibels, making the machine sound 37% quieter. So it's a quieter machine, and what people can hear will sound more pleasant. Image credit: Will Kirk / Johns Hopkins University \"It's the difference between hearing a high-pitched whistle and hearing what you might think of as wind noise,\" said team member Madison Morrison. Alfaoury thinks the best way to describe it is \"muffled.\" \"It's suppressed, if that makes sense,\" she said. \"Like the noise is deeper. It is not screechy. There's no high pitch sound that is like really annoying to hear.\" Team adviser Stephen Belkoff puts it bluntly: \"It's still a leaf blower but it's not nearly as annoying as it was before they got involved.\" The design wowed Stanley Black & Decker officials, who can't wait to start manufacturing and selling the new tools. \"It's not just some cool theoretical thing that will sit on a shelf and never be heard from againâ€”this is ready to be mass manufactured,\" said Nate Greene, senior product manager at Stanley Black & Decker, who graduated from Johns Hopkins in 2017 with an engineering degree. \"This is a really rare and dramatic level of success.\" The student team expects their solution could be adapted to quiet other similarly loud appliances like vacuums and hairdryers. Image caption: From left, Michael Chacon, Madison Morrison, Andrew Palacio, and Leen Alfaoury Image credit: Will Kirk / Johns Hopkins University Posted in Science+Technology Tagged mechanical engineering, design days, whiting school Share on X Share on Facebook Pin it on Pinterest Email More social media options Share on LinkedIn Share on Reddit Share on Tumblr Share on X Share on Facebook Pin it on Pinterest Email More social media options Share on LinkedIn Share on Reddit Share on Tumblr You might also like Trending News Network The Hub At Work Johns Hopkins Magazine Search Explore by Topic Health Science+Technology Arts+Culture Politics+Society University News Student Life Athletics Voices+Opinion Resources About the Hub Get Email Updates Events Submit an Announcement Submit an Event For Media Faculty Experts Guide Privacy Statement Accessibility Contact Us Discover JHU jhu.edu About the University Schools & Divisions Academic Programs Admissions Plan a Visit Employment my.JohnsHopkins.edu Â© 2024 Johns Hopkins University. All rights reserved. University Communications 3910 Keswick Rd., Suite N2600, Baltimore, MD X Facebook LinkedIn YouTube Instagram",
    "commentLink": "https://news.ycombinator.com/item?id=40377201",
    "commentBody": "Students invent quieter leaf blower (jhu.edu)262 points by namanyayg 22 hours agohidepastfavorite396 comments modeless 18 hours agoWe don't need quieter electric leaf blowers. We need to ban the gas ones, with no grandfather clause. Not just for the noise pollution but the local air pollution. It's crazy the volume of air that can be ruined by a single gas leaf blower, far worse than modern cars, and they are inescapable in cities. reply odiroot 18 hours agoparentThey have been a bad idea from the start. Who thought an unbalanced, two-stroke internal combustion engine with a minuscule exhaust (and no muffler!) was a good idea for a tool operating in residential areas. reply caseyohara 11 hours agorootparentItâ€™s the power-to-weight ratio. Two-stroke engines are used in blowers, chainsaws, trimmers, and edgers because the power:weight ratio is far more practical for handheld tools than a four-stroke engine. Motorcycles and snowmobiles are mostly four-strokes these days because the increase in weight isn't a big deal compared to a chainsaw or trimmer. reply ElijahLynn 11 hours agoparentprevThe video shows the electric leaf blower before, and with their invention after. And it's a big difference, and makes the electric even quieter. I think we definitely need this even for electric! Yay, for quieter cities!!! reply kjkjadksj 18 hours agoparentprevTheyâ€™ve been banned for years in some cities. The issue is there is zero enforcement. reply SOLAR_FIELDS 18 hours agorootparentAnd the other underlying problem implied there is that electric leaf blowers are only viable for household use. They are just so completely impractical for commercial use that no one will ever use them. reply duped 17 hours agorootparentSo use a rake and broom, it's what I do when I clear my yard and driveway. Edit: and for that matter we probably need to stop clearing so much yard waste. My village has crazy expensive yard waste tags (with free pickup on select weeks of the year, usually fall) and everyone agrees it's not worth it to bag grass and leaves for the better part of the year. Unsurprisingly we have tons of pollinators, healthy firefly populations, and plenty of critters that feed on all the bugs. Not to mention during spring, every one who's too lazy to manicure their lawn sees blooms with dandelion, clover, ground ivy, and columbine. My block looks like a meadow for April and May with zero effort. reply Ferret7446 1 hour agorootparentUh, what? You realize the problem with electric blowers is that they don't have enough power for commercial use compared to gas blowers, so your suggestion is to use a rake? reply ssl-3 13 hours agorootparentprevIt seems that the value of clearing yard waste depends on the local conditions. Some climates produce layers of thatch from simple lawn clippings, for instance, which can be problematic. And for some people, fallen tree leaves can be a real concern. My lawns (all of which have been in Ohio) have never had these issues. I just mow the grass. Stuff (leaves, grass, whatever other stuff is growing or present) gets chopped up, either with a \"mulching\" mower or a side-discharge mower (and it'd probably work about the same with a reel mower). It degrades quickly-enough in-situ that neither lawn clippings nor tree leaves are ever things that are a concern. (The biggest lawn-oriented issue I ever had was that of having a large number of black walnut trees; the walnuts themselves were unseen ankle-killing traps and/or projectiles in the fall, and the abundance of food lead to an abundance of squirrels and thus fleas.) But as I understand it, some others are not so lucky. I'm not familiar enough with the problems because I've never had any problems, but I understand that they do exist in some areas. (Heavily-manicured deliberately-monoculture lawns are a different thing that I'm not even attempting to address here.) reply modeless 17 hours agorootparentprevI've seen plenty of companies using them. It's not even close to impossible. They're just not the majority. reply SOLAR_FIELDS 14 hours agorootparentAre these companies operating at scale? We have a couple in my city as well. But it's one guy maintaining their own fleet of equipment. Does the cost rival gas powered companies? The companies I'm aware of that offer this service specifically market it as a premium and appeal to eco friendly consumers that want the less noise and pollution, and are willing to pay more than double what it costs to have a gas powered company do it. Unfortunately, until the technology improves I think we have a tragedy of the commons scenario here, because gen pop is probably willing to trade the noise and air pollution for the cheaper service reply kbenson 17 hours agorootparentprevWhy? I'm sure they're less practical than the gas powered ones, but every tool system with their own battery standard seems to have one. Even if you had to have a few batteries charged in reserve, that seems more like slightly more expensive and annoying than utterly impractical. Am I missing something? reply xkqd 17 hours agorootparentYou basically can run through a high capacity battery in less than 10 minutes, completing a light cleanup of a standard 1/4ac lawn. The battery itself will take 3-4 hours. Running through an entire block would deplete numerous batteries, meaning youâ€™ve got to purchase 2 dozen if your crew is going to do the average 20ish homes a day. The purchase cost is one thing sure, but batteries are a consumable and the logistics of charging are no joke for the average crew. This is all just to blow some light leaves and clippings. This doesnâ€™t account for running trimmers or god help you the lawnmower itself. The tech just isnâ€™t there yet and given the extremely high energy density and ease of use of gasoline, it may never match it. reply kbenson 11 hours agorootparentFrom a little looking, the Greenworks 82BA26-52DP[1] seems like it might work well. It has a fairly long run time on battery on high (40 minutes), very long on low (2 hours), and has a dual port charging solution that seems to be able to charge batteries in 40-60 minutes depending on battery size. About a hour per tank of gas for a gas powered leaf blower seems to be about average, so I don't think stopping that often is really a problem. It is more expensive up front, from even the electric blower's own numbers, but they say it's much cheaper over a year if you have a 4 hour daily usage cycle.[2] I don't know enough to know whether the claims make sense or not. Maybe you know more about this, but maybe it's not as clearly one sided as you think? 1: https://www.greenworkscommercial.com/products/82ba26-52dp-82... 2: https://www.greenworkscommercial.com/cdn/shop/files/82BA26-S... reply modeless 17 hours agorootparentprevI understand that they are less convenient and probably significantly more expensive for commercial use. That's why legislation is necessary, so landscapers who choose them aren't at a cost disadvantage. Externalities like air pollution are the textbook reason for regulations like this. reply SOLAR_FIELDS 17 hours agorootparentI mean we are talking an order of magnitude more effort and cost in exchange for noise pollution. I suspice if you told voters lawn care would quadruple in price in exchange for less (note, not eliminated) noise and air pollution that voters would not be terribly keen to approve such a solution. reply modeless 17 hours agorootparent> lawn care would quadruple in price Come on, they're expensive but not that expensive. reply alach11 11 hours agorootparentprevI'm on the (admittedly expensive) EGO system of lawn tools, and I can mow, trim, and blow my entire yard (front and back) in a relatively normal lot (8000 sq ft) on one 10.0Ah battery. It recharges in 2 hours. So I think electric is a touch more practical than your numbers might represent. But for commercial use I agree, the upfront capex cost is prohibitive. And the need for charging infrastructure (in truck or other) presents an issue. reply atonse 9 hours agorootparentThere are companies that make battery packs the sizes of small ice coolers that can serve as a charging â€œhubâ€ on your truck. Plus there are trucks like the f150 lighting that have electrical outlets so you could recharge in the field. Thirdly, with 1-2 spare batteries that you can swap and charge, you basically have zero downtime. reply slimsag 17 hours agorootparentprevThey're not even in the same ballpark My 80v electric blower with a heavy battery runs for 21 minutes. A gas blower with 1.5 gallons of fuel will last 10 hours. A ban on gas blowers - or blowing in general - will only harm minorities already underpaid, often under the table. reply modeless 17 hours agorootparentThose minorities get the worst of the air pollution and dangerous noise levels themselves. And you have to add the externality of everyone else being affected by the pollution before you weigh the costs and benefits. Of course landscapers shouldn't be expected to switch voluntarily when it puts them at a competitive disadvantage, it's a textbook case of externality needing regulations. reply kbenson 11 hours agorootparentprev> My 80v electric blower with a heavy battery runs for 21 minutes. A gas blower with 1.5 gallons of fuel will last 10 hours. I found backbpack models (and if we're comparing professional services that's what seems we should compare) that claim 60 minuntes on high at 800cfm+ and 20 hours on low, with dual charger systems you can buy to supplement. I saw numbers quoting that most professional leaf blowers go through about 0.43 gallons of fuel an hour. The top backpack blowers I looked up didn't even have a 1.5 gallon tank. The Echo PB-9010T has a 83.8 fl. oz. tank. The Stihl BR 800 C-E Magnum has a 67.6 oz. tank. The SCHRÃ–DER SR-9900X 80cc has a tank size of 75 oz. If you have to stop to refuel every hour or so anyway, swapping out a battery that's been charging doesn't seem like a big inconvenience. > A ban on gas blowers - or blowing in general - will only harm minorities already underpaid, often under the table. I'm not sure we should be avoiding legislation meant to protect the public in general (air and noise pollution) because of possible affects to some specific subcategory (leaf blowing) of an industry (landscaping) which happens to employ minorities in a higher percentage than other industries. If we were to always do that, then we'd rarely ever have any useful public protections, would we? How many professional leaf blowers per capita do you think we have, anyway, and if it costs more for everyone since it's regulated, why would the impact really be that great, since it should just mean they charge more? reply kjkjadksj 17 hours agorootparentprevThey are also nearly as loud to my ear as a gas one. Turns out blowing air is noisy. reply modeless 17 hours agorootparentMaybe they sound loud when you're using them but the difference is night and day when you're a bit farther away. I haven't heard a single electric blower that's louder than the quietest gas blower. And honestly the air pollution is my bigger complaint. reply tracker1 17 hours agorootparentBanning air freight would be more effective in terms of reducing pollution. reply modeless 17 hours agorootparentI'm not talking about CO2 for global warming here, it's negligible. This is local air pollution, polluting the air I breathe in my house and on my street. The other big offender in this category is wood smoke from fireplaces, which I would also be in favor of banning, though I understand this would be extremely unpopular (I know, I love a good fire too). People don't realize that wood smoke is every bit as harmful as cigarette smoke and much worse than modern car exhaust. Many (most?) days in winter around here fireplace smoke is by far the biggest contributor to general poor air quality, and then there are the days when my neighbor's chimney smoke blows directly into my yard where my children want to play, for hours... reply tracker1 16 hours agorootparentThe city I'm in banned fireplaces in new houses a few decades ago. Of course, Phoenix is too hot far more than it resembles cold, and most will stay inside as much as possible for at least half the year. reply kylebenzle 16 hours agorootparentprevI guess I'm glad we don't use your ear as a way to measure sound levels then because we would all be way off. Gas-powered leaf blowers typically operate around 90-100 decibels (dB), while electric leaf blowers usually range from 60-70 dB. reply jasomill 14 hours agorootparentTo put this into perspective, per Wikipedia[1]: 60 dB SPL: TV (set at home level) 100 dB SPL: Jackhammer [1] https://en.wikipedia.org/wiki/Sound_pressure#Examples_of_sou... reply raddan 14 hours agorootparentAlso, crucially, dB is a logarithmic scale. So 100 dB is MUCH louder than 70 dB. reply ssl-3 13 hours agorootparentAlso, crucially: dB is a measure of sound pressure level at a point in space. It is not at all a measure of total sound output. And it tends to fall off at a rate of 6dB per doubling of distance. So by halving the measurement distance and changing nothing else, a thing reads as being about 6dB louder. And by doubling the measurement distance and changing nothing else, a thing reads as being about 6dB quieter. So stating that a jackhammer is 100dB and a television is 60dB is rather meaningless by itself. If the jackhammer is measured at 0.5 meters (the distance of the operator's ears, say) and the television is measured at 2 meters (the distance of the viewer's ears, say), then there is a measurement delta of 12dB, which is a difference more than an order of magnitude in energy intensity. And all we did to produce that massive delta was vary the distance where we've placed the meter. (And, no, there is no standard measurement distance. Loudspeakers are often [but not always!] measured at a distance of 1 meter, and generators are often [but not always!] measured at a distance of 20 feet. It needs to be explicitly stated. In all cases, if the only parameter relayed is \"dB\" then it doesn't really mean very much. And this isn't even getting into other important factors, like if the measurement is performed in a half-space or anechoic or whatever environment.) reply shagmin 17 hours agorootparentprev...yet where I live all the parks, public landscaping, etc., that are owned by the municipality are maintained with electric leaf blowers except for areas where they have it contracted out and then it's a mix. It's totally possible, but I think the larger problem is the sunk money on equipment that doesn't need to be replaced any time soon. reply SOLAR_FIELDS 14 hours agorootparentI've seen a couple businesses in my city that use electric. It's their main selling point. But in both the cases I'm aware of it's literally just one guy maintaining his own tiny fleet of equipment. And it's more than double what it would cost to get a bigger landscaping company to do it. I would really like to see an example of a landscaping company do this at scale, because I haven't seen it. The equipment itself is not even really that big of an investment to my understanding. A good electric leaf blower and battery is probably equivalent or cheaper than its gas powered equivalent. It's the logistics and maintenance burden of having to constantly charge, swap, replace, and maintain the batteries. Kind of why electric cars only became viable in the last 20 years. The technology has been around a long time, it's just only now viable enough due to capacity restrictions. Due to the form factor and energy requirements, it may be a long time before that happens to replace two and four stroke motors for commercial use cases. reply ericmcer 16 hours agorootparentprevI am so tired of noise and air pollution having 0 enforcement in cities, but if a car is parked for 15m too long in a metered spot they are ready like hawks to swoop down and dispense a $60 ticket. I was eating lunch at a restaurant few weeks ago and a parking enforcer was ticketing a car right next to us. A few feet past the car three dudes on motorcycles were revving their engines and blasting music at the stop light. No one could talk and the air smelled for a couple minutes after they left. It just seemed so wrong who was getting punished and what cities prioritize in that instance. reply jauntywundrkind 7 hours agorootparentprevDC seems to be doing pretty great with our ban. Theres some loud-ish electrics but it's still 1/8th the horror that it used to be; it used to be that someone two blocks away was still creating a living hell, but now it's really just someone across the street with a particularly poor model. Next up on my list, construction sites! We've had a small condo going up nearby, wood framed, and the generator is loud as fuck all the time. They use so little power though. A hybrid setup with 1kwh battery would let that thing rest 95% of the time. Ditto for their air compressor; a even modest sized 300 PSI air receiver tank would radically improve the neighborhood for nearly no cost. reply modeless 18 hours agorootparentprevYeah a ban in a suburb of a city doesn't work because they are brought in by landscaping companies not based in that suburb. reply kjkjadksj 17 hours agorootparentUsually the ban is something like you cant use it in 500ft of a residence, which obviates that issue if cops bothered to patrol for this or if there was a reporting hotline that was well advertised. reply riffic 18 hours agoparentpreva buy-back program would be a good first step. reply coolspot 16 hours agoparentprev> Not just for the noise pollution but the local air pollution. Also, leaf blowers make a lot of dust airborne, which canâ€™t be good to inhale. reply divbzero 16 hours agoparentprevItâ€™s not only noise and air pollution for the neighborhood, but also a matter of safety for the operators. reply cchi_co 12 hours agoparentprevBut more sustainable alternatives to gas-powered leaf blowers are needed I think reply craigmcnamara 12 hours agorootparentHave you heard of a rake? reply grecy 18 hours agoparentprevI'm always shocked that small ICE equipment don't have catalytic converters, or any emissions reducing devices. Especially given the operator is actually holding the thing and the exhaust is just a foot or two from their face, surely the health consequences are capital letters bad. reply xkqd 17 hours agorootparentUsually the crews running them are more focused on feeding their families over their own long term health. Iâ€™m still surprised when I see some crews have hearing protection. reply adrianmonk 17 hours agorootparentThat is exactly the kind of situation where regulations are needed. Sometimes the market can take care of things, and regulation isn't needed. But these workers don't have lots of leverage. If conditions are bad, they can't tell the boss \"I have other options\" and quit. So the market won't solve this case. reply xkqd 16 hours agorootparentIn all fairness, weâ€™re not wrangling in a megacorp or small company / bad actor type. These are usually tiny businesses where the owner is busting their ass in the hot sun alongside their crew. These are usually the smallest of small biz, and oftentimes just a young guy and a single helper. I donâ€™t believe we can expect lawncare prices to 4x, but this is a perfect example of targeting those who we should be supporting. If anything, structure the regulations to tier controls by size of the operation. We absolutely should not be making the lives of a 20 year old kid trying to start something up any harder than it already is. reply modeless 15 hours agorootparentI am sympathetic to this argument. I also think the buyback program suggested upthread is probably a good idea. reply grecy 14 hours agorootparentprevBut by that logic we should let a 20 year old kid start as asbestos mine with hand tools next to a drinking water source, or let them operate heavy machinery on a highway with no training of any kind. Clearly, just because doingis a path to making money, it absolutely does not mean we should automatically reduce all barriers and allow it to happen. \"More jobs\" should absolutely NOT be the goal, and anyone that says it is clearly hasn't thought to hard about it. Quality jobs are clearly much, much more important. reply daveguy 16 hours agorootparentprevI expect you don't see the hearing protection most of the time. 30 dB Ear plugs are 20 cents each and a reusable respirator is ~$25. Peanuts compared to gas and equipment. reply BenjiWiebe 15 hours agorootparentprevSome do. https://www.stihl.com/catalytic-converter.aspx reply datahack 15 hours agoparentprevThey are already banned in California. The rest of you need to catch up. I for one am stoked to have a quieter electric one though of course Iâ€™m behind your sentiment! But for Calfironians, itâ€™s already better for the environment with all these small engines phasing out, and now itâ€™s quieter too? Slick. reply modeless 13 hours agorootparentI'm in California and the ban is only on sales, not use. There has been no difference in practice, yet. And my city also has a citywide ban on use, but there's no enforcement, so it's pretty much a joke all around. reply datahack 13 hours agorootparentIâ€™ve noticed a drastic reduction here where I live already. Use will take care of itself if you ban the sale, which is what happened. Why the pessimistic take? Donâ€™t you want to live in a quieter environment? Transitions take time â€” but we are well on our way. Most places can only dream about not having a gas powered leaf blower going on and on for hours while they try to work: here itâ€™s already transitioning. So why be anything but positive about it? reply geocrasher 19 hours agoprevWhat I loved about this is that all of their prototypes were with a stock leaf blower with *3D Printed* attachments. This really shows the value of the rapid prototyping that 3D Printing has allowed. It also shows that any of us could have done this with enough time and effort. And I don't mean literally any person- but there are a LOT of YouTube engineering channels that could likely have tackled this, had they been asked to. reply pradn 15 hours agoparentThere's a lot of value in coming up with a clear problem statement and giving it to the right people. We see this with DARPA, at a much bigger scale. A lot of the value in engineering leadership is in making sure the right problems are being solved. reply cchance 17 hours agoparentprevThe funny part here is they say product, but in reality as soon as this ships someone will hit it with a hammer, figure out the internal layout with some calipers and we'll have an STL lol reply StimDeck 3 hours agorootparentCanâ€™t we just look for the patent application rather than wait two years for a concrete product? reply pradn 15 hours agoparentprevThere's a lot of value in coming up with a clear problem statement and giving it to the right people. We see this with DARPA, at a much bigger scale. reply Mountain_Skies 18 hours agoparentprevThere are a lot of ongoing attempts in the 3d printing community to replicate the Wilson airless basketball. I expect there will be similar efforts in to produce something similar to what the students created. Wonder if they applied for a patent and if that would prevent clones from being made. reply unsupp0rted 18 hours agoprevThe first time I woke up in North America to the sound of a neighbor with a leaf blower, I asked myself how this could possibly be legal. reply hindsightbias 18 hours agoparentYou should go to the beach and relax with a two-stroke jet ski. reply nisse72 12 hours agorootparentor on a hike with a UE Boom reply nikolay 15 hours agoprevI watched years ago a presentation at the City of Irvine, California, from a scientist that all these small engines (leaf blowers, mowers, etc.) pollute California's air way more than all cars combined. Also, the leak machine oil. To me personally, leaf blowers are bad not only due to their exausts, but because they also make all kinds of bacteria and pollutants airborne, most specifically, fungus, feces from animals, large particles, etc., which end up in our lung eventually. To me leafs are not a big issue. I'd rather have grass with decaying leaves then grass and leaf blowers! UPDATE: It seems that California has banned the sale, not the use of gas-powered small engines [0]! [0]: https://www.cityofirvine.org/environmental-programs/lawn-equ... reply rldjbpin 21 minutes agoprevlove the ingenuity but this reminds me of the \"pen vs pencil in space\" myth. while the residents should not be really using them in the first place, i hope local municipalities would acquire quieter options for maintaining public spaces. reply moribvndvs 13 hours agoprevI welcome even quieter electric, but the two stroke engine on most blowers (particularly the pack blowers) is the real problem and they are EVERYWHERE. Every day from sun up to sun down from March until December my neighborhood has a nearly constant drone and reeks of two stroke gas. It has gotten so much worse over the past 7 years Iâ€™ve lived here, and sharply worse since pandemic. I dunno if itâ€™s attributed to more affordable pack models becoming more popular with homeowners or increased usage of landscapers, but it has become an extreme nuisance. I have a handheld electric to help with a couple of hard to reach spots. While itâ€™s not as quiet as I wish, you canâ€™t (well, least I canâ€™t, from my testing) really hear it after about 75 to 100 feet. The surrounding neighborsâ€™ blowers can be heard over a quarter mile away when Iâ€™m walking around the block. It has ruined enjoying time out in the backyard, especially during the fall which is my favorite season. reply foobarian 20 hours agoprevI got an electric leaf blower mostly to avoid the noise and partly to avoid gasoline engine issues (a Kobalt 80V blower). What baffles me is that here the designers had a chance to make something truly quiet but instead they blew it and used a super-high-RPM motor-powered narrow turbine placed inside the pipe. It sounds like a dental drill amplified through a set of loudspeakers. I would kill to get a commercially designed blower powered with a large squirrel cage driven by a low-RPM brushless motor. I'm sure they exist by now and I imagine they are glorious. I'm not sure what these students did but if I was doing that project today that is the first thing I would try. reply chmod775 19 hours agoparent> What baffles me is that here the designers had a chance to make something truly quiet but instead they blew it and used a super-high-RPM motor-powered narrow turbine placed inside the pipe. They didn't change anything about the blower. They made an adapter you plug on the front that tries to cancel out the the worst offending frequencies. Like a silencer, but for leaf blowers. It's the red thing you see on the pictures. reply flanbiscuit 19 hours agorootparentI think foobarian is referring to is: > I got an electric leaf blower mostly to avoid the noise and partly to avoid gasoline engine issues (a Kobalt 80V blower). ...and not the content of the post. I was a little confused as well though so you're not alone. But I'm pretty sure that's what they meant. reply SoftTalker 19 hours agoparentprevThey are made. Of course a hand-held blower that has enough air velocity to do its job is going to make some noise, but I walked by a landscape maintenance guy outside work yesterday, he had a battery-electric blower and it was much quieter than the old two-stroke gas blowers they were using last year. I didn't note the brand but the casing was green. Maybe Deere, but it wasn't quite the Deere shade of green so I don't know. You know what's quieter than any blower? A broom. But not as fast. reply debunn 19 hours agorootparentGreenworks offers battery powered leaf blowers - might have been one of these? https://www.greenworkstools.com/collections/leaf-blowers reply organsnyder 18 hours agorootparentOr Ryobi. Though Greenworks is probably more likely for a professional. reply auntienomen 18 hours agorootparentEGO makes a really good one. reply Kirby64 13 hours agorootparentprevLikely Ego. Ego makes probably the most premium electric only power tools. reply Mountain_Skies 20 hours agoparentprevMakes me wonder if they intentionally kept some noise to combat consumer perception that it was weaker than gas models. reply swayvil 20 hours agorootparentGood point. If you want a good accurate model of human psychology, look to world of marketing. There is a similar noise-is-strength in vacuum cleaner sales. reply dylan604 19 hours agorootparentWe all know loud pipes save lives, so just think of all of the lives you'd be putting at risk by making quieter anything. reply Mountain_Skies 18 hours agorootparentBack before they started adding in artificial noise, I almost got hit by a Prius because I couldn't hear it and the driver was distracted. It was only due to the noise of some loose gravel on the pavement that I became aware of the car and got out of the way. reply sandworm101 19 hours agoparentprev>> instead they blew it and used a super-high-RPM motor-powered narrow turbine placed inside the pipe. Because it is a handheld tool. It cannot be heavy. If you want to shove lots of power through an electric motor then that motor has to be either very heavy or very fast. The same is true for turbines. And a lighter consumer product will generally be cheaper to manufacture. reply johndough 19 hours agorootparentAnother reason for smaller and lighter fans is the lower moment of inertia, which means faster spin up and spin down. Unfortunately, these frequent spin ups annoy me to no end. reply riversflow 19 hours agoparentprevI have had the twin battery Makita model for several years now. Itâ€™s a fabulous tool, basically functions how you describe I believe. Puts out a max of 61db on high. Expensive, but we already have makita tools, and it made a hated chore essentially not exist because its so convenient, fast and easy. reply BurningFrog 19 hours agoparentprev\"instead they blew it\" I see you! reply loceng 20 hours agoparentprevElon Musk at one point once suggested Tesla would make a quiet leaf blower - due specifically to the noise. I wonder if Tesla perhaps has a whole bunch of technologies they're developing incognito in the background - or if he's perhaps being limited for some artificial reasons? It may just be a market size issue - and cities passing bylaws to disallow gas powered, only allow electric under a certain dBs is the fix; and for some reason aren't caught under existing noise pollution-nuisance laws. reply willsmith72 20 hours agorootparentIs that really what people want? Leaf blowers to me are possibly the least interesting, least appealing way to use modern tech To clarify, as a research project, cool. We can probably use any new developments elsewhere. But as a tesla product, just why? reply jandrese 19 hours agorootparentI want it. Specifically I want it to be mandatory for all of the lawn services that use straight pipe two stroke leaf blowers at 6 in the morning, every morning. All other lawn equipment is loud but manageable. Leaf blowers are unreasonable. They are also the only equipment even the lawn service guys wear heating protection while using (sometimes). reply willsmith72 18 hours agorootparenti think i've just grown up in different areas to a lot of you all then. this has never been a problem for me, but maybe it's regional/cultural/climate-dependent. reply eyelidlessness 19 hours agorootparentprevWhile I am reticent to speculate on anything Musk or Teslaâ€¦ > Is that really what people want? I would literally buy substantially quieter leaf blowers, as gifts, for neighbors whom I do not even like. There are few things I want more. reply marcosdumay 18 hours agorootparent\"Oh, he gave me one too. They can't blow shit, they don't even sound like a leaf blower.\" Your disliked neighbors talking to each other in the future, probably. reply dylan604 19 hours agorootparentprevThey could open source the tech and the take PR victory laps on how they are helping lower irritating noise, saving the environment, and being very cool about not trying to profit over it. That's the kind of thing that would blow up on this site. How would an electric leaf blower (or anything electric/battery/motor related) released by Tesla be any different from a flamethrower made by Boring company? At least there's a bit of resemblance from the tech used, but a self-lighting gas device from a digs hole in ground company has nothing to do with anything. reply loceng 16 hours agorootparentI think enough of the ideological mob on HN that hate Elon would claim \"he's just doing it to not look so evil!\" reply loceng 19 hours agorootparentprevThey know and have the supply chain setup, and they are arguably specialists in electric motors? Well, and technically specialists in rocket motors too - at least access via SpaceX engineers. reply Delmololo 19 hours agorootparentprevIt's probably just not a market anyone really cares. The person who does it a few times a year just buys something cheap. The professional needs to have it running the whole day. No cable and just noise means that the boss saves money and the worker can just use ear protection. reply wannacboatmovie 19 hours agoparentprev> (a Kobalt 80V blower). What baffles me I don't understand. You opted to buy the inexpensive store brand tools (Kobalt is Lowe's house brand) and now you're complaining that shortcuts were taken and it didn't exceed requirements or your expectations? I don't walk into Harbor Freight and expect Snap-On tools. reply sameerds 19 hours agorootparentIf I am not mistaken, the first sentence mentions what the GP commenter has, while the second sentence talks about what's mentioned in the article. You seem to be conflating the two. EDIT: s/argument/article/ reply mistermegabyte 17 hours agorootparentprevThe Kolbalt 80V line was made by Greenworks, which makes excellent products for pros. I have the Kobalt 80V blower and it is an excellent blower (loud) and is just a rebranded 80V Greenworks. Not Harbor Freight cheapness for sure. I also have the 80V mower and trimmer and they too are just rebranded Greenworks tools. Excellent products overall. reply MisterTea 18 hours agorootparentprevYou'd be surprised with the quality of some of the latest harbor freight tools. They are still shaky with some stuff but they aren't the \"hazard fraught\" of 5+ years ago. reply pxx 17 hours agorootparentThis is a good point but you're never going to win an argument with somebody who has spent more money than warranted on a purchase. Whether it be title insurance, a name brand on an item that came from the same factory as another item, or even religious tithings, people are both financially and emotionally committed to past expenditures and it is extremely tough to fight past this commitment. reply xxs 22 hours agoprevUnfortunately the article is very poor on details. The sound from the video is insufficient to tell. Personally, I'd be quite excited to see what are the changes engineering wise. I bet it'd make a proper addition to BOLTR. I still can't see how it'd be much quieter, as lots of the noise is just the air moving (and making sound waves), perhaps less vibrations, different frequencies due to different rpm? reply planb 22 hours agoparent\"Our product takes in a full blow of air and separates it,\" said team member Leen Alfaoury. \"Some of that air comes out as it is, and part of it comes out shifted. The combination of these two sections of the air makes the blower less noisy.\" Sounds like they created a noise cancellation air channel. reply gwbas1c 13 hours agorootparentBasically, by splitting the airflow into a shorter and longer channel, the slight delay in the longer channel cancels out the most annoying frequency. It would be interesting if they stacked two or three together to muffle even more noise. reply xxs 21 hours agorootparentprevI reread it - it says 40% reduction, that's -7dB... I can believe that part. Edit: checked DCBL772X1 - it's listed 68 dBA - that's not necessarily loud, so if they managed -7dB, massive props to them. reply SV_BubbleTime 19 hours agorootparentExcept it is not. They claim a 2db reduction overall. Then they say that is 37% the noise. But it is not. Human hearing isnâ€™t linear with power. 2db is not the human perceived volume. The article isnâ€™t light on details - itâ€™s bullshit. reply barfbagginus 17 hours agorootparentDuring the great American knowledge collapse, it's becoming more and more important to make American students look smarter for working, like, less harder. reply regularfry 21 hours agorootparentprevThere was a paper a few years ago describing something that sounds very similar: https://journals.aps.org/prb/abstract/10.1103/PhysRevB.99.02... reply addandsubtract 21 hours agoparentprevI might be going deaf and losing high-pitched frequencies, but I couldn't tell much of a difference in the video example of before/after. reply SV_BubbleTime 19 hours agorootparentBecause itâ€™s 2db overall. No camera is going to pick that up because no human is going to hear it. They claim 37% reduction, but that isnâ€™t true for human perceived volume. reply SOLAR_FIELDS 17 hours agorootparentAnd as has already been pointed out elsewhere, even if it was an actual 37% reduction it would be useless anyway since no commercial operation would be viable with electric leaf blowers. Theyâ€™re good for blowing the leaves out of a homeowners driveway and not much else reply SV_BubbleTime 16 hours agorootparentHonestly, my EGO â€œ670cfmâ€ on turbo is really quite good. But yes, I use it for maple leaves. reply xyst 20 hours agoprevCool invention. Will the students get paid royalties or is the university and private company taking all of the royalties/profits? reply klankschap 21 hours agoprevHow about leaving leaves for what they are. Just leave them and move on with your own life. reply cityofdelusion 18 hours agoparentI tried this when I first got a house. The leaves decompose and you end up shoveling a layer of mud off your waking surfaces. It also becomes incredibly slippery when wet. A dense layer of waxy oak leaves can be like walking on ice. reply digging 17 hours agorootparentHm, residential walking surfaces are easily swept with a broom though. reply cchance 17 hours agorootparentHe's saying to leave it on the yard to break down, if you do that it turns to slippery ass mud eventually, and guess what people like to be able to walk in their lawns, if we're sweeping up the entire yard so that we can use our yard without it being slippery and muddy from decomposed leaves... congrats you've just fucking reinvented the rake and leaf blower reply digging 15 hours agorootparent> you end up shoveling a layer of mud off your waking surfaces Doesn't imply that the entire yard was being considered a walking surface reply mlrtime 21 hours agoparentprevHave you ever considered it's just a name and it's actually used on more than just leaves? Or was the post sarcasm? Poe's law. reply barfbagginus 16 hours agorootparentIf they are serious, then they are making the equivocation fallacy - arguing by using a word in two different ways and hoping nobody notices the mistake. But it's likely they are doing this as a pun, where readers are supposed to notice the equivocation, and find it funny or annoying. For example we can imagine a lazy husband saying \"they're called leaves, so that is why I'm going to leave them for tomorrow!\" This is not a serious attempt to equivocate the two meanings of \"leave\" - it communicates non willingness while also causing laughter or annoyance. An obvious equivocation is not usually an effective argument. But making it a pun can win points with a good humored audience, because they find it funny. Funny arguments can influence opinions even though we know they are nonsense. TLDR; when people mix word meanings secretly to confuse people and win points, it's equivocation, and that's a morally bad argument and is usually unacceptable. But when people mix meanings blatantly to win points by being funny, it's a pun, and that may be acceptable in non-serious conversations. reply kreyenborgi 21 hours agoprevhttps://twitter.com/moxie/status/1582154037700399104 moxie marlinspike invented one a few years ago reply ZeroCool2u 20 hours agoparentThis was the first thing I thought of when I read the headline. I'd be curious to hear his thoughts on this student design. reply v7n 22 hours agoprevI wonder if the efficiency is indeed unchanged, or as quoted in the article \"keeps all that force\". If so, and if the added weight is really minimal, I wonder if this could be applied to EDF aerial vehicles such as hobbyist RC planes. reply omgJustTest 21 hours agoprev\"Their design cuts the most shrill and annoying frequencies by about 12 decibels, which all but removes them, making them 94% quieter. The team reduced the overall leaf blower noise by about two decibels, making the machine sound 37% quieter.\" [1] Somewhat upsetting here... I don't have a problem with people doing things like this and students need encouragement, but we are talking about shifting from the sound of a leaf blower to the sound of a vacuum cleaner [2]... in the best case. One particular annoyance here: the sound emission must be from the end of the blower but also from its casing. I feel many products like these are cheaply designed, and the OEM could solve many of the nuisance issues with simple housing changes... or spending a few more pennies on the bearings or blades in assemblies. These are not OEM primary goals, as they are looking to save pennies in a lot of the parts in these designs. JHU should make these comments!, and also offer their designs for free given these are public orgs using mostly public dollars... if the result is such a big deal, getting manufacturers to commit to sound reduction in licensing deals would be a true result! https://audiology-web.s3.amazonaws.com/migrated/NoiseChart_P... [2] reply omgJustTest 19 hours agoparent(Also for those claiming JHU is private therefore not majorily dependent on federal funding, please read JHU website:https://hub.jhu.edu/2024/01/05/nsf-higher-education-research...) reply rad_gruchalski 21 hours agoparentprevTry this one: STIHL BGA 86 Akku LaubblÃ¤ser. It's shocking how quiet it is. reply whiplash451 21 hours agorootparentmmm, the spec says 90dB [1] which is the sound level of a motorcycle at 25ft [2]. not amazing (at least on paper) [1] https://www.stihl.de/de/p/laubblaeser-blasgeraete-saughaecks... [2] https://www.chem.purdue.edu/chemsafety/Training/PPETrain/dbl... reply mc32 21 hours agorootparentEven gasoline powered echoes claim 87db. The battery powered Egos are quieter. reply sokoloff 21 hours agoparentprev> JHU should make these comments!, and also offer their designs for free given these are public orgs using mostly public dollars JHU is private. It seems like this research may have been sponsored by Black & Decker, also private. reply natemcintosh 20 hours agorootparentYes, these mechanical engineering senior design projects at JHU are all sponsored by some organization or another, and the sponsor gets to keep the end product (and in this case also patent pending). Source: did a mechanical engineering senior design project at JHU 6 years ago (though mine was less successful, haha) reply grubbs 20 hours agorootparentWas yours the pizza transport box for Pizza Hut? ;) reply omgJustTest 19 hours agorootparentprev\"Johns Hopkins researchers' success in winning federal fundingâ€”which accounted for close to 87% of its 2022 R&D expenditureâ€”enables them to pursue projects in an array of fields, from human genetics to artificial intelligence.\" [1] https://hub.jhu.edu/2024/01/05/nsf-higher-education-research... Oh yes... \"private\" org using public dollars is more appropriate. reply sokoloff 13 hours agorootparentIt appears as if this specific research was funded by Black & Decker. If they couldn't get the benefits from it, it's not as if they'd pay JHU to do and make public this research, but rather that they'd do the research a different way, likely robbing the JHU students of the real-world problem-solving experience as a capstone project of their engineering curriculum. How JHU's other, unrelated research is funded doesn't seem terribly relevant to this privately-funded, patent-pending innovation. reply ChrisMarshallNY 21 hours agoprevIf this becomes popular, I hope they get a Nobel prize. reply dsizzle 20 hours agoparentHaha I came here to make the same comment reply Scene_Cast2 21 hours agoprevWhisper Aero is a startup trying to commercialize a quiet leaf blower. I don't think they're selling their product yet, unfortunately. reply tmnvix 14 hours agoprevI still recall a tragicomic leafblower event that made the local news when I lived in Australia. A caretaker was killed when a tree fell on him while he was using a leafblower during a storm. The added irony was that he was doing this at 'The Lodge' - the official residence of the Australian Prime Minister which had been vacant for some time because the Prime Minister refused to live their (preferring a residence in Sydney). So an entirely unnecessary event all around. reply lukas099 21 hours agoprevI was hoping the video would show it actually blowing leaves. reply pnielsen2 16 hours agoprevThe madlads they finally did it! https://www.youtube.com/watch?v=3Eo2uq5k1O0 reply DasCorCor 17 hours agoprevPut them up for the Nobel. reply bibanez 17 hours agoparentThe Nobel of Peace, of course reply maven29 22 hours agoprevCan't be quieter than a rake. reply xxs 22 hours agoparentUnless you stumble on it. Other than that - leaf blowers are not used only in gardening work. reply huhtenberg 22 hours agorootparentYep, it's invaluable for getting your BBQ grill really going. reply rimunroe 19 hours agorootparentI actually got into metal casting and blacksmithing because one day I tried using my dad's shop vac to blow air into a fire I'd made in the backyard. The shop vac was about as strong as a leaf blower and was extremely effective. After that I dug a small pit, trenched a 2\" pipe into the bottom of it to act as a tuyere, and then hooked the shop vac hose to the other end of the pipe. That fire got hot enough that some rocks lining the pit glowed white and sand started to clump together. I could toss an 8-10 inch piece of (undried) oak log into the fire and it would completely burn away in under ten minutes. I had used an old log holder from a fireplace made of 3/4\" iron bars to allow airflow around the larger logs as the fire was starting. When the fire died down I discovered it had completely buckled and collapsed from the heat. I went on to learn how to make refractory bricks and distill charcoal. I switched from the shop vac to a computer case fan for my actual forges though, as the shop vac easily blew all the charcoal out of the fire pot and was very loud. reply mlrtime 21 hours agorootparentprevI use it to dry my car which is ceramic coated, one of the best tools I have recently purchased. reply mlrtime 7 hours agorootparentedit: Sorry I meant when I wash the car. For some reason I thought that was obvious. reply kreyenborgi 21 hours agorootparentprevwhy would you dry a car instead of buy one that is water proof i would be leaf blowing my car every other day with the amount of rain here reply mlrtime 7 hours agorootparentI'm sorry, is this is sarcasm? When you wash the car you want all the water off of it. Water isn't clean. reply riffic 17 hours agorootparentprevwater spots lol. reply teekert 21 hours agorootparentprevI have never dried a car, does a car not dry by itself? reply CalRobert 20 hours agorootparentI have never dried my own cars but my dad and grandfather insisted on towel-drying cars to avoid water spots. Though come to think of it, a leaf blower might not work for that, unless it's actually managing to remove the water mechanically and eliminating evaporation. I recall mechanized car-washes using blow driers so maybe this does, indeed, work. reply mlrtime 7 hours agorootparentYou're from a great line of dads! When you wash the car properly, you want to remove the excess water as it's not clean. Most people do this with a microfiber, towel or chamois. These can scratch the surface if not done properly. A strong blower will remove the water without scratching the surface. It also works in places too small to reach with a towel. reply sidewndr46 21 hours agorootparentprevI've noticed roofing crews use them to remove old shingles. It must work pretty well, if they are dealing with carrying them around on the top of a house. reply rimunroe 19 hours agorootparentmy neighbor uses them to clean his gutters reply baerrie 17 hours agoprevThank god, i am so sensitive to all lawn equipment noise, this is a huge public good and I think there should be more restrictions on this class of machine, gas and electric reply WaltPurvis 20 hours agoprevCan someone explain to me what \"quieter\" means in this context and/or how it's calculated? I don't understand what they mean when they say reducing the noise by 2 decibels made it 37% quieter -- it wasn't making only 5 decibels of noise before, was it? >>Their design cuts the most shrill and annoying frequencies by about 12 decibels, which all but removes them, making them 94% quieter. The team reduced the overall leaf blower noise by about two decibels, making the machine sound 37% quieter. reply tomoyoirl 20 hours agoparentDecibels are logarithmic; a 1 dB reduction in sound is ~26%. reply SV_BubbleTime 19 hours agorootparentBut that is NOT the same as human perceived volume. Less 37% energy is not 37% less volume to humans. You wonâ€™t be able to tell the difference in volume except for the tone which could be more or less pleasing depending on the frequency they say they got 12db on. reply WaltPurvis 17 hours agorootparentI learned something new today (I didn't know decibels were logarithmic), but I still don't understand how it relates to \"human perceived volume\" as you put it. If a typical electric leaf blower makes 70 decibels of sound, it seems odd that cutting that to 67 decibels makes it sound 37% less loud. Perhaps it does, but I think I'll have to hear it to believe it. I may have to buy a sound meter and run some experiments. reply ssl-3 12 hours agorootparentA reduction of 3dB at any point in space is equivalent to halving the energy at that point. But we humans don't perceive sound energy linearly, so half of the energy is not equivalent to half of the perceived loudness. The usual rule of thumb is that it takes a reduction of 10dB (1/10th energy) for a thing to sound about half as loud, or an increase of 10dB (10x energy) for a thing to sound about twice as loud. (This leads to all kinds of interesting problems with making things quieter or louder. It seems superficially implicit that moving from a 100-Watt amplifier to a 1,000-Watt amplifier would be strikingly-dramatic difference, but in an ideal world where everything else is the same then that change only makes things about twice as loud -- the same as moving from a 1-Watt amplifier to a 10-Watt amplifier.) reply calfuris 15 hours agorootparentprevThe sound has 37% less power, but human perception of sound intensity is roughly logarithmic. Looking at the difference in dB will give you a better estimate of the perceived change than the difference in actual sound power. reply anarticle 20 hours agoparentprevDecibels are log scale, reducing by 3db cuts energy by half. reply unglaublich 20 hours agoprevDoesn't matter. We have quiet vacuum cleaners, quiet cars, quiet motorbikes, and quiet mowers, but that doesn't trigger the feeling of primal power that many buyers search for. reply grugagag 20 hours agoprevA rake is also an option reply lotsoweiners 18 hours agoparentNot when you have gravel landscaping and a yard full of shrubs with small leaves. The rake will work a little on the larger branches but wonâ€™t do a good job of cleaning up. reply TOMDM 22 hours agoprevIf these truly sound that much better I'd personally buy every gardener in a 3 block radius one of these myself just to get rid of the bloody gas ones. reply mikeyouse 21 hours agoparentMany affluent areas have already banned gas leaf blowers and itâ€™s incredible how quiet the battery powered replacements are. I was in Palm Springs recently and had nearly walked past a landscaper using one before if occurred to me just how quiet it was - didnâ€™t even interrupt our conversation. I believe it was a Stihl backpack version (maybe https://www.stihlusa.com/products/blowers-and-shredder-vacs/...) but yeah, highly recommend! reply sidewndr46 21 hours agorootparentIt isn't so much the noise that bothers me, what I've never understood about leaf blowers is what are they meant to accomplish? When I watch people use them they either blow the leaves into the street or the neighbors yard. What do they think that does? Now on the other hand, I do own a very noisy leaf vacuum. But when I've collected a bag full I can just deposit the leaves in my collection container. They are taken off to be composted reply KineticLensman 18 hours agorootparentI own a Stihl leaf blower and primarily use it to clear debris from the gravel paths in my garden. Because raking gravel also collects the stones. Debris includes leaves, leaf husks, beech nuts, catkins, and a range of other things that drop off trees. I use a big rake to clear the lawn (I actually enjoy the physicality of this task). All of this stuff is composted over the year in a large pile in a secluded corner of my garden, along with grass cuttings, scarified moss, etc. The volume of stuff usually exceeds the amount I can get rid of using the local council's garden waste collection. reply sidewndr46 17 hours agorootparentNow that you say that, it makes much more sense. It isn't like I go into my neighbors backyards and monitor them using their leafblower. So all I really see is the yard maintenance guy in the front yard. I'll commonly just see them blowing them into the street. Not all of them do this however. reply dgacmu 20 hours agorootparentprevI use mine (electric) to blow leaves from the street and sidewalk back onto my grass so that I can mulch them with the lawn mower. I also use it to blow debris back onto the grass-free perennials area around my tree to get free mulch. I'm weird, but it's really handy for that. The entire reason I own a lawn mower and a leaf blower is because I couldn't find a lawn care crew that would mulch everything in place - everyone around here wants to take your leaves away and then bring in artificially dyed mulch (and charge you for it). They also work for blowing snow off the sidewalk if the snow is still fluffy. reply nkrisc 19 hours agorootparentprevYes, any tool can be used in foolish ways. I use mine to blow debris from the driveway onto the lawn so it doesnâ€™t get tracked into the garage, or to clean the leaves, sticks, and pollen from our many trees that accumulate on the back deck. The times Iâ€™ve had landscapers come they used tarps to collect the bulk of the debris they gathered with the blowers and hauled it away. reply lesuorac 20 hours agorootparentprevKeep in mind; in some towns a truck comes around and collects the leaves from the street with a vacuum (although I guess your town doesn't?). I have seen (predominately contractors) blow leaves into a tarp to take away on a truck though. reply sidewndr46 20 hours agorootparentThere is a pile of leaves so deep in the street in front of my house that it has an entire ecosystem living in it. At this point they have composted some, insects have begun to live in them and grass is growing from the pile. reply nkrisc 19 hours agorootparentIn many places that would be the homeownerâ€™s responsibility to clean up. Even if not, itâ€™s often in the homeownerâ€™s best interest to not have a huge pile of rotting leaves clogging the gutter. reply sidewndr46 19 hours agorootparentthere is no gutter, just the curb. The couple times I looked into this, to do maintenance on the street I'd need to have some form of insurance. reply nkrisc 18 hours agorootparentWell I guess everywhere is different. That's truly bizarre to me though. reply SoftTalker 19 hours agorootparentprevOur town used to do that, then they decided it was too costly and stopped. I am waiting for them to corelate the increased need to clean leaf-clogged storm drains with this decision. reply organsnyder 18 hours agorootparentI would think that encouraging everyone to put their leaves in the gutter might also cause clogged storm drains. reply francisofascii 20 hours agorootparentprevTo be fair, they are very good at removing debris from a front-porch. I fully support banning them, and they are heavily overused in situations when a rake works just as well, but they are superior in some cases. reply ericmay 20 hours agorootparentThey're great for landscapers. I just use a push broom. It takes more time, sure, but efficiency isn't the goal. reply sidewndr46 20 hours agorootparentprevI guess that makes sense, but I always personally just use the hose for that. The way I am billed, I don't really pay much for the water I use. reply y-c-o-m-b 17 hours agorootparentprevI use it to remove pollen, pine needles, gravel, debris from clippings, etc from my deck and drive-way. Sometimes I use it to clear out the gutters on my roof. I usually blow it all down into one corner then use a dust-pan and broom to collect it all and throw it in the debris bin. I hate it when people just blow the debris somewhere else; they're making it somebody else's problem and that's wrong. reply aga98mtl 19 hours agorootparentprevThe leaf blower is used after using the weed eater (String trimmer) to blow all the little bits back into the grass. reply Joker_vD 20 hours agorootparentprevWouldn't letting the leaves to decompose be better for the soil instead of constantly removing them? I mean, the tree supposedly uses the nutrients from the soil to grow those leaves, and if you keep removing them away, at some point the tree will simply starve and die, right? reply jandrese 19 hours agorootparentBetter for the soil, but it kills off the grass. Lawn services mostly use leaf blowers to clear driveways and sidewalks of grass clippings. reply micromacrofoot 21 hours agorootparentprevgenerally for landscapers it saves them the trouble of raking, which can put a lot of strain on your back â€” they'll blow the leaves onto a tarp and then wrap them up for easy removal in my experience, homeowners mostly dick around with them reply jrmg 19 hours agorootparentThis thread is like people whoâ€™ve never cleaned a yard before saying â€œIâ€™ve never understood the purpose of rakes and brooms - donâ€™t they just move things around? Surely you need to pick things up to really clean?!â€ reply sidewndr46 20 hours agorootparentprevI guess that would work, but I have never seen anyone do that. reply rpdillon 18 hours agorootparentMy son and I raise money for our Boy Scout troop by doing yard cleanup in the fall. Using leaf blowers and tarps is how the crew worked through 20 acres of cleanup over two weekends. reply stronglikedan 19 hours agorootparentprevOnly for lack of trying. Most of them do do just that. reply SV_BubbleTime 20 hours agorootparentprevA groupof Bay Area condo and apartment owners discuss that they donâ€™t understand leaf blowers. Good thread. reply sgarland 21 hours agoparentprevThere are problems with battery-powered tools (at least, leaf blowers) still, especially at the commercial level. For one, they just donâ€™t have the runtime. I briefly had an 80V blower. On its highest power â€“ which is the only way it could come close to a gas-powered model, it was barely able to get all of the leaves out of the yard (we had a tree with leaves that had needle-like protrusions, which made them quite hard to dislodge), and lasted about 10 minutes per charge. If you donâ€™t have sticky leaves, or are clearing primarily hard surfaces like a deck, then absolutely, battery-powered is the way to go. But if youâ€™re a commercial operator who is driving tools more or less non-stop all day, itâ€™s going to be a hard sell to have to have a minimum of N*2 batteries (at $150-200 each), plus the downtime of swaps, plus having to run a generator on your truck constantly to charge the off-duty batteries. EDIT: Sibling comment below linked to a Stihl model that appears to offer an hour of runtime at full tilt. Itâ€™s also $2400 for the unit / battery / charger, tbf, but it at least has the performance. reply xxs 20 hours agorootparentA whole hour of runtime would be mean 1C discharge. 80V (which is likely 72V, but in the US it's ok to label the max voltage rather than the actual one) is made of 20 Li-Ion batteries in series. Lets say 2 in parallel, so total 40 batteries. I'd go with 3Ah per battery (could be more for 21700) and around 2Kgs weight. For 1h work that's ~430W of power which is rather under powered. That fast charger (say 30min to charge) for this thing would be quite a thing to witness with over a kW of power draw. About Stihl, it uses a 36V battery, so 10 Li-Ion in series. Which is half as powerful. I can't see a capacity higher than 36V/6Ah from Stihl. Now, it possibly uses multiple batteries, however, the issue with charging still remains the same. Running a generator would be louder than the device, so imo that's a moot point. I'd consider using a massive power bank and/or lots of pre-charged batteries to carry the day but not an inverter.Taking enough batteries to swap and charging them in off-hours seems the only sensible approach (albeit not cheap) reply jandrese 19 hours agorootparentFor what it is worth the chargers for tool batteries are almost never fast chargers. So it takes 4 hours to charge for 15 minutes of runtime. reply xxs 22 hours agoparentprevThat is battery (li-ion) powered, so it's already quieter to begin with. reply hedora 19 hours agoparentprevIn San Jose, whenever someone proposes this (or at least getting the gas powered ones to stop dumping carcinogens), theyâ€™re non-ironically branded as racist. People argue the battery powered ones arenâ€™t good for professional use (short runtimes) but that problem was solved years ago. They also argue theyâ€™re too expensive, but that argument falls apart if you include engine maintenance and gasoline in the cost. reply noobcoder 21 hours agoparentprevWould love to know what neighbourhood you live in so that I dont have to get it for my gardener reply giovanni_or2 20 hours agoprevI love the sound of a leaf blower. Makes me sleepy. reply rangledangle 17 hours agoprevTo me the noise was 10% of the problem. Who wants to breathe in what lies on the ground? Just lick it instead. reply dagurp 21 hours agoprevI hope they'll put this on hand dryers too reply prmoustache 21 hours agoprevIsn't it called a leaf rake? Frankly I never understood the popularity of leaf blowers to begin with. They are noisy, less effective than a leaf rake and very bad for health and back of the users. It seems they exists only because people are stupid enough to think that something that makes noise and use a lot of energy would necessarily be better. reply fkyoureadthedoc 21 hours agoparent> less effective than a leaf rake and very bad for health and back of the users. Citation needed. I can clear my whole yard with an electric blower much faster than with a rake. I also have no idea how holding a leaf blower would be bad for my back or health. reply derbOac 19 hours agorootparentThere's also leaves that can't be raked because they're too small. reply lotsoweiners 18 hours agoparentprevRaking leaves out of landscaping rock is a PITA. I blow the leaves and other debris onto the driveway and then sweep up. Easy peasy. reply linhns 21 hours agoprevCan this idea be adapted to vacuum cleaner? Would appreciate that since my head starts to spin when I hear one. reply hyping9 19 hours agoparentIt's called hearing protection. People wear it while operating heavy machinery, shooting guns, or being at rock concerts. Might not hurt to keep a pair around your home. reply stevage 20 hours agoprevYou kind of get the impression that manufacturers never even bothered to try to make them quiet before. reply ajmurmann 19 hours agoparentWhile I'm usually very free market, I think this is a case where we have such a high negative externality that we need regulation. Everyone is annoyed by leaf blowers, but the tradeoff for users, especially commercial, of paying the extra cost isn't worth it to them. I don't think we should ban them, but have a maximum permitted noise level. reply handsclean 20 hours agoprevThereâ€™s some other â€œquiet leaf blowerâ€ on the market, and all theyâ€™re doing is reducing power and telling you special nozzles make up for it, which of course they donâ€™t. This article omitting performance measures is a red flag for me. Whatâ€™s the CFM impact? Itâ€™s 40% quieter, but is it also 40% worse at blowing leaves? reply stevage 20 hours agoparentIt says like 10 times in the video that equal performance was the KPI. reply handsclean 20 hours agorootparentTimestamp? Iâ€™ve watched the video twice now and read the whole article and canâ€™t find one mention of it. The closest is one statement of â€œit keeps all that force still thereâ€, which is vague, definitely not the same thing as CFM, and sounds like the sort of statement thatâ€™s compatible with the aforementioned nozzle lines. reply kingcai 20 hours agoprevThis is cool. Kudos to the team too - I feel like this is what engineerings all about. reply danielohrlund 21 hours agoprevIf it works I'll buy one for my neighbor as soon as they're available. reply indigo0086 17 hours agoprevNot one leaf blown. reply the_real_cher 19 hours agoprevMoxie Marlinspike tried this. Pretty decent try. https://twitter.com/moxie/status/1582154037700399104?lang=en reply pferde 20 hours agoprevCool, now outlaw the loud ones in populated areas. Next step, the same thing with the obnoxiously loud motorbikes in cities. reply piokoch 19 hours agoprevLeaf blowers are one of the most idiotic inventions ever made. What is good about moving throwing leafs from place A to place B, where they will be rotting in the same way. Blowing with all other dust and trash. Luckily they got recently banned in Warsaw. reply KingOfCoders 21 hours agoprevI also have one, it's called a rake. reply Pikamander2 21 hours agoparentThe one I use is called \"letting the leaves decompose naturally and accepting that certain areas will be mulchy\". Plus a broom to keep the sidewalk clean. reply KingOfCoders 20 hours agorootparentTried that, but it's not working for me on the (small) patches of grass in our garden - I guess it depends on the climate. reply ks2048 18 hours agoparentprevPeople don't have time to do physical work like rake the lawn. They need to finish the yard work and drive to the gym to get some exercise. reply KingOfCoders 17 hours agorootparentReminds me of the escalator to gym meme. reply fkyoureadthedoc 21 hours agoparentprevMany people have an even quieter one, no yard, what's your point? What's so important about this statement that you had to be the 3rd one to make it? reply KingOfCoders 21 hours agorootparentIf three people make this, then it should say something about a.) leaf blowers and how they are liked by bystanders b.) that this might be solving the wrong problem. \"you had to be the 3rd one to make it?\" With people making a personal attack out of everything, I wonder: Does this make you happy? How are those people in real life? Can't they discuss things without getting personal? (Oh and I see the irony of my comment, but I do consider this a meta-discussion) PS: No I don't read every one out of 180 comments before I comment myself. Chapeau if you do! reply fkyoureadthedoc 21 hours agorootparent> With people making a personal attack out of everything, Just because you feel attacked doesn't mean you were attacked. Nothing bad happened to you, other than being asked a simple question. > PS: No I don't read everyone of 180 comments before I comment myself. In this case 0 were read in order to rush and make a low effort joke because there were two rake comments above the fold and nowhere near 180 total when you wrote it. There's no need to lie here, you gain nothing from it. reply KingOfCoders 20 hours agorootparent\"In this case 0 were read in order to rush and make a low effort joke\" You should work for the NSA or the three later agency of your country, you can spot what people do possibly thousands of kilometers away! There was this one Columbo episode, one of my favorites, where the NSA wanted to hire such a guy. Sadly it was all fake. So the cynical side of me assumes you also can't spot what I'm doing at my computer, and your assertion you could see what I was doing, was fake :-( \"make a low effort joke\" You still have not understood my comment. You make no effort to understand the comment, even with my explanation. I guess this is because you don't want to understand people but get something out of attacking them. My comment was not a joke, which was the point of my previous comment. reply fkyoureadthedoc 16 hours agorootparentThe point stands that you lied about the number of comments to aid your position, and that you didn't read even the above the fold comments. So you weren't making a low effort comment, you were trying to start substantive discussion, but you didn't even read other comments? Sounds likely. I guess since we're telling pointless stories about TV shows I should comment on your bright future as a HumancentiPad component. reply KingOfCoders 15 hours agorootparentI was not making a joke. But that's not fitting the narrative in your head. You invent other people in your head, me \"rushing to the comments to make a low effort joke\", ignoring what they say (\"I was not making a joke\"), then make up what they say, so you can attack them, instead of an argument (\"I was not making a joke\"). \"The point stands that you lied about the number of comments\" I never said how many comments I have read. How can I lie about the number of comments I have read then? Are you mixing up comments? You see me highly confused. [Edit] I made the comment because there are many leaf blowers here - and while they do individually safe time to the user, they create hell for everyone else who might be noise sensitive. And I made the comment to express that there is already an invention, the rake. So people could use that instead of optimizing their comfort and time against everyone else wellbeing. But people don't care. reply dontupvoteme 19 hours agoprevThe innovative power of the hangover reply tao_oat 21 hours agoprevSee also https://news.ycombinator.com/item?id=40374795 (posted 9 hours ago). reply chiefalchemist 21 hours agoprevTuesday I mowed the lawn. Yesterday morning, I got up, made coffee, grabbed my shop broom and cleaned up out front. Not a leaf blower insight. Sure it took a couple of extra minutes but I also got some light exercise. I understand why a lawn service uses a leaf blower. I don't understand why my neighbors do. reply hyping9 19 hours agoparentnext [2 more] [flagged] chiefalchemist 19 hours agorootparentHey whatever. I don't care. But when I hear a leaf blowers early on a Sunday or even a Saturday, I cringe. There's no reason miserable people need to make others miserable as well. reply unpopularopp 20 hours agoprevAwful lot of NIMBY people on HN, that always surprises me reply shiftpgdn 20 hours agoparentHating on a universal annoyance isnâ€™t NIMBY behavior. reply Log_out_ 18 hours agoprevIt creates dustdevils that clean up your yard. reply sandworm101 20 hours agoprevA quieter leaf blower? No. They did not do that. They found a way to quiet an existing leaf blower. Adding a silencer to a gun doesn't mean that you have invented a new gun. >> They workshopped more than 40 versions of the solution they finally settled on: an attachment that cuts the machine's noise almost like a silencer on a gun or a muffler on a car. And for all the people screaming about electric v. gas, this isn't about that. This device looks like it could be used on any leaf blower, although the difference is probably less dramatic on a gas-powered model. reply alberth 21 hours agoprevHN 7-months ago199 comment Similar story: https://news.ycombinator.com/item?id=37932971 EDIT: why the downvotes? reply SigmundA 21 hours agoprevMilwaukee just came out with a blower claiming 40% quieter then their last revision hard to tell if the students version is quieter: https://www.youtube.com/watch?v=q2NSBAe6bdI reply luketollefson 21 hours agoprevHN commenter with this exact idea 2019 https://news.ycombinator.com/item?id=20379490 haha. Good stuff reply StimDeck 2 hours agoparentGive that commenter some upvotes. Also did you just pull this from memory? reply Kuinox 21 hours agoparentprevIt looks like the same structure. reply mccrory 22 hours agoprevNow if we could solve this for the rest of the lawn equipment, especially mowers and string trimmers. reply infecto 21 hours agoparentThe switch to electric will help a lot in this situation. Unfortunately I don't think the equipment is good enough contractors yet. reply jchw 21 hours agorootparentIt's probably getting there given what Ego has on offer, but I think until it is downright better in at least some dimensions, it's going to be a hard sell. Right now it seems like it's more expensive, at best similarly powerful, and obviously batteries take time to recharge. I think it's gotta be niche for contractors. That said, given how bad gas lawn equipment is for the air in a locality, maybe regulatory nudges are in order. I suspect if the incentives were right the rest of the problems would solve themselves. reply cooperadymas 21 hours agorootparentAs someone who went all in on Ego about 3-4 years ago, let me tell you, the technology is nowhere close to capable enough for even small-time contractors yet. You would need at least 3 batteries per piece of equipment in use at one time in order to not have to spend time idle while a battery recharges ($700-$1000 upfront investment in batteries per piece). The lifespan of those batteries under constant usage would be atrocious. Even if you could solve the battery problem, the power of the equipment doesn't come close to gas. My Ego leaf blower doesn't even compare to the plug-in electric one I had prior to acquiring it, and I still have to revert for some harder jobs. An example of this: if there is a clump of wet grass on concrete, like something left behind from a mower wheel, the Ego struggles to move it while the plug-in has no problem. Or if a pile of leaves is damp, forget about it. The mowing quality is terrible, leaving long patches everywhere (despite a sharp blade and slow progression). The form factor of the mower deck makes corners and edges much more difficult than other machines. And because the power is limited, the mulching capabilities are almost nil. It shuts down quickly if you hit a particularly tough piece of lawn to avoid overloading its motor. reply derbOac 19 hours agorootparentReading through the comments here I feel like I live in a parallel universe. I have Ego products and don't see any problems with them whatsoever. I've used and have gas and corded equipment, and by far prefer Ego. I haven't noticed any functional difference in how they perform, and if anything I get annoyed by gas models because they're heavier and more annoying to start and stop. Sure they're more powerful sometimes but I've never needed the extra power they provide. It's not like I'm going to chop up a log using my lawnmower. I've never had problems mulching anything or mowing well, and it works perfectly. And I live on a fairly wooded property so we get tons of leaves. The batteries last plenty long and charge really fast. For what it's worth, they do make batteries in different Ah capacities. I don't even remember which ones we have but maybe we have the higher capacity ones? I can see why contractors might have issues with constant use of cordless equipment. But I'm not a contractor, and my guess is they'd have more problems with battery lifespan than charging in practice if they timed the charging well. I also understand why people wouldn't like the sound of leaf blowers but to me I don't understand the level of animosity about them, in the sense that there's other things that are much louder that I don't hear laws being passed about and so forth. To me it feels a bit like they're being singled out for some reason, I assume because people believe they're unnecessary? Either that or I'm just not bothered as much by that particular noise. reply jchw 20 hours agorootparentprevI have all electric lawn equipment as well, though my mower is a Toro. No disagreements that a 13A blower connected to AC will beat the shit out of a battery-powered leaf blower, but I'm sure you do and hopefully did realize that, the math just doesn't work out. The one place the Ego does excel at is stuff like edging and string trimming, where there's not nearly as much power needed. They definitely struggle a bit on things like chainsaws and blowers where more power is just generally better. The place where it is weakest is probably snow blowing. They now have a 2-stage electric blower, but I am pretty sure it's just nowhere near gas. I live in the midwest in an area where the 1-stage Ego electric blower is already kind of overkill, so that's what I'm running. It has its negatives and positives: it always starts without having to worry about the fuel sitting over the seasons, it's quiet during operation and doesn't pollute, the batteries are always ready since they are on the charge when not in use, and I have enough battery to run it for much longer than needed. That said: the batteries are, indeed, simply too expensive. I'm surprised the mower sucks, this Toro electric mower feels reasonable compared to anything else I've ever used (granted, I do not have much lawn and have never used any serious mowers. Just your average lawn mowers). I wonder if it's true that all electric mowers suck or maybe it's just that Ego isn't/wasn't doing a good job on mower design. reply cooperadymas 20 hours agorootparentI have no real problem with the blower being underpowered compared to a plug-in, but for commercial use, it would be a deal breaker. The Ego leaf blower and even the chain saw are good tools for 90% of my average home usage, and the convenience of not having to deal with cords or trying to start a small gas engine makes them worth it to me. I have not had to go to my old string trimmer once and should probably sell it. Living more north of you, I haven't dared try the snow blower. The gas blower I have struggles with some of our snows up here. The mower on the other hand, I wanted to return after the very first mow but convinced myself that even with a poor cut the trade off was worth it. 4 years later and with batteries dying I'm considering other options (including the Toro electric, but many reviews made similar remarks to the Ego). reply jchw 19 hours agorootparent> I have no real problem with the blower being underpowered compared to a plug-in, but for commercial use, it would be a deal breaker. Yeah, exactly. That was my thought, too. I don't think they're that far behind, but improvements in battery technology might be necessary for commercial usage to become viable without being subsidized or regulated. > The mower on the other hand, I wanted to return after the very first mow but convinced myself that even with a poor cut the trade off was worth it. 4 years later and with batteries dying I'm considering other options (including the Toro electric, but many reviews made similar remarks to the Ego). Yeah, I suspect you really do need the power of gas for your mowing. That does make me wonder why some people clearly do and some people clearly don't, but it's probably not worth wasting too much time pondering. reply infecto 20 hours agorootparentprevI love my ego but agree will all of your problems. It just does not have the power that gas mowers have. Suction can be a real problem on them, they use proprietary blades that have to be light weight because of the electric motor. I do think their more recent models fix a lot of these issues but I don't think its ready for commercial use. Just having to have a large number of batteries to sustain your day of work is limiting. reply criddell 21 hours agorootparentprevIf governments want to help the adoption of electric tools, they should mandate the use of standard batteries. reply deadbunny 21 hours agorootparentprevMaybe it's just a UK thing but I can't think of the last time I even saw a non-electric lawn mower. Even going as far back as the 80s they were the standard, just don't mow over the cable! reply Maxion 21 hours agorootparentDepends on where you live and the size of the yard. Electric are great when the size isn't that big. Once you go larger, it becomes very hard to do practically with electricity. reply kristofferR 21 hours agorootparentIsn't it the opposite? Doing it the manual way with gas is super hard compared to just buying an electric robot mower, especially in large yards. reply xxs 21 hours agorootparentThere are different types of mowers - push (usually 4cycle), push+self propelled, riding one(s), then 2cycle scythe types, and then trimmers and brushcutters (spinning blades). Those options (more or less) are available battery powered, too. Battery powered ones have shorter use per charger but they are lighter (and usually less powerful). However, if you can use a robot one (or few of them), it tends to be an easier setup - it does require flatter lawn and what not, though. However they are insufficient in cases where one really needs a riding mower. Personally, I have/use a robot, a battery powered strimmer, gas powered brushcutter, and a push behind mower. The main job is done by the little robot, but the rest have their uses as well. reply KineticLensman 18 hours agorootparentprev> Maybe it's just a UK thing but I can't think of the last time I even saw a non-electric lawn mower UK here. I've been using a petrol mower for the last 25 years. My lawn is 40m long. I do own a 50m extension cable but it would be a real hassle for grass cutting. My three adjacent neighbours also have petrol mowers. reply actionfromafar 21 hours agorootparentprevSmall gardens reply actionfromafar 21 hours agorootparentprevIt will get there I suspect, the tools and batteries can charge in the truck en route. Easier to just fuel up the truck once instead of filling up little gas tanks all the time. reply travisb 15 hours agorootparentCharging using the truck would require running the truck all day -- probably not an acceptable alternative. Consuming 2-10 Kw from a 200 Kw engine would be so inefficient that it'd be too expensive anyways. Instead you'd need to run a generator all day charging batteries. A fast charging, high capacity tool battery takes at least 60 minutes to charge. In high power applications (lawn mower, leaf blower, chainsaw, etc) those batteries might be emptied in a little as 15 minutes. A better alternative might be corded 240v tools running directly off the generator for high-power applications. 120v tools are limited to 2-3HP which doesn't compare well to gas engines. reply actionfromafar 13 hours agorootparentHybrid truck? reply travisb 9 hours agorootparentIf you had a serial plug-in hybrid with a 20+Kwh battery which also supported exporting 120vac, that would work. AFAIK such a vehicle doesn't exist in North America yet and might not exist anywhere globally. You start stacking energy efficiency losses (engine -> charger -> battery -> inverter -> charger -> battery -> motor) and economic losses (expensive serial hybrid, higher than expected vehicle battery cycles, still need a large number of tool batteries which wear out in about a year, etc.) though. reply infecto 20 hours agorootparentprevI am sure it will, its just no where close yet imo. Truck charging is not as practical; if the crew is running a tight ship, they should not be far between jobs. So you would basically need a lot of batteries to sustain a day full of jobs. reply twoquestions 21 hours agoparentprevI love my battery powered mower and trimmer (wow there's so many names for that)! I can mow the lawn and come back in and relax with a quiet show or game! reply haunter 20 hours agoparentprevWe have a 1 acre garden. Electric gardening tools are just toys for this size. I'd love to use electric but nothing comes close to gas. reply xxs 22 hours agoparentprevLawn mower robots do the trick quite nicely actually. reply 134 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Johns Hopkins University engineering students created a quieter leaf blower, cutting noise levels by almost 40% and getting rid of irritating frequencies.",
      "The patent-pending design wowed sponsors and is projected to hit stores in two years, showcasing the students' dedication to refining the product over months.",
      "This innovation could not only enhance loud appliances but also indicates the students' potential to impact other products positively."
    ],
    "commentSummary": [
      "The debate focuses on electric vs. gas leaf blowers for landscaping, discussing environmental impact, practicality, and effectiveness.",
      "Advocates suggest banning gas leaf blowers to cut pollution, balancing considerations of noise levels and air quality.",
      "Mentioned are challenges of battery-powered tools, potential quieter tech advances, and ideas for regulations, incentives, and alternative yard maintenance methods."
    ],
    "points": 262,
    "commentCount": 396,
    "retryCount": 0,
    "time": 1715860054
  },
  {
    "id": 40378218,
    "title": "Neovim 0.10: Enhanced Features & Community Engagement",
    "originLink": "https://gpanders.com/blog/whats-new-in-neovim-0.10/",
    "originBody": "What's New in Neovim 0.10 May 16, 2024 Neovim 0.10 was the longest release cycle since the heady days of the 0.5 release. There are a ton of new features in this release (as well as some breaking changes), so be sure to check the full release notes. You can view the release notes directly in Nvim with :h news. The news file includes information on new features, deprecations, and breaking changes. I especially urge plugin authors to read this file carefully. Like last time, in this post Iâ€™ll cover a subset of the new features. As I said, itâ€™s a big release, and I wonâ€™t write about everything, but these are some of the highlights. Table of Contents Defaults Builtin commenting Terminal UI enhancements LSP inlay hints Tree-sitter query editor Miscellaneous Roadmap Defaults Colorscheme Nvim has been in need of a new default colorscheme for a long time. While the default colors have some charm and nostalgia, there are serious accessibility and aesthetic issues, particular when using Nvim is a diff viewer. The screenshot below shows the default colorscheme before Nvim 0.10: Nvim 0.10 now ships with a new default colorscheme, which you can see below: The new default colorscheme was heroically contributed by Evgeni Chasnovski, who endured seemingly endless bikeshedding and successfully navigated the treacherous waters of such a subjective change. There were many constraints imposed on the design of the colorscheme, which you can read in the PR (and the many follow up PRs and issues linked therein). It is quite literally impossible to please everyone with a single colorscheme, and there is no expectation that we have achieved that, but the new colorscheme does, hopefully, improve the default experience for many people. LSP and Diagnostics Mappings Nvim 0.10 adds a new default mapping: K in Normal mode maps to vim.lsp.buf.hover() whenever a buffer attaches to an LSP client, unless 'keywordprg' is already set to a non-default value. Use this to view information about the function or variable under the cursor. This in addition to the existing defaults mentioned in :h lsp-defaults which were added in the previous release. In addition, there are new default mappings for navigating diagnostics: [d and ]d in Normal mode map to vim.diagnostic.goto_prev() and vim.diagnostic.goto_next(), respectively. Use these to navigate between diagnostics in the current buffer. d (and ) in Normal mode map to vim.diagnostic.open_float(). Use this to view information about any diagnostics under the cursor in a floating window. The diagnostics mappings override builtin mappings. These builtin mappings are not often used, but if you do use them you can delete the new default mappings with vim.keymap.del() or :unmap. The intention behind providing more default mappings is to make it easier to get started with LSP in Neovim. The hope is that most users should be able to get up and running with useful LSP features with little to no configuration and without needing to write a bunch of Lua code. We have plans to add more defaults in future releases, though as you might imagine this is a fraught exercise. It is quite difficult to change default behavior in a tool as extensible and customizable as Nvim without breaking users' workflows. Two features which many users rely on for their LSP experience are snippets support and autocompletion. Both of these features are on the roadmap to be included in Nvim core (see #27339, #25696, and #25670) which will, hopefully, make the experience of using LSP in Neovim even smoother in the future. Builtin Commenting Longtime Vim users are likely familiar with the venerable vim-commentary plugin, which creates mappings and operators for commenting and uncommenting text. Thanks to Evgeni Chasnovski, Nvim 0.10 now bundles this functionality by default, using a from-scratch implementation in Lua. Unlike vim-commentary, Nvimâ€™s builtin implementation provides a text object and supports Tree-sitter, which is useful when working in injected languages (example: if you comment text inside a tag in an HTML buffer, it will correctly use the Javascript // comment string rather than HTMLâ€™scomment string). See :h commenting for more details. Terminal UI enhancements Nvim 0.10 adds support for many new terminal based capabilities. Synchronized Output Many modern terminal emulators support synchronized output which allows terminal applications (like Nvim) to â€œbatchâ€ all of their UI updates in the terminal emulator and display them all at once. This can reduce â€œflickeringâ€ and â€œtearingâ€ when a terminal UI (TUI) is being drawn very rapidly. This can sometimes happen in Nvim when using plugins that perform rapid UI updates (e.g. spinners, LSP status windows, etc.). Nvim 0.10 introduces a new 'termsync' option (enabled by default) which enables this feature if it is supported by the terminal emulator. System clipboard synchronization Nvim 0.10 can now use the OSC 52 escape sequence to write to (or read from) the system clipboard. OSC 52 is only used automatically when (1) it is able to determine that the terminal emulator supports it (via XTGETTCAP), (2) it is running in an SSH session, and (3) when the 'clipboard' option is unset. Note that some terminal emulators do not support reading from the system clipboard with OSC 52, or only allow it after prompting the user for confirmation. It is recommended to use the traditional â€œpasteâ€ key binding (e.g. Cmd+V on macOS or Ctrl+Shift+V on Linux) to paste into Nvim from the system clipboard and use \"+ to copy to the clipboard inside Nvim (see :h quoteplus). Hyperlinks Nvim 0.10 introduces experimental support for hyperlinks using the OSC 8 sequence. By default, this is used in Markdown for links of the form [example](https://example.com). If your terminal emulator supports the OSC 8 escape sequence, then the text example in the Nvim buffer will contain a hyperlink that can be clicked and will open https://example.com in your web browser. This means that users can view Markdown files with :set conceallevel=2 and get an experience much closer to the rendered output: In the screenshot above, the underlined words are clickable link text, just as you would find in a web browser. Automatic truecolor detection Nvim 0.10 will now automatically determine if the terminal emulator supports 24 bit color (â€œtruecolorâ€) and enable the 'termguicolors' option if it does. It does this through a combination of heuristics ($COLORTERM, terminfo) and terminal queries (DECRQSS, XTGETTCAP). This detection works even over SSH connections and when inside a terminal multiplexer such as tmux. LSP inlay hints Nvim 0.10 now supports LSP inlay hints thanks to Chinmay Dalal. A picture here will do more than my words can: The dark colored texts which display type annotations for variable declarations are inlay hints. This text is not part of the actual source file in the buffer, but is â€œvirtualâ€ text inserted by Nvim and provided by the language server. These hints can be enabled or disabled dynamically using vim.lsp.inlay_hint.enable(). Many other new LSP features were added in Nvim 0.10 as well. Refer to the â€œLSPâ€ section in :h news for a full list. Tree-sitter query editor Nvim 0.10 adds even more tools for working with Tree-sitter queries. If you didnâ€™t know already, Nvim bundles an â€œinspectorâ€ which allows you to view the abstract syntax tree of any source file with the :InspectTree command (so long as a Tree-sitter parser for the fileâ€™s language is installed). Example: Thanks to Maria JosÃ© Solano, Nvim 0.10 adds a powerful capability to the Tree-sitter inspector: a query editor. The query editor allows you to write queries and see the matches in a source buffer in real time. Being able to create and modify queries interactively makes writing new queries a breeze. Example: In the screenshot above, the query editor is open in the top-right window, the tree inspector is in the bottom-right window, and the source buffer is in the left window. Notice that the text that is matched by the query in the query editor is highlighted in the source buffer and that the text initializer (the capture group used in the query) is floating on the line next to the match. As the query is updated in the editor, the corresponding highlights in the source buffer change in real time. The query editor can be opened by pressing o in the :InspectTree window, with the :EditQuery command, or by calling vim.treesitter.query.edit() directly. With :InspectTree and :EditQuery, Neovim is one of the best tools (if not the best tool) for working with Tree-sitter, even if you donâ€™t actually use Neovim. Miscellaneous As I mentioned at the top of this post, there are a lot of new features in this release, and I am not going to cover all of them. Here Iâ€™ll list a few more that I personally think are worth mentioning: The :terminal command now accepts modifiers, so you can use e.g. :botright terminal (or :bo te) to open a new terminal window in a split at the bottom of your screen. In addition, :terminal buffers that are started with no arguments (and thus open a shell) will close automatically when the shell exits without an error. gx in Normal mode calls vim.ui.open() on whatever is under the cursor, which shells out to your operating systemâ€™s â€œopenâ€ capability (e.g. open on macOS or xdg-open on Linux). For instance, pressing gx on a URL will open that URL in your browser. Tree-sitter based syntax highlighting is enabled by default for Lua, Vimdoc (:help), and Tree-sitter queries (to revert to traditional regex based syntax highlighting, create a FileType autocommand or ftplugin with vim.treesitter.stop() for the respective filetype). Q and @ in Visual mode will execute the last recorded/executed macro for all visually selected lines. Users using a terminal emulator that supports the Kitty keyboard protocol can create mappings using the â€œsuperâ€ and â€œmetaâ€ modifiers with theis Cmd+S on macOS). Roadmap The Neovim project is loosely organized and structured. We follow a â€œfun driven developmentâ€ paradigm: for the most part, contributors and maintainers work on things that are personally interesting to them. Because of this, it can be difficult to predict what will happen in future releases. If there is a feature you want to see implemented, the best way to do it is to take a crack at it yourself: many of the features mentioned in this very blog post were contributed by users that are not part of the â€œcoreâ€ maintenance team! There is active chatter about further improving the LSP and Tree-sitter experience (as mentioned above, builtin snippet and completion support are a work-in-progress). One of the biggest challenges with Tree-sitter is parser distribution: currently, parsers are shared object files which must be compiled on every userâ€™s machine or distributed with a system package manager. We are already working on implementing the new Tree-sitter WASM capabilities which will enable distributing Tree-sitter parsers as portable WASM blobs. This solves the distribution problem and may enable Neovim to ship more Tree-sitter parsers out of the box. We would also like to integrate some of the functionality from nvim-lspconfig so that, ideally, nvim-lspconfig is just a â€œbag of configsâ€ without any smarts or core logic. How best to do this is still hotly debated, but it is something that is being discussed. Getting Involved There is nothing quite as fun as hacking on your own tools. If you are a Neovim user, I encourage you to get involved, whether that is through contributing directly to the Neovim project or a plugin, or simply participating in community spaces such as the Neovim Matrix room. If you have pain points or frustrations when using Neovim, please let us know. Many of us on the core maintenance team have been using Vim/Nvim for so long that weâ€™ve forgotten what itâ€™s like to be a beginner and, speaking for myself at least, this can leave blind spots on how things can be improved. Thanks for reading and for using Neovim! Hopefully the next update will come a little sooner. One Last Thing The Neovim project now has a merch store! If you didnâ€™t know that you needed a Neovim branded hoodie or mug, now you do. All proceeds raised from the store are used to fund project needs and sponsor full-time development work. Last modified on May 16, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40378218",
    "commentBody": "What's New in Neovim 0.10 (gpanders.com)261 points by gpanders 20 hours agohidepastfavorite112 comments azemetre 19 hours agoWhen I first started to learn how to program I was following along a basic tutorial by Jeffrey Way and his first sentence was \"We're going to use vim.\" That tutorial, whose topic I can't even remember now, set me on a path for my professional career. During 2012-2015 there seemed to be way more competition in the editor space before VS Code gobbled the community mindshare. I remember starting my first professional job and having a coworker to keep pressuring me to use vim because he used emacs and wanted to argue with someone about emacs in the office (all in good fun I assure you :D). I think I started using nvim when 0.2 was release, but then I didn't really do much more with my rc file than what vim offered. When neovim enabled plugin authoring with lua that's when it felt like the magic of neovim started to click for me. Plugins like telescope, harpoon, and fzf changed the way I fundamentally work now. Although I think my favorite thing about neovim is watching other people use neovim, I'm always learning new workflows to introduce into my workflows. It sounds tiring, but it doesn't feel tiring if that makes sense? Really excited to see inlay hints natively as that's something I really struggled to configure myself. reply celie56 19 hours agoparentI love watching others use Neovim and that's how I learned more about the LSP / treesitter integration. I still find that VS Code is my recommendation for new contributors to an existing codebase because of how intuitive it is to resolve problems solo. If I want to debug a change in an existing project I will almost always reach for VS Code due to the integration with build systems (CMake for example) or other tools. That said, I find that I do \"real work\" in neovim: thinking, exploring, or writing this reply. If I were to teach someone from the beginning I would still recommend (neo)vim. reply sph 17 hours agoparentprev> When I first started to learn how to program I was following along a basic tutorial by Jeffrey Way and his first sentence was \"We're going to use vim.\" That tutorial, whose topic I can't even remember now, set me on a path for my professional career. I like this origin story. In my case, I was already a decent programmer and beginner UNIX admin when I got my first job, and one day I was using nano or some other \"friendly\" editor to edit some files on a server, when the literal grey-beard senior sysadmin that was looking over my shoulder pulled a face and said \"OK, it's time you learn how to use vim\", and spent some time teaching me the basics of it. Now I have surpassed the Master and I use Emacs, though vim is still my second favorite editor. reply DEADMINCE 16 hours agoparentprev> because he used emacs and wanted to argue with someone about emacs in the office That's weird to me as in more than 20+ years I don't think I've ever been around people arguing that in real life. It's always been more of a meme to me than anything real. reply azemetre 14 hours agorootparentIt was always good natured and I enjoyed the comradery that came from it. He also taught me a lot about vim and command line tools in general. reply zabzonk 18 hours agoparentprevback in the early 1990's i worked for a commercial training company (The Instruction Set) and the first day of our \"Programming In C\" course normally went something like this: me: we are using these beat-up terminals trainees: is this what we are paying for? me: we will be using unix (no linux easily available then) trainees: but we use VMS! me: and we will be using vi to edit our programs trainees: wha??? ....a week passes trainees: actually quite neat! i really like vi reply durandal1 18 hours agoprevThe ultimate proof that Neovim has a healthy team of contributors, is that they successfully agreed on a new default color scheme. I am now convinced they can succeed with anything. reply nicce 15 hours agoparentThe proposal from a brave soul: https://github.com/neovim/neovim/pull/26334 reply jthemenace 14 hours agoparentprevNext up, tabs vs spaces!!! reply bbkane 19 hours agoprevWow, I love that so much stuff is coming to core! Every once in a while for the last few years I overhaul my Neovim config and try to add all the new goodies (commenting, LSP, etc., that are table stakes for most IDEs) as plugins using the latest and greatest plugin manager. That works for a while, but like clockwork, something breaks- a plugin updates incompatibly, Neovim updates incompatibly, an external binary the plugin relies on updates incompatibly... At this point I'm stuck with a broken IDE and I don't have the energy to debug all the moving parts. I suffer for a month or something and then restart the cycle. For my latest config, I decided to treat Neovim and \"just a text editor\" and made a much smaller config ( https://github.com/bbkane/dotfiles/tree/master/nvim-03-lazy ). It's been really nice having something that \"just works\" for text edits and using VSCode for heavier IDE tasks. I WANT to use Neovim for more complex tasks, but I also want a simple config that \"just works\". I'm really excited that the core devs seem to agree and are adding tablestakes features to core- the new default colorscheme, Treesitter WASM, and better commenting will all make my config even simpler! At some point I might even try LSP integration again! reply eptcyka 17 hours agoparentMy vim config is generated by nix, if I donâ€™t break it, it does not break. reply desdenova 17 hours agoparentprevI just use CoC for all LSP functionality, and everything just works with almost no issues. Configuring the native LSP client is still too clunky to switch. reply tristan957 19 hours agoparentprevI haven't used it, but vscode-neovim might give you the best of both worlds. reply EasyMark 18 hours agoparentprevthis is why I only update once a year or so around the beginning of the year. I mean \"bit rot\" is a real phenomenon but not in a year's time. If it fails. I just go back to my old config that is backed up in the cloud. If it fails, I can try again in a month. I'm too old to constantly be tinkering every week or two and hoping it doesn't break. reply marinhero 18 hours agoparentprevHave you tried using an nvim distribution? They take care of all the plugin loading, config and testing. They stay reasonably updated too. reply bbkane 18 hours agorootparentI tried using LazyVim, but I didn't put much effort customizing it so I missed my custom config and I found it somewhat janky reply scutrell 17 hours agorootparentprevI think they are a good middle ground, but you're still left with some of the busy work. Further, you're a bit more at the mercy of the maintainer. Likely, Lazyvim isn't going anywhere, but it isn't out of the realm of possibilities either. reply whinvik 18 hours agorootparentprevWhat distribution would you recommend? reply nop_slide 18 hours agorootparentI recently started with Kickstart paired with this video, it's really easy and beginner friendly. https://github.com/nvim-lua/kickstart.nvim https://www.youtube.com/watch?v=m8C0Cq9Uv9o reply EasyMark 18 hours agorootparentprevI think lazyvim is one of the more successful/dependable ones reply kevincox 19 hours agoprevWow. Almost all of these are things that I will be using right away. It's not often that a release, especially one for software that has lineage back decades, is so relevant to my use cases. I already had `K` set to LSP hover. I just switched my comment plugin to get something LSP aware. Hyperlinks can be a bit annoying. Because sometimes the line wraps so default terminal auto-linking doesn't work properly. Having explicit metadata will be excellent. I already had inlay hints enabled, but they would appear at the end of the line. Having these in the right place will be fantastic. `gx` open is not something that I was already using but I will probably start using this. reply wonger_ 16 hours agoparentI feel exactly the same - I've never been so pleasantly surprised by release notes. Immediate wins for current users. And hopefully these builtin QOL features will make nvim easier for new users. reply sdwolfz 18 hours agoprev\"Nvim 0.10 can now use the OSC 52 escape sequence to write to (or read from) the system clipboard.\" This is a big deal! (it shouldn't be, but it is) My main complaints about vim/emacs in the past was at the sheer complexity of getting something that should not even be a concern (clipboard integration) working properly, when other text/code editors did not have this problem at all. Searching online, it seems like tmux has some nice documentation related to OSC 52 usage: https://github.com/tmux/tmux/wiki/Clipboard I will be playing around with this for a bit to understand it more. But honestly, this is the sort of thing that should \"Just Work TM\". \"VTE terminals (GNOME terminal, XFCE terminal, Terminator) do not support the OSC 52 escape sequence.\" https://gitlab.gnome.org/GNOME/vte/-/issues/2495 That's a shame, but I'm not against using a different terminal emulator. Up until now I did not really have a good reason to. reply tasuki 13 hours agoparent> My main complaints about vim/emacs in the past was at the sheer complexity of getting something that should not even be a concern (clipboard integration) working properly What problems have you encountered? I have the following shortcuts in my .vimrc: vnoremap y \"*y noremap p \"*p vnoremap c \"+y noremap v \"+p Space + y/p is the copying/pasting from/to the \"primary selection\" (the mouse middle click). Space + c/v is copying/pasting from/to the regular ctrl+c/ctrl+v clipboard. This... just works for me? reply urxvtcd 31 minutes agorootparentMy solution is to have this snippet in my vimrc. Don't ask me why this works. It's been years, and I had no issues with it. \" System-agnostic setting making the unnamed clipboard register act like \" clipboard in any other editor. Copy with y commands, and paste with p or P. if has('unnamedplus') set clipboard=unnamedplus,unnamed else set clipboard+=unnamed endif Beside this, there is also the issue of setting paste when pasting in insert mode. reply yoavm 19 hours agoprevNeovim is great and is my daily driver for a couple of years now. I was really looking forward to 0.10 because the roadmap said \"multicursor\", and that's the only thing that sometimes make me open Sublime Text, but it seems like it was more complex to implement than originally estimated and so it was now pushed to 0.12 (https://neovim.io/roadmap/). reply wonger_ 17 hours agoparentI used to want multicursor as well. But I heard a recommendation that multicursor is not \"the vim way\", and instead to use macros or regex search-and-replace or visual-block mode. That's worked for me. Of course multicursor must be commonly requested for a reason. Just passing along some alternatives. reply ratorx 13 hours agorootparentI think multicursor vs macro is basically a case of whether the feedback is instant, rather than delayed. Multicursor (in other editors) is a lot better, because you donâ€™t have to think about which exact motion to use as much (since you can see it as you do them). On the other hand, macros and vim motions are a lot more general, but require you to think about the exact motions a lot more ahead of time. I think substitution (and command) previews (vs not having these features when substituting) is a good parallel to what multicursor adds over just macros. reply vander_elst 15 hours agoparentprevWhat's the difference between multicursor and visual block? Genuinely curious, is it that things don't have to be vertically aligned? What's the ux expectation in a pure keyboard based workflow? reply 000ooo000 10 hours agorootparentYeah I think that's it. You can place the cursors arbitrarily with Ctrl+mouse3 in editors like VSCode, ST3, IIRC. Multiple cursors in one line is a scenario I don't think visual block would be great for. I say this as an nvim user who uses macros and will occasionally copypaste a block into VSCode just if i'm feeling lazy and want to multicursor something. reply strangelove026 17 hours agoparentprevNoticed this also. Truly the only reason I still open up vscode. And repo find / replace. Otherwise Switched to nvim full time about 5 months ago, can do everything and more ha reply Zizizizz 14 hours agorootparenthttps://github.com/nvim-pack/nvim-spectre Is a great find and replace plugin for your repo. so is quick fix list + `:cdo s//gc:cdo update` reply jasonpeacock 16 hours agoprevFor everyone asking for more IDE features...that's literally a non-goal for Neovim: https://neovim.io/charter/ Neovim aims to be extensible and enable plugins to do amazing things, but also be minimal. There are many projects that use the rich set of plugins to provide IDE experiences (LazyVim, AstroNvim, LunarVim, etc). reply scutrell 17 hours agoprevAs a decade long vim user, I just gave nvim a try this year, and I really wanted to like it. In most every way it is a straight upgrade, but I find myself kind of bummed out that it is still so barebones on install. Really, I was hoping that something like Lazyvim would be the default because I would love a more \"out-of-the-box\" solution. I don't want to have to worry about keeping the LSP etc. up to date. So instead, I've been looking more into Helix. Still not sold on the bindings, but what you get just by installing it is great. reply WuxiFingerHold 6 hours agoparentI've settled on LazyVim after many happy years with Jetbrain IDEs and very few unhappy years with VS Code. I have the impression that most Neovim users are building their own config, which is great, if you have the knowledge and personal resources. I would still recommend spending some time understanding how the config generally works (e.g. by reading kickstart and watching TJs video or/and typecraft's videos). But then, I'd recommend to the person who just wants the best IDE experience to just use LazyVim (or other full blown distributions like AstroNvim). Great discoverability. Lots of features. I use LazyVim with LazyExtras. No customization except the color scheme and adding LSP and TS for Svelte and Rust. I got to work on my projects immediately. My problem with Helix is that there're many for me important IDE features missing (which you get with LazyVim or AstrNVim or NVChad), decisions of the maintainers regarding the priorities and the that vim keybindings are ubiquitous. reply tiffanyh 6 hours agoparentprev> bummed out that it is still so barebones on install. Helix might be your cup of tea then. https://helix-editor.com (Though it will take awhile getting use to the inverted keybindings) reply behnamoh 17 hours agoparentprevyou should use neovim distributions like LazyVim. reply scutrell 17 hours agorootparentI did use Lazyvim. It was definitely better (though I spent a fortune in time modularizing is plugins). It just doesn't feel like a great solution for a variety of reasons. You're still a little on the hook for plugins and LSP configs. You're beholden to the distro e.g. if Lazy ever grows obsolete, Lazyvim could go too. In a perfect world there would be a neovim core (what it is now) and a formal neovim distro. reply WuxiFingerHold 6 hours agorootparent> You're beholden to the distro e.g. if Lazy ever grows obsolete, Lazyvim could go too. That is my only concern, too. But I decided not to worry. Getting into LazyVim was very easy, so I'm not concerned potentially having to switch to another distro or IDE. reply kzrdude 13 hours agorootparentprevThere's just a lot more innovation and development in the offshoot projects than in the big projects. The main project is gradually agreeing on /some/ default key bindings for lsps, as seen in this release (core does a great job on neovim no offense meant there.) In the same time, LazyVim and AstroNvim have built whole worlds of configuration and LSP integration because they are free to tinker, at a speed far outpacing core neovim. Because the core project wants/needs to cater to everyone. Even you said it was a straight upgrade (to Vim, I assume) and just keeping it that way is not easy. reply lawn 19 hours agoprevQ or @ to execute a macro over all visually selected lines is a feature I didn't know about but sounds amazing. All too often I create a macro that I want to execute many times, but it's hard to know how many. I've tried the guessing approach but that has a tendency to under- or overestimate. reply linsomniac 19 hours agoparentI'll often visual select (\"v\" and motion) and then \":norm @a\" to run the macro on all the selected lines. reply kevincox 19 hours agoparentprevMy general approach for macros that I want to execute many times is to end by going down a line (for sequential lines) or to end with a search for the next place that the macro can run. Then I can easily review the targets and run or skip on each. reply bitdivision 19 hours agoparentprevYou might find relative line numbers useful. `set relativenumber` reply lawn 19 hours agorootparentI already use relative line numbers but they don't help when the lines continue below the window. reply tiffanyh 19 hours agoprevRelease Notes (Neovim 0.10): https://neovim.io/doc/user/news-0.10.html reply Affric 19 hours agoprevPretty much exactly what is needed. Helix shows the way IMO but the Neovim guys are clearly not conservative. Exciting to see the tree sitter and lsp improvements. reply imjonse 19 hours agoparentIncluding more basic (as of 2024) features in the core like Helix would indeed be a good idea but would go against the existing culture of vim with many plugins competing. reply linsomniac 19 hours agorootparentThat's why I went with LunarVim, I was tired of maintaining my own plugins and configs, and wasn't quite ready to fully jump ship to Helix (though I do like the direction Helix is going, it'd be an easier sell if shells and everything had Helix keymaps). reply imjonse 17 hours agorootparentMain main gripe about Helix is that helix-like keybindings in VSCode are not working well for the times I need to use that :) reply Affric 1 hour agorootparentMe too. I am vi mode everywhere so I couldn't quite make the switch on the bindings but I loved the ideas in Helix. Truly a great project. reply ephimetheus 19 hours agoprevSupport for inlay LSP hints is the big one for me here. Thatâ€™s mainly whatâ€™s kept me from switching over from vim so far. reply rane 17 hours agoparentHow does it keep you from switching from vim when vim does not have it? reply ephimetheus 16 hours agorootparentIt does have it though. Been using it for at few years already with coc. reply lawn 16 hours agorootparentCoc works with Neovim too if that's the logic. reply ephimetheus 16 hours agorootparentI know, but previously, the inlay hints would be displayed at the end of the line in Neovim, making them near useless. reply lawn 16 hours agorootparentHuh, does it work inline in Vim with Coc? reply ephimetheus 15 hours agorootparentYes thatâ€™s right! reply xyst 18 hours agoprevI have been transitioning my workflow from macOS to Linux. Discovered itâ€™s kind of pain in the ass to get a gui based editor like Intellij to work correctly, especially within a VM. Happened to have discovered neovim, and so far itâ€™s been a delight to use. Much faster and much lighter on resource use. Do any neovim veterans have recommendations on plugins to enable? Or even hidden features that would improve workflow. reply mdaniel 18 hours agoparent> Discovered itâ€™s kind of pain in the ass to get a gui based editor like Intellij to work correctly, especially within a VM. Depending on your use-case, that's what their Gateway productis designed to solve: it runs (effectively) headless IJ in the VM, so indexing and analysis happens there, and then streams the GUI part over a custom protocol to your local IJ to handle the time-sensitive GUI bits Currently, to the best of my knowledge, they actually do require ssh, so it won't work over AWS SSM nor kubectl exec or similar, but I have high hopes they're going to fix that glaring bug Any Minute Now â„¢ see also: - https://www.jetbrains.com/help/idea/remote.html - https://jetbrains.github.io/projector-client/mkdocs/latest/i... - https://github.com/JetBrains/projector-docker#run-jetbrains-... reply xyst 17 hours agorootparentBut I still need to have the gui app installed correctly with opengl/hardware acceleration enabled , right? My problem isnâ€™t with inconsistent development environments. I have trouble spinning up the IntelliJ ide locally. Thus the need for something more lightweight. Also I have used this in the past and the experience wasnâ€™t the greatest. Tried with a dev server with gateway hosted within intranet. Used an m1 Mac as thin client. Issues with syncing state of client. Significant input lag in a large project. I remember trying to refactor a method in a 500K+ LoC and the UI would hang. Syncing plugins was also an issue at the time. I suspect these issues would likely be exacerbated over internet with tailscale reply asabla 17 hours agoparentprevI usually recommend new users to check out Kickstart. It contains a set of plugins and nice to haves so you don't have to discover them your self. All plugins are in one file + has a lot of comments to help you get started. ref: https://github.com/nvim-lua/kickstart.nvim reply WuxiFingerHold 6 hours agorootparentYep, I followed this recommendation, but when I was about to use Neovim in \"production\" I checked out LazyVim and AstroNVim and chose LazyVim by purely personal taste. Thanks to having learned how the config works with kickstart I don't feel lost, but still benefit from the big efforts and deep knowledge of the distro maintainers by assembling a sound full featured package. reply sciolist 16 hours agorootparentprevI second Kickstart! The single-file and comments make it easy to learn and configure yourself. reply lawn 18 hours agoparentprevThere are many great plugins. Telescope, nvim-cmp, treesitter are standard recommendations. I'll give a shout-out to conform.nvim that gives you very solid format on save functionality that's also easy to setup: https://github.com/stevearc/conform.nvim reply joeconway 18 hours agoparentprevThis isnâ€™t neovim specific but this was one of the more delightful and impactful discoveries https://shapeshed.com/vim-netrw/ Configuring netrw right and having my vimrc load a side pane with it on load, combined with configuring my tab key to cycle between windows... Perfect. reply james2doyle 17 hours agoparentprevI'm doing the same on an old macbook. Off topic, but any idea on how you remap command + left/right? On a mac it is the equivalent of Home and End. I tried xmodmap but it doesn't seem to work with those types of combinations... but maybe I'm missing something obvious? reply v3ss0n 19 hours agoprevWe need proper Neovim gui that is officially maintained reply lawn 19 hours agoparentI don't get it, why do we need that? And I already use Neovide as a GUI pretty often. reply dpcx 17 hours agorootparentI've been using neovide for a few months now, and my biggest gripe is that there's not an easy way to automagically open a new file in an existing neovide window as a tab. With macvim I could do `--remote-tab-silent` and it was handled, but neovide seems to want me to use some kind of background server and a bunch of other hoops to jump through. reply trip-zip 19 hours agoparentprevWhat's the use case for a separate GUI for neovim? I remember using macvim for a few days maybe 8 years ago, but I never \"got it\". It felt like the benefits of having my editor in my terminal were thrown out for little return. reply doix 19 hours agorootparentIf neovim had a proper gui, you could move away from some of the limitations of the terminal. The biggest being using fixed width characters for drawing UI elements. Emacs does it pretty well, one of the few things that makes me jealous of emacs as a vim user. reply kevincox 19 hours agorootparentIIUC fixed widths is more than just a UI problem. Lots of internal code is assuming that. But maybe it works well-enough that it isn't a real issue. I remember trying a terminal that didn't have fixed char widths and it mostly worked. The only real issue was line wrapping (as vim and the terminal would both wrap based on how long they considered the line to be). So maybe it would be possible! I would love to see solid support for variable-width fonts. I know variable-width fonts are controversial, but I actually think they work well for coding but haven't had the chance to use them much due to Vim limitations. But especially for Markdown and similar mostly-text content they seem like a clear win. reply kzrdude 18 hours agorootparentprevAnd input limitations can be resolved by non-terminal UIs (for example like Ctrl+i and Tab being mapped to the same control character in old terminals - that one is solved by newer protocols, but the problems don't end there.) reply rockorager 11 hours agorootparentNeovim already supports these keys as long as you are using a terminal that supports the Kitty keyboard protocol (Kitty, wezterm, alacritty, foot, ghostty) reply eviks 18 hours agorootparentprevalso even the newer protocols fail to support modifier sides (left vs right shift) reply rockorager 11 hours agorootparentKitty keyboard protocol does indeed support modifier sides. reply eviks 5 hours agorootparentNo it doesn't, and the author rejected the proposal to add them https://sw.kovidgoyal.net/kitty/keyboard-protocol/ Modifiers are encoded as a bit field with: shift 0b1 (1) alt 0b10 (2) ctrl 0b100 (4) super 0b1000 (8) hyper 0b10000 (16) meta 0b100000 (32) caps_lock 0b1000000 (64) num_lock 0b10000000 (128) reply bbkane 19 hours agorootparentprevI'd really like image support in a Neovim GUI. It'd make markdown editing easier for me reply Macha 19 hours agorootparentSeems more likely to be something you implement with e.g. kitty/iterm/sixel escape codes than moving to a GUI app. Actually probably is something that could be implemented in neovim today. Maybe even by a plugin, not sure what control they have over stuff like that. reply kzrdude 18 hours agorootparentprevsee 3rd/image.nvim on github. There might be others reply snarfy 18 hours agorootparentprevJust basics like fonts and window sizing make the gui version of Vim a better experience for me. reply anta40 18 hours agorootparentprevI mostly work on macOS nowadays, and I like macvim. Of course there are plenty of Neovim GUI. Currently happy enough with VimR. reply alwillis 16 hours agorootparent+1 for VimR reply eviks 18 hours agorootparentprevproportional fonts many broken things fixed automagically, like those meta keybinds that took years to implement, and also clipboards, then menus then window management from resizing to switching with Alt-Tab and direct keybinds then easier integration with external tooling since it's easier to detect the app in a dedicated window Then freer keybindings not conflicting with the terminals' Terminal is a poor restricting UI for any complex app such as the text editor reply EasyMark 18 hours agoparentprevthat would be nice, currently neovide works pretty well for me. I've heard some who like VimR a lot as well but it's a bit cluttered for me, I just want a fast minimal GUI reply phplovesong 6 hours agoprevAwesome release! Ditching my colorschemes and going for the default one. Looks like i can drop even more deps like vim-commentary, and i can remove some keybindings that now come as default! Neovim keeps getting better and better! reply laktak 19 hours agoprevI tried to switch to nvim but quickly discovered that there are breaking changes that just don't work for me, like system() not being interactive and having to use term. nvim might be great for some but it's not a vim replacement, it's a different editor with different drawbacks. reply bbkane 18 hours agoparentIts a fantastic vim replacement for most people I think. My Vim -> Neovim migration was simply using the new binary with the same vimscript config, I was really impressed. reply kps 17 hours agoparentprevIs `!` still broken? Last I looked there seemed to be resistance to fixing it. reply laktak 12 hours agorootparentYes, ! has the same issues as system() which I'd need to integrate with lf. reply vander_elst 15 hours agoprevEvery ~6 months I try to switch from vim to nvim, but somehow it never sticks. Not sure why but in my use cases it is slower than vim, the terminal is imo still worse than vim and it s harder to copy and paste to the terminal: in vim I yank and than C_W\"0 (or whatever register I need) in nvim I didn't find a solution yet. Nvim always feels more clunky. reply jarbus 18 hours agoprevLove neovim, great to see more parts already in my config coming to core. Maybe one day most of us won't even bother with plug-ins :) reply LeSaucy 19 hours agoprevI am curious if any of the termsync options can make neovim play nicely with mosh. My dream setup is to be able to spin up preconfigured dev environments in docker containers, and use blink shell on my iPad for on the go coding. Unfortunately mosh and neovim always end up with display corruption. reply cyberpunk 19 hours agoparentI used to use blink quite a lot on my iPad and Iâ€™ve noticed it really going â€œweirdâ€ lately. They have some script that executed on login, which tried to â€œupgradeâ€ my connections to mosh by downloading a static mosh bin from some server they own (so, could contain anything) and it was opt out â€” and lately randomly some keys just stop working on the keyboard (like, the c key just doesnâ€™t work at all in the app). I jumped ship to Termius, shame. Howâ€™s your experience lately? reply LeSaucy 19 hours agorootparentI refuse to pay a subscription for a terminal app. reply cyberpunk 18 hours agorootparentThe subscription just seems to be for teams features like a shared address book and whatever a â€œvaultâ€ is â€” Iâ€™ve not paid them anything. I probably would pay them if they would add the Berkeley Mono font though ;) reply linsomniac 19 hours agoparentprevDoes wezterm work on iPad? I used to use mosh+tmux for remote coding, but a couple years ago switched to wezterm which includes some builtin mosh+tmux like capabilities directly in the term so it's truly first-class remote terminal functionality. reply morning4coffe 18 hours agoprevExciting to see Neovim 0.10 bringing so many core features! And although I don't use it daily now, I believe it's a game-changer for many. Kudos to the team for keeping it evolving! reply xutopia 19 hours agoprevI love seeing the development of an amazing modern replacement for Vim. I look forward to the moment where it has tons of plugins that are as easy to install as VSCode extensions are. reply nerdix 19 hours agoparentThat's pretty much already possible today with nvim distros like lazyvim. reply fh9302 19 hours agoprevFor some reason vim-airline in combination with neovim 0.10 has really bad performance when scrolling large files. This doesn't happen with neovim 0.9 and regular vim. reply edvards 19 hours agoprevAm I the only one who doesn't like the new color scheme that much? It seems that it just plainly removes all the syntax highlighting more or less. reply kzrdude 15 hours agoparentFunctionally it's good - adapts to both light and dark background, adapts to both 256 and truecolor terminals. I think I miss some of the color even if bright color in light background themes is often detrimental. Only real dislike is the too gray tinted background. Should be more towards white for light background, to be more neutral. reply pynappo 14 hours agoparentprevyou might want to try linking @variable to Identifier, i think the original author decided to keep @variable unhighlighted to keep the color diff between having `termguicolors` on/off to a minimum (Identifier assumes `termguicolors` is enabled, but for default colorscheme it's likely not always the case). see https://github.com/neovim/neovim/pull/26334 and the comments in highlight_group.c reply ms-menardi 18 hours agoparentprevI like bright and bold colors, vibrant and flavorful. these colors feel pastel, weak, and faded. I don't like them. reply nallerooth 18 hours agoprevThis sounds like a really awesome release, well done! reply ilrwbwrkhv 18 hours agoprevFantastic release. The neovim project is one of the best recent projects I have seen. It tries to make things look hot by default instead of trying to look \"open source\". reply AltruisticGapHN 17 hours agoprevIs there a modern equivalent of MacVim on Linux ? Gvim is OK though the Ux (tabs etc) looks dated. reply nicce 17 hours agoparentneovide.dev ? reply quux 17 hours agoprevLSP inlay hints is so nice. Instant upgrade just for that :D reply xbar 18 hours agoprev [â€“] Thank you Mr. Anders. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Neovim 0.10 brings a variety of new features like a default colorscheme, improved terminal features, LSP inlay hints, and a Tree-sitter query editor.",
      "Enhancements in commenting, diagnostic mappings, and default LSP mappings are also part of this update.",
      "The release emphasizes community engagement, ongoing discussions for enhancing LSP and Tree-sitter features, integration of nvim-lspconfig, and a merchandise store to support project development."
    ],
    "commentSummary": [
      "Users share their experiences and preferences using Neovim, focusing on Lua for plugin authoring, tools like telescope and fzf, and the anticipation for inlay hints.",
      "Neovim 0.10 introduces new features such as multicursor and visual block editing, prompting discussions on customizing editors and productivity-enhancing distributions like LazyVim and AstroNvim.",
      "Concerns arise regarding GUI choices, Vim compatibility, performance, color schemes, and integrating Neovim with Intellij in a virtual machine."
    ],
    "points": 261,
    "commentCount": 112,
    "retryCount": 0,
    "time": 1715866217
  },
  {
    "id": 40377685,
    "title": "F* â€“ Innovating Proof-Oriented Programming Language",
    "originLink": "https://www.fstar-lang.org/",
    "originBody": "Introduction Download Learn Community Uses Research People Introduction F* (pronounced F star) is a general-purpose proof-oriented programming language, supporting both purely functional and effectful programming. It combines the expressive power of dependent types with proof automation based on SMT solving and tactic-based interactive theorem proving. F* programs compile, by default, to OCaml. Various fragments of F* can also be extracted to F#, to C or Wasm by a tool called KaRaMeL, or to assembly using the Vale toolchain. F* is implemented in F* and bootstrapped using OCaml. F* is open source on GitHub and is under active development by Microsoft Research, Inria, and by the community. Download F* is distributed under the Apache 2.0 license. Binaries for Windows, Linux, and Mac OS X are posted regularly on the releases page on GitHub. You can also install F* from OPAM, Docker, Nix, or build it from sources, by following the instructions in INSTALL.md. Learn F* An online book Proof-oriented Programming In F* is being written and regular updates are posted online. You probably want to read it while trying out examples and exercises in your browser by clicking the image below. Low* We also have a tutorial that covers Low*, a low-level subset of F*, which can be compiled to C by KaRaMeL. Course Material F* courses are often taught at various seasonal schools. Lectures and course materials for some of them are also a useful resource. Embedding Proof-oriented Programming Languages in F*) Online lectures at the Oregon Programming Language Summer School (2021): Lecture notes, slides, code Formal Verification with F* and Meta-F* Lectures and tutorial at ECI 2019: Lecture notes, slides, code Verifying Low-Level Code for Correctness and Security Lectures at the Oregon Programming Language Summer School (2019): Lecture notes, slides, code Program Verification with F* Course at 2018 EUTypes Summer School, 8-12 August, 2018, Ohrid, Macedonia Course material Community Please use GitHub Discussions to ask questions about F*, learn about announcements, etc. We also have a mailing list, which has very low traffic. You can subscribe at fstar-mailing-list. The F* developers and many users interact on this Slack forum---you should be able to join the forum automatically by clicking here, but if that doesn't work,please ask for access on this thread. There is also a public forum on Zulip. The F* PoP Up Seminar, a users and developers meeting is open to all. We aim to schedule it once a month, though the schedule is irregular---we hope to see you there! You can also contact the maintainers of F* at fstar-maintainers@googlegroups.com. Uses F* is used in several projects in both industrial and academic settings. We list a few of them here. If you are using F* in your project, please let us know by writing to the fstar-mailing-list. Project Everest Project Everest is an umbrella project that develops high-assurance secure communication software in F*. A big part of the development of F* has been motivated by the scenarios that Project Everest targets. Several offshoots from Project Everest continue as their own projects, including some of those listed below. HACL*, ValeCrypt, and EverCrypt HACL* is a library of high-assurance cryptographic primitives, written in F* and extracted to C. ValeCrypt provides formally proven implementations of cryptographic primitives in Vale, a framework for verified assembly language programming embedded in F*. EverCrypt combines them into a single cryptographic provider. Code from these projects is now used in production in several projects, including Mozilla Firefox, the Linux kernel, Python, mbedTLS, the Tezos blockchain, the ElectionGuard electronic voting SDK, and the Wireguard VPN. EverParse EverParse is a parser generator for binary formats that produces C code extracted from formally proven F*. Parsers from EverParse are used in production in several projects, including in Windows Hyper-V, where every network packet passing through the Azure cloud platform is parsed and validated first by code generated by EverParse. EverParse is also used in other production settings, including ebpf-for-windows. Research F* is an active topic of research, both in the programming languages and formal methods community, as well as from an application perspective in the security and systems communities. We list a few of them below, with full citations to these papers available in this bibliography. If you would like your paper included in this list, please contact fstar-maintainers@googlegroups.com. The Design of F* and its DSLs Dependent Types and Multi-monadic Effects in F* (POPL 2016) This is the canonical reference describing the F* system. The language has evolved in significant ways since 2016, however, its core design and implementation is based on this paper. Verified Low-level Programming Embedded in F* (ICFP 2017) which describes the Low* fragment of F* which is a low-level subset of F* that can be compiled to C by KaRaMeL. A Verified, Efficient Embedding of a Verifiable Assembly Language (POPL 2019) which describes the Vale language, a verified assembly language embedded in F*. Meta-F*: Proof Automation with SMT, Tactics, and Metaprograms (ESOP 2019) which describes MetaF*, a metaprogramming system within F* used to implement various aspects of F*, ranging from its tactic engine to its support for typeclasses. Programming and Proving with Indexed Effects (TR 2021) which describes the design of F*'s support for user-defined effects and provides a calculus that describes the logical core of F*. Steel: Proof-oriented Programming in a Dependently Typed Concurrent Separation Logic (ICFP 2021), which describes the Steel language and its use of the SteelCore concurrent separation logic for proofs of imperative programs with various forms of concurrency. Semantics and Effects Verifying Higher-order Programs with the Dijkstra Monad (PLDI 2013), which introduces the concept of the Dijkstra monad, a core feature of F*'s system of effects. Dijkstra Monads for Free (POPL 2017), which shows how to automatically derive Dijkstra monads for a class of computational monads using a continuation-passing transformation A Monadic Framework for Relational Verification: Applied to Information Security, Program Equivalence, and Optimizations (CPP 2018), which builds on the Dijkstra Monads for Free work to construct a framework for proving properties that relate multiple programs or program executions. Dijkstra Monads for All (ICFP 2019), which generalizes the notion of a Dijkstra monad and shows how to systematically relate computational and specificational monads via monad morphisms. Recalling a Witness: Foundations and Applications of Monotonic State (POPL 2018), which describes the design of a program logic for reasoning about programs whose state evolves monotonically, e.g., where the state is an append-only log. This logic underpins both Low* and Steel. SteelCore: An Extensible Concurrent Separation Logic for Effectful Dependently Typed Programs (ICFP 2020), which describes the SteelCore concurrent separation logic, the basis of the Steel DSL. Applications in Security and Cryptography Many papers applying F* in security and cryptography can be found in the Project Everest bibliography. We mention a few prominent ones here as well as other applications not related to Project Everest. WYS*: A DSL for Verified Secure Multi-party Computations (POST 2017), which describes the WYS* language, a domain-specific language for writing verified mixed-mode secure multi-party computations. Implementing and Proving the TLS 1.3 Record Layer(S&P 2017), which describes a verified implementaion of the TLS-1.3 record layer in Low*. HACL*: A Verified Modern Cryptographic Library (CCS 2017), which describes HACL*, a verified cryptographic library implemented in Low*. Formally Verified Cryptographic Web Applications in WebAssembly (S&P 2019), which develops LibSignal*, an implementation of the Signal protocol in F* using HACL*, compiled to Wasm by KaRaMeL. EverCrypt: A Fast, Verified, Cross-Platform Cryptographic Provider (S&P 2020), a crypto provider combining C and assembly code from HACL* and Vale, as well as some applications built on top of it, including a verified high-performance Merkle tree that was used in an initial version of Microsoft Azure CCF. HACLÃ—N: Verified Generic SIMD Crypto (for all your favorite platforms) (CCS 2020), which metaprograms vectorized versions of cryptographic primitives, enabling a \"write-once, get vectorized versions for free\" style. A Security Model and Fully Verified Implementation for the IETF QUIC Record Layer (S&P 2021), a verified implementation of the QUIC record layer in Low* combined with the protocol logic implemented in Dafny. DICE*: A Formally Verified Implementation of DICE Measured Boot (USENIX Security 2021), which proves the correctness & security of the DICE measured boot protocol for micro-controllers, implemented in Low*, using EverCrypt and EverParse. DY*: A Modular Symbolic Verification Framework for Executable Cryptographic Protocol Code (Euro S&P 2021), a framework for type-based symbolic security analysis of cryptographic protocol implementations developed in F*. A Tutorial-Style Introduction to DY* (LNCS 2021), which is, yes, a tutorial-style introduction to DY*. An In-Depth Symbolic Security Analysis of the ACME Standard (CCS 2021), which proves the security of a model of the ACME certificate issuance and management protocol using DY*. Noise*: A Library of Verified High-Performance Secure Channel Protocol Implementations (S&P 2022), which metaprograms provably secure implementations for a family of secure channel protocols. TreeSync: Authenticated Group Management for Messaging Layer Security (USENIX Security 2023), a reference implementation of MLS in F*, proven secure using the DY* framework. Modularity, Code Specialization, and Zero-Cost Abstractions for Program Verification (ICFP 2023), which describes proof-engineering techniques used in HACL* for generic implementations of cryptographic constructions that can be specialized repeatedly to many concrete implementations in C. The techniques used here led to the adoption of verified cryptographic code into the libraries of the Python programming language. Verifying Indistinguishability of Privacy-Preserving Protocols (OOPSLA 2023), which provides a library called Waldo in F* that enables proofs of indistinguishability over traces of communication in networking protocols. Comparse: Provably Secure Formats for Cryptographic Protocols (CCS 2023), which provides a parsing library for data formats that are appropriate for use with symbolic protocol analyzers. Comparse provides bit-level precise accounting of formats allowing the DY* protocol analysis framework to reason about concrete messages and identify protocol flaws that it previously would have missed. Applications in Systems Provably-Safe Multilingual Software Sandboxing using WebAssembly (USENIX 2022), which describes a verified implementation of a sandbox for WebAssembly modules in Low* and Rust. FastVer: Making Data Integrity a Commodity (SIGMOD 2021), which formalizes a protocol for data integrity monitoring in F*. FastVer2: A Provably Correct Monitor for Concurrent, Key-Value Stores (CPP 2022), which proves the correctness of a low-level, concurrent implementation of the FastVer protocol in Steel. Applications in Parsing EverParse: Verified Secure Zero-Copy Parsers for Authenticated Message Formats (USENIX Security 2019), which describes the EverParse parser generator for parsing binary formats, producing C code. Hardening Attack Surfaces with Formally Proven Binary Format Parsers (PLDI 2022), which uses EverParse to harden network packet parsers in Windows Network Virtualization and Hyper-V. ASN1*: Provably Correct Non-Malleable Parsing for ASN.1 DER (CPP 2022), which formalizes the ASN.1 DER format in F* and proves the correctness of a parser for it in EverParse. Applications in Programming, Program Proof, and Program Analysis Verified Compilation of Space-Efficient Reversible Circuits (CAV 2018), which presents ReVerC, a compiler for reversible circuits proven correct in F*. Verified Transformations and Hoare Logic: Beautiful Proofs for Ugly Assembly Language (VSTTE 2020), which develops verified transformations for assembly programs in the Vale framework. Statically verified refinements for multiparty protocols (OOPSLA 2020), which presents Session*, a session-typed programming language for multiparty protocols, formalized in F*. Verified Functional Programming of an Abstract Interpreter (SAS 2021), which develops an abstract interpretation framework for an imperative language with a very compact proof of soundness developed in F*. Catala: a programming language for the law (ICFP 2021), where core parts of the compiler are formalized and proven correct in F*. Verification of a Merkle Patricia Tree Library Using F*, which ports a Merkle tree library from OCaml to F*, finds and fixes a bug, and eventually proves it correct. Certified mergeable replicated data types (PLDI 2022), which presents PEEPUL, a framework in which to build replicated data types for use in distributed programming, formalized in F*. Aeneas: Rust verification by functional translation (ICFP 2022), which translates Rust into pure F* enabling functional correctness proofs. Q*: Implementing Quantum Separation Logic in F* (PlanQC 2022), which adapts the SteelCore separation logic for use with a quantum programming language. Pipit: Reactive Systems in F* (Extended Abstract) (TyDe 2023), which describes a embedded DSL for verifying reactive systems. Securing Verified IO Programs Against Unverified Code in F* (POPL 2024), which presents SCIO*, a formally secure compilation framework for statically verified programs performing input-output (IO). Miscellaneous A Theorem Proving Approach to Programming Language Semantics (ICSE-SEET 2023), which reports on experiences teaching operational, denotational, and axiomatic semantics to students using F*. Papers about an older version of F* The first paper to introduce a system called F* was in 2011. Although the current version of F* was redesigned and implemented in 2015, we include some of these older papers here for completeness. Secure Distributed Programming with Value-dependent Types (ICFP 2011), a longer version of which also appeared in JFP. Self-certification: bootstrapping certified typecheckers in F* with Coq (POPL 2012), which certifies the correctness of the F* typechecker by programming it in F* itself and bootstrapping the process by checking about 7GB of proof using Coq in about 24 machine-days of compute time. Fully abstract compilation to JavaScript (POPL 2013), which models a subset of JavaScript in F* and develops a secure compiler from an ML-like language to JavaScript. Gradual typing embedded securely in JavaScript (POPL 2014), which develops a source-to-source compiler for JavaScript with defensive checks to ensure the soundness of gradual typing in adversarial contexts, proven corrent in F*. Probabilistic relational verification for cryptographic implementations (POPL 2014), which develops RF*, a relational dialect of the language useful for proving security properties like noninterference and for game-based cryptographic proofs. BESbswy BESbswy",
    "commentLink": "https://news.ycombinator.com/item?id=40377685",
    "commentBody": "F* â€“ A Proof-Oriented Programming Language (fstar-lang.org)216 points by montyanderson 21 hours agohidepastfavorite80 comments tombert 20 hours agoMan, back when I did F# for a living, I really really wanted to use this for production, but I could never quite get sign-off. I was a big fan of Idris at the time, and F* seemed like it could more or less satisfy that itch while still being compatible with F#. One thing is that there didn't really appear to be any kind of IDE support, and while I'm alright just hacking up everything in Vim, I think the rest of my team was not. I never really got to use it, and all I've ever done with it is a few of the toy examples on their website, but I haven't completely given up on it either. I think it's a much more approachable system than Coq or Agda, but still gives you sexy dependent types. My PhD stuff is in Isabelle, and I do really like Isabelle, but I find that dependent types translate a bit more directly to \"real code\" than Isabelle's higher-order logic, so I would really like to utilize it for something, particularly with its .NET integration. reply daxfohl 18 hours agoparentI remember reading (~10 years ago) that F* was created as part of a \"Project Everest\" a long time back, with the goal of creating a provable TLS implementation. I never saw that anything came out of that though. If it's that hard to create something as well-defined as a TLS implementation, it seems futile to think this could ever be used for hand-wavy things we encounter in day-to-day work, no? Or are there real-world use cases where this could really be applied? reply lambdanik 18 hours agorootparentF* existed before Project Everest, but Everest did power a lot of its development. We have built verified systems and components in the TLS ecosystem, including parts of TLS, QUIC and related protocols, and continue to do so: https://project-everest.github.io/ Some of it is deployed in production systems: * Verified parsers in the Windows kernel and elsewhere: https://www.microsoft.com/en-us/research/blog/everparse-hard... * Verified crypto in Linux, Firefox, Python, ... https://github.com/hacl-star/hacl-star reply daxfohl 6 hours agorootparentSo _would_ it possibly be useful for business apps? Or is that still a long way off? reply octachron 18 hours agorootparentprevThe Everest project did publish a proved TLS implementation: https://mitls.org. And at least the EverCrypt* cryptographic primitives has been used outside of academia. reply onhacker 19 hours agoparentprevAfter C#, I learned F#, I loved language structure, but I was not able to run it on production effectively. A language isn't enough, a language recognized from its support in ide/production and community reply tombert 19 hours agorootparentI didn't find F# so hard to run in production, particularly after JetBrains released Rider, but even before that I didn't think it was so bad. At Jet we managed to get to pretty decent scale with F#, and for the most part got pretty ok performance. Often I would use the C# versions of libraries simply because they were updated more frequently. Everyone says that the C# interop is clunky and I think that's just not true, I found it relatively easy to work with C# libraries and utilize the .NET Framework. I used ConcurrentDictionary and SemaphoreSlim pretty heavily, for example. For the stuff was a little cludgy, I found it pretty straightforward to simply make wrapper functions that did what I needed. I even found the object-oriented support in F# to be pleasant, though I didn't use it a lot. The syntax was really terse but easy to read, so in the rare cases where I had to extend a class or something, it wasn't hard. If I needed to implement an interface, it was also pretty easy to write an anonymous interface and plop that into a wrapper function. One thing that I didn't like about F# was the kind of unpredictable performance with the async monad. It was hard to measure, and it didn't seem to work completely deterministically due to some kind of laziness that I never completely understood. The task monad released a bit later seemed to fix that, but that was integrated a bit later than my time at Jet. Still, I found it a pretty decent language, to a point where if I started a company I would genuinely consider utilizing F#. reply williamcotton 17 hours agorootparentprevIonide, The F# language server, is excellent. I use F# in .NET Interactive Jupyter notebooks daily at work and it works quite well. The community around the language is very helpful and the Discord is great for all sorts of issues ranging from beginner to advanced. I love the Fable compiler which targets JS, TS, Python and Rust and makes for a wonderful way to share a domain design across multiple code bases. reply lambdanik 18 hours agoparentprevHave you seen https://github.com/FStarLang/fstar-vscode-assistant? Copilot & F* works pretty nicely. We've also had a pretty nice emacs mode for a while: https://github.com/FStarLang/fstar-mode.el reply tombert 18 hours agorootparentI have not tried the VSCode stuff, but I did try the Emacs thing. Looking at the repo you linked, it looks like the first commit was last year and I left Jet in 2018. The Emacs mode was fine, I didn't think it was bad, but it was still a tough sell to my team; none of them wanted to install Emacs, they wanted a Visual Studio or JetBrains experience. I'm aware that's an uphill battle, and maybe it would be a different story if the VSCode extension existed in 2018. reply toasted-subs 18 hours agoparentprevWhere do you even find orgs that let you program in those fun langs? University jobs? reply tombert 18 hours agorootparentI was working for Jet.com, it was one of the very few places that did F#. The reason I was hired was because I had Haskell experience from working at NYU as an engineer before. reply Nuzzerino 14 hours agorootparentI used F# at realtyshares in 2017. Didn't think it was particularly great for anything except Payment processing. The F# tools were only good with VS IDE on Windows at the time. I would probably use it again though, the REPL is much better than anything C# has to offer. The Rider release was a shitshow, lots of bugs that went unfixed. Productivity went way down when I had to switch to a mac laptop (keep in mind this is 2017 on a Microsoft language). Had similar experiences with Rubymine in 2022 (poor YARD support, lots of bugs in type inference even with simple things, bug tickets left open for years, thank god for Sorbet-lsp). The tooling is probably better these days but I don't trust Jetbrains for anything, they are a rent-seeking company. reply neonsunset 14 hours agorootparent2017 was right as the very first releases of .NET Core 1, 1.1 and 2.0 were happening. Itâ€™s most likely your experience today would be a polar opposite to this. reply happypumpkin 7 hours agorootparentprevMaybe try looking for Clojure jobs? They aren't super common but are a lot more so than any other lisps or functional languages that I'm aware of (except maybe Scala). reply barrenko 16 hours agorootparentprevThere are some trading companies as well, I guess because it's ocaml adjacent. reply jfoutz 20 hours agoparentprevLately I've been dabbling with lean. pretty tight vs code integration. I don't know why I keep getting pulled toward dependent types, like a damn moth to a flame. I get a little scorched, then, oh I should try ... But yeah, compiler checked properties are something kinda magical. Even more when you can specify the property to check. reply ykonstant 18 hours agorootparentLean is lovely, but those of us using it for general purpose programming are a lonely bunch; virtually all discussion on Zulip is about mathlib and tactics (which is understandable). reply eggy 12 hours agorootparentI have heard of Lean, but I just took a look for the first time. Certainly, much more Idris/Haskelly than the OCamlish F*. Are there libraries available for general programming in Lean? Can you compile to another lower-level language like C? I would be interested in writing some embedded code that could formally be verified. Right now, I have put some time in to SPARK2014, the subset of Ada. reply ykonstant 12 hours agorootparentLean in fact compiles to C so the C FFI is trivial to use. However, the only general programming facilities Lean has seem to be those required to bootstrap the language. I find it equal amounts funny and sad that you still cannot get the Unix epoch in Lean; you need to call the C functions through the FFI. For verifying code Lean is not great right now (see a sibling comment in this post). For embedded code in particular, I remember there was a low-level formalizer, but I cannot remember what it was. This post here has many discussions and links: https://news.ycombinator.com/item?id=31775216 Maybe I am remembering this: https://en.wikipedia.org/wiki/ATS_(programming_language) But I was under the impression there was an almost assembly-level functional programming language with formal verification capabilities; I cannot recall it. reply 6gvONxR4sf7o 16 hours agoprevI wish one of these languages (where you can prove and confirm that your code follows the formal spec) would aim for production use. I was really interested in Lean 4 when I found out that it aims to be a general purpose language, but then I saw that the language manual still has a section titled \"Should I use Lean?\" that emphasizes it's just a research project not a product and still expects a bunch more breaking changes, and so on. Some day, I'd love to write proofs instead of tests in some places. reply bluGill 16 hours agoparentWhile I agree with that in principal, in talking to people who have actually written proved programs I get the impression they don't think it is practical to prove programs that are more than medium sized. I'd love to prove my code correct, but I deal with 10s of million lines of code and nobody has a clue how you would approach a problem that large (we use C++, but you can select a different language if you want - the problem is the size and you can't get around that with a different language reply agentultra 15 hours agorootparentI talk to folks who are involved in proof engineering and they disagree here. It is possible to prove large systems when you have good automation. But perhaps it's writing the automation that is hard right now due to a small overlap in skills. Writing the proofs is one thing but writing the automation that scales those proofs to a larger system and which makes it easy to extend the system without breaking the proofs constantly is key and requires more \"engineering\" focused people rather than proof-focused ones. reply Someone 15 hours agorootparentprevDivide and conquer does work a bit, though. Languages that support strong encapsulation of various structures will be easier to work with than those that pass pointers around. As an example, having proofs of various properties of strcat, strcpy, etc. will help less in large programs than having proofs for all Javaâ€™s methods on String. In the former, youâ€™ll also have to proof that covers all accesses to your data. In the latter, the JVM guarantees that. reply PhunkyPhil 15 hours agorootparentprevSurely it wouldn't be aimed at proving a 10 million line black box of code, right? In my mind it would have to be built from the ground up, sub unit tests for function proofs and maintain 100% coverage as you go along. As long as the constituent parts are proven you don't have to zoom out to a macro level. reply ReleaseCandidat 15 hours agoparentprev> Some day, I'd love to write proofs instead of tests in some places. Believe my, you only want to do that if the proof assistent accepts \"I leave the details as an exercise to the reader\" ;) reply tombert 15 hours agorootparentI do a lot of work with Isabelle, and when doing proofs, you can use the word \"sorry\" to basically say \"this is true because I said it's true okay\". It's become a running joke in my grad school of \"when in doubt, there's always 'proof by sorry'\". I'm not as familiar with a lot of the other proof assistants but I suspect there are similar constructs? reply nextaccountic 14 hours agorootparent> I do a lot of work with Isabelle, and when doing proofs, you can use the word \"sorry\" to basically say \"this is true because I said it's true okay\". I always thought that unsafe { .. } blocks in Rust should be called trustme { .. } But sorry { .. } is even better! reply ReleaseCandidat 12 hours agorootparentMy favorite is accursedUnutterablePerformIO https://hackage.haskell.org/package/bytestring-0.12.1.0/docs... This \"function\" has a superficial similarity to unsafePerformIO but it is in fact a malevolent agent of chaos. It unpicks the seams of reality (and the IO monad) so that the normal rules no longer apply. It lulls you into thinking it is reasonable, but when you are not looking it stabs you in the back and aliases all of your mutable buffers. The carcass of many a seasoned Haskell programmer lie strewn at its feet. reply tombert 13 hours agorootparentprevYeah, it's pretty funny to see the first draft of anything I'm trying to prove; it'll be polluted with sorry's everywhere; it comes off as the most apologetic, completely un-confident bit of math you can think of. The worst part is when you forget to remove a sorry (or three) because of a linked file you didn't check, and you submit stuff to other people on the team thinking you discovered something pretty cool, only to find out that you didn't actually prove anything. reply dunham 11 hours agorootparentprevLean has `sorry` and Idris has `believe_me`. Recalling my math education, I would think the appropriate keyword would be `clearly`. reply naasking 9 hours agorootparent> Recalling my math education, I would think the appropriate keyword would be `clearly` I prefer the slightly more ominous \"surely\". reply Nevermark 4 hours agorootparent\"Obviously\" casts a nice aspersion upon anyone so uncouth as to question its validity. Of course, any junior member of a team that is willing to stand up and state that, no, the assertion is anything but obvious to them, should get an immediate promotion, and be quickly moved to another group! reply ReleaseCandidat 12 hours agorootparentprevCoq has \"admitted\" (or \"admit\"), but sorry is of course way better :). Lean also has \"admit\". reply rtpg 11 hours agoparentprevWell Coq is used to build a C compiler used in aerospace. At the very least you could write \"trricky\" stuff in that, and then use the compiled artefacts in your toolkit. I get the general complaint, though. I wish I could have the syntax-based interactive proof system everywhere. reply yodsanklai 14 hours agoparentprevI wonder how that is compatible with the industry requirements, and even with software engineering in general. A lot of the code we write is short lived, either because we're iterating, or because features aren't used anymore. Also, bugs aren't the end of the world most of the time. You don't aim for 100% correctness, but for something that provides value to users and it's better than your competitors. Formal proofs may be useful in some case, but I don't see them outside very niche fields. Even regular static types can be argued against. reply amw-zero 8 hours agoparentprevCode written in F* is running in Firefox, Linux, Windows, and Azure: https://project-everest.github.io/. reply ykonstant 15 hours agoparentprevFor small projects without tight performance or reliability requirements, Lean 4 is fine. It is lacking a lot in basic I/O functions, but you just yank them directly from the C standard library via the FFI and use them in your code. Don't expect to be able to prove anything about your code, though; just treat Lean as a pure functional language like Haskell but with dependent types and eager default evaluation. reply nequo 12 hours agorootparentIn your experience, what is the main impediment to proving properties of oneâ€™s code in Lean? Is it something specific to Lean or more generally an issue with theorem provers? reply ykonstant 12 hours agorootparentBy far the main impediment is that the current community does not care about this use-case. Lean's proof system works mainly by using its metaprogramming aspects to write macro-type objects called tactics; they perform transformations on the goals of your proof to simplify or dispatch them. [Note that this meta-programming is very powerful, but also extremely hard to use from what I have managed to see; do not expect LISP style ergonomics here. It doesn't help that the meta-programming book shows some trivial examples of macro rules and then delves deep into proof tactics for the next 2 chapters, leaving the reader who wants general code transformations stranded]. In order to use Lean for proving properties for serious amounts of code, you need to write an entire tactics library similar to mathlib (but for code). Nobody has done this. Maybe it is reasonably hard, or maybe unreasonably hard; the point is, there is no serious collaborative effort that I know of. reply nequo 12 hours agorootparentDo you get the sense that this would be easier with Coq due to the availability of suitable tactics? What makes you pick Lean instead of Coq for your projects? reply ykonstant 12 hours agorootparentProbably, from what people are telling me. But Coq is not a general purpose language, it is a dedicated theorem prover. I don't use Lean as a theorem prover for code (only for mathematics) and I myself don't do any code formalization unless someone offers to pay me. The reason I code in Lean is because I find it fun, and I think it is a very nice general purpose language; for instance, I like Lean much better than Haskell. If Lean ever gets the libraries Haskell has, I will be really excited. reply eggy 19 hours agoprevI prefer F#/F* syntax, but I had to go with Ada/SPARK2014 for the safety-related control systems I am trying to verify formally and use for high-integrity applications. Rust is making some inroads with AdaCore and Ferrous Systems partnering on providing formal verification tools for Rust like they do for Ada/SPARK2014, but Rust still doesn't have a published standard like C, Common Lisp, Prolog, Fortran, COBOL, etc. Plus the legacy is immense for Ada and SPARK2014. reply letmeinhere 19 hours agoparentMy understanding is that the key feature of SPARK is design-by-contract aka run-time enforced pre- and post-conditions plus invariants for loops. Whereas F* lets you define dependendent types, a subset of which are compile-time constraints similar to those SPARK contracts. Is that a fair contrast? reply Jtsummers 18 hours agorootparentFairly short course on SPARK/Ada - https://learn.adacore.com/courses/intro-to-spark/index.html SPARK's pre-/postconditions and assertions can be statically checked, they aren't just for runtime enforcement. This is its key value proposition, if it were just runtime enforcement it'd be nice, but not that great. reply debugnik 18 hours agoparentprev> with AdaCore and Ferrous Systems partnering I thought the partnership was already over? AdaCore left Ferrocene, and released its own support for a Rust toolchain lacking formal verification tools. reply eggy 13 hours agorootparentVery well might be the case. I am speaking on old news. I would guess the lack of an official published standard makes it hard to create tools and support them over time - a moving target. reply dang 5 hours agoprevRelated. Others? The F* Programming Language - https://news.ycombinator.com/item?id=31517176 - May 2022 (6 comments) Verified Programming in F*: A Tutorial - https://news.ycombinator.com/item?id=25629058 - Jan 2021 (76 comments) F* â€“ An ML-like functional programming language aimed at program verification - https://news.ycombinator.com/item?id=15582969 - Oct 2017 (95 comments) KreMlin: from (a subset of) F* to C - https://news.ycombinator.com/item?id=12753788 - Oct 2016 (2 comments) Verified Programming in F*: A Tutorial - https://news.ycombinator.com/item?id=10949288 - Jan 2016 (28 comments) F*: A Verifying ML Compiler for Distributed Programming - https://news.ycombinator.com/item?id=2663240 - June 2011 (9 comments) reply abeppu 20 hours agoprevAs someone only dimly aware of this space, I wish upfront they would highlight what they see as their relative strengths to similar systems and techniques. For example, I'm aware that both NuPRL and Coq have some ability to extract programs from proofs. What kinds of problems does F* do better at? Are there some areas where the SMT solver is a particular advantage? Are the extracted programs superior in some way? reply octachron 18 hours agoparentF* has an extraction backend which targets \"human-readable C\" code, contrarily to Coq which extracts proof to \"machine-written OCaml\" (typically the extracted code use a type-system-escape-hatch left in OCaml for the sake of Coq extraction). Consequently, part of the Everest project (the proven cryptographic primitives in particular) has been integrated into C code base like the linux kernel, firefox . reply jfoutz 19 hours agoparentprevI think humanity in general are only dimly aware of this space. The Research section is probably your best bet about what's different. I think your questions are what academics call \"open\". reply abeppu 19 hours agorootparentActually it does look like their book has at least some additional info in their intro section \"To F*, or not to F*?\" The highlights seem to be: - extensional equality (similar to nuprl) - undecidable type-checking - combination of both SMT and tactics, metaprogramming - focus on compilation to mainstream languages, programming more than formalizing math reply pelagicAustral 19 hours agoprevThe first thing that came to mind when I entered the site was the resemblance of the classic Soviet iconography to their logo, sans the hammer and sickle, then I checked the repo, and coincidentally, they have a recent commit (`c6fac4d`) titled \"kremlin -> karamel\" [0] ([...] a tool for extracting low-level F programs to readable C code*)... Apparently, the commit is one big rename operation from Kremlin to Karamel, funny. 0: https://github.com/FStarLang/FStar/pull/2489 reply seanw444 18 hours agoparentI'm curious why the resemblance and homage to the Soviet Union in the first place, but I find it sad that people feel the need to rebrand things like this, to avoid the mob. Just because I don't like communism, doesn't mean people can't have things named after one of recent history's most well-known superpowers, with admittedly cool style. reply debugnik 18 hours agorootparentI'm guessing they came up with the wordplay before the invasion, and then regretted it because the reference suddenly stopped being purely historical. And I get it, I've been phasing out this username, which I picked with bad timing, to avoid unintended connotations, even though I was simply thinking of Robotnik and not anything russian. I've got nothing to do with their language, so it just isn't worth it. reply kgeist 18 hours agorootparent-nik is a suffix which exists in all Slavic languages, including Ukrainian. Nothing specifically Russian about it. reply debugnik 17 hours agorootparentI, personally, am aware, but I'm not so sure everyone who will read my username knows that, and there's enough war-related shilling around (and suspicion thereof) that the pun simply isn't worth it. reply andrewflnr 17 hours agorootparentprevAnd even if it was, poking gentle fun at a Russian suffix would not be an endorsement of the invasion. reply chuckadams 14 hours agorootparentprevYeesh, avoiding obvious Russian-isms is one thing, but a common suffix? I say Nyet! Anyone triggered by that isnâ€™t worth accommodating. reply wisemang 16 hours agorootparentprevWell tbf Kremlin (as typically used) isnâ€™t just a USSR reference itâ€™s a specific place in Moscow. Still used as a metonym for Russiaâ€™s government. That said I do actually love that Soviet propaganda aesthetic. Can appreciate not wanting to be associated with the existing madman running Russia though. reply mapcars 18 hours agorootparentprevAgree, and there are other projects with fun names like https://en.wikipedia.org/wiki/Stalin_(Scheme_implementation) reply pelagicAustral 18 hours agorootparent\"Coon - new tool for building Erlang packages, dependency management and deploying Erlang services\" [0] comes to mind. Highly recommendable thread to read. 0: https://erlang.org/pipermail/erlang-questions/2018-February/... reply wk_end 17 hours agorootparentprevIt's odd how this is deemed acceptable - Wikipedia explains that the joke is in reference to its \"brutal\" optimization, which I'm sure eastern Europeans find hilarious (they might, they're known for their grim sense of humour) - but no one would seriously consider naming, say, their fork of the GNU assembler \"Hitler\". reply seanw444 15 hours agorootparentStalin never earned the same perception as Hitler, probably because he won and Hitler didn't. History is written by the victors. There's a reason the cliche move in politics is to call your opponent \"literally Hitler\" and not \"literally Stalin\". That said, I doubt any tool named \"Stalin\" would gain any major traction. Adopting such a tool would be a huge liability for a company. reply saurik 8 hours agorootparentI always figured this would be the correct name for a tool designed to erase unwanted objects out of photos (whether using classic techniques or AI, whatever). reply unstruktured 19 hours agoprevF* + 1ml (https://people.mpi-sws.org/~rossberg/1ml/) would be the ultimate experience. I was born too early! reply wk_end 16 hours agoparentCorrect me if I'm wrong (I've only dabbled in F* and only briefly read about 1ML) but wouldn't F*'s full dependent types make 1ML redundant? That is, once you've brought types into the value level, modules themselves become redundant - they're just records, and functors are just functions. The point of 1ML, IIUC, is to accomplish a similar unification without demanding full dependent types and the attendant complexities they bring. reply unstruktured 14 hours agorootparentInteresting point. I never inferred a strong connection between dependent types and the unification of records and modules. Maybe a real PL theorist around here can provide insights on that subject. reply joshmarlow 18 hours agoprevI'm curious how similar F* is to Lean Prover (which I've dabbled in). reply slushy-chivalry 14 hours agoparentand both are backed by msft? reply wyes 11 hours agoprevWe use F* for some of our crypto for embedded systems software :D reply bmitc 18 hours agoprevI've never understood the relationship between F# and F*. I had previously come to the conclusion that F* was merely inspired by F#'s syntax and base-level semantics but that was where the relationship ends. As far as I can tell, F* is not a .NET language and doesn't run on the CLR. Is that correct? In the description it says it compiles to OCaml, which confuses me even more about the F* naming. What is the relationship to or level of interoperability with F#, if there is any? reply samueldurante 18 hours agoparentI believe that F* is named purely for marketing purposes, or perhaps to specify another programming language with syntax derived from OCaml. But other than that, I don't think it has any other relation. reply mkehrt 12 hours agorootparentI'd assume both are named after System F, the Simply Typed Lambda Calculus enriched with a variety of types of what would widely be called generics. reply lambdanik 17 hours agorootparentprevNot just marketing ... About the name: https://fstar-lang.org/tutorial/book/intro.html#a-bit-of-f-h... reply User23 17 hours agoprevThey wrapped Dijkstra and Scholten's predicate transformer semantics [2] in a monad[1]! This almost irrationally pleases me. I'd really love the general concept to get wider traction too. While it's particularly useful for this kind of deep language design, a weakest precondition calculus be used manually when writing code[3] without any particular additional effort once proficiency has been achieved. To use an analogy, it's like the old trick of solving a maze by starting at the end and working backward. Often it ends up being considerably easier. [1] https://link.springer.com/book/10.1007/978-1-4612-3228-5 [2] https://dl.acm.org/doi/10.1145/2499370.2491978 [3] It pretty much boils down to looking at your code and asking yourself \"what has to be true for this to work?\" and then writing code that ensures whatever is necessary is true for all possible code paths. Naturally that means limiting possible code paths. There's just one more reason why spaghetti code is bad. reply 082349872349872 15 hours agoparent> looking at your code and asking yourself \"what has to be true for this to work?\" Wait a moment: are there people who write and ship code without continually asking this question, at least to handwaving precision? reply chuckadams 14 hours agorootparentThey internalize it with tacit assumptions and let runtime exceptions deal with it when the assumptions are violated. We all do this to some extent, and not just in programming, but many people are a lot more YOLO about it when the language allows it (see â€œduck typingâ€) reply vinnyvichy 5 hours agorootparentprevIt takes effort for me to compute whether grandfather is de gauche or de droite.. the better question to ask yourself continuously is whether: does this noise (spaghetti/imprecision in this context) improve or remove performance ((0-1) though the 2 questions are related; it's enough to point out that if necessity is the mother of invention, then paradox is the father of discovery)? (0-1) https://quillette.com/2022/04/05/noise-a-flaw-in-human-judgm... https://www.newscientist.com/article/2431131-buildings-that-... reply mkw5053 18 hours agoprev [â€“] It makes me miss my time spent tinkering with Idris :) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "F* is a proof-oriented programming language developed by Microsoft Research, Inria, and the community, supporting functional and effectful programming with dependent types and proof automation.",
      "Used in projects like Project Everest for secure communication software, F* has offshoot projects such as cryptographic libraries like HACL* and EverCrypt, focusing on security, cryptography, and formal methods.",
      "F*'s implementations cover data integrity monitoring, reversible circuits, and more, with active use in teaching and research, accompanied by online resources for learning and community engagement."
    ],
    "commentSummary": [
      "The text delves into the programming language F*, highlighting its significance in program verification and its application in projects like Project Everest for developing verifiable TLS implementations.",
      "It discusses the challenges and prospects of utilizing F* for business applications in the future, along with experiences with F# in diverse work settings for verification and general programming tasks.",
      "The conversation covers topics such as naming conventions in software projects, utilizing calculus in manual code writing, and the necessity of meticulous proofing in coding, exploring multiple facets of programming languages and best practices in software development."
    ],
    "points": 216,
    "commentCount": 80,
    "retryCount": 0,
    "time": 1715863627
  },
  {
    "id": 40380639,
    "title": "Author's Frustration with Google's AI Search Impact",
    "originLink": "https://aftermath.site/google-ai-search-god-no-why",
    "originBody": "Blog I Donâ€™t Want To Spend My One Wild And Precious Life Dealing With Googleâ€™s AI Search Google's AI search has come for me By Riley MacLeod 9:45 AM EDT on May 16, 2024 Share on X (formerly Twitter) Share on Reddit Share on Email 20Comments Googleâ€™s AI search has arrived, uninvited, to my browser, and I cannot make it leave. It isnâ€™t just that it serves me crap whenever I enter a question into my search bar, but that I have to wait for all the crap I don't want in the first place. Let me tell you a story from my day: I was paying invoices, and I wanted to doublecheck that the number of episodes of our podcast, Aftermath Hours, squared with what our producers had billed for. I typed â€œAftermath hours spotifyâ€ into my browser window, whichâ€“depending when Iâ€™ve last cleared my historyâ€“either autofills the URL for the podcast on Spotify or takes me to Google search results, where our Spotify page is the top result. But now, when I get Google, I have to wait through a nearly three-second pause before AI information about the podcast appears at the top of the page, followed by a link to Spotify and other results. While I appreciate that, in this instance, the AI-generated information about the podcast is correct, this information is not what Iâ€™m looking for, and I have to wait three seconds for it to show up just so I can ignore it. These three seconds are wrecking me. Iâ€™m not one of those lifehacking types who wants to optimize every bit of their day, but that three second wait is just enough friction that I notice it every time. Itâ€™s a small annoyance in the moment, but over the course of a dayâ€™s queriesâ€“any writer or editor can tell you that the number of weird searches you do adds upâ€“that friction starts to build into a drag. I feel like Iâ€™m losing chunks of my one and only life waiting for bullshit I didnâ€™t ask for and donâ€™t want to load onto my screen so I can scroll past it. That's something I already deal with when visiting the ad-laden websites Google search brings up; I donâ€™t need a preview! It makes the already unpleasant experience of Google search even worse than it already is. Before some stray AI evangelist leaps into the comments to promise the tech will get better, I want to be clear that even if it were instantaneous, I still wouldnâ€™t want it. I didnâ€™t ask for results from the plagiarism machine! My Aftermath colleagues arenâ€™t getting it, so I assume itâ€™s just rolling out to more people this week on the back of Googleâ€™s I/O conference. I should, apparently, be able to get around all this by selecting â€œwebâ€ results from the â€œmoreâ€ dropdown, but Iâ€™m not seeing that option yetâ€“and I assume Iâ€™d still have to wait for the AI results to load first. All the instructions for how to disable AI search presume I opted into it, which I very much did not. Plus, Googling â€œhow do I turn AI search offâ€ still gives me AI results; while its answers square with what actual websites tell me, itâ€™s a real 2001: A Space Odyssey vibe. In lieu of being able to turn it off, Iâ€™ve been trying to race the AI results, clicking â€œsearchâ€ and then scrolling as fast as I can down the page before the AI text appears. While this adds some excitement to my day, it also adds more stress and time crunch to a life thatâ€™s already full of it. I donâ€™t want this! I donâ€™t need this. Life is too short. Already a user?Log in Thanks for reading Aftermath! Please register to read more free articles Email Register See all subscription options Enjoyed this article? Consider sharing it! New visitors get a few free articles before hitting the paywall, and your shares help more people discover Aftermath. Share on X (formerly Twitter) Share on Reddit Share on Email Riley MacLeod@rcmacleod Editor and co-owner of the good website Aftermath. Read More: AI, google, oh no Stay in touch Sign up for our free newsletter Email Sign up More from Aftermath CEO Of Take-Two, Reportedly Closing Two Studios, Denies Closing Two Studios 'We didn't shutter those studios', says man who clearly appears to have shuttered two studios Luke Plunkett May 17, 2024 Blog DeviantArt In 2024 Sure Sounds Like A Shithole Like many websites, it used to be a good one 1Comments Luke Plunkett May 17, 2024 Feature Eric â€œConcernedApeâ€ Barone Canâ€™t Let Go Of Stardew Valley \"Once I reopen the book on Stardew, I always have a hard time closing it again\" 6Comments Nathan Grayson May 16, 2024 Video Games 40 Years Of Hurt Never Stopped Me Dreaming Singleplayer sports games are dream factories 6Comments Luke Plunkett May 16, 2024 See all posts",
    "commentLink": "https://news.ycombinator.com/item?id=40380639",
    "commentBody": "I don't want to spend my one precious life dealing with Google's AI search (aftermath.site)197 points by awkwardpotato 16 hours agohidepastfavorite196 comments wrs 16 hours agoThis is kinda crazy considering the tremendous effort Google has gone to over the decades to shave milliseconds off their response time. They invented a whole TCP replacement to reduce page latency, and now this? reply h2odragon 16 hours agoparent\"happy users\" has not been on google's priority list for a long, long time. 20 years or more. reply derefr 16 hours agorootparentThis isn't even about \"happy users\", though; it's about money. Where does Google's ad revenue come from if users give up on waiting for their searches to complete before they're ever shown any revenue-generating sponsored links? Actually, thinking about this more, I fundamentally don't understand Google's search experience strategy over the last 10 years. Even before AI answers, they were heuristic-ing answers into a little box that pushed sponsored ad placements below the fold. Why push sponsored results below the fold? How does Google make money from a search engine that just answers people's questions directly, rather than doing lead-gen for the rest of the Internet (with much of the Internet willing to pay for that)? reply JumpCrisscross 15 hours agorootparent> Where does Google's ad revenue come from if users give up on waiting for their searches You serve the ads while the answers spin up. reply mrweasel 14 hours agorootparentThat would be kinda sad, given that Google would previously forgo showing ads, if they didn't arrive on time. This is actually a problem I currently have with Ecosia on mobile. I search, get the result, and then the ads pop in, pushing the search results down, causing me to click the ad and not the result that previously occupied that part of the screen. reply voiceblue 15 hours agorootparentprevI donâ€™t think that comment was in regards to AI, I think it was about the blurb that appears instantaneously from Googleâ€™s knowledge engine (e.g. when searching a celebrityâ€™s age). reply zitterbewegung 16 hours agorootparentprevI think they just want to have your captured on their platform . If you get all of your answers then why pick a competitor? reply theolivenbaum 14 hours agorootparentThey probably also know that some types of queries are not ad-worth (like age of an actor, etc), while others would never show a box reply derefr 13 hours agorootparentThat's a really good point. Google has likely decided that some query categories are unprofitable-enough already that they can just drop the rest of the expected revenue from them, and instead use them as loss-leaders â€” aiming to give the customer a better (but zero-revenue) experience today, to increase retention, so they'll come back with positive-revenue-generating queries later. They've just done a rather braindead job of it, with the experience of these loss-leader queries feeling perceptuallyâ€  worse than a regular SERP page would. It's like a grocery store running a sale on e.g. milk, selling it for below-cost â€” but then making you have to wait in a line for five minutes in front of the milk cooler to get it. It feels like so much friction that not only wouldn't lure people in; it would push people to avoid that grocer when its milk sales are happening, and shop at other stores instead! --- â€  I emphasize perceptually here. Even if the total time spent waiting for an AI answer is shorter than the time it would take to load a SERP page, read and select a link that looks like it'll have your answer, click it, load the resulting page, and read it â€” the AI experience could still feel longer, in large part because \"the ball is in your court\" for a lot of the self-navigated query, with you being given things to look at and click on; while \"the ball is in their court\" for the entirety of the AI response, with just a spinner and no indication of what's happening. As such, I wonder if this could be solved by just running a cute little animation under the AI prompt window: make it look like it's automating the loading of a [blurred to non-identifiability] SERP page, scrolling down, clicking a result, loading an [again blurred] page, highlighting a few random fragments of it, and then transposing them together to form the paragraphs of the answer â€” before the answer actually snaps into place on top of that animation. If you can predict how long before the AI answers, you can even use that to determine how long the animation should spend dicking around on the pretend SERP page and answer page. reply bilekas 15 hours agorootparentprev> How does Google make money from a search engine that just answers people's questions directly It did what it needed to do to realise the same thing and get their fingers in all the other pies. reply otabdeveloper4 15 hours agorootparentprevGoogle works because it is a monopoly. All human eyeball traffic goes through Google. It is in their interest to keep destroying the open information marketplace because then advertisers are forced to buy through Google. (Much easier and more profitable than trying to make a good adtech product.) reply panarky 15 hours agorootparentCompetition is just one click away. As others in this thread already point out, it's extremely easy to use DDG or Bing if you want. reply otabdeveloper4 3 hours agorootparentNo. Google owns your phone and your browser, your email, your video feed and often your office productivity tools too. All human eyeballs go through Google's advertising network first. (Unless you're an Apple-only person.) So for advertisers it makes no sense to budget anything but Google first and foremost. Maybe they'll add some Bing-Yahoo if they have spare money laying around and want to catch the remaining couple percent of the audience. P.S. Search is only a small part of Google's advertising network, and not the most important one nowadays. reply doublerabbit 15 hours agorootparentprev> Competition is just one click away. As an illusion sure, in practice not really. I use Kagi, I bought the family plan so I could try convining my family to use it, did they? No. Did my family want to use Signal for messaging? No. Do my friends want to use something else than Discord for communicating with me? No. Competition exists and in plenty but folk are too mind sucked to want to move platform. If its not broke, why change? People don't want to change. And until such platforms close their gates or whereby something new comes along that isn't a clone; there will be no shift. reply skydhash 14 hours agorootparentLead by example, not by preaching. And taking a stance. You wonâ€™t find me on any social media other than Linkedin and Twitter. And on those, I no longer post or interact with people. I keep Twitter because of announcements and Linkedin as a public CV. I also use WhatsApp because alternatives are not really viable (but I reduced its social aspect as much as possible). Youâ€™re free to make your choices. Just donâ€™t complain about it, if you wonâ€™t heed my advices. reply doublerabbit 14 hours agorootparentYour still part of the problem regardless if you use the services or not: the fact is these corporations are so ingrained with the weedy roots, you can't. Google is testing on those as we test on animals. ML for only search? Naw. If everyone turned off their droid, stopped using their email, switched to Firefox, they would still be on top. Yes. It's better not to, and if your going to preach, yeah. As I use no services other than Signal but we are still just pawns in this game. We are a just pittance of income of those who are keeping the empire's on top. And who do you run too? DDG is owned by Apple so your only fuelling their empire. This goes deeper than you could imagine. reply thegrimmest 14 hours agorootparentprevDoesn't this just mean that the vast majority of users don't care enough about these sorts of things? Doesn't that mean that the market is working? If switching cost > perceived benefit why should we expect anything other than status quo? When a truly innovative platform that offers benefit > switching cost, users will naturally flock to it. We're already starting to see that with ChatGPT. reply MereInterest 10 hours agorootparent> Doesn't this just mean that the vast majority of users don't care enough about these sorts of things? Doesn't that mean that the market is working? No. Network effects mean that there's not only a high cost of switching away from the largest network, but there's a high cost to use anything other than the largest network. When that bias exists, you cannot infer any preferences from market outcomes. reply holonsphere 15 hours agorootparentprevEverything they do is about projecting power and silencing(i.e. drowning out) the \"opposition\" https://english.almayadeen.net/articles/blog/genocide-in-the... reply genman 15 hours agorootparentnext [10 more] [flagged] forgetfreeman 14 hours agorootparentAdmittedly I didn't read the whole page but a quick skim of the first several paragraphs didn't produce anything with obvious ties to national socialism, what am I missing? reply wahnfrieden 13 hours agorootparentgenman is saying that critical evaluation of Israelâ€™s automated targeting AI system (used for selecting bombing targets without human verification) is equivalent to supporting Hitler. Their logic is that Palestinians represent a credible existential threat to Jewish people internationally in the same way that Hitlerâ€™s military did, so that criticism of IDF bombing campaigns is equivalent to Naziism, and Palestinian resistance is identified as genocide against Israel. reply forgetfreeman 5 hours agorootparentThat's kind of what I was afraid of. reply genman 13 hours agorootparentprevIt is calling Israel \"the so-called Jewish state\" and 'Israel' what effectively means a claim that Jewish people do not have right for the state on their ancestors land and genocide against them (like genocide on 7th October, or earlier intifadas) is somehow justified. reply CatWChainsaw 11 hours agorootparentThe Palestinians currently living there had their own ancestors that also lived there. Do they not count? reply genman 10 hours agorootparentRussia is right now trying its best to forcefully assimilate all the small nations it keeps occupying, because it is afraid that in one they have to give all of it back. reply CatWChainsaw 9 hours agorootparentSince that has nothing to do with what came previously, I'll be 100% uncharitable and assume that's a big old No and you support IDF bombing hospitals and schools and aid convoys unless you explicitly indicate otherwise. Glad we had this little chat. reply genman 9 hours agorootparentnext [3 more] [flagged] wahnfrieden 9 hours agorootparentComplete distortions and lies reply genman 8 hours agorootparentThe history disagrees with this assessment. reply phreeza 16 hours agorootparentprevGoogle is not a monolith, there are plenty of people at Google trying to make a good user experience. reply toomuchtodo 16 hours agorootparentLeave and deliver somewhere itâ€™s possible. Youâ€™re never going to win against corporate inertia and management interests at Google. reply aiauthoritydev 16 hours agorootparentA small improvement done at Google's scale as pretty low end engineer would have greater impact on world than any \"elsewhere\". reply legulere 15 hours agorootparentI think you're greatly underestimating the low hanging fruits in big important non-tech organisations like governments. reply throwup238 15 hours agorootparentMy lumberyard of choice still uses DOS machines for their computers and POS. I'm not saying you'll change the world by revolutionizing lumberyard inventory management software but I wanted to illustrate just how low the low hanging fruit are. reply ddalex 4 hours agorootparentIF somebody could make 6-figure comp writing lumberyard inventory management systems, they would reply aiauthoritydev 14 hours agorootparentprevIf it works what is wrong with DOS ? But even if you redo the whole thing and it is efficient, it is still less than some minor performance improvement in Chrome can achieve for the world. reply throwup238 14 hours agorootparentSpare parts, for one. BART for example is dependent on old computer parts from Ebay to keep the Bay Area's main mass transit system running: https://news.ycombinator.com/item?id=32884814 Speaking as a customer, it's slow, annoying, and makes the shopping experience there miserable. If you innovate in that software space, you might be able to make a significant impact on the trade of certified exotic wood and maybe even save a few species of tree. reply nyarlathotep_ 14 hours agorootparentprevYes but non-tech organizations are often a disaster for getting even simple things done--crap like filing tickets to get something simple approved like provisioning something via a Cloud provider paired with loads of bureaucracy and (often) lower skilled employees are not an ideal arrangement for picking said fruit. reply phreeza 16 hours agorootparentprevMany people actually deliver things that are objectively improvements to user experience, such as latency improvements? reply internet101010 15 hours agorootparentDoesn't matter if the search results are shit, which they are. Not as bad as YouTube's search though, as the breakdown is 3 relevant results -> 12 irrelevant \"people also watched\" results -> then back to normal results. And that's assuming you have an extension installed to filter out everything related to Shorts. reply toomuchtodo 16 hours agorootparentprevServing ads and poor quality search results faster is an objective improvement? Agree to disagree. If the only thing gen AI delivers is killing Googleâ€™s search standing, itâ€™ll have served a useful purpose. reply phreeza 16 hours agorootparentIs it a deterioration? I don't disagree that results are getting worse, but I'd still say all else being equal faster results are better than slower results. reply toomuchtodo 16 hours agorootparenthttps://mashable.com/article/google-search-low-quality-resea... https://downloads.webis.de/publications/papers/bevendorff_20... https://fortune.com/2024/01/18/why-is-google-search-so-bad-s...https://archive.is/CLO4S https://searchengineland.com/google-to-cut-thousands-of-sear... (I use Kagi, DDG, and OpenAI for search primarily, all paid for, so my first hand experience with Google Search is limited, intentionally; are faster poor results better than slightly slower good results? I can spare a few seconds for better, this is not high frequency trading) reply Alupis 16 hours agorootparent> and OpenAI for search primarily How is this in practice? Normal GPT is entirely untrustworthy for a lot of it's information. How can you trust it's \"search\" results/summaries? I've said it before, but it's like watching the news about a topic you know a lot about and realizing how wrong they are... yet you continue to believe the same people regarding subjects you know nothing about. GPT feeds you BS, and you have to be knowledgeable about the subject to detect it... yet we blindly trust it's output on subjects we know little about. That's... dangerous. reply toomuchtodo 16 hours agorootparentI don't rely on GPT output as canonical, I only use it to help surface big rocks I can refine with other engines and find primary sources. It's fancy autocomplete after all, but PageRank was just weighting links in a link web as well. reply Alupis 15 hours agorootparentI've attempted to use it as a guided learning mechanism - and had some great success, but also it's sent me down some very deep, dark rabbit holes that turned out to be entirely wrong. It frustrates me to no end... and then I go back for more punishment naively believing this time it'll actually be right. With that said, the newer voice interactive version (using the app), I've found to be pretty slick for debating yourself on technical merits of designs/architecture, etc. reply holonsphere 15 hours agorootparentKeep in mind the whole \"easy to read\" over any network thing openai had going on early on. Theyve only gotten better at hiding their datamining. Theyre more interested in your mind than your wallet. dont reinforce other peoples' algorithm if they wont be straight up regarding what theyre really doing with it. reply toomuchtodo 14 hours agorootparentI pay for enterprise, but Iâ€™m also fine with them consuming what I provide to improve, for now. reply stevenally 16 hours agorootparentprevGoogle is evil. Sorry. It is driving people mad via the YouTube algorithms. And it is destroying democracy. reply bee_rider 15 hours agorootparentDo you have a specific example for Google? The fact that it has been reported by groups like Amnesty International that Facebook helped to enable the ethnic violence in Myanmar makes arguing this sort of point much easier. People want to treat complaints about attention economy companies like they are coming from whiners who just donâ€™t like ad profiles. It is useful to have specific information to remind people of the actual stakes of uncontrolled, personalized propaganda and social manipulation that these companies can enable. So if you have one for Google Iâ€™d definitely be interested in adding it to my collection. (Iâ€™ll admit some bias, I think they are a little better than Facebook, but that bar is so low, letâ€™s be careful not to trip over it). reply holonsphere 15 hours agorootparentSome of the best examples are too sensitive to share on this forum. Other things get flagged and reported. Some new topics/sources that squeeze by invite the bots. The best arguments for Google's algorithms making people crazy for lay people would be Aaron Swartz like individuals who just go unknown. I can think of atleast 4 individuals new to me the last 6mo ive discovered who used to cover court cases, ran NGOs, or worked as journalists that have been seemingly swept up in what looks like delusions. Lots of typos, egegious oversights, etc#. Its hard to personify these individuals as theyre hard to reach and anyone w ptsd or whom knows people w ptsd know how hard it is to provide support to someone locked in a fight-or-flight reflex. After a terror/fear/paranoia becomes familiar anything else feels foreign. Human connection becomes scary. Read up on bateson-esque schizomogenisis and reflect on the CIAs relation with the \"unabomber\". reply kridsdale3 14 hours agorootparentWhat youâ€™re describing sounds uncannily like the effects of Snow Crash. reply FredPret 16 hours agorootparentprevWhich democracies have descended into dictatorships because of Google? All Youtube does is feed me engineering and astronomy videos. It's actually improving my life. Your algorithm is a reflection of you. reply Alupis 16 hours agorootparent> Your algorithm is a reflection of you. This is objectively false. \"The\" algorithm is designed to maximize engagement - so you will be shown content you are most likely to watch, click, listen to the most. As it turns out, \"Outrage Porn\" is highly engaging... Scroll through enough YouTube Shorts, and just like TikTok, your \"algorithm\" slowly but surely reduces to outrage porn. All paths lead to outrage porn. All of them... reply silverquiet 15 hours agorootparentI was watching exercises for shoulder tendonitis and it escalated to surgeries of shoulder replacement - it seems to be good at upping the intensity (for lack of a better word) of whatever you're watching regardless of the subject. reply supriyo-biswas 15 hours agorootparentprevn=1, but I've watch a fair bit of Youtube shorts and this has never happened. The algorithm rewards what you watch, and someone addicted to politics and the culture of outrage around it, will get what they ask for. reply Alupis 15 hours agorootparentIt usually starts off with just content you're overtly interested in. Then, they'll sprinkle in random clips every so many scrolls to guard against overfitting the model and getting stale for the user. Some of those random clips are Outrage Porn designed to get a reaction out of you... You scroll past, then scroll back because \"wtf did I just see?\" - and now you're in. The frequency starts to increase and pretty soon you're shouting at clouds feeling like you're the only one that realizes how crazy everything is... It's hard to keep your feed \"clean\" and dialed into just things that bring you intellectual stimulation or enjoyment. It's not impossible, but it's quit difficult. You constantly have to realign your algorithm lest it goes off into the weeds. reply marcosdumay 15 hours agorootparent> It's hard to keep your feed \"clean\" and dialed into just things that bring you intellectual stimulation or enjoyment. The confusion happens because this can be very easy. All it takes is rarely watching youtube. If you only watch a random video here and there, Google won't push all the bullshit at all. So the people watching many videos, getting the shitty recommendations, and complaining that the internet is crazy end-up sounding insane to everybody else. reply FredPret 14 hours agorootparentprevThe algo will only push outrage on you if you secretly like it enough to spend hours watching that shit. I have consumed more than my fair share of content on Youtube, Instagram, Facebook videos, and TikTok. My timeline is all engineering, spaceships, jumping puppies, and comedians (and not the negative kind). It's an algorithm, it wants you to watch more and click on all the ads. It doesn't care if the world burns, but it also isn't going to push you that way. My statement will only be \"objectively false\" if the algorithm is somehow programmed for political extremism. In reality, each of us is in the driver's seat. People have been spouting crap since time immemorial - doesn't mean you have to watch it. I would suggest a heavy and sustained dose of puppy videos. reply Alupis 14 hours agorootparentHow do you use these short video services? Are you searching for content then watching, or just \"doom scrolling\" while on the toilet? Searching then watching is effectively realigning the feed to your latest and most engaged preferences. Doom scrolling will get worse and worse as time goes on - it appears entirely unavoidable. They pick up on \"positive\" interaction signals such as slowing down while scrolling past a video, scrolling back to a video, letting it play more than once, even downvoting can be a sign of engagement and a catalyst for more of the same... You are right - the algorithm doesn't care if the world burns... it just wants to maximize engagement. That, for most of the human population, means stuff that gets immediate reactions. Unfortunately that often means outrageous material. reply mrweasel 14 hours agorootparentprev> Your algorithm is a reflection of you. Yes and no, you're correct in that it feeds you more of the stuff you engage with, but that's not what it should be going if YouTube cared about the mental well being of it's users. The YouTube algorithm is notorious for not responding to deliberate user input. Say I know that the content I engage with is harmful to my mental health, first step in dealing with the issue. You CANNOT tell YouTube to stop enabling you, even if you try. There are things the algorithm isn't smart enough to understand, or if YouTube is evil, understand that it SHOULD NOT respond to. Example: I wasted a lot of time on Shorts, and videos less than 2 minutes, junk content. So I start hitting \"Not interested\", the algorithm WILL NOT pick up on the thing these videos have in common, that they are short. You can block channels, that works, except that there are thousands of similar channels which YouTube will then just push instead. What I would like to see is YouTube have settings for: What kind of person do you want to be? And then just push the hell out of relevant content, ignoring any level of engagement. I think everyone knows why YouTube won't be doing that. YouTube is a company, they do what's good for the stock price / profit margin. If it hurts the users, they don't care. It's not that they are evil, they just don't give a crap. reply gspencley 14 hours agorootparentprevI'm starting to consider creating different accounts / profiles for my different interests. The problem that I have with YouTube is that it can't know what I'm in the mood for at any given moment and it thinks that if I click on one single video about a sensitive topic that suddenly I want my entire home page to be overrun with recommendations about that. To give a specific example, something that honestly kind of baffles and bothers me is the amount of firearms related videos in my recommendations despite the fact that I never watch them, I don't own any firearms and I keep clicking \"Don't Recommend Channel\" and they never seem to go away. It has to be because the topic is tangentially related somehow to something I've watched, or maybe people who are into firearms overlap with some of the content I watch. But it's the volume and the non-responsiveness to my feedback that annoys me. Another example: my wife and I enjoy watching the Eurovision Song Contest every year. So naturally we've watched a lot of that content in the days and weeks leading up to it. Obviously the algorithm is going to recommend content related to Eurovision, but my home page is completely flooded with these recommendations to the seeming exclusion of most other stuff that I want to watch. And I keep clicking \"Don't Recommend Channel\" on the various \"reaction\" videos that are just feeder content featuring people reacting to the songs and performances ... because I CAN'T STAND reaction videos in general and NEVER watch them. But they keep appearing in the recommendations nonetheless. Recommendation algorithms are a hard problem to solve, for sure. I'm not trying to be unfair to YouTube because I know these recommendations are somehow related to what I do watch. I just know that it feels like 90% of those recommendations miss the mark regardless. YouTube is starting to feel like cable TV these days (\"200 channels and nothing to watch\") where my wife and I often find ourselves just doom scrolling and refreshing the home page (we watch on our TV) hoping that something we're interested in watching at that moment will appear. Often times nothing does and we go do something else. reply gspencley 12 hours agorootparentReplying to myself because I just thought of a 3rd example that is extremely common for me: news channels. I don't watch news on YouTube, ever. If I see a video from a news outlet I automatically click \"Don't Recommend Channel.\" And I've done that with all of the big major news channels like CNN, Fox News, MSNBC etc. But that doesn't stop videos from local affiliates showing up in a never ending game of whack-a-mole. To be fair these do not tend to \"flood\" my recommendations. But I want them to go away all together and I can't seem to make that happen. reply legulere 15 hours agorootparentprevOne example of meta instead of google: https://www.amnesty.org/en/latest/news/2022/09/myanmar-faceb... reply SkyBelow 15 hours agorootparentprevIt ends up being a reflection in the flaws built into humans. We have many vices. Individuals overcome it, but as a group we are susceptible. We have a long history of deciding where to draw the line between exploiting a vice to control someone and where it becomes letting others live while minding ones own business. We might allow alcohol starting around 18-21, but we ban food companies putting certain addicting drugs in their recipes (but yet allowing others, not fully consistent). Where this algorithm's exploit falls is a new area we haven't really decided upon as a society. Is it like adding cocaine to soda or like adding caffeine to soda? reply mateus1 16 hours agorootparentprevBut the good people are being driven out while the good product are being killed. reply mrguyorama 16 hours agorootparentprevThat does not matter one iota. Google's goal since they bought doubleclick has been to serve more ads and make more cash, and everything is subservient to that goal. If serving more ads reduces the user experience, they will not choose to stop serving those ads, they will choose to reduce the user experience. Companies are not democracies. If every single dev thinks that the user experience matters, but the CEO wants more ads, you will get more ads. It's literally a tyranny. reply phreeza 15 hours agorootparentYou can get away with a lot of things even inside of a tyranny, if you are good at selling to your superiors. So in your example, a dev who wants to improve user experience might have to couch it in terms of how users are likely to come back more often an click on more ads, and if they do this well, they will often be allowed to do the improvements they want. reply hehdhdjehehegwv 15 hours agorootparentprevLeadership however is a monolith: they are all 100% locked into quarterly stock market price as the single criteria for making decisions. Or, as I like to say, Google hired some of the best, and promoted all of the worstâ€¦and after 25 years here we are. reply buildsjets 16 hours agorootparentprevThe cafeteria ladies? reply ilrwbwrkhv 14 hours agorootparentprevI think those people are the minority. Ux at Google has always been poor and they have never been able to ship a bug free product. Now they are bending over backwards to stay in the AI race but honestly it just seems like they are done. They are a huge balloon so it will take a while to come down but the gas gas started leaking. reply georgeecollins 16 hours agoparentprevNot surprising to me after their AMP initiative. Supposedly this was supposed to make the mobile web faster. Really the point was to make it more difficult to get different bid for ads. This is just one example of a pattern of behavior of saying you are doing something for the consumer but really its just to exploit a monopoly. If you are in a field with digital advertising you really should read the link below, and be very suspicious of Google. https://texasattorneygeneral.gov/sites/default/files/images/... reply barfbagginus 13 hours agoparentprevIt is standard with Bing and chat GPT to wait a few seconds before the result appears. Early adopters excuse this since they value the AI text, realize it's being generated at high expense, and there's no way to make it much faster on the backend. Non-adopters won't value AI text or the technical hurdles. Google is in a hard place - they need to roll the feature out to stay relevant to early adopters of AI. But they can't give good results without making it a huge loss leader - their revenue comes from sending users to spam. They can't seriously commit to a loss leader that counters their entire business model, so they're going to half ass it. That stands to upset established users and early adopters alike, with an unfocused and executive sabotaged Hail Mary. I call this the \"decline of AOL\" phase of Google's lifecycle. There's a big crisis about the value and necessity of the service, but rather than innovating, execs can only push annoying ads and gimmicks. reply pushedx 13 hours agoparentprevThey've invented multiple TCP replacements to reduce page latency. Remember SPDY? Not to mention improvements to TCP itself (BBR congestion control). This is really sad. Seems like a product team throwing many tens of millions of dollars worth of performance research out the window. reply gmuslera 16 hours agoparentprevRemember the Not be Evil? And how minimal used to be the Google search (and gmail) user interface? This is just another step into that direction. All the other optimizations were intended to minimize the intrusiveness of those anti optimizations. reply caesil 15 hours agoparentprevReally seems like they are terrified and flailing wildly reply surfingdino 13 hours agoparentprevAI is a play to appease Wall Street. It is similar to the VR race, which has just ended and anyone investing heavily in it would not necessarily be praised by the stock market. Companies like Alphabet, Meta, or Apple have to be seen to be innovating or else their stock will suffer. So, even if they know it is all not going to work they are forced to show they are keeping up. So they suck life of the new tech by deploying billions of USD to hoover up talent and tech and thus asphyxiate competition, especially smaller players. Once the dust settles in a couple of years there will be some leftover tech that might be useful and a whole bunch of patents kept at the ready for the next round of crazy. Google could be doing nothing, but there would be no end to the comments that they are finished and have no future. Funny that nobody expects Oracle or Autodesk to out-hallucinate their competition. I guess they don't because bank ledgers or high-rise designs are best kept away from the tricksters selling another iteration of Mechanical Turk under the guise of \"saving humanity\". Unfortunately for us, unlike previous advances in IT this one make things slower, uses way more energy, and spits out BS. Give it a couple of years and a wider war effort where compute power might get nationalised for the purpose of fighting the enemy in a more efficient way or designing deadlier weapons faster and we will not see AI available to the general public for much longer. Not that it's a bad thing, SEO spammers trying to outdo one another in who can publish more crap is something I'd like to see less of. reply 1vuio0pswjnm7 9 hours agoparentprev\"They invented a whole TCP replacement to reduce page latency, and now this?\" What is the reason for the page latency. Is it TCP. No. It is pages laden with excessive amounts of advertising. Google is an advertising company. The problem is the advertising, which causes latency, not TCP. Moreover, they did not \"invent\" this TCP replacement, they borrowed the idea from djb (CurveCP) who may have borrowed it from someone else. CurveCP does better as it encrypts each packet individually, does not require TLS and allows multiple websites to be hosted on the same IP address. No plaintext domainnames on the wire (SNI) required. Nor some elaborate, complex and cumbersome Band-aid like ECH. Google's problem is how to deliver more advertising without affecting www speed, i.e., without web users noticing how much advertising slows the web down. But Google spins this problem as how to \"make the web faster\". It is Google's business, online advertising, that is slowing the web down. Google deliberately adds latency to pages when \"loading\" so that ad auctions can take place first. Advertising is the priority, not reducing latency. reply christkv 15 hours agoparentprevNot yet in Europe it seems. I canâ€™t wait /s. Might have to finally sign up for kagi. reply cyanydeez 13 hours agoparentprevThey ditched real search results for markrting 5 years ago. Why pretend theyre doing anything but making ads more than anything else reply Vvector 14 hours agoprevhttps://www.mozilla.org/en-US/firefox/new/ Don't complain about a company having a monopoly while using their products WHEN THERE ARE COMPLETELY FREE AND VIABLE ALTERNATIVES. reply mkeedlinger 14 hours agoparentAnd alternatives that I honestly think are better. One reason I'm unwilling to move from Firefox right now: Recommended Extensions. They're extensions that are checked by Mozilla employees for quality, security and privacy. Extensions have such unfettered access to my browsing, and so many have such nefarious practices that I'll only install extensions that Mozilla vets. reply raxxorraxor 3 hours agorootparentThis argument of allegedly hostile addons is true to an extend. They theoretically do indeed have access to your browsing, just like your browser has access to your browsing. However the security argument was used to inhibit ad blockers and get more control about browsers, an already quite restricted ecology. I gladly have the option to vet addons myself just like I do vet browser vendors. Some of the later and attached companies might have questionable goals. For me this feature of Firefox is the least important, but demands differ I guess. reply leotravis10 13 hours agoparentprevHate to tell you this but Mozilla is also going to drink the AI kool aid soon judging by their plans for Firefox in recent months. They're also planning shopping ads. https://bugzilla.mozilla.org/show_bug.cgi?id=1858644 https://old.reddit.com/r/browsers/comments/18du4qs/firefox_a... reply rezonant 13 hours agoparentprevDear sir/madam, that's a browser. This is a feature of Google Search, which is a search engine. reply neal_jones 8 hours agoparentprevIâ€™m not saying FF is perfect but just this week a coworker fixed this major lag issue on one of our pages and did a pull request. I tested it but that page didnâ€™t have any issues on my machine, switched from FF to Chrome and the page was unusable. Apparently â€œborder-radiusâ€ can cause absolute havoc sometimes (at least it did in Chrome) reply bradgessler 4 hours agoparentprevNow everybody is going to reply with all the reasons they canâ€™t switch off Google. reply renegat0x0 13 hours agoparentprevYet FF also wanted to capture user search data. I feel that ff is also not the best option. reply gwervc 14 hours agoparentprevYeah, free and \"viable\" alternatives funded at 90% by said monopoly haha. reply adolph 14 hours agorootparentLots of people are getting paid by Google to be default. Alphabet CEO Sundar Pichai on Tuesday confirmed that Google pays Apple 36% of Safari search revenue, under the terms of a default search agreement that is core to the Justice Departmentâ€™s antitrust claims. https://www.cnbc.com/2023/11/14/google-pays-apple-36percent-... reply Barrin92 14 hours agorootparentprevThere's no way Mozilla can win on this. You can't charge for a browser at the scale to compete with Google, not enough people will pay. When they start to open up alternative services that actually could generate revenue, people yell at them and tell them to work on the browser. This is 100% on the consumers, over and over open source projects receive no funding and exist by virtue of big companies subsidizing them because nobody is willing to pay for their principles. reply pessimizer 13 hours agorootparentThis is 100% on the government failing to regulate monopolies. This is 100% on Microsoft antitrust action over the browser war being allowed to degenerate into farce. This is 100% on people defending arrangements like this by guilt-tripping consumers: instead of Mozilla's relationship with Google being corrupt, it's actually the entire rest of the world that is corrupt. If Firefox can't survive without Google, then at least they won't be able to beard for Google's monopoly. reply barfbagginus 14 hours agoparentprevFirst, Mozilla's execs killed ff and made the organization into basically a subsidiary of Google, dependent on its support. Second, ff comes with Google as its default search - so that's going to suck. I will be happy for you to yell at me to use Firefox when you have fired Mozilla's execs, and dropped Pocket and the Google default search. Until then, I feel like you're not facing reality about what ff has become due to it's cooperation with Google. reply davidcbc 14 hours agorootparent> Second, ff comes with Google as its default search - so that's going to suck. I'm confident that if you can post on HN you can figure out how to change a default setting reply luqtas 13 hours agorootparenti heard there's a lot of old timers here... who knows if they know how to deal with new tech reply TZubiri 14 hours agoparentprevDon't complain about a product when it's free. Exactly how many dollars is OP paying google to complain about 3 second delay times? What's his premium support plan and how does that pay employees to handle his banalities? reply bee_rider 14 hours agorootparentAd supported products arenâ€™t free, if they were, Google would not be one of the worldâ€™s richest companies. Ad supported products are just priced in a sufficiently convoluted manner that the customers donâ€™t know how much the ad companies are making off them. Having a convoluted pricing scheme shouldnâ€™t make a company immune to criticism. reply rgbrenner 16 hours agoprevâ€œ Googleâ€™s AI search has arrived, uninvited, to my browser, and I cannot make it leave. â€ You can make it leave. Firefox isnâ€™t dead; browser choice still exists. reply Always42 14 hours agoparentYes, use firefox or something not chromium based people! We don't want all the other browsers dying, then google requiring you to use chrome to view youtube, google, gmail, etc. reply ozten 15 hours agoparentprevDuckDuckGo.com will fix this inside of Chrome as well. reply davidcbc 14 hours agorootparentDDG is rolling out the same kind of thing with DuckAssist reply divbzero 14 hours agorootparentDuckDuckGo provides an option to turn off AI if you donâ€™t want it: https://duckduckgo.com/settings reply doublerabbit 14 hours agoparentprev> Firefox isnâ€™t dead Yet. That's to say that Firefox feels as it's currently on life support; alas one thanks to Google. All it would take is for Google to remove funding and the browser sinks, Mozilla with it too. reply skeaker 12 hours agorootparent>That's to say that Firefox feels as it's currently on life support No it doesn't? -- Sent from Mozilla Firefox reply doublerabbit 12 hours agorootparentGoogle, Alphabet needs to fund Mozilla because there are no other internet browsers available suitable for today's Internet standards. Microsoft gave up, Opera gave up and Webkit is the only other and that's now iDevice exclusive. If they didn't they'd be vulnerable to an very large anti-trust lawsuit. reply skeaker 11 hours agorootparentRight on, but the browser works on my machine. Doesn't feel like it's \"dying\" or whatever other nonsense. reply Always42 14 hours agorootparentprevcan you explain? From my understanding firefox is owned by mozilla? reply beretguy 14 hours agorootparentGoogle is paying to Mozilla a lot of money in exchange for Firefox having Google as default search. reply doublerabbit 14 hours agorootparentprevTl;dr: Google needs to fund Mozilla because there are no other internet browsers available; suitable for todays Internet standards. Microsoft gave up, Opera gave up and Webkit is the only other and it's now iOS exclusive. It failed as a desktop browser. Without Firefox, Alphabet would be liable to an anti-trust lawsuit. Apple not so, because they keep it to their iDevice. - Firefox is Mozilla's and Mozilla is a non-profitable organisation. The story as I know it is that in the early days Mozilla became the defacto internet suite as they produced a suite of applications. Email, FTP client and a browser and these were crafted and sustained by volunteers. (This is skipping the predecessor, Netscape). The internet was simple then. HTML and CSS with an lil' bit of Javascript made the internet fine. Everything was open and the rainbow coloured fence of your neighbour was pretty. You could even implement your own renderer and know it would work. In the dozens: https://eylenburg.github.io/browser_engines.htm Introducing Google: they started out just as search engine and that it was. Pretty great at it what it was and their was no other. It's boasted feature was one of that you could rank pages with PageRank although in the long run became unprofitable. The popped dotCom boom had made VC's scared to invest and Silicon Valley was still recovering from the aftermath. Unlike Yahoo, Lycos and other service providers, who all had offered services like email and entertainment subscriptions, survived. Google, as bankruptcy neared had offered to sell to Yahoo for $500k and what a different world we would be in. But this didn't happen. Google then started their up-taking. By introducing advertising to their search engines. The gimmick I recall is \"buying nukes\" as if you searched \"nukes\" you'd get a banner in the right hand side of the page of \"buy nukes on ebay\". Geeky college humour. Eventually, they branched out releasing gMail with beta invites and insanely large inbox sizes where the latter only gave you small amounts of 20mb. And folk flocked to this service. You didn't need 1gb of email storage but hey, you had it. They had it all, a feature rich simple email client. Simple being the key, Simple search engine and your simple website now possible to be seen. As well as vendor lock in. As to change email is as painful to change mobile phone numbers. Dark-UI. You had a exclusive gmail email, a chance to be on top of Googles search and it thrived. The internet existed but wasn't something for everyday everyone but heck was it a good time. Introducing Apple and the iPhone. This was the new strike to the internet. The internet wasn't an everyone thing but it was now. Apple created the iPhone from the previous based Java firmware driven non-smart phones with apps and Google introduces with Android a few years later with their apps. Apple users already being an exclusive clique of the time flocked in masses and this boosted Apple sky high. Eventually major vendors started to suck up to Google as Apple as we know doesn't play ball with the BlackBerry being the business phone, tried! in the end lost as it wasn't innovative enough nor was designed for the consumer market. We now had this fantasy tech but no future internet for it to work. And so Google crafted the next-gen specifications for HTML. HTML5 for the internet - This was to enable the \"future\" and Chrome came with it to carry out these new features. For their phone and for the desktop web browser prior to that you had Internet Explorer or Firefox. Even then Firefox was least popular because Internet Explorer was shipped in Windows and sabotaged. This was a further blow for Mozilla because now as an volunteer organisation with less money now had to implement all these new features while Google already had their thing. This kept Firefox lagging behind and made FireFox less popular as the new rebranded Internet wouldn't work with it. Google with that and advertising money as well as resources could afford to keep implementing, sabotaging and make it painful expiration for anyone to keep up the pace. While this is excluding Mozillas mishandling and not greatest decisions but here we are now, Google dictating the latest internet splash of paint. The younger crowds who adopted Google, adopted Chrome as the browser and the legacy keeps going. Googles vendor lock in for gmail as the same with Canonical's Ubuntu, (which helped Firefox a bit) with its free-cd campaign, and so boosted Linux but ultimately with less money and community support has brought Mozilla to it's knees. reply jfim 16 hours agoprevThe worst part is when it hallucinates an answer. Google slides doesn't have a morph transition (PowerPoint does), but the AI will confidently claim it does: https://www.google.com/search?q=google+slides+morph+transiti... reply akira2501 15 hours agoparentFor almost an entire decade, I forgot that bookmarks exist, why would anyone use them when you have Google? Over the past year, I've fallen in love with my bookmarks again. They're curated. They take me right to the answer I want. You can set the \"omnibar\" up to search your bookmarks. They don't hallucinate themselves into existence. So, thanks Google, I've gone back to 1999, for the total failure that your service is. reply abraae 14 hours agorootparentIdentical experience! Though ironically, having useful bookmarks pushed me into turning on sync in chrome so they would be accessible one all devices, pulling me further into the Google tarpit. reply renegat0x0 13 hours agorootparentprevI read that grimoire is quite popular repo. I haven't used it, but looks promising to self host. https://github.com/goniszewski/grimoire reply skydhash 13 hours agorootparentprevon macOS, I use anybox (I could do with a note app, but itâ€™s neat). For the past year, any interesting link I come across, I add it there. The few I use daily, I add them to the browser as bookmarks. Most of my browsing is autocompleting from the history instead of search engines. reply raxxorraxor 2 hours agoparentprevTry language settings that include different decimal signs. Did you know the diameter of the sun is only 1.4 kilometers? reply Bjartr 14 hours agoparentprevThat might not even be a hallucination, just incorrect data in its dataset: https://www.youtube.com/watch?v=9skSE3FJC1U reply UniverseHacker 16 hours agoprevI'm shocked Google thought this tool was production worthy, since it mostly gives really wrong results, in a confident manner. I don't think you can reasonable expect all users to realize it is low quality nonsense, when it is presented at the top of the results. It's one thing if you know you are using an LLM tool, but when using a search engine, people won't expect this. reply avery17 16 hours agoparentOh so its the same as regular search then. reply yifanl 14 hours agorootparentI would be rather embarrassed to spend $100 billion dollars creating a new feature that's not better than the legacy feature. (Notably, this isn't even a rewrite, this is greenfield work!) reply nerdjon 15 hours agoparentprev> I'm shocked Google thought this tool was production worthy Honestly, I would not be surprised if they didn't think it was. But thanks their \"Code Red\" they seem determined to get as much out the door as possible to avoid someone else doing it first. > I don't think you can reasonable expect all users to realize it is low quality nonsense, when it is presented at the top of the results. And that is the problem, we are training a large number of non technical people that these tools are supposedly reliable. When the problems with them confidently giving very wrong results are well understood. But we just don't talk about it anymore outside of certain circles. If we did keep talking about it, all the AI hype would die off or at least he seriously hampered. reply UniverseHacker 14 hours agorootparentThey're simultaneously both overhyped and underhyped because people aren't really thinking about them the right way, or using them the right way. They want to use it as an oracle where they ask a straightforward question, and get a straightforward correct answer. In reality they're more of a simulator- you describe a scenario with your prompt, and they play it out for you the way it would likely occur in real life. To accurately predict text as they are trained to do, they have to simulate the scenario generating the text, not provide the most correct and simple completion to the text. This is why you can ask it a simple physics question for example, and the default might be to give a wrong answer based on a popular misconception. But tell it that it should answer as Richard Feynman, and it can give the correct answer. It \"knows\" that the first answer was incorrect, but it's still a more appropriate/likely answer given the default scenario, where it effectively assumes it is supposed to act as a random internet stranger when it answers. reply skydhash 13 hours agorootparentYou do simulations in a lab, you go to the library for information. Google search was supposed to be the webâ€™s library, where you go looking for what other users have produced. Now, itâ€™s a simulation lab, where the input is imprecise, the process unknowable, and the result unreliable. Thatâ€™s a childrenâ€™s playground. reply UniverseHacker 13 hours agorootparentYeah, they are an awful replacement for a search engine... but I think their actual intelligence and abilities is much higher than people realize or expect, because of misunderstanding what they are, and hoping them to be something else. reply egypturnash 16 hours agoprevTime to switch your default search engine I guess then, dude? You can do that, even if you're using Google's browser, it's the first thing in the 'search' pane of the prefs of Chrome, Firefox, and Safari. reply knob 16 hours agoparentHell no in Firefox. To change the setting on Firefox it is burried at the bottom of another bottom. I'm a 99% Firefox user. reply computerfriend 15 hours agorootparentClick the URL bar. If on a page that provides a search engine, you can add it immediately. If not, click the cog on the right, then choose a new default search engine. reply vaughnegut 16 hours agorootparentprevKagi has an extension that just switches it for you in Firefox reply daedalus_j 16 hours agorootparentprevReally? Open Settings, there's a \"Search\" tab on the sidebar. Literally the first item is \"default search engine\". At the bottom of that tab is the \"Search shortcuts\", which makes it trivially easy to have multiple search engines installed and use the one you want from your search bar. (I use @g for google, @d for DDG, and @k for Kagi, with an @v for DevDocs.io) reply aspenmayer 16 hours agorootparentprevFirefox settings has a search bar, but donâ€™t worry, it doesnâ€™t use Google as it runs locally. /s reply wackget 14 hours agoprevWhile I agree the AI answer is unnecessary, I'm more angry about how it forces itself into the top of the page, causing the actual search results to be forced further down the page. There's a term for this; it's called \"layout shift\". And guess which giant search engine company actually punishes websites which include layout shift? You're damn right, it's Google: * https://developers.google.com/publisher-tag/guides/minimize-... * https://web.dev/articles/cls These big companies supposedly only hire world-class developers; the cream of the crop. And yet they can't even get the basics right. Stuff that I would have avoided in my first Geocities site when I was a kid. Stupid hypocritical twats. reply AlexandrB 16 hours agoprevI continue to wonder about the economics of stuffing AI into everything. Compute isn't free - how are Google and Microsoft going to recoup the costs of running these models for every search? reply pflenker 15 hours agoparentThatâ€™s a secondary concern. Right now, the race is on, and while it is ongoing itâ€™s acceptable to burn money. Later on, enshittification will kick in and make the end result of the race worse in order to stop burning money. reply freediver 14 hours agoprevDisclaimer: founder of Kagi search It would do Google good to publish an AI integration philosophy to address critical issues related to AI in search. Such a document would allow for public scrutiny, which is crucial when your user base is a few billion strong and you are as influential player in the field. It would also serve as a good platform for other companies to study. Kagi has an AI integration philosophy [1], which, while modest, has successfully navigated us through the current AI cycle and I think helped our users understand what they can expect from us. AI can enhance the search experience, but the core search functionality must be strong and robust first. An LLM grounded in search will only be as good as the search results it gets. Google's \"all-in\" rollout of AI into search without first addressing these foundational principles and improving the core search experience is interesting - does it really mean they are betting the house on AI? The more I see things like this from Google and others, the more I want to go back to basics and just continue improving the core search quality. [1] https://blog.kagi.com/kagi-ai-search#philosophy reply leotravis10 13 hours agoparentKeep in mind that this guy and Kagi themselves can't be trusted as proof by this piece: https://d-shoot.net/kagi.html Related: https://news.ycombinator.com/item?id=40011314 reply freediver 13 hours agorootparentI'll let the public record speak to my ability to execute and run the business. If you have any concrete points that you think I did not already adequately address, I am happy to do it. Just please do not slander publicly (and keep things on-topic if you can). reply whilenot-dev 13 hours agoparentprevIt's fine to have a philosophy, yes, but if GDPR and the right to be forgotten is not taken seriously enough[0] by a founder of a young product I'll have a hard time to see anything beyond just a mere marketing piece without any liability. [0]: see sibling comment reply freediver 13 hours agorootparentKagi takes GDPR seriously. My personal relaxed attitude (also taken out of context) is due to the fact that we do not need or sell customer data, and have nothing to hide. Transaction with Kagi is as simple as it can be - you pay to be our customer, and we try to give you the best web search results. Happy to address any issues related to GDPR that you think are not already addressed by our privacy policy. reply johndough 16 hours agoprevWhile I agree with the general message, I find it ironic that the author laments about Google wasting his time, yet wastes my time with two popups, one of which is extremely obnoxious, while simultaneously downloading 10s of JavaScript files and a needlessly large yet compressed-to-hell GIF. reply windowshopping 16 hours agoprevI just got sick of this yesterday and checked to see if there was a chrome extension removing it. There is, it just doesn't easily come up in searches right now. It works great though. https://chromewebstore.google.com/detail/hide-google-ai-over... reply elashri 16 hours agoparentIf you are using ublock origin (which you should) then add that in the filters > google.com##.GcKpu reply zamadatix 16 hours agorootparentYou can also use the same logic as that extension does instead: google.com##h1:has-text(AI Overview):upward(*) The upside being you don't have to rewrite it every time the sites layout is updated with new random IDs, only when the AI Overview heading itself changes wording or style. reply causal 14 hours agoparentprevIt's wild what hoops people jump through to stay on Chrome reply windowshopping 7 hours agorootparentI would need this same extension in another browser. This comment would make sense if you said \"the hoops people jump through to stay on google,\" but I'm not sure what this has to do with Chrome. reply spondylosaurus 16 hours agoparentprevThank you! reply Animats 16 hours agoprevDuckDuckGo? Useful trick with Google for common searches: add -\"best\" Kills most of the clickbait. Bing, unfortunately, does not have \"-\" exclusion. reply GrantMoyer 15 hours agoparentDuckDuckGo rolled out its own LLM results, \"DuckAssist\". At least they are very upfront about how to disable it, though; they link directly to the relevant setting from each LLM result. reply Animats 15 hours agoprevGoogle getting hammered on Twitter.[1] There's no way to make it stop. [1] https://twitter.com/di_friscoSEO/status/1790824143752954101/... reply tr3ntg 16 hours agoprevIn my very first interaction with their AI search results, the results were actually wrong. Very cool. reply randgoog 15 hours agoprevFor those of you missing the old Search experience, this new Search mode from Google might be particularly interesting to you: https://twitter.com/searchliaison/status/1790473952256786805 reply woopsn 13 hours agoprevA big part of the problem is illustrated by the fact we are now trained to google e.g. even basic information about our own podcast. Big tech gets so much more out of us than we get out of them - their products are entrenched largely by perception. You can use another search engine. Open a spreadsheet from your Documents directory. Run 7-13B models yourself with llama.cpp. Save a bookmark. Wait three seconds. Whatever you need to do you can do. The data brokers, ad men, media corporations etc. now identified as \"the technology industry\" are (explicitly) in the business of wasting precious time, not saving it. reply frizlab 13 hours agoparentI have chosen to use another search engine, which I pay for. There are other alternative that are free and definitely good enough for a common usage. reply pentagrama 8 hours agoprevThe AI hype is so big and tech companies are blinded by this, is incredible that Google ship this to his first and flagship product on by default to many users, and not opt out option (I conclude that by the OP article). I remember see Google launching features off by default with some nagging to turning on, but this is so greedy and dictated by the race on AI, every company want to have AI on their branding like the popular girls on Mean Girls want to be in that group. reply autoexec 15 hours agoprevLeave JS off and google search is still nearly useless and full of unnecessary bloat before you get to real results, but at least it's instant. reply pentagrama 8 hours agoprevWhy so many comments recommending switch browser from Google Chrome to Firefox? This is a Web Google Search feature right? If is only enabled on Chrome now I'm sure will soon be enabled on other browsers. I also encourage to switch to Firefox, but in this case to escape this feature is changing the default search engine on your browser, which I recommend Kagi (paid without ads) or Duck Duck Go (free with ads). reply rznicolet 16 hours agoprevI wonder how this is going to play out. At a company I previously worked for, we ended up not rolling out personalized on-site search because while the results were better in theory, in practice it was so slow nobody wanted to use it. Then again, Google is so dominant that many folks won't quickly bounce to an alternative... reply UtopiaPunk 15 hours agoprevI've been using DuckDuckGo for a while now on my personal machines, but still used Google on my work computer. I started getting the AI blurbs this week and they were so annoying, so I switched to DuckDuckGo on my work computer as well. reply aresant 16 hours agoprevI read this title and instantly related to it from the business owner / SEM / SEO perspective Google controls 90% of search and that's where most consumers start their journey The current state of the union with Google for businesses, especially small business / local business, is a disaster - Bidding on your own keyword, to prevent competitors from showing up as #1 - currently consumes 15 - 25% of total paid budget across a number of businesses we own. It's literally just a 1@%!@% tax. - Google constantly rolls out tests in the name of \"quality\" - recently for local businesses \"hours of operation\" became a search signal. Pragmatic enough right? But instantly the spammers started doing 24/7 hours with fake phone numbers etc registered. The road to hell is paved with good intentions they say, this is a constant theme with Google where they come up with some great idea, and then can't figure out how to defend vs the spammers creating massive headaches, costs, etc. - Google continually takes away visibility and contrl. EG their new AI budget manager takes further visibility away. Right now it drives a little efficiency. But when everybody has it? It will optimize SMB (and everybody else) to the fracture line. And NOW we are going to spend our precious life trying to figure out how the !%!@ to engage with an LLM (that Google doesnt' even understand)? I just want to give up. Honestly it's no wonder that private equity is gobbling up everything from dental practices, to plumbers, to HOUSING It's become such a crazy sophisticated game that nobody else can play and survive reply drewg123 13 hours agoprevI use firefox, and I've never seen this before. Turns out that it's because it seems to be tied to using a chrome based browser. I just tried chrome and chromium, and it happens to me on chromium and chrome when I do a google search in them. (was assuming it was some flag on my account or some a/b test i was in) Its ironic that this new feature may drive people off of chrome.. reply dr_kretyn 15 hours agoprevSame. May i recommend Ecosia? Not only it doesn't want to be smarter than needed, I actually feel good clicking on ads as the revenue goes to ecological causes. reply ashryan 16 hours agoprevThe good news is that we don't have to: there are alternatives. reply browningstreet 16 hours agoparentI recently switched from DDG back to Google, but now I need to switch back to DDG because it's quicker and easier to get to Google Maps via the !gm bang via DDG than it is through any direct typing mechanism made available by Google. reply aiauthoritydev 16 hours agoprevAI-powered search is not a good idea as of today. Someday it would be, but that day is not today. Google knows this well, and hence that is why despite having their internal LLMs for a long time, they did not touch search with it. Google's hand is forced by OpenAI-related news and investor pressure. LLMs, on the other hand, are incredibly useful in their other products where we have to write text. I find myself relying heavily on Gemini to improve my grammar, emails, social media posts, and whatnot. This post too is spellchecked by Gemini. reply kichimi 15 hours agoparentPerhaps not a popular opinion - and slightly besides your point, but english that is too formal and too correct can sound unnatural. reply aiauthoritydev 14 hours agorootparentYes. But you can also use it just for basic typo and grammar correction. reply IncreasePosts 15 hours agoprevThe trick, which is actually the solution to 99% of usability problems on the internet, is to simply disable javascript for the site. reply anonyfox 14 hours agoprevSo what is left to do to get some visibility as an indie hacker? Spamming twitter/reddit like no tomorrow? reply shuntress 14 hours agoprevChrome and the modern browser landscape is a monument to our failure to produce a good operating system. reply cdme 15 hours agoprevA solution in search of a problem that makes the existing solution worse. Kudos, Google. reply ccppurcell 14 hours agoprevI guess we are going to need something like ublock for AI content. reply deadbabe 16 hours agoprevSick and tired of Google products. Why donâ€™t they just pivot to being a hedge fund or something if they have more money than they know what to do with? reply elromulous 16 hours agoprevSo many folks here criticizing Google for this move. Can you really blame them? A year or so ago everyone was eulogizing them because of chatgpt. Damned if they do or don't. reply rsynnott 16 hours agoparentThese... weren't necessarily the same people. reply grraaaaahhh 15 hours agoparentprev>Can you really blame them? Yes. reply CatWChainsaw 11 hours agoprevSo AI-generated answers will kill websites and then we'll be completely dependent on Google and LLM whimsy to find out what real information is. I assume end users will have to deploy their own AI of some sort to wade through the shit. Increase in complexity of one magnitude and increase in inefficiency and bullshit of greater magnitudes, but you can't back out because that lowers your guard and yet another global prisoner's dilemma is born. This is what happens when you blindly worship at the altar of Progress. reply throwaway888abc 16 hours agoprevGoogle now offers â€˜webâ€™ search â€” and an AI opt-out button https://www.theverge.com/2024/5/14/24074314/google-now-offer... reply delecti 15 hours agoparentThe article mentions the \"web\" search, which is the \"opt-out button\" that link is talking about, but it doesn't acutally opt you out, it just turns off AI for that single query. reply j45 13 hours agoprevWhat's amazing is how unpolished the various AI search features are. When google first launched, it was visibly much better at finding results. reply filipwojda 13 hours agoprevthe 3 seconds which the author hates to wait is the only metric Google will see in his point. theyâ€™ll optimize for latency not for quality lmao reply swozey 16 hours agoprevI had this annoying thing running awhile ago and finally shut it off. You can do it in the Labs button - https://labs.google.com/search. Well, I can, not sure if everyone can. reply daft_pink 15 hours agoprevKagiâ€¦ just sayin' reply leotravis10 13 hours agoparentMaybe you shouold read this: https://d-shoot.net/kagi.html Discussion: https://news.ycombinator.com/item?id=40011314 Whip up a SearXNG instance or use one instead. reply doublerabbit 11 hours agorootparentMeh. Every search engine has it drama. But I still find Kagi more refreshing than Google. reply paul7986 15 hours agoprevI personally am liking chatGPT (i know its not that but feels like it) rolled into Google search. Overall im hoping OpenAI and Microsoft create a chatGPT phone to compete with iPhone and Android. Either they go the Android route (create a phone OS for manufacturers) or build a direct iPhone competitor. The UI/UX would be fairly minimal and ur chatGPT phone would be used as your 2nd brain / your AI friend. You wouldn't interact with the web so much .. maybe you still would with apps but not as much as your home screen 50% of the time would provide textually, graphically or audibly what you seek with minimal effort on your part. Your AI friend knows you well.... reply autoexec 15 hours agoparent> ur chatGPT phone would be used as your 2nd brain / your AI friend. That's what we need, a brain/\"friend\" that collects and analyzes every single thing we think/ask about to use against us later and/or sell to third parties. No thank you! The only AI \"friend\" you'll ever have will be run locally entirely on your own hardware and will never send/share/leak any part of your interactions with anyone else for any reason. reply pessimizer 13 hours agorootparentAny AI personal assistant that is working for me should do everything short of illegality to protect any information about me, or what I do, that I haven't explicitly told it I want to be shared, and with whom. You might say that's crazy, but that's just Overton. It's the expectation we have of librarians (and that they have of themselves.) It took PATRIOT to erode that norm (and many others.) Right now, that at the least means running it locally, although that's not going to be sufficient. reply paul7986 10 hours agorootparentprevMaybe time will tell (im betting yes on AI powered phone as noted above and via chatGPT/Microsoft) and there's two camps currently .... like myself i sing the praises of Meta RayBan's smartglasses ... i can take pics/videos way easier then pulling out my phone. Yet if i pull out my phone one isnt going to know 100% if they are being video(ed) or photographed unless it's very obvious (they are following the subject with their phone held up). Meta's Smartglasses makes it less obvious and i guess those in the camp against meta's glasses would argue it erodes privacy. Yet legally in public spaces we have zero privacy! I guess it's a control thing. reply AnimalMuppet 16 hours agoprevWell, there are a lot of things I don't want to spend my one precious life dealing with. Advertising, especially intrusive advertising. Spam. Misinformation, and people who believe it. Politics. Weeds. Google's AI search, so far, is pretty far down on the list, at least for me. reply ziddoap 14 hours agoparentIt's really neat how Google is also involved in almost all of those, too. reply kernal 16 hours agoprevHell Yeah. I've switched to Duck Duck Go AI Search. reply Filligree 16 hours agoprevSo the AI search generally provides correct results, but the guyâ€¦ just doesnâ€™t want to hear anything about AI? I suppose itâ€™s an interesting psychological example. reply pastureofplenty 16 hours agoparentI don't want to hear anything about AI either, especially if it takes an extra 3 seconds to load. reply rkagerer 16 hours agorootparentI just came from Google I/O, it was all AI, which I didn't want to hear anything about either. reply hackernudes 16 hours agoparentprevThe author of the article is annoyed about waiting for the results to appear in a box that takes up almost the whole screen (obscuring the traditional non-AI results). The author also points out that sometimes the AI information is wrong. reply stevedonovan 16 hours agorootparentAh, Edge/Bing went through this phase recently. A split personality, where sensible stuff appeared on the left, and Copilot laboriously typing on the right. I disabled it, really did not add anything to the experience. reply labrador 14 hours agoprev [â€“] No one is forcing this person to use Google. His article drips with AI phobia. There's no nuance to it. For example, I love LLMs but hate AI music and think it should be banned. AI music solves no problems for us like LLMs are helping us do. AI phobics hate all AI. I'm starting to feel personally attacked by people like this because I am enthusiastic about some AI. reply ziddoap 12 hours agoparent [â€“] >His article drips with AI phobia. Where? The article drips with annoyance, not fear, at 3 second searches that no longer have the results that were previously returned in fractions of a second. >There's no nuance to it. Why does there need to be? Author is annoyed. Author explained annoyance. The end. >I'm starting to feel personally attacked by people like this That is a very strong indicator that you should divest yourself from the topic for awhile. The author does not attack you in any way. reply labrador 9 hours agorootparent [â€“] >>I'm starting to feel personally attacked by people like this > That is a very strong indicator that you should divest yourself from the topic for awhile. The author does not attack you in any way. Before some stray AI evangelist leaps into the comments to promise the tech will get better, I want to be clear that even if it were instantaneous, I still wouldnâ€™t want it. I didnâ€™t ask for results from the plagiarism machine! That doesn't sound like annoyance to me. It sounds like hate. Three days ago from my comment history: -4 points by labrador Maybe AI will speed up the development process afavour Maybe AI will replace eyes labrador I'm not going to stop talking about AI just because some hate it afavour And I won't stop mocking AI hype just because some believe it So you see, I'm starting to take it personally reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author criticizes Google's AI search for delivering unwanted information and causing delays in search results, despite efforts to disable it, resulting in stress and annoyance.",
      "Continuous encounters with AI-generated content burden the author and have a negative impact on their daily life.",
      "The author finds Google's AI search feature frustrating and believes it disrupts their routine."
    ],
    "commentSummary": [
      "The discussion delves into Google's search experience strategy and how AI influences user satisfaction and ad revenue.",
      "Concerns are raised about ad prioritization, Google's market dominance, and skepticism towards relying excessively on algorithm-powered search engines like Google and OpenAI.",
      "Criticisms encompass Google's ad-centric approach, perceived lack of innovation, and its adverse effects on user experience, prompting discussions on alternatives such as Firefox, DuckDuckGo, and Ecosia, alongside privacy, data protection, and AI transparency concerns."
    ],
    "points": 197,
    "commentCount": 196,
    "retryCount": 0,
    "time": 1715878960
  },
  {
    "id": 40383263,
    "title": "Deutsche Bahn Unveils MetaWindow Noise Reduction Technology",
    "originLink": "https://www.railtarget.eu/technologies-and-infrastructure/deutsche-bahn-introduces-metawindow-a-gamechanger-in-noise-reduction-for-railways-8449.html",
    "originBody": "1280 x 720 (lg) RAILTARGET Freight Passenger Business Technologies and infrastructure Interviews and Events searchDeutsche Bahn Introduces \"MetaWindow\": A Game-Changer in Noise Reduction for Railways Popular news 16 / 05 / 2024 Deutsche Bahn Introduces MetaWindow: A Game-Changer in Noise Reduction for Raiâ€¦ 14 / 05 / 2024 Derailing Stability: The Escalation of Russian Railway Sabotage in Europe Amidstâ€¦ 08 / 05 / 2024 ÄŒD Cargo Poland has won a prestigious contract in Poland, with interest also shownâ€¦ 07 / 05 / 2024 Archicom and Budimex Forge Record-Breaking Contract for PoÅ‚udnik 17 Estate in Wrâ€¦ 04 / 05 / 2024 Railway Giants: Without Education, but with Vision! Ericson Protects Swedish Linesâ€¦ photo: Dominic Dupont / DB AG / Public domain/Berthold Huber 16 / 05 / 2024 Facebook Twitter Google Plus Deutsche Bahn has unveiled a pioneering advancement in noise control technology with the introduction of the MetaWindow, a transparent noise barrier boasting unparalleled sound-absorbing capabilities. Read more Derailing Stability: The Escalation of Russian Railway Sabotage in Europe Amidst War In recent developments, European intelligence agencies have issued warnings about a calculated increase in Russian sabotage activities, particularlyâ€¦ 14 / 05 / 2024 Technologies and infrastructure Developed in collaboration with Italian start-up Phononic Vibes, the MetaWindow was recently showcased at the Greentech Festival in Berlin. This new system integrates meta technology, which utilizes a unique geometric design to enhance acoustic efficiency far beyond traditional noise barriers. The first real-world application of this innovative technology is set to commence on the S4 railway construction in Hamburg later this year. Source: DB AG / Public domain Berthold Huber, a DB Board Member for Infrastructure, emphasized the dual benefits of the MetaWindow. \"To achieve our climate protection targets, we need to get more traffic on the rails and expand and extend the network,\" emphasized Huber. \"But we can only gain the necessary acceptance from residents if rail transport becomes quieter. This is precisely where the innovative MetaWindow comes in. With the transparent noise barrier, local authorities no longer have to choose between appearance and functionality.\" Read more Budimex Launches New Tram Line in Warsaw Warsaw officials announced the opening of a new tramway route, significantly improving public transport connectivity for residents of Lower Mokotow.â€¦ 15 / 05 / 2024 Technologies and infrastructure The barrier achieves noise insulation levels ranging from 34 to 37 decibels while maintaining up to 72 percent transparency, a stark improvement over existing solutions that often sacrifice effectiveness for visual openness. The MetaWindow is specifically designed for sensitive areas where strict noise reduction regulations apply, such as urban settings, tourist spots, residential zones, and protected landscapes. Its design minimizes visual disruptions, aligning better with the environment and reducing public grievances often associated with the construction of conventional noise barriers. Source: DB AG / Public domain Although the MetaWindow comes at a higher material cost, the overall financial implications are mitigated by the potential for faster planning approvals and reduced objection rates from communities, ultimately speeding up project completions. Read more â€œHigh-Speed Lines Are Not Just Transit Lines to the Main Airport, but Will Connect theâ€¦ We exclusively present an interview with Zbigniew SzafraÅ„ski, the newly appointed chairman of the supervisory board of CPK SA, the investment company ofâ€¦ 16 / 05 / 2024 Interviews and Events author: Mariia Akhromieieva Facebook Twitter Google Plus Tags Deutsche Bahn, DB, noise reduction, MetaWindow, noise barrier, soundproof, What next? Revolutionizing Railway Safety: Ã–BB and Stadler Introduce Hybridâ€¦ Derailing Stability: The Escalation of Russian Railway Sabotageâ€¦ Feasibility Study Underway for High-Speed Rail Link Connectingâ€¦ Europe's Rail Freight Enters the Digital Era: A Deep Dive intoâ€¦ A Leap into the Future: Japan's L0 Series Maglev Shattering Speedâ€¦ The Legacy of TurboTrain: A Glimpse into the 1960s Era of High-Speedâ€¦ Manage consent|GDPR|Contact Copyright Â© 2020-2024 RailTarget.eu LinkedIn RSS",
    "commentLink": "https://news.ycombinator.com/item?id=40383263",
    "commentBody": "Deutsche Bahn introduces \"MetaWindow\" (railtarget.eu)192 points by metters 12 hours agohidepastfavorite252 comments earthnail 2 hours agoI love this. I read so much criticism here, but noise pollution is a main issue when it comes to railroads in residential zones. Yes, punctuality is an issue with Deutsche Bahn. No, this doesnâ€™t fix that instantly. But as an organisation you can work on two things at the same time. This invention is spectacular. I wish more people would work on noise pollution. It makes a huge difference. reply nonrandomstring 4 minutes agoparent> I wish more people would work on noise pollution Absolutely agree. It's one of the most insidious kinds of pollution that has big effects on mental and cardio-vascular health, and is accumulative. Everything from aircraft, to emergency vehicle sirens, to construction and poor housing, is slowly killing people. In Europe we've actually made big leaps forward with regulation, building standards for isolation, and abatement laws. But these often go unenforced or even flippantly dismissed and mocked because people don't recognise the harm pathways and effects. Whenever this topic comes up I am reminded of this (very funny) curmudgeon's screed \"On Noise\". Although Arthur Schopenhauer was \"serious\" about this, his acerbic style only gets more funny with time [0]. [0] https://www.gutenberg.org/files/10732/10732-h/10732-h.htm reply lqet 11 hours agoprev> a transparent noise barrier Most rail noise barriers in Germany are completely covered in graffiti [0], so I wouldn't expect them to remain transparent for more than a few weeks. [0] https://ga.de/imgs/93/8/5/9/3/0/9/1/9/tok_8596521c60eeaa53ee... reply Propelloni 45 minutes agoparentSad, but true. Some people even spray paint the windows of the actual passenger cars [1]. It's not rare and most sprayers do not have the skill of the person who painted this car. I don't get it. [1] https://www.flickr.com/photos/kami68k/50329760658 reply tuukkah 16 minutes agoparentprevDB is also deploying robot dogs against graffiti painters: https://news.ycombinator.com/item?id=40388114 reply umpalumpaaa 11 hours agoparentprevIf you dive into the graffiti scene a bit you will start to appreciate all those graffitis. The story behind some of them is super interesting. There is a lot of \"competition\", \"collaboration\", and group dynamics involved. It is truly fascinating. I was living in Cologne (Ehrenfeld) for a while in a place with awesome graffiti and every weekend there were people taking pictures \"collecting\" and documenting the graffiti. Edit: Not \"all of those\" but \"many of those\" reply constantcrying 5 hours agorootparentThere is exactly nothing about defacing public infrastructure which elicits the tiniest spark of \"admiration\" or \"interest\" in me. If you want to live out your \"artistic ambitions\" do it somewhere away from public property. reply bondarchuk 6 minutes agorootparentMeanwhile in non-defaced public property: https://upload.wikimedia.org/wikipedia/commons/c/c0/1_times_... The thing about a big city is it's not just about the people who own the stuff you look at, it's about all the other people who have to look at it. I'll take graffiti over advertising any day. At least graffiti isn't trying to sell me anything or make me depressed or addicted or whatever. reply oaiey 4 hours agorootparentprevUnfortunately, life is not black and white. Even without knowing anything about graffiti culture, there is a border between defacing and improving. And graffiti artists are moving over that border back and forth. Some of the most beautiful art I have seen are graffiti reply charamis 2 hours agorootparentLife would be meaningless if it was just black and white. Fortunately there are times that we're reminded that people do live in cities and do stuff other than just minding their own. reply 72deluxe 1 hour agorootparentprevWhat a strange argument that seems to romanticise this \"border\" called \"the law\". It is black and white: someone is defacing something that doesn't belong to them. You can call the result whatever you want (\"art\",\"expression\" etc) but the fundamental issue doesn't change. Would you be happy to wake up and see your car covered in paint? What about the windows on your house? Would you see this as an \"improvement\" too? reply nicolas_t 1 hour agorootparentI think Iâ€™d be relatively happy if I woke up one day and saw a banksy or an invader mosaic on my wall. Iâ€™ve seen graffiti art that definitely improved grey ugly walls and barriers. Iâ€™ve also seen ugly tags that are nothing more than letters. Itâ€™s relative reply LoganDark 1 hour agorootparentHonestly, I would too. Illegal or not, whether it's \"defacing\" is definitely subjective. reply highcountess 49 minutes agorootparentprevIs not relative at all to rational people. Let me just put it this way, do I get to just move into your home and take it over simply because I believe that I can make it a better home than you can? Do I get to steal your car/property because I believe I can make better use of it? Stop rationalizing narcissistic behavior and people trying to impose themselves on others. Itâ€™s not relative at all. You or the narcissistic graffiti vandals have no right to impose themselves on others. reply wiseowise 1 hour agorootparentprevMost of the time this is a black and white matter. reply constantcrying 4 hours agorootparentprevI have never seen a good looking graffiti which was defacing public property. Granted, I have seen competent images which obviously were commissioned by building owners. All of it was bad art though and immensely displeasing. reply yardstick 2 hours agorootparentHave you seen any Banksy? Do you consider his work graffiti? Most of his work is graffitiâ€™d onto public property without permission. https://www.artsy.net/artist/banksy reply constantcrying 2 hours agorootparentI grant Banksy that he has some technical competency and is able to do something somewhat visually interesting (his use of color works quite well and makes his pieces stand out within the medium), but I really hate him as an artist. There is basically no one who makes greater kitsch than him. Everything he makes is steeped in the middle class, liberal, mediocrity of someone who points out that things, which everyone agrees are bad, actually are bad. It seriously is something of the worst \"art\" I have ever seen and actually makes me quite sympathetic to the post modernists whose movement is a reaction to people like him. The middle schooler, scribbling on canvas, is at least not trying desperately to impress the most bourgeois group of people the world has ever seen. That alone puts everything he does a serious step above Banksy. reply kmmlng 2 hours agorootparentprevOf course you can find stuff that's high quality, but that is rare. Rather than looking at outliers, it might be more sensible to look at the average and the reality is that the average graffiti does not have any artistic value. reply wiseowise 1 hour agorootparentprev> Have you seen any Banksy? Do you consider his work graffiti? Yes and yes. Overhyped \"I'm 14 and this is deep\" energy. reply highcountess 41 minutes agorootparentprevOf course itâ€™s graffiti and itâ€™s still imposing on others against their will, regardless of whether itâ€™s peak narcissist Banksy or someone else. Is very much about transgression and imposition and sadistic domination for personalities like Banksy and graffiti artists in general; itâ€™s precisely why they put their â€œartâ€ in other peopleâ€™s things against their will. So if I graffiti your car because I believe it improves your car; would that be ok with you? Itâ€™s art. You should be happy, right? reply charamis 17 minutes agorootparentIn what kind of city do graffiti happen on cars and households? mostly it's on public property reply TapamN 2 hours agorootparentprevThere are a few here that are actually pretty good: https://forums.somethingawful.com/showthread.php?threadid=40... reply carstenhag 2 hours agorootparentAhh yeah, the typical reason people hate forums nowadays. Registration-wall/paywall. Amazing reply kalleboo 1 hour agorootparent\"Nowadays\", Something Awful has required paid registration since like 2001 reply mtlmtlmtlmtl 1 hour agorootparentprevUsername checks out... reply kichimi 3 hours agorootparentprevDefacing is your opinion, I think a city without graffiti is a dead city, it's an improvement. reply wiseowise 1 hour agorootparentGood for you. Keep it to your backyard. reply petre 4 hours agorootparentprevnext [6 more] [flagged] constantcrying 3 hours agorootparent>Are you an art major to be able to judge objectively? There is precisely nothing about \"being an art major\" that gives you any more or less right to an opinion. Especially if you actually had read anything about current philosophy of art you would realize how dumb that sounds in this context. Since \"postmodern\" theories of art focus on the inner expression of the artist, contrasted with the subjective experience of the art by the viewer. I am the one who has to suffer through this every day in the train. How am I not entitled to an opinion about that \"art\"? reply yesco 3 hours agorootparentprevAre you suggesting most people enjoy graffiti? Because I don't know anyone irl who does so I'm a bit surprised by this perspective. I've personally always viewed it as equivalent to littering and assumed the ones doing it were just thrill seekers up until now... reply flohofwoe 3 hours agorootparentI do. When I first moved to Berlin I was thinking the same, but now I prefer it when modern concrete buildings are touched up with graffity no matter if commissioned or \"illegal\" - the important part is to give the eyes something to stumble over. Historical buildings is a different matter of course. reply jorvi 3 hours agorootparentprevThere are two types of graffiti: actual art, and tags which are akin to the forum signatures of yore. The actual art is often a bit strange but can be beautiful, and is more interesting than a bare concrete wall or train hull. But I agree with you that virtually all tags are ugly. And not only that, tags represent an extreme concept of ego, where you subsume the art, spending your entire canvas on your signature. reply nicolas_t 1 hour agorootparentWhat I despise the most are taggers who tag on top of a beautiful graffiti with lazily styled letters. reply highcountess 53 minutes agorootparentprevnext [2 more] [flagged] latentcall 40 minutes agorootparentYour reply is way out of whack compared to that persons comment. You seem to have taken it quite personally which I find strange but interesting. Also please refrain from name calling, it isnâ€™t in the spirit of this site. reply muditsahni 3 hours agorootparentprevItâ€™s always a struggle for me to accept that many people actually like graffiti. Maybe graffiti can add flavour to a city if itâ€™s really drab and ugly (although Iâ€™m not too sure about this), but it only defiles cities which are aesthetically pleasing and beautiful. The technicality of graffiti has little to do with its appeal or itâ€™s appropriateness. Something can be hard to make but still be garbage and/or misplaced w.r.t itâ€™s surroundings. reply danieldk 2 hours agorootparentMost so-called â€˜pleasingâ€™ cities are full of advertisement pollution. If I have to choose one of them, Iâ€™d choose art over advertising. I wish people would be as much against advertising as they are against graffiti. reply helboi4 56 minutes agorootparentFr. Its so wierd for me when people get super mad about graffiti like they own any of these walls and could choose what was on them. If the graffiti wasn't there it would just be an ad, but I guess we're okay with that because consumerism is good because the our overlords tell us to like it. reply kalaksi 31 minutes agorootparentMost graffitis I've seen are on empty walls or buildings with no ads. Brick wall looks way better without them. And to me it looks more like it's the graffiti maker that thinks that they own the wall and can choose what should be on it. reply helboi4 25 minutes agorootparentProperty that is used by the public should be owned by the public. By that logic, graffiti artists as regular people who use public infrastructure in the area should as much right to paint on the wall as you do to paint the wall in your house. And you can paint over it if you hate it so much. But its all down to the community. It should not be a crime enforced by a ruling class who nominally owns the wall but doesn't use it, so is totally not actually inconvenienced by it being painted. You are part of the community. So is the artist. The person who owns the wall is mostly likely not. Stop pretending you're on the same side because you think you may also become a millionare by osmosis. reply atoav 2 hours agorootparentprevAs someone with an art degree (with no great admiration for street art per sÃ©) I have to ask one question: Could you imagine that one person's \"defaced\" is another person's \"finally some colors\"? The destruction of property, trespassing etc. is obviously on the wrong side of the law, but on purely aesthetical terms this could be argued either way making it for that narrow category a subjective thing. Proponents of graffiti could argue you cannot deface a faceless thing, opponents would argue they like their lawn short, their fence white, the sky blue. One persons order is another persons prison. Note that I tried to look at the aesthetic question while ignoring the legal question â€” mainly because you made an aesthetic argument. For many people the two would be entangled however: Something being illegal makes them look at the result unfavourable, even if a similar legal wall mural would strike them as aesthetically superior to the 10 years weathered white wall that it was before. As an art person I really see truly good graffiti, yet I have to notice that heavily graffitied parts of my city are tourist magnets â€” so many people tend to like those \"defaced\" walls. reply soco 2 hours agorootparentLet's be honest, 99.999% of graffiti is smeared black lines barely recognizable as tags, over more smeared tags and curse words and just dirt. If that is aesthetic, we might have a very different definition of aesthetic than the art schools you mention. Do I see sometimes street art? Yes, but almost never on such places - the real street art is one done on commission (I assume) on some private house walls, while the rest is at best ignored. There's a reason you never see trains stations on Instagram. reply wiseowise 1 hour agorootparentprevThat's easy: Was the graffiti made with approval of the owner of the building? Does it fit general aesthetics of the city? Yes and yes - it's finally some colors. Otherwise it's a vandalism. If it's a public building - it's vandalism, unless it was decided by all people living there. > As an art person I really see truly good graffiti, yet I have to notice that heavily graffitied parts of my city are tourist magnets â€” so many people tend to like those \"defaced\" walls. Yeah, way to make life hell for residents of the neighborhood. reply kalaksi 20 minutes agorootparentMany cities here also have walls dedicated for graffiti and such to give street artists some space and bring some color. Some small infra-related buildings also have street art done on commission and they look great! But shitty tags and graffitis still exist and my impression has always been that the maker probably wasn't thinking about art or anything deeper for that matter... reply JW_00000 1 hour agorootparentprevThis is pretty ironic to read on a forum called \"Hacker\" News, which also originated as a counter-culture that considered itself creative but was regarded as criminal by the general public. reply helboi4 42 minutes agorootparentFr. God you have to be so boring and pro-authoritarian to really be offended by buildings you don't own and will never have the power to own, being drawn on by the public. Sometimes I think graffiti is nice looking. Sometimes I think its ugly as shit. I would never begrudge someone doing it though, since I appreciate the spirit of reclaiming public spaces by the people who actually live there, who will often never be able to own spaces of their own. I am not offended for the ruling classes when their property, that they do not use, gets some paint on it. That's some crazy bootlicking behaviour. reply waihtis 1 hour agorootparentprevlol, the hacker in hacker news is not in reference to the blackhat, but a tinkerer reply mejutoco 34 minutes agorootparentprevI found an example of graffiti that both sides of this conversation can agree on. As always, reality has some nuance, and we need to be careful about assumptions. https://en.m.wikipedia.org/wiki/Reverse_graffiti reply brnt 4 hours agorootparentprevCan't tell if you speak about architecture of graffiti artists... reply flakyfilibuster 1 hour agorootparentprevcall it whataboutism (not directed towards your comment, but related): every time i'm in a discussion involving graffiti and people complain about it i ask about advertisements plastered though the city - people just shrug reply flohofwoe 3 hours agorootparentprevBah, sorry, but most modern concrete buildings do indeed look better with graffity, no matter whether you see it as art or not. Every bit of color helps on those grey/dirty glass and concrete monstrosities. (the OPs photo is actually a perfect example of that, without graffity it would just be a depressing grey wall, I much prefer the colorful \"defaced\" version) reply krona 3 hours agorootparentEverything has been vandalized but we shouldn't blame the vandals. [They were] built by vandals and those who added the graffiti merely finished the job. - Scruton. reply flemhans 11 hours agorootparentprevI can also start a subculture about competing for the best type of bank robberies, doesn't make bank robberies a nice thing to do. But yeah fascinating reply vasco 11 hours agorootparentWhen graffiti is done on public owned objects or walls, it's impact is merely aesthetic. Not like a bank robbery. And I'd rather see graffiti, even if I find some ugly, than ads all over. And there's way more public ads anywhere than graffiti. I think local urban expressions like stickers and graffiti is pretty cool. The mainstream prefers ads I guess. reply ldjb 10 hours agorootparentThe impact isn't merely aesthetic. For one thing, it can be costly to remove graffiti. And when it's on publicly owned property, who pays for that removal? The public, of course. If, for example, a train is the target of graffiti, it will often need to be taken out of service. This, then, results in a degraded service to the travelling public. Furthermore, graffiti artists often put themselves in dangerous situations. Numerous people have been seriously injured or killed when doing graffiti. That not only sucks for them, but also has various knock-on effects. Some graffiti art can look really nice, whereas others have little artistic value. Regardless, the negative impacts of graffiti should not be overlooked. reply thuuuomas 10 hours agorootparent> The impact isn't merely aesthetic. For one thing, it can be costly to remove graffiti. The cost incurred here is a choice the owner makes when they disagree with the aesthetics of the graffiti. reply ldjb 10 hours agorootparentWe're talking about public property here. Many authorities have a 'no tolerance' approach to graffiti. Even if it looks nice, it will be removed. There is a belief that removing graffiti quickly discourages it. If graffiti artists find that their work won't last long, they may be discouraged from doing it in the first place. Aesthetics doesn't really come into it. reply lloeki 4 hours agorootparent> There is a belief that removing graffiti quickly discourages it. If graffiti artists find that their work won't last long, they may be discouraged from doing it in the first place. Ephemerality is known, understood, accepted, and even leveraged in art. I don't think this is an efficient deterrent, or even a deterrent at all. reply whilenot-dev 3 hours agorootparentprev> There is a belief that removing graffiti quickly discourages it. It's the other way around, if it isn't quickly removed it will be encouraged: https://en.wikipedia.org/wiki/Broken_windows_theory reply Thorrez 3 hours agorootparentThat's not really the other way around. That's 2 ways of stating basically the same thing. reply TillE 9 hours agorootparentprevI dunno about the entirety of Germany, but I don't think I've ever seen graffiti removed in Berlin, and there's a ton of it. It's fine, nobody cares. reply Symbiote 8 hours agorootparentGraffiti on trains in Berlin is very quickly removed. reply portaouflop 2 hours agorootparentHaha thanks for the light chuckle as I wake up reply wiseowise 59 minutes agorootparentprevIs it fine or public just fed up constantly removing it? reply sircastor 9 hours agorootparentprevBut that cost is not paid by the person creating the graffiti. The owner has a cost forced on them. The aesthetic argument here is trying to validate a violent act. A lot of graffiti is beautiful, but that doesnâ€™t mean itâ€™s okay. reply complaintdept 9 hours agorootparentWhat violent act? reply tsimionescu 8 hours agorootparentModifying someone else's property, or public property, without consent. reply TallTales 5 hours agorootparentThis is a fascinating comment. How would you define violence? reply usrusr 3 hours agorootparentIf I smash your car, is that violence or not? What if I take care to smash your car only so much that it will still be able carry you to work and back? reply helboi4 53 minutes agorootparentprevThey definitely have a very hyper-capitalist definition of violence. It's sort of pathetic how much people somehow care about the property of the ruling classes that they will never own. reply fragmede 5 hours agorootparentprevnot op but violence is traditionally defined as physical force to cause harm. but now there's financial violence and social media violence and here the message in the graffiti causes harm. eg die techy scum. it's not physically violent, but some think it's helpful to frame it as a non-physical violent act because of the expression of dislike for a particular community. it doesn't cause any grave harm, but everyone who walks by and sees it is affected by it. reply wiseowise 1 hour agorootparentprevNice. I'm going to spray a can of paint on your car and explain to judge that \"it's thuuuomas's problem now, since he disagrees with aesthetics of his new car color\". reply tpm 2 hours agorootparentprevNo, the owner or rather operator (if the carriage is publicly owned) might be legally obliged to remove it just for the carriage identification to be clearly visible, the windows to be clean etc. reply matrix_overload 5 hours agorootparentprevWhy does this comment read like it's written by AI? reply ben_w 2 hours agorootparentPossibly because AI was trained on humans. The \"furthermore\" and the \"Regardless, the negative impacts of graffiti should not be overlooked\" do feel a bit AI-esq these days, but it was only yesterday that I myself felt like I was writing like an LLM by responding to a \"you misunderstood, I meant â€¦\" with an \"ah, now I understand\": https://news.ycombinator.com/item?id=40380692 reply saagarjha 3 hours agorootparentprevBecause the only other group of people who use transitions so often are third graders making sentences from templates. reply walterbell 5 hours agorootparentprevObservations affect the observer? reply vasco 10 hours agorootparentprevnext [5 more] [flagged] ldjb 10 hours agorootparentIn a democratic society, if citizens are particularly concerned about the aesthetics of public property, they can make their views known to the relevant authorities and elected representatives, and it could even become an election issue. I think that's far better than citizens fighting with paint. reply rjh29 9 hours agorootparentprevBroken window theory. Once a few things have graffiti, it will quickly proliferate including stuff that isn't exactly aesthetic. reply vasco 9 hours agorootparentAny cursory googling will yield several papers debunking the broken window theory for you. reply rjh29 8 hours agorootparentSorry, I used the term incorrectly. I'm not suggesting that graffiti increases crime, only that the presence of graffiti encourages more graffiti. I live in Japan which is usually free of litter, put a few empty beer cans on the floor and come back 24 hours after and you will have a trash pile. I don't need a paper to tell me that. reply nextaccountic 7 hours agorootparentprevWhy remove it? reply stormking 1 hour agorootparentBecause 99.99% of it is shit and the rest is barely above shit. reply germinator 11 hours agorootparentprevThey're very cool until it's your apartment or commercial building, and you have to clean it up - because let's face it, for every clever graffiti, there are fifty that are just tags, swear words, or worse. And your framing is odd - can you only dislike one of these things? Graffiti or ads? There are successful movements to rid cities and scenic areas of ads, or to tone them down. reply aeyes 9 hours agorootparentI solved this problem by contracting an artist to put a painting on the wall of my house. Sprayers are artists, they won't paint over it. reply GrayShade 5 hours agorootparentI've seen a lot of tags put on top of pretty nice-looking murals, many sprayers won't care. reply petre 3 hours agorootparentTags always looks better on an empty wall. reply taskforcegemini 3 hours agorootparentbut not better than the empty wall reply Doctor_Fegg 4 hours agorootparentprevIf only. The murals under canal bridges in Worcester (UK) have been defaced beyond recognition with tags. reply wiseowise 57 minutes agorootparentprevFifty? More like fifty thousands. reply wahnfrieden 10 hours agorootparentprevin toronto it's embraced to the extent that in areas where it's common, there's funding by businesses and even residences or local gov commission it or permit it and nice work by local artists is less likely to get tagged or covered. there's at least some upside to cooperating when there's a culture to it (to some extent) reply 2024throwaway 10 hours agorootparentprevnext [15 more] [flagged] ponector 10 hours agorootparentGraffiti makes world more beautiful the same way as ads do. It is a vandalism and you shouldn't normalize it. reply 2024throwaway 10 hours agorootparenthttps://w0.peakpx.com/wallpaper/697/794/HD-wallpaper-graffit... You don't get to tell me what I find beautiful. reply JumpCrisscross 9 hours agorootparent> You don't get to tell me what I find beautiful Right. Thatâ€™s the point. In public spaces, the public has chosen what it believes to be beautiful. Illegal graffiti is one person forcing their aesthetics on everyone. Plenty of cities have surfaces that are open to being grafittiâ€™d. In those cases, the artists bothered to think about others before taking unilateral action. reply vasco 9 hours agorootparentHave you chosen what you think is beautiful for your city? Most city decorations are decided by direct action from the council without consultation from the public. Sometimes involving as little as one or two people. For private property I agree with you, the owners have it how they want to have it. reply JumpCrisscross 9 hours agorootparent> Have you chosen what you think is beautiful? Most city decorations are decided by direct action from the council without consultation from the public. When itâ€™s mattered, Iâ€™ve showed up. Or signed petitions saying something is ugly and would benefit from being replaced by just about anything else. Plenty of communities embrace their mural and graffiti culture. Plenty donâ€™t. Imagine if someone who doesnâ€™t like murals went around whitewashing painted walls. reply 2024throwaway 9 hours agorootparentprevMy city pays graffiti artists to do their thing, but go off. reply wiseowise 52 minutes agorootparentprevWhile I find this specific beautiful, retouched and over-saturated picture beautiful. I'm pretty sure it would look much better without the graffiti, trash and huge puddle in front of it. reply raverbashing 9 hours agorootparentprevnext [3 more] [flagged] 2024throwaway 9 hours agorootparentnext [3 more] [flagged] raverbashing 9 hours agorootparentYes because they don't have to be empattic right? And society has to accept any bs they come up with reply 2024throwaway 9 hours agorootparentYou know what? Youâ€™re right. I guess people should be permanently maimed or disfigured for creating art in a location you disprove of. Keep it up. reply BriggyDwiggs42 10 hours agorootparentprevGraffiti is about 20 to 30 times better than ads brother. reply vasco 10 hours agorootparentprevI've normalized it all my life and will keep doing it, art should be around us and bring interestingness to public spaces. People like you would rather walk around in the equivalent of a hospital 24/7 and you currently have the law on your side but it doesn't mean you're right. reply Symbiote 8 hours agorootparentThe door of my apartment building is graffitied every couple of months, and without any respect whatsoever your community's \"art\" can piss off. reply 2024throwaway 8 hours agorootparentIâ€™m so sorry to hear that. I canâ€™t even begin to imagine how hard what youâ€™re going through right now must be. Thoughts and prayers in this difficult time. reply vasco 7 hours agorootparentprevI hope this made you feel better. Good luck finding a new place to live or growing out of being upset from paint or it seems like you're going to be mad every couple of months until the rest of your days. reply diego_sandoval 10 hours agorootparentprevI don't think the reason that ads are allowed is because people prefer them. The reason is that whoever puts an ad does so on their own property. You don't put an ad on someone else's wall against their will. Graffiti, on the other hand, is usually done without authorization from the owner of the wall or facade being graffitied. reply saagarjha 3 hours agorootparentPeople do this all the timeâ€¦ reply Nathanba 6 hours agorootparentprevPrivate individuals should not get to decide what public building aesthetic I need to accept reply vasco 3 hours agorootparentWho are these public individuals that can decide? All choices are done by some person. reply constantcrying 5 hours agorootparentprevYes of course they should. Youth gangs on the other hand shouldn't. reply Thorrez 3 hours agorootparentprevMost of the graffiti I see is on bridges over the freeway. This is distracting while driving, especially because freeway signs are also hung in that same place, so I look up there for relevant information and instead am distracted by various phrases that I don't understand. Often there's even graffiti on the freeway signs, sometimes covering up the text, making it unreadable. Yes, billboards have some similar problems, but that's somewhat mitigated because those are on the side of the road, not directly above it. But you're right, certainly not as bad as a bank robbery. reply wiseowise 1 hour agorootparentprev> And I'd rather see graffiti, even if I find some ugly, than ads all over. How about neither? reply edejong 3 hours agorootparentprevOne bad does not legitimize another. reply gradschoolfail 7 hours agorootparentprevThis debate over graffiti aesthetics seems like itâ€™s semantically adjacent to the rift between political left and right. And so: Have you seen Japanese graffiti? Compared to Japanese ads? Average tokyo ads/grafs are at least more aesthetic than the median in Western cities. With graffiti strangely better than ads by most measures. No , itâ€™s not eye of the beholder, more like the soul of the despoiler. EDIT, for the mods, artificial or not: Japanese spoliation aesthetics are a safe-ish counterexample for rightwingers as they localize the field of contention to the high local effort-high social payoff quadrant, where existing metrics are not questioned. You really want to constrain debate to the low local effort-high global payoff quadrant, which triggers all stripes, but are most relevant for humanity. Consider a GPT7 that requires only 10 dollars to train. Its worthwhile to think about but scares the bejeezus out of most folks. Analogously, left wingers want to move the debate to low local effort-low global cost quadrant, because it seems straightforward to redefine cost metricsâ€¦ moat and bailey dynamics really, quite curious. reply lifeofguenter 5 hours agorootparentprevComparing Graffiti with Bank robbery is crazy. Its Art. I would like to understand why people take offense in it - especially if done on places that are so non-important. reply constantcrying 4 hours agorootparentBecause at best it is ugly. On average you are defacing someone's property and worst case you are causing serious economic damage to someone. It's a reason it is a crime, although sadly it doesn't seem to be really enforced or punished, given the prevalence. reply damsalor 2 hours agorootparentItâ€™s a coping mechanism for youth culture. Your distain has already lost reply wiseowise 49 minutes agorootparentprev99% of it is not art, sorry, just litter on the walls made by delinquents. reply stormking 1 hour agorootparentprevNo, it's not. reply tpm 2 hours agorootparentprevSome of it can be art, but 99.9% is not, it's territory marking. reply ozim 2 hours agorootparentprevIf you want a realistic example look at football ultra fans. There is whole subculture, competition and collaboration networks between fan groups. Some call it bestial street fighting where people lose lives and health but some might find it fascinatingâ€¦ reply HPsquared 1 hour agorootparentOr, on a larger scale, military history. reply Hugsun 11 hours agorootparentprevImplying that graffiti is as bad as bank robberies is wild. reply jhhh 8 hours agorootparentThe point of the post was that merely having a subculture attached to something doesn't make it good or bad. The addition of the bank robbing was to make that point obvious by attaching a subculture to something obviously bad. If you thought they were saying that graffiti is bad because it's like bank robbery (which is bad) then you misunderstood the point of the post. reply loloquwowndueo 10 hours agorootparentprevDunno dude. If my bank is robbed thereâ€™s no real impact to me - all the money is insured. If someone graffitis my house then it looks horrible and I have to spend time and money cleaning it up. reply tshaddox 10 hours agorootparentMost houses in Germany are not covered in graffiti. reply buster 5 hours agorootparentExcept in Berlin. My house front is covered completely with ugly tags. Not even nice graffiti. My 2 year old can draw better. reply Tenoke 2 hours agorootparentSame here, especially since they put scaffolding for construction work on our building. reply vasco 3 hours agorootparentprev> My 2 year old can draw better. Seems like you got the idea. Give her some stencils and have some fun. reply wiseowise 46 minutes agorootparentSo your solution to vandalism is to give in to vandals and vandalize your building yourself? reply buster 1 hour agorootparentprevI actually wouldn't mind if the house would be covered in nice grafiti! Get some cool artist and have him spray the front, i don't mind. The bullshit tagging is just the worst and stupidest thing to do. It's the difference between vandalism and art. reply 2024throwaway 9 hours agorootparentprevHow many times has that happened to you? reply loloquwowndueo 9 hours agorootparentI donâ€™t know, itâ€™s not like the bank publishes heist metrics :) reply 2024throwaway 9 hours agorootparentTouchÃ©. reply cm2187 2 hours agorootparentprevI am not sure I agree. You are making the life a little worse to hundred of thousands of people by making them feel like they live in a trash city every day. I am for tough penalties on the authors of grafitis. At least make them pay the full cost of cleaning them up plus heavy fines. reply tshaddox 10 hours agorootparentprevBut in a bank robbery youâ€™re taking someone elseâ€™s property no no no do not have a moral philosophy argument on HN in conclusion, thatâ€™s why a Georgist land value tax is one of the most economically efficient forms of taxation. reply lqet 11 hours agorootparentprevThat's fair, but even interesting graffiti still won't let any sunshine come through. Also, I would rather look out the window [0] than appreciate artwork when riding on a train. [0] https://www.swr.de/swraktuell/rheinland-pfalz/trier/17134459... reply 2024throwaway 10 hours agorootparentWhen I ride my local rail, I look forward to getting to pass another train to see all the amazing artwork. It's far nicer and more interesting than yet another development or parking lot. reply imp0cat 5 hours agorootparentOh lucky you. Most of the defaced trains I see are not amazing. They are hastily done and would hardly qualify as artwork. :( reply fcsp 10 hours agorootparentprevConsidering the look of the train to the vast majority of people outside of it, I'm fine with not seeing anything - I'm staring at my book anyway for the most part, and there's another window on the other side. And I prefer it a lot over those ads that anyway otherwise contaminate the window with some random, probably sexist, racist, or otherwise shite nonsense. reply yodsanklai 8 hours agorootparentprevMy city is filled with horrible graffitis. Some types of ugly signatures, even on historical buildings. It takes only a few weeks after walls are cleaned up to see new graffitis reappearing. It's really sad. reply damsalor 2 hours agorootparentThe money would probably be better spent in community outreach than cleaning services reply wiseowise 45 minutes agorootparentSome people just want to see the world burn, no amount community outreach will fix that. reply HPsquared 1 hour agorootparentprevhttps://en.m.wikipedia.org/wiki/Broken_windows_theory reply yongjik 4 hours agorootparentprevI'm from a country where they once called up the fucking Interpol when someone vandalized a subway car and ran away. There are many things I complain about my country, but this isn't one of them. You wouldn't admire it if you were in a coffee shop and someone decided to unload their artistic ejaculation on your MacBook. Public infrastructure belongs to the public, no single person is the owner, and you don't get to deface it just because you think it's pretty that way. Cleanly maintained public infrastructure sends a message: that this is a place where people take these things seriously. reply doctor_eval 4 hours agorootparentAre graffiti artists not part of the public? What makes a billboard, for example, more legitimate than graffiti? reply wiseowise 42 minutes agorootparentWhat does have billboard to do with ugly graffiti? They're not defacing billboards, are they? reply yongjik 4 hours agorootparentprev> Are graffiti artists not part of the public? In the same sense bike thieves are. reply fragmede 4 hours agorootparentprevconsent. same as the difference between a shower and getting caught out in the rain reply doctor_eval 2 hours agorootparentI never consent to billboards. reply Moldoteck 1 hour agorootparentmajority of ppl voted for some party, a party that gave consent to place/allow billboards, so indirectly, you gave consent. In the graffity's case - even the ruling party didn't gave consent, it's that they don't have resources to penalize and clean this mess reply helboi4 50 minutes agorootparentThat implies that there was a party available that would ban billboards. There isn't, so graffiti is a way of actually taking back agency over our public spaces by underrepresented counterculture. Deal with it. reply wiseowise 40 minutes agorootparent> Deal with it. Incentivizing violence? Bold strategy. reply helboi4 30 minutes agorootparentPainting a wall is not violence. That is an extremely pro-authoritarian, hyper-capitalist viewpoint that is useful for the state and the property-owning ruling classes to enforce their rule. It has no basis in fact. Painting a wall does zero harm. If you own a massive building that is not your home, you can afford to paint over it. You don't need to though, because it is used by members of the public, not you, so it's actually meaningless to you. It's not the same as if graffiti artists painted over the front of your house as a middle class person. So there is no reason for you to be mad for uber-rich people who do not care about you. Walls that are used by the public should be owned by the public, and by that logic we all have the right to paint it whenever we want to. Just as you could paint a wall in your house. reply wiseowise 41 minutes agorootparentprevGo deface them then. reply stormking 1 hour agorootparentprevYes, you did. reply doctor_eval 9 minutes agorootparentWho are you to say what I consented to and what I did not? cm2187 2 hours agorootparentprevPlanning permission. reply doctor_eval 8 minutes agorootparentPermission is not remotely the same as legitimacy. reply a-french-anon 1 hour agorootparentprevSome people actually have to live in your decadent cyberpunk wet dream, you know? reply bayindirh 6 minutes agorootparentprevI mean, if they appreciate the effort going into the keeping the infrastructure working, they can have some (un)written rules like not spraying identification numbers, street signs, transparent surfaces (like windows), I think many people will appreciate what they do and the story behind more. Iâ€™m all for street art, but not fond of not being able to navigate because some group decided to let me they were here by making a road sign unintelligible. reply wongarsu 11 hours agorootparentprevIn our city graffiti is allowed on a couple select bridge pillars and retaining walls. Those often have excellent artworks that anyone can appreciate. Not that illegal graffiti can't produce great art too, and the illegality is a part of what fuels the culture. But I've come to the conclusion that if a place is likely to be \"vandalized\" by graffiti anyways you are better off just allowing it and see what people do without the time pressure of avoiding arrest. reply edejong 3 hours agorootparentprevIf you dive into: [wine, jazz, modern art, craft beer, tennis, â€¦] (pick one), youâ€™d also appreciate it more. Thing is, if I decide not to do that, the impact on my life is relatively minor. What gives graffiti artists the right to impose their personal predilection unto others? In other words, given your reasoning, whatâ€™s stopping me from playing John Coltrane at 110dBA the whole day and night? reply xandrius 3 hours agorootparentprevIf you only call graffiti the so-called \"street art\" then yeah but when most are bullshit tags from teenagers in the same cliche style with 0 creativity then it's trash. And the problem is that 99% of the graffiti in the world is trash tags in stations/trains which has the direct impact of giving a rough feel to any well-meaning location. So to me, that kind of graffiti is the result of a \"me important\" mentality which totally disregards the rest of the community who just loses in all fronts (including aesthetics and monetary). reply tetris11 3 hours agorootparentOnce you've seen \"Becky and Stace\" written large on every train station from Basel to Frankfurt, you can't help but admire the effort. reply 72deluxe 1 hour agorootparentprevWould you be happy to wake up to your car covered in graffiti? It's \"art\" after all! If not, why not? reply cubefox 14 minutes agorootparentprevThe vast majority has no aesthetic value to 99% of people and certainly not to the owner of the property. reply wiseowise 1 hour agorootparentprevUgly defacement of public property. reply zo1 3 hours agorootparentprevThis entire sub-thread has me worried about society. People that thinks this way about the common good is why we can't have nice things. This is why it'll always be \"50% vs 50%\" and why we can't all get along and need to be separated. reply flemhans 11 hours agorootparentprevSure but it's been like that since forever and doesn't change the original point that you may be ever so innovative but it's gonna be painted over reply overstay8930 7 hours agorootparentprevShiny pile of shit is still pile of shit, Iâ€™m glad people are starting to remove the graffiti. Nobody except hippies likes it. reply pizzalife 10 hours agorootparentprevHighly recommend the movies by the 1UP crew to get a feel for why this is actually great art. reply highcountess 59 minutes agoparentprevMany things are covered in graffiti in Western Europe. It always baffles me that people are in such a defeated state of mind that graffiti is just simply accepted and seemingly nothing is done about it. reply lynx23 55 minutes agorootparentHey, control freak, what realistic solution do you propose? reply andersa 11 hours agoparentprevThat's because the current ones are all ugly metal walls. Painting stuff on them makes it at least slightly less depressing. reply muspimerol 2 hours agorootparentDo you think this \"MetaWindow\" is much more attractive? Here's a similar looking transparent sound barrier in a new building area that is already starting to be covered in graffiti: https://youtu.be/e7-Fd1HOw_g?si=OTNn_NyV_W7iJStz&t=265 At least some light will still get through in the gaps between graffiti, but I don't think they will end up looking much different than non-transparent barriers. reply wiseowise 37 minutes agorootparentprevNo, it doesn't. Before it was a plain metal wall, now it's ugly metal wall with idiotic tags on it. reply constantcrying 4 hours agorootparentprevIt makes it more depressing to see them though. Who likes to be reminded that people will just deface public property for fun? reply mtmail 10 hours agoparentprevThe article ends \"the potential for faster planning approvals and reduced objection rates from communities, ultimately speeding up project completions.\" so their goal might be to build faster regardless how they'll look soon after. reply wongarsu 11 hours agoparentprevWith the goals stated in the article they only really need to stay transparent in concept renders of new projects. Once built they only need to fulfill the noise insulation targets and be less of an eyesore than their solid counterparts reply DeathArrow 4 hours agoparentprevIsn't vandalism an offense in Germany? reply fodkodrasz 4 hours agorootparentIn many places in Europe there is a de-facto truce between graffiti artist and the local governments: You can paint/tag some areas. Typically noise barriers are such, while trains themselves or stations are not. Harder persecution both by authorities and self-policing in the subcult community after some prominents were persecuted and agreed with to help normalize the situation has led to the current status quo, which for example in Hungary has normalized the situation pretty much, public transport and stations are generally not vandalized, and some larger well exposed areas were designated as local \"legal walls\". I guess the panopticon (cameras becoming cheap and ubiquitous) also helped reply HPsquared 1 hour agorootparentI think if it was put to a vote, most people would be against graffiti. reply carstenhag 2 hours agorootparentprevThese guys know the city in and out. Only in cases where you already expect them, you could be able to catch them. Also, police always has to prove you did it, and not some other member of the group. https://youtu.be/Y9Lm0dkkVAw?si=NDHBYtciFPDhp78I reply pjc50 2 hours agorootparentprevAlmost everywhere, but it's fairly low priority and impossible to prosecute without Orwellian levels of surveillance. reply HPsquared 1 hour agorootparentWe already have those levels of surveillance. It's just an unwillingness to do anything. reply Maxion 4 hours agorootparentprevI'm pretty certain it's an offense in most developed countries. reply nonrandomstring 15 minutes agoparentprevIt's interesting to read this conversation about graffiti happening on a hacker forum, yet it seems stuck in a polarised stand-off around aesthetics and ownership rights. That's a shame, because the root issues are in information warfare, the battle to control information spaces. To the extent The Internet is still considered a \"public space\"; Is spamming and trolling not a form of digital graffiti? Is the creation of products and apps that have a negative impact on society not a \"narcissistic imposition\"? Is the appropriation of the commons or other private property to spread messages (advertising or graffiti) not the same in the digital realm? And those who \"clean up\" graffiti... do we not call then \"censors\" or \"like down/up-voting\" when we wish to amplify or make other people's communications in the world disappear because we disagree with them? At the end of the day we are all still animals shouting to be heard the loudest in our jungle. Online or offline we're party to the same personality traits of quiet orderliness or disorganised expression. What happens in cyberspace hardly seems different from what happens IRL with spray-paint. reply ghostly_s 11 hours agoparentprev[0] https://ga.de/imgs/93/8/5/9/3/0/9/1/9/tok_8596521c60eeaa53eea42eea57c8b7dc/w1200_h630_x662_y525_GA_85197421_2005565667_RGB_190_1_1_2d14a73e871971ed95a819ea6b69b342_1593349745_2005565667_77b22cacaf-f8bed87dc312e74a.jpg looks much nicer than a blank wall to me. reply labster 10 hours agorootparentI donâ€™t know, I doubt I would want a URL this long on my wall. reply damsalor 2 hours agorootparentThe aesthetics of qr codes are sublime reply smokel 3 hours agoprevMy hart jumped when I initially thought that they had implemented an idea that I had once. Turns out MetaWindow is not an augmented reality display in the train's window, where one can read information on the scenery that one passes through while traveling. What is that city in the distance? When was that church built? How many cows are in that meadow? Stuff one has to know. reply JR1427 17 minutes agoparentI don't think this would make looking our of (or at) the window as enjoyable as with a normal transparent window. Unless you mean that there would still be a normal window, too? reply pjc50 2 hours agoparentprevSome aircraft designers have proposed doing this, because a screen can be lighter than a pressure resistant window. reply reportgunner 22 minutes agoparentprevJust sit at home and stare at a video of the scenery at that point. reply tetris11 3 hours agoparentprevA public institution doing this, fine fire away. A private train company? This will be an obnoxious video ad space. reply crote 5 minutes agorootparentA large fraction of trains and buses in Europe are already equipped with large full-color monitors. They are primarily used to show trip progress, potential transfers, and basic informative messages. Ads are rare, and are usually static images advertising the transport company's own products. reply culturestate 2 hours agorootparentprevDB is still a 100% state-owned enterprise; itâ€™s â€œprivateâ€ in name only. Sort of like Singapore Airlines, which is listed but majority-owned by one of Singaporeâ€™s sovereign wealth funds. reply mikeiz404 10 hours agoprevThis article goes into a little more detail: https://www.heise.de/en/news/MetaWindow-Laermschutz-an-Gleis... And the PhotonicVibes site is here: https://phononic-vibes.com/metawindow-for-railway/ Here is a demo video for a meta material made by them: https://youtu.be/NElK8qKRrBU?si=CfBjUESlu_XUvnn_ reply riffraff 4 hours agoparentThat's a really cool demo! reply kierenj 3 minutes agorootparentWeirdly it says \"up to 10dB\" attenuation.. which isn't actually that much at all. 10dB would be a halving/doubling. I'm not sure how the apparent loudness / change in waveform amplitude display is so great, considering that actual hard stat... reply Etheryte 2 hours agorootparentprevHonestly, that demo alone would be enough to get funding at any demo day, really cool stuff. reply mbforbes 10 hours agoprevA semi-related surprising fact I only learned recently is that the ultra-long nose of Japanese bullet trains is not for aerodynamics, but to reduce noise. Specifically, \"tunnel boom.\" Random source: https://www.jrpass.com/blog/why-shinkansen-bullet-trains-no-... reply bobthepanda 9 hours agoparentthis is only a problem in japan because the shinkansen is the oldest high speed network in existence. new train tunnels built in Europe are wider and flare out at the end so that there isn't a tunnel boom. reply mbforbes 7 hours agorootparentFascinating, and now I learned another new thing! Thank you for sharing. reply bobthepanda 6 hours agorootparentyup. for a more detailed explanation, there's this segment of the article: > Basically what happens is when a train enters a tunnel at high speed, the air in front of it is compressed and does not have enough time to flow past the trains body. When all released at once, the pressure causes a shockwave that goes boom! This is basically a very rudimentary version of the piston effect: https://en.wikipedia.org/wiki/Piston_effect reply esafak 11 hours agoprevThe quality of my life would be better improved through public transportation and these sound absorbers than almost any app I use. Hooray for basic infrastructure. reply danpalmer 5 hours agoparentI would go further, and say that public transport improves quality of life far more than sound absorbers for public transport do. It's nice that these things exist, but we should be spending money on more public transport, not necessarily on making public transport more palatable to people. I realise that's an unfortunate necessity, but it's clear that people pushing back on public transport just haven't seen its benefits enough. reply Maxion 4 hours agorootparentI think you're missing the point. Many public transport projects are dependant on the community around allowing them to be built, mitigating the impact of said projects allows more public transport to be built. E.g. a tram doesn't go very fast and is also pretty quiet. A train usually runs a lot faster, and causes more noise pollution. If you can mitigate the noise, then you'll probably be able to build the railway instead of the tram. Allowing more capacity, higher speeds, and a better public transport solution. reply eru 1 hour agoprevThey specifically mention railway noise. I wonder whether there's something special about railways, or whether it would work for other noise as well? Especially roads with cars on them? reply metters 1 hour agoparentI think there are noises specific to railways. And from what I believe this \"MetaWindow\" targets relevant frequencies. However, I am sure this also works for the frequencies generated by car traffic. At least the linked youtube video in this comment [1] does not mention anything about frequencies. [1] https://news.ycombinator.com/item?id=40384778 EDIT: I was wrong about the video. There is _no mention_ about frequencies. reply croemer 10 hours agoprevTerrible press release. The first picture shows an _intransparent_ barrier. Is that a before after picture? And what is \"meta technology\"? reply metters 4 hours agoparentThis [1] is the official press release by Deutsche Bahn. I wanted to post this instead, but it is in German. [1] https://www.deutschebahn.com/de/presse/pressestart_zentrales... reply wiml 3 hours agoparentprevMy guess is it's related to \"metamaterials\", which are materials engineered to have interesting properties by including structures smaller than the wavelength of whatever is going through them (sound, microwaves, even visible light if the structures are fine enough). There is quite a lot of research into sound-absorbing yet porous acoustic metamaterials. (Related, but maybe not technically a metamaterial, previously on HN: https://news.ycombinator.com/item?id=38678415 ) reply addandsubtract 8 hours agoparentprevSeems to be a before picture. There's an \"after\" picture further down the page. Meta technology maybe because it's not actual train related tech, but meta tech related to trains. reply ghostly_s 11 hours agoprevOkay it's clear-ish...but where's the noise level sample vs. the alternatives? edit: I did find this cool demo of a similar product of theirs, but seems to be nothing more online about the noise barrier. https://www.youtube.com/watch?v=DUee93HcPVQ reply felsokning 4 hours agoprevThey don't give any numbers on the amount of resistances to the expansion of the infrastructure, based on noise alone. This reads like a \"we did a cool thing\" but without qualitatively demonstrating the merits for the need. reply mindwok 10 hours agoprevLots of negative comments on this. I, for one, am glad to see work that supports better transport infrastructure while not being insanely ugly like a lot of transport infrastructure is (like the giant concrete birds nests of highways in US cities). I want to live in cities that are visually appealing. reply ggm 11 hours agoprevI can't find it any more but I read a paper decades ago on the sound modulation effects of different plants, at scale and how designed planting around motorways can help reduce local resident impact. reply vezuchyy 11 hours agoprevCool, one day CP will install those along their tracks and my high-rise will shake silently every time https://en.wikipedia.org/wiki/EMD_F59PH#F59PHI departs from the station. reply FearOfTheDuck 1 hour agoprevA train does not make noise if it's cancelled reply lionkor 11 hours agoprevNow the trains have to actually arrive and depart within, say, 5 minutes of the planned time, and we will be in the 21st century finally. reply throwaway4good 6 hours agoprevThis is an international site and I think people donâ€™t understand just how big Deutsche Bahnâ€™s problems with delays are and how incredible dissatisfied its customers are. The situation with DB is really unique compared to its neighbors in any direction. While the tech described probably has merits, anyone who has been near DB lately would instinctively go: why are you doing this when you cannot get the basics right? reply jonp888 2 hours agoparentNo other railway has to deal with with so much traffic on infrastructure that is so old and out of step with the demands placed on it. People tend to obsess over DB and it's management, but they only control maintenance. All decisions about renovations are made by the government. So what do you want? - Wait years for large renovation projects on all major routes, including lengthy closures for work(the current strategy) - Cancel 25-50%% of all trains permanently, if then people can't travel because it's impossible to get through the door, tough The latter one is the French solution - just run very few trains, regardless of demand. The last time I wanted to travel by train in France, I simply couldn't because all trains on the route for the entire day were 100% sold out. Then there's Spain. The last time I wanted to travel there, I didn't because the first(!) train of the day left at lunchtime and arrived mid-afternoon. reply jamil7 4 hours agoparentprevItâ€™s also gotten so expensive and unreliable that some people Iâ€™ve spoken to are just driving again instead whereas years ago they would have always gone by train. I canâ€™t help but feel that the weird ownership model contributes to this and the whole company should just be properly nationalised. reply tetris11 3 hours agorootparentHell I used to bike 20km to work to avoid it reply marsRoverDev 4 hours agoparentprevI fly to germany when I can, or take any other operator's train. I am way, way more familiar with Karlsruhe than I would like to be. reply panick21_ 3 hours agoparentprevDB is a gigantic organization. Do you think it is reasonable for them not not make progress or advancement in anything as long as the ICE delays are not fixed? They can never change a train interior, improve the food menu, or 1000s of other things? This is a totally unreasonable suggestion. The reason for DB reliability problem is 50+ years of infrastructure neglect, fixing it will not be improved by shutting down every other group at DB. Personally having traveled threw Germany many times, its a mostly amazing. Yes sometimes trains are late sometimes, but the trains themselves are great and travel in them is a joy. I think what Germans don't understand is how good they have it compared to many places in the world. reply probably_wrong 2 hours agorootparentSomeone turned on the DB signal[1] so here I am. > sometimes trains are late sometimes, but the trains themselves are great and travel in them is a joy. \"Sometimes\"? Let me tell you about my friends in the German area of NRW. The one that commutes far away regularly gets stranded on the way because the trains arrive so late that there's no connection home till the next day and because, of the two lines that take her home, one is closed. The second one commutes within the city and has decided to buy a car because the SBahn was closed for over a year with a repair that took longer than planned. The other two don't even consider trains in their daily life. My GF at the time had a year-long line closure, we moved to a place with a year-long train closure and I'm living now in an area where my regular train won't run until November (assuming no delay). Yes, DB trains are pretty nice on the inside. Quiet, too. But what good is a nice train that doesn't take me to where I need to go, or at all? If anything, I think those that don't rely on the trains daily fail to realize how bad the situation is. Ten minutes delay on the one ICE trip on holidays? Sure, whatever, it's fine. Ten minutes delay on a five minutes connection to work? Enjoy wasting half an hour of your life every other day, like I did during my studies. Switzerland has cut DB off [2] and Scottish fans received warnings [3] about how unreliable German trains are. It is bad. [1] The DB signal is like the bat signal for comments downplaying DBs issues, but you often don't see it because there's a \"SignalstÃ¶rung\" and it shows up an hour later. They usually apologize for the inconvenience. [2] https://www.iamexpat.de/expat-info/german-expat-news/deutsch... [3] https://www.indonewyork.com/m/science/european-football-cham... reply panick21_ 26 minutes agorootparentLook I understand all that. And Im all for fixing it. But its still objectivly better then in many other places. Rail overall in Germany is great. ICE are the weakness for sure. But its still much better then many other places in the world. reply throwaway4good 55 minutes agorootparentprevUnder normal circumstances I would agree with you. But is DB and they really need to go all hands on deck and fix their reliability problem. reply tetris11 3 hours agorootparentprevBut they had it better only a few years ago. DB has really crumbled. reply lukan 5 hours agoparentprevOr basic information about when and where a train comes late or not at all. Sometimes the information is there and correct - sometimes not at all or is wrong and 100+ people waiting for a train that is never coming. Experienced that way too often. But hey, the Bahn management achieved all their self proclaimed targets (non of them related to reliable trains) so they surely deserved their fat bonus. reply mschuster91 3 hours agoparentprev> While the tech described probably has merits, anyone who has been near DB lately would instinctively go: why are you doing this when you cannot get the basics right? DB is facing the problem that the network needs substantial overhaul - the problem is that when you do a large-scale renovation, you gotta adhere to current code, not late 19th century code (which is when quite a few of the railways had been built). And that means noise protection anywhere where the tracks are adjacent to residential areas, but NIMBYs will launch intensive protests if they get presented with a massive wall of steel in their backyard - understandably so, these things are an eyesore. So, it's a prerequisite for DB to tackle its problems... because most of them are caused by the aged infrastructure. Right next to Munich, on the route to MÃ¼hldorf, there are still mechanical switches in place, built around 1900 [1]. [1] https://www.merkur.de/lokales/erding/der-bahnausbau-nach-mue... reply codemusings 3 hours agoprevNow could Deutsche Bahn please also invest in some actual infrastructure, trains and make them go on time? Thatâ€˜d be great! Thanks. reply flohofwoe 1 hour agoparent> Now could Deutsche Bahn please also invest in some actual infrastructure The main \"problem\" currently is not that they modernise too little, but too much. For the last 5 years or so, during the summer months I need to add one or two hours to nearly all my connections because of construction work that slowly seems to move from cities into the rural regions (I'm not complaining though, no matter what the Bahn does, travellers will be affected one way or another, and I bet most of the delays you are seeing are caused by construction work somewhere at the 'leaf nodes' of the network). Of course a couple of decades of the \"kaputtsparen\" mentality didn't help, it would obviously have been better to spread out the required maintenance work and modernization over those decades of infrastructure negligence. reply eigenspace 1 hour agoparentprevIn the article they say that one of their main motivations for this is that they hope it will speed up the approval times for train routes, because it'll lessen the noise and visual complaints. reply locallost 1 hour agoparentprevDeutsche Bahn pays for the usage of the infrastructure just like any other company using it (e.g. Flix or any of the regional carriers). The infrastructure is the responsibility of DV InfraGO (formerly DB Netz). reply donw 6 hours agoprevI cannot be the only person that read this as â€œMetalWindowâ€, a.k.a. â€œwallsâ€. reply harha 9 hours agoprevI mean it's cool, but how about getting some basics like punctuality and cleanliness right first. reply Lorin 11 hours agoprevOk, now they have an excuse to employ a crew to keep them clean like any other window-like product... instead of it just being a wall? I don't get it. reply fcsp 10 hours agoparentThere's maintenance management fees to be earned! I don't know about how this stuff works, but as a matter of fact there's management bonuses for new development for DB execs, whereas nothing is gained from plain bleak maintenance. So guess why many major train stations in Germany have been undergoing major, multi-billion relocations and redesigns (often with worse throughput metrics). reply eternauta3k 4 hours agoparentprevBest way to make a city look crappier is replace a dirty wall with a dirty window reply danielfoster 10 hours agoprevNow they just need to be on time. reply ivan_gammel 11 hours agoprevA startup with wrong product focus would be insolvent in a few months. Deutsche Bahn can rot for decades spending money on technology that would not make any difference when a quarter of its trains is delayed or cancelled. reply usr1106 4 hours agoparentDeutsche Bahn is not a startup, but provides public service. Are the Autobahns profitable? That they have problems with service quality does not mean other problems should not be addressed. Noise pollution has massive health consequences for those living in affected areas. reply microtherion 10 hours agoparentprevMy understanding is that some of the mitigation for delayed or cancelled trains will involve new construction, and that might be facilitated by reducing the noise impact. reply thewarpaint 11 hours agoparentprevCare to explain how trains being delayed or canceled is related to a new technology reducing sound pollution? reply ivan_gammel 3 hours agorootparentThe prospects of building something new with this tech are very distant. Just to get an approval for construction in Germany it can take years and then there will be traditional delays along the way. We wonâ€™t see it in any meaningful quantities before 2030-2040 - whether this project will survive until then is an open question. The acute service problem on the other side could be addressed by simpler means like investment in IT and better internal processes. My last trip was cancelled one hour in advance, despite that they knew it couldnâ€™t happen days before. I had to visit their travel center, because the app couldnâ€™t apply my seat reservation to alternative route, and that experience was awful. It is very hard to understand why some tech that may never see the light due to bureaucratic hurdles deserves investment at the time where service doesnâ€™t show any signs of improvement. reply tschwimmer 10 hours agorootparentprevThe article posits it could make approvals to build new rail lines near noise sensitive areas easier. reply yau8edq12i 2 hours agoparentprevA decades old national train company is about as far from a startup as can be. That's a really strange comment. reply 2 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Deutsche Bahn has unveiled MetaWindow, a revolutionary noise reduction technology utilizing a distinctive geometric design to improve acoustic efficiency on railways.",
      "The transparent noise barrier offers noise insulation levels of 34-37 decibels and maintains a transparency of 72%, expected to accelerate project timelines by mitigating objections from local residents, despite higher material expenses.",
      "Intelligence agencies issue alerts due to an increase in Russian railway sabotage acts in Europe, emphasizing the importance of railway security."
    ],
    "commentSummary": [
      "Deutsche Bahn has implemented MetaWindow technology to combat noise pollution from railroads, triggering discussions on graffiti on noise barriers and passenger cars.",
      "The debate revolves around whether graffiti constitutes art or vandalism, its effects on urban environments, and the efficacy of graffiti removal.",
      "Some advocate for enhancing German train infrastructure and service quality, expressing dissatisfaction with current reliability levels."
    ],
    "points": 192,
    "commentCount": 253,
    "retryCount": 0,
    "time": 1715894087
  },
  {
    "id": 40379175,
    "title": "Efficient New Algorithm for Counting Distinct Elements",
    "originLink": "https://www.quantamagazine.org/computer-scientists-invent-an-efficient-new-way-to-count-20240516/",
    "originBody": "Computer Scientists Invent an Efficient New Way to Count Read Later Share Copied! Comments Read Later Read Later algorithms Computer Scientists Invent an Efficient New Way to Count By Steve Nadis May 16, 2024 By making use of randomness, a team has created a simple algorithm for estimating large numbers of distinct objects in a stream of data. Read Later Nico Roper/Quanta Magazine By Steve Nadis Contributing Writer May 16, 2024 View PDF/Print Mode algorithmscomputer scienceexplainersAll topics Introduction Imagine that youâ€™re sent to a pristine rainforest to carry out a wildlife census. Every time you see an animal, you snap a photo. Your digital camera will track the total number of shots, but youâ€™re only interested in the number of unique animals â€” all the ones that you havenâ€™t counted already. Whatâ€™s the best way to get that number? â€œThe obvious solution requires remembering every animal youâ€™ve seen so far and comparing each new animal to the list,â€ said Lance Fortnow, a computer scientist at the Illinois Institute of Technology. But there are cleverer ways to proceed, he added, because if you have thousands of entries, the obvious approach is far from easy. It gets worse. What if youâ€™re Facebook, and you want to count the number of distinct users who log in each day, even if some of them log in from multiple devices and at multiple times? Now weâ€™re comparing each new login to a list that could run to the billions. In a recent paper, computer scientists have described a new way to approximate the number of distinct entries in a long list, a method that requires remembering only a small number of entries. The algorithm will work for any list where the items come in one at a time â€” think words in a speech, goods on a conveyor belt or cars on the interstate. The CVM algorithm, named for its creators â€” Sourav Chakraborty of the Indian Statistical Institute, Vinodchandran Variyam of the University of Nebraska, Lincoln, and Kuldeep Meel of the University of Toronto â€” is a significant step toward solving whatâ€™s called the distinct elements problem, which computer scientists have grappled with for more than 40 years. It asks for a way to efficiently monitor a stream of elements â€” the total number of which may exceed available memory â€” and then estimate the number of unique elements. â€œThe new algorithm is astonishingly simple and easy to implement,â€ said Andrew McGregor of the University of Massachusetts, Amherst. â€œI wouldnâ€™t be surprised if this became the default way the [distinct elements] problem is approached in practice.â€ To illustrate both the problem and how the CVM algorithm solves it, imagine that youâ€™re listening to the audiobook of Hamlet. There are 30,557 words in the play. How many are distinct? To find out, you could listen to the play (making frequent use of the pause button), write down each word alphabetically in a notebook, and skip over words already on your list. When you reach the end, youâ€™ll just count the number of words on the list. This approach works, but it requires an amount of memory roughly equal to the number of unique words. In typical data-streaming situations, there could be millions of items to keep track of. â€œYou might not want to store everything,â€ Variyam said. And thatâ€™s where the CVM algorithm can offer an easier way. The trick, he said, is to rely on randomization. Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters Vinodchandran Variyam helped invent a technique to estimate the number of distinct elements in a stream of data. Craig Chandler Introduction Letâ€™s return to Hamlet, but this time your working memory â€” consisting of a whiteboard â€” has room for just 100 words. Once the play starts, you write down the first 100 words you hear, again skipping any repeats. When the space is full, press pause and flip a coin for each word. Heads, and the word stays on the list; tails, and you delete it. After this preliminary round, youâ€™ll have about 50 distinct words left. Now you move forward with what the team calls Round 1. Keep going through Hamlet, adding new words as you go. If you come to a word thatâ€™s already on your list, flip a coin again. If itâ€™s tails, delete the word; heads, and the word stays on the list. Proceed in this fashion until you have 100 words on the whiteboard. Then randomly delete about half again, based on the outcome of 100 coin tosses. That concludes Round 1. Next, move to Round 2. Continue as in Round 1, only now weâ€™ll make it harder to keep a word. When you come to a repeated word, flip the coin again. Tails, and you delete it, as before. But if it comes up heads, youâ€™ll flip the coin a second time. Only keep the word if you get a second heads. Once you fill up the board, the round ends with another purge of about half the words, based on 100 coin tosses. In the third round, youâ€™ll need three heads in a row to keep a word. In the fourth round youâ€™ll need four heads in a row. And so on. Related: Scientists Find Optimal Balance of Data Storage and Time Researchers Approach New Speed Limit for Seminal Problem Mathematicians Discover the Perfect Way to Multiply Eventually, in the kth round, youâ€™ll reach the end of Hamlet. The point of the exercise has been to ensure that every word, by virtue of the random selections youâ€™ve made, has the same probability of being there: 1/2k. If, for instance, you have 61 words on your list at the conclusion of Hamlet, and the process took six rounds, you can divide 61 by the probability, 1/26, to estimate the number of distinct words â€” which comes out to 3,904 in this case. (Itâ€™s easy to see how this procedure works: Suppose you start with 100 coins and flip each one individually, keeping only those that come up heads. Youâ€™ll end up with close to 50 coins, and if someone divides that number by the probability, Â½, they can guess that there were about 100 coins originally.) Variyam and his colleagues mathematically proved that the accuracy of this technique scales with the size of the memory. Hamlet has exactly 3,967 unique words. (They counted.) In experiments using a memory of 100 words, the average estimate after five runs was 3,955 words. With a memory of 1,000 words, the average improved to 3,964. â€œOf course,â€ he said, â€œif the [memory] is so big that it fits all the words, then we can get 100% accuracy.â€ â€œThis is a great example of how, even for very basic and well-studied problems, there are sometimes very simple but non-obvious solutions still waiting to be discovered,â€ said William Kuszmaul of Harvard University. By Steve Nadis Contributing Writer May 16, 2024 View PDF/Print Mode algorithmscomputer scienceexplainersAll topics Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters The Quanta Newsletter Get highlights of the most important news delivered to your email inbox Email Subscribe Recent newsletters Comment on this article Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. Show comments Next article Strangely Curved Shapes Break 50-Year-Old Geometry Conjecture",
    "commentLink": "https://news.ycombinator.com/item?id=40379175",
    "commentBody": "Computer scientists invent an efficient new way to count (quantamagazine.org)188 points by jasondavies 4 hours agohidepastfavorite56 comments novaRom 0 minutes agoI wish we had a theory connecting randomness with time/space complexity. Intuitively I think the key to many computational limitations is making use of randomness. reply pixelmonkey 3 hours agoprevThis algorithm seems to resemble HyperLogLog (and all its variants), which is also cited in the research paper. Using the same insight of the estimation value of tracking whether we've hit a \"run\" of heads or tails, but flipping the idea on its head (heh), it leads to the simpler algorithm described, which is about discarding memorized values on the basis of runs of heads/tails. This also works especially well (that is, efficiently) in the streaming case, allowing you to keep something resembling a \"counter\" for the distinct elements, albeit with a error rate. The benefit of HyperLogLog is that it behaves similarly to a hash set in some respects -- you can add items, count distinct them, and, importantly, merge two HLLs together (union), all the while keeping memory fixed to mere kilobytes even for billion-item sets. In distributed data stores, this is the trick behind Elasticsearch/OpenSearch cardinality agg, as well as behind Redis/Redict with its PFADD/PFMERGE/PFCOUNT. I am not exactly sure how this CVM algorithm compares to HLL, but they got Knuth to review it, and they claim an undergrad can implement it easily, so it must be pretty good! reply hmottestad 1 hour agoparentItâ€™s also possible to use HLL to estimate the cardinality of joins since itâ€™s possible to estimate both the union and the intersection of two HLLs. http://oertl.github.io/hyperloglog-sketch-estimation-paper/ reply usgroup 2 hours agoprevI found the paper took about as long to read as the blog post and is more informative: https://arxiv.org/pdf/2301.10191 It is about estimating the cardinality of a set of elements derived from a stream. The algorithm is so simple, you can code it and play with it whilst you read the paper. The authors are explicit about the target audience and purpose for the algorithm: undergraduates and textbooks. reply vanderZwan 1 hour agoparentIf you refer to the subtitle of the paper - An Algorithm for the (Text) Book - I think that is actually a reference to something *Paul Erdos allegedly said about some proofs are so elegant in their simplicity and beauty that they are \"from The Book\", like representing some divine Platonic ideal. Given that Knuth himself reviewed it, he might have remarked that this was one of those algorithms! Perhaps the authors decided to include it in the title as a not-so-humble brag (which would be well-earned if that's the case!) edit: originally this comment said Knuth was the one who said this about some algorithms being from The Book, but that was my faulty memory. reply kibibu 1 hour agorootparentI thought The Book was an Erdos thing. I wonder who used it first. reply stevesimmons 48 minutes agorootparent\"During a lecture in 1985, ErdÅ‘s said, `You don't have to believe in God, but you should believe in The Book.`\" https://en.wikipedia.org/wiki/Proofs_from_THE_BOOK reply vanderZwan 16 minutes agorootparentprevI think you're right, I must have confused the two. I'll edit my comment to reduce the spread of misinformation. reply swores 37 minutes agoparentprev> \"The authors are explicit about the target audience and purpose for the algorithm: undergraduates and textbooks.\" If you're saying it's just for \"undergraduates and textbooks\", as opposed to just being simple enough for them to use but not limited to them, would you mind explaining what makes it useful for undergrads but not for professionals? reply coldtea 46 minutes agoparentprev>The authors are explicit about the target audience and purpose for the algorithm: undergraduates and textbooks. Doesn't seem like it. Seems like an algorithm (similar to other approximate cardinality estimation algorithms) with huge applicability. reply akamoonknight 2 hours agoprevI don't know a word or phrase for this, but I really enjoy any examples of \"thinking outside the box\" like this because it's something I struggle with in my professional career. Learning not only the right ways to solve problems, but figuring out the questions to ask that make solving the problems you have easier or even in some cases possible. In this case, it's hey, we don't need exact numbers if we can define a probabilistic range given defined parameters. Other problems are gonna have other questions. I guess my hope is that if I see enough examples I'll be able to eventually internalize the thought process and apply it correctly. reply wmwragg 2 hours agoparentI think it's generally thought of as \"lateral thinking\", Edward de Bono has written a few books about it you might find interesting. reply coldtea 44 minutes agorootparentAnd some more commonplace words like \"creativity\" (as in \"creative solution\") etc. would apply. reply melq 1 hour agoprevEstimating the amount of unique elements in a set and counting the amount of unique elements in a set are very different things. Cool method, bad headline. reply dools 1 hour agoparentIt's an approximation, not an estimation. reply ranguna 1 hour agorootparentStill very different things, no? reply coldtea 43 minutes agorootparentIt's the same thing at different degrees of accuracy. The goal is the same. reply imoverclocked 2 hours agoprevWhen do we stop calling this counting and start calling it estimation? reply BlackFly 2 minutes agoparentWhen it is actually impossible to count something and when the error between estimation and an exact answer is not significant the pedantic distinction is not helpful. The same thing happens with measurement. No measurement is ever exact. If I said I was measuring a count, someone would probably correct to say that I am counting. Common speech is like that. reply card_zero 2 hours agoparentprevSeems this is one of those things like UUIDs where we rely on it being very unlikely to be wrong, because statistics. > the accuracy of this technique scales with the size of the memory. I wonder if that's proportional to the number of distinct items to count, though. > if the [memory] is so big that it fits all the words, then we can get 100% accuracy Yes, but then the algorithm isn't being used any more, that's just normal counting. They counted the distinct words in Hamlet with a memory size of 100 words, about 2.5% of the number to find, and got a result that was off by 2. If you do the same with the whole of Shakespeare, again using 2.5% of the memory needed to hold all the distinct words, is the accuracy better? Anyway, this is limited to counting, and doesn't help list what the words are, though quickly counting them first is perhaps a way to speed up the task of actually finding them? reply vlovich123 2 hours agoparentprevAs soon as people start reading past the headline. reply 112233 2 hours agorootparenttbh, the title (and introduction) did a lot to dissuade me from finishing the (really good) article. It was actually informative, why dress it as a SEO blogspam? reply seanhunter 2 hours agorootparentPresumably so it is optimised for search engines and people find it. Publishers generally have good data about where their audience comes from. They wouldn't do this if it wasn't the best way they know of to maximise readership. reply HDThoreaun 2 hours agorootparentprevSo they can get paid for their work? Are you giving them anything? reply pmontra 2 hours agoparentprevYes, even the subtile states \"a simple algorithm for estimating large numbers of distinct objects\". reply cubefox 27 minutes agorootparentThis doesn't excuse the title though. reply thesz 1 hour agoprevHyperLogLog uses additions, it keeps sums. Thus, you can subtract one HLL sums from other. This is useful if stream supports deletion. Streams with deletions can be found in log-structured merge trees, for one example, so one can estimate count of distinct elements in all of the LSM tree hierarchy. The algorithm in the paper does not allow for deletions. Also, if one counts statistics of the stream of large elements (say, SHA-512 hashes, 64 bytes per hash), this algorithm requires some storage for elements from this stream, so memory requirement is O(table size * element size). reply drycabinet 39 minutes agoprevDoes finding the number of unique elements in a set actually require comparison of each element with everything else? Can't you use a hashtable? For every element, add it to the table (ignore if already exists), and finally, take a count of keys. reply Anduia 13 minutes agoparentUsing a hashtable is effective because you only compare elements within their hash buckets, not the entire set. However, they can become inefficient with very large datasets due to memory usage and processing time, which is where approximate counts shine. reply jangxx 27 minutes agoparentprevUsing a hashtable is the \"normal\" approach mentioned in the article. It works of course, but requires memory to store each unique element (or their hashes). If you have less memory available, the described algorithm can still give a very good approximation. reply theginger 23 minutes agoparentprevThat is fine when you have say 1 million values and only 1000 are unique. But when you have 1 million values and about 900 thousand are unique you are putting more or less the whole data set into memory. reply xwolfi 26 minutes agoparentprevImagine a million elements. How big must your hashtable be ? The article explains it very well, did you miss it ? It's a way to save memory. But to be honest I implemented it, ran it on Hamlet, and it's very wrong, it's barely useful but maybe if you just need a vague idea... reply gh0stcloud 32 minutes agoprevvery interesting solution. A perfect example of how even some very complicated problems can sometimes have simple solutions. Will definitely try to write an implementation of this. The only minor downside to this is that it's obviously not deterministic since it depends on chance. But for many applications where the dataset is so big it doesn't fit in memory, that's probably just a tiny rounding error anyway. reply saulrh 2 hours agoprevHuh, that's a clever twist on reservoir sampling. Neat. reply hum3hum3 1 hour agoprevThe counting/estimstion technique is rather like a floating point number. An integer exponent k and a mantissa of a population. reply kromem 1 hour agoprevAh, so Thanos was just conducting a census. reply biscuit1v9 2 hours agoprev> The trick, he said, is to rely on randomization. > When the space is full, press pause and flip a coin for each word. Heads, and the word stays on the list; tails, and you delete it. I wasn't expecting to go that far: randomization. How can you verify if the answer is good? Only approximation, maybe.. reply seanhunter 2 hours agoparentThe proof is pretty straightforward and is included in the paper https://arxiv.org/abs/2301.10191 reply HDThoreaun 2 hours agoparentprevYes, the result is an estimation. reply biscuit1v9 44 minutes agorootparentThanks. Just wanted to be sure I didn't misunderstood. reply 8372049 2 hours agoparentprevDid you read the (entire) article? reply 112233 2 hours agoprevAfter skimming Knuth's paper â€” does the algorithm work if values are hashed, that is, the \"uniform deviate\" is selected deterministically for each unique value of the stream? reply devnonymous 1 hour agoparentNot sure which Knuth paper you're referring to but skimming through the article my understanding is this algorithm works /only/ if the values are hashable. IOW how else does one define unique/distinct values ? reply hcs 1 hour agorootparenthttps://cs.stanford.edu/~knuth/papers/cvm-note.pdf Looks like it was posted at the time https://news.ycombinator.com/item?id=36079213 but not much discussed. I found it over here https://news.ycombinator.com/item?id=40387594 reply 112233 1 hour agorootparentprevhttps://cs.stanford.edu/~knuth/papers/cvm-note.pdf note how \"u\"s are selected every time value is not in a list. I don't read it as being a hash. reply hcs 1 hour agorootparentI think the analysis relies on independent random \"u\"s, even for the same key. reply dist-epoch 52 minutes agoprevDo they assume any particular distribution of the items? Otherwise Nassim Taleb would like a word with them. reply coldtea 41 minutes agoparentNo, and Taleb is not relevant for this. reply dist-epoch 17 minutes agorootparentIt is if the distribution is extreme. reply coldtea 11 minutes agorootparentIf Hamlet was 100000000 times the word Hamlet and 1 time the word pancake, it would still give an good estimate measurement - even if pancake gets 0. reply aaron695 1 hour agoprevKnuth talks about this paper here - \"The CVM Algorithm for Estimating Distinct Elements in Streams\" - https://cs.stanford.edu/~knuth/papers/cvm-note.pdf reply matt3210 2 hours agoprev [â€“] CS guys always wanting to throw away a good system and start from scratch. reply 112233 2 hours agoparentWhich good system are you referring to? reply Miraltar 2 hours agoparentprevWhich good system are we talking about ? reply coldtea 39 minutes agoparentprevYeah, if only we have stuck with those stone wheels from 20,000 B.C. reply baq 2 hours agoparentprev [â€“] Tell me you didn't read the article without telling me you didn't read the article. ...but actually, I think you didn't even read the headline...? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Computer scientists introduced the CVM algorithm, leveraging randomness to estimate distinct elements in data streams efficiently with minimal memory retention.",
      "The algorithm, suitable for various applications like tallying unique words or users logging in, employs randomization and iterative selection rounds for precise estimates in low-memory environments.",
      "This novel approach marks a substantial progression in addressing the long-standing distinct elements problem in computer science research for more than four decades."
    ],
    "commentSummary": [
      "Computer scientists have created a new algorithm like HyperLogLog to estimate the number of elements in a set from a stream accurately while consuming minimal memory.",
      "Discussions cover \"The Book\" concept in mathematics, various counting techniques, and the application of algorithms like HyperLogLog for estimating a large number of distinct objects.",
      "Conversations also debate on estimating unique elements through hashtables or approximation techniques, emphasizing simplifying complex issues and recognizing potential limitations of novel computer science algorithms."
    ],
    "points": 188,
    "commentCount": 56,
    "retryCount": 0,
    "time": 1715871265
  }
]
