[
  {
    "id": 40479729,
    "title": "How Home Assistant Helps Ukrainians Monitor and Respond to Missile and Drone Threats",
    "originLink": "https://denysdovhan.com/home-assistant-config/config/war/",
    "originBody": "War SafetyÂ¶ In 2022, Russia launched a full-scale invasion of Ukraine, waging a genocidal war against my country. Ukraine is being hit by all types of weapons (except nuclear) daily. Home Assistant helps me stay safe and notifies me about incoming threats. We hear the siren a few times a day. Life would completely stop if we went to the shelter every time the siren goes off. So, people adapt. In Ukraine, we tend to differentiate the levels of danger. When the siren goes off, practically everyone starts checking their phones: \"What is going on?\" We have various applications and Telegram channels for monitoring the type of danger, missile paths, and understanding whether we are in direct danger or can continue with our lives for another minute. This is what war in the 21st century looks like: you can practically monitor a missile or a drone that is trying to kill you right from your phone. This is like a Black Mirror episode in real life. ðŸ˜… There are different kinds of air alarms with varying levels of danger: MiG-31K take off â€“ This can happen multiple times during the day. The MiG-31K can carry a very dangerous Kh-47M2 Kinzhal hypersonic missile. Although it happens rarely, you can't predict when the missile is attached and when it is not, so most people tolerate this level of danger. Suicide drones attack â€“ Usually carried out by Iranian Shahed 136 drones. Most of them get shot down, but they are still dangerous and scary. We call them \"mopeds\" or \"lawn-mowers\" because of the sound of their engine. Ballistic missile attack â€“ This can happen multiple times a day. Ballistic missiles, like the 9K720 Iskander, are extremely fast (2 km/s). You have only up to 10 minutes to hide somewhere. Usually, the fastest way is to hide behind two walls (corridor or a bathroom). Cruise missile attack â€“ Cruise missiles, like the Kalibr, are relatively slow and fly like a plane. Nevertheless, they can fly a long distance and easily reach any point in the country. Of course, the most dangerous type of attack is a combined one. This means all of the above are raining down on Ukrainian cities simultaneously. These usually happen overnight at 4:00 in the morning. The drones and cruise missiles are used to exhaust air defenses, followed by ballistic and/or hypersonic strikes. Monitoring Air AlertsÂ¶ Home Assistant has a built-in Ukraine Alarm integration. It monitors the nation-wide system of air alarms and toggles safety sensors in HA. When there is any type of danger, I send a critical notification and announce the message on my smart speakers. Of course, the air siren goes off on the streets, roaring across the city, so everyone hears the danger is approaching. But I made an automation to send a critical notification and speak at home speakers, so I certainly wake up to check what is going on. id: air_siren_kyiv alias: 'Alert: Air Siren in Kyiv' description: Air Alert announcement when we are in Kyiv. Sends critical notifications and announces on speakers. trigger: - platform: state entity_id: binary_sensor.alerts_kyiv_air to: 'on' from: 'off' variables: title: Air Alert goes off! - platform: state entity_id: binary_sensor.alerts_kyiv_air to: 'off' from: 'on' variables: title: It is safe now! condition: - alias: Someone is in Kyiv condition: state entity_id: sensor.family_in_kyiv state: 'on' action: - service: script.announcement data: title: '{{ title }}' force_speak: true # Speaks even in DND mode notify_data: group: air-alerts push: sound: name: default critical: 1 volume: 0.75 Scraping Monitoring ChannelsÂ¶ I already mentioned we have various Telegram channels for monitoring the situation during an attack. Those channels provide live updates on dangers, flight paths, and the type of attack. So often I found myself constantly checking my phone to understand whether I am in direct danger or can sleep for a few hours. I know it sounds crazy, and normal people would go straight to the nearby shelter, but this is life in Ukraine. You don't have to follow my reckless example. If you are in Ukraine, GO TO THE SHELTER! I decided to automate it. Instead of reading these channels myself, I delegate this task to HA. I use the HA Multiscrape custom integration for that. You may ask, \"why do you need a custom component when HA has a built-in scraping component?\" Yes, it does, but I need multiple sensors from a single scrape, and I need to work with lists of data. The built-in component has some limitations with that. Monitoring Imminent DangerÂ¶ Cruise missiles are usually carried and launched by Tu-95 bombers. They fly to the missile launch sites for about 3 hours, launch their missiles, then it takes about 1-2 hours for missiles to fly to Kyiv. So there's some time to prepare a hideout (in my case, it's the bathroom), gather documents, and sleep for a few hours before the \"show\" begins. Notification about Tu-95 bombers taking off Usually, it happens in the evening and means tonight will be a massive missile attack. I have a sensor that checks the Telegram channels, scrapes the list of messages every 5 seconds, and checks if the latest message contains a specific set of words, like \"take off\" and \"plane\" and \"tu-95\". It also stores the latest message as an attribute. multiscrape: - name: War Monitor resource: https://t.me/s/war_monitor scan_interval: 5 list_separator: '|||' binary_sensor: - unique_id: imminent_attack_in_war_monitor name: Imminent Attack in War Monitor icon: mdi:airplane-clock device_class: safety select_list: '.js-message_text' value_template: >- {% set message = value.split(\"|||\")lastlower %} {{ \"Ð·Ð»Ñ–Ñ‚\" in message and \"Ð±Ð¾Ñ€Ñ‚Ñ–Ð²\" in message and \"Ñ‚Ñƒ-95\" in message }} attributes: - name: latest_message select_list: '.js-message_text' value_template: \"{{ value.split('|||')last }}\" So when the sensor turns on, it means the bombers are airborne and it's time to get ready. A notification is sent: alias: 'Alert: Imminent Attack by Strategic Bombers' description: Send a notification when Tu-95 strategic bombers take off from Russian airfields. This means an attack by cruise missiles is imminent. Prepare a hideout. trigger: - platform: state entity_id: - binary_sensor.imminent_attack_in_war_monitor - binary_sensor.imminent_attack_in_operinform from: 'off' to: 'on' action: - service: script.announcement data: service: notify.all speak: false notify: true title: 'Bombers take off ðŸ›«' messages: - '{{ trigger.to_state.attributes.latest_message }}' Direct Danger AlertÂ¶ This is the most interesting sensor, which notifies me right when there's a direct threat to my location. Notification about direct danger When an attack happens at night, you need to decide: Are you going to the shelter to get a sleepless night somewhere in a basement or in the subway? Or are you going to stay in bed as long as possible to get some sleep, because you need to go to work tomorrow? Every normal person would go to the shelter. But when you live in these conditions for some time, you try to calculate the risk: You need to get proper sleep to be able to work. The air defenses are titans; they do their job excellently. Flying threats are getting shot down regularly. In Kyiv, the risk of a direct hit or hit by debris is relatively tolerable: I guess like being hit by a car (this estimate is completely unscientific!). If you are unlucky to catch a direct hit â€“ you are dead anyway. There's very little chance to survive that. If the missile/drone gets shot down nearby, the shockwave will blow your windows. So what do you do? It's up to you, but most of the time, I decide to sleep in bed. When things get hot, I hide in a bathroom so that when something blows up nearby, I will be behind two walls from glass shards and shockwaves. I have a sensor that watches for specific keywords like \"Kyiv\" or a neighborhood name, for \"warning\" or \"be in a safe place\" or \"fast target\". multiscrape: - name: War Monitor resource: https://t.me/s/war_monitor scan_interval: 5 list_separator: '|||' binary_sensor: - unique_id: danger_in_war_monitor name: Danger in War Monitor icon: mdi:rocket-launch device_class: safety select_list: '.js-message_text' value_template: >- {% set message = value.split(\"|||\")lastlower %} {% set in_kyiv = \"ÐºÐ¸Ñ—Ð²\" in message or \"ÑÐ²ÑÑ‚Ð¾ÑˆÐ¸Ð½\" in message %} {% set danger_now = \"ÑƒÐ²Ð°Ð¶Ð½Ð¾\" in message or \"ÑˆÐ²Ð¸Ð´ÐºÑ–ÑÐ½Ð° Ñ†Ñ–Ð»ÑŒ\" in message or \"Ð¿Ð¾Ð´Ð°Ð»Ñ– Ð²Ñ–Ð´ Ð·Ð¾Ð²Ð½Ñ–ÑˆÐ½Ñ–Ñ… ÑÑ‚Ñ–Ð½\" in message or \"Ð±ÐµÐ·Ð¿ÐµÑ‡Ð½Ð¸Ñ… Ð¼Ñ–ÑÑ†ÑÑ…\" in message %} {{ danger_now and in_kyiv }} attributes: - name: latest_message select_list: '.js-message_text' value_template: \"{{ value.split('|||')last }}\" When this sensor turns on, it means there's a direct danger to me and I should hide immediately. I send a critical notification, speak a danger message on speakers, so I can quickly wake up and go to the hideout. alias: 'Alert: Danger in Kyiv' description: Danger of missile/drone strike in Kyiv RIGHT NOW. Critical alert to hide immediately. trigger: - platform: state entity_id: - binary_sensor.danger_in_war_monitor - binary_sensor.danger_in_operinform from: 'off' to: 'on' action: - alias: Send a critical notification service: script.announcement data: service: notify.all speak: false notify: true title: Direct Danger âš  messages: - '{{ trigger.to_state.attributes.latest_message }}' notify_data: group: air-alerts push: sound: name: default critical: 1 volume: 1 - variables: messages: - Ð£Ð²Ð°Ð³Ð°! ÐŸÑ€ÑÐ¼Ð° Ð·Ð°Ð³Ñ€Ð¾Ð·Ð° ÑƒÐ´Ð°Ñ€Ñƒ! - Ð£Ð²Ð°Ð³Ð° Ð·Ð°Ð³Ñ€Ð¾Ð·Ð° ÑƒÐ´Ð°Ñ€Ñƒ Ð¿Ð¾ ÐšÐ¸Ñ”Ð²Ñƒ! - Ð£Ð²Ð°Ð³Ð°! ÐÐµÐ³Ð°Ð¹Ð½Ð¾ Ð¿ÐµÑ€ÐµÐ¹Ð´Ñ–Ñ‚ÑŒ Ð´Ð¾ ÑÑ…Ð¾Ð²ÐºÑƒ! - Ð£Ð²Ð°Ð³Ð°! ÐÐµÐ³Ð°Ð¹Ð½Ð¾ ÑÑ…Ð¾Ð²Ð°Ð¹Ñ‚ÐµÑÑŒ! - Ð£Ð²Ð°Ð³Ð°! ÐŸÑ€ÑÐ¼Ð° Ð·Ð°Ð³Ñ€Ð¾Ð·Ð°! - Ð£Ð²Ð°Ð³Ð°! ÐÐµÐ³Ð°Ð¹Ð½Ð¾ ÑÑ…Ð¾Ð²Ð°Ð¹Ñ‚ÐµÑÑŒ! - Ð£Ð²Ð°Ð³Ð°! ÐÑ‚Ð°ÐºÐ° Ð½Ð° ÐšÐ¸Ñ—Ð²! - service: media_player.volume_set entity_id: data: volume_level: 0.6 target: device_id: media_player.bedroom_homepod - alias: Speak in Bedroom service: script.announcement data: speak: true speaker: media_player.bedroom_homepod notify: false force_speak: true messages: '{{ messages }}' - delay: hours: 2",
    "commentLink": "https://news.ycombinator.com/item?id=40479729",
    "commentBody": "How Home Assistant is being used to protect from missile and drone attacks (denysdovhan.com)357 points by slovette 14 hours agohidepastfavorite135 comments supriyo-biswas 10 hours agoThe existence of this is fascinating and horrifying at the same time. I wonder how he tests it though; when writing tons of YAML for K8s or Ansible, you usually test it in a test environment before putting it in production. Unlike the other cases though, a bug in your YAML here can literally lead people to lose their lives. reply xyst 9 hours agoparentThe term â€œbattle testedâ€ is used literally here reply yard2010 8 hours agorootparentMade by the people from the trenches reply somethingreen 4 hours agoparentprevThe actual horrifying part is that this is more of a coping tool than a warning system, as its utility as the latter is limited even in Kyiv. If you are not at the point of accepting your fate, but have already given up on attempting to get to actual shelter, you can set this up and only hide from glass shrapnel for an hour when the cruise missiles and killer drones arrive instead of hiding for hours while they fly all over the country through the gaps of air defense. For anywhere closer to the frontline than Kyiv this is almost completely useless. Travel time of even non-hypersonic ballistics, hell, even of glide bombs is so short you'd be listening to your alarm and the sound of explosions almost simultaneously. reply import 8 hours agoparentprevMost of the stuff moved to UI already in home assistant and less than error prone compared the last reply yard2010 8 hours agoparentprevWelcome to the dystopian future timeline! It gets worse reply igammarays 9 hours agoprevTo see some statistics about the number and duration of air alerts in all regions of Ukraine, including number of media-reported explosions by region and time period, check out https://alerts.in.ua/en, they have a statistical summary section there. Click the hourglass button on bottom of the screen, then filter by time period. reply elric 11 hours agoprev> Home Assistant has a built-in Ukraine Alarm integration. It monitors the nation-wide system of air alarms and toggles safety sensors in HA. I don't know anything about the HA community, but I would be very wary of any new commits impacting this plugin... reply oaiey 10 hours agoparentConsidering they are running in thousands if not millions of homes, I hope they are anyway checking everything reply alias_neo 9 hours agoparentprevI'm not sure what your implication is exactly regarding the HA community, but that aside; I work in an industry that puts huge emphasis on the risks of software supply chain attacks; regardless of the community, in an ideal world, and in this situation, I too would be making sure any such code was very carefully reviewed by a trusted group of peers (including myself) and using signatures et al to ensure everyone is \"getting what they paid for\", so to speak. This might not be relied on to the extent people's lives depend on it, but if it's important enough to use, it's important enough to be sure. All of that said, it's easy enough for me to say when there isn't such a terrifying list of munitions raining down on my home when I'm trying to get some rest, so a simple step such as \"not updating from a known-good configuration\" might be enough. reply H8crilA 9 hours agoprevThe real question is why there isn't any official API that details the nature of the danger. You shouldn't have to scrape Telegram to figure out the type/speed of the air assault weapon, and the likely time on target. BTW, also check out Kropyva, it's like Uber for artillery strikes. Very helpful with deleting Russians. reply skjoldr 4 minutes agoparentThe chief reason is decentralization. Journalists who are updating these channels have their own sources in the Ukrainian air defense network as well as OSINTers who, for example, monitor Russian radio traffic using SDR, or even sometimes have people on the ground observing the take-off of planes in Russia and Belarus (horrifically dangerous, but there are ways to send this information somewhat safely; planes tend to be loud). If one of the journalists goes down for any reason, there will be other people writing updates. Each oblast also has their own channels where they announce attacks, some of them owned by the local administration, some by the emergency services. The air defenders themselves are a bit too busy to monitor and write this stuff; often, the best they can do is to write some short messages into a group chat or a Telegram bot before things go down, and even then, all parties involved have to balance providing an appropriate warning window with not letting the timing of this information to reveal the capabilities and locations of different kinds of Ukrainian observation stations. And this whole system has to be simple, since not every trained air defender is tech-savvy in general. Many don't know what an API even is. Many Ukrainians, too, wouldn't understand how to work with an API, but they can read the warnings in Telegram. Then there are the obvious security concerns, personal communications and group chat access can be vetted and it's hard to break the anonymity of Telegram channels from the outside to even be able to target their devices with cyberattacks. While an API must be open to the world, and thus it immediately becomes a target. It's a messy system but it works. Kropyva is not available to the general public and it's very far from the capabilities of similar NATO systems, its strength lies in the fact that it's an Android app that can be used on cheap tablets, so it doesn't rely on the military-industrial complex provided hardware, which is safer, but far more expensive. reply INTPenis 8 hours agoparentprevAny single API for this would be constantly attacked. They're distributing the attack surface by using other services. reply H8crilA 8 hours agorootparentLet's not exaggerate. There are APIs that distribute the list of oblasts (regions) that are deemed to be under attack (for example https://alerts.com.ua/). The only problem is that you don't know if the attack is expected in 10 minutes, or 6 hours, and this is something that the military intelligence has, and could share with a small amount of effort. They effectively already share it via people running those channels. Also, nothing stops you from redistributing the structured messages through multiple channels. reply withinboredom 7 hours agorootparentThe problem is that you let the enemy know the detail of your intel. Using compartmentalization, they can locate leaks and determine how you are getting the intel. As a military, you never want to give that away. Looking at WWII, the UK/US were able to decrypt messages daily from the Germans (thanks to Turing!), but they pretended they couldn't so the Germans wouldn't change their encryption scheme. reply sidewndr46 6 hours agorootparentThis is a significant mistelling of the history of the German \"Enigma\" device. Significant usage of Enigma was done during the war in a manner that was secure enough to prohibit interception. Turing's methods are brilliant as are the contributions of numerous other cryptographers. They relied on numerous operational failures of some branches of the military to be possible. So it was not from \"the Germans\", but from specific branches of the military that failed to follow already established best practices reply withinboredom 4 hours agorootparentI'm not sure what you mean. They used daily weather reports to decrypt the enigma for that day, so I'm not sure how that is an operational failure. If you know part of the cleartext, it's possible to brute-force any encryption given enough time. https://www.accuweather.com/en/weather-news/how-british-cryp... gives a pretty decent summary. reply H8crilA 4 hours agorootparentprevBut they already share it, just in a messy format. No need to philosophise. reply withinboredom 4 hours agorootparentI'm not philosophising, this was literally my job in the military and worked with a number of analysts who worked on this sort of thing. reply H8crilA 1 hour agorootparentI see, but this military does share this very information. reply withinboredom 1 hour agorootparentThey share enough information to be useful to the civilians but not enough information to show capabilities. If everything is automated, the enemy can subscribe to the automation and work out radar capabilities, response times, and accuracy. Those are all terrible things for an enemy to use and abuse. reply dewey 8 hours agorootparentprevNot sure outsourcing it to a Russia affiliated messaging app is the best choice then. reply kwhitefoot 2 hours agorootparentWhat would you choose? reply dewey 1 hour agorootparentNot an easy questions as it depends what's popular in the local market, you need to be where the users are even if you don't like it in cases like this. Telegram also has a great bot API, which makes it a harder sell to use alternatives (Signal, WhatsApp) or open technology like Matrix, where it's only useful for people that like to play around with technology and not regular people. reply ta1243 1 hour agoparentprev> it's like Uber for artillery strikes ... reply thefz 11 hours agoprevThe fact that this exists is at he same time chilling and inspiring. reply moffkalast 10 hours agoparentI didn't think I'd ever read a programming tutorial on string matching Tu-95 take-offs and Kalibr launches in anything but a fictional setting, holy shit it feels so surreal. Like a modding guide for Cold Waters or something. reply 5e92cb50239222b 9 hours agorootparentnext [4 more] [flagged] pjc50 8 hours agorootparent> Western media tend to portrait Israel in a negative light Western media bend over backwards to report the official Israeli spin on events as often as possible and they still end up looking bad, mostly because people can get information from non-MSM sources as well. The problem with the Palestine conflict is that there are way more than just two sides involved. People keep overlooking Iran. And the Syria disaster. reply moffkalast 8 hours agorootparentThe counterintuitive bit is that a lot of western support for Israel also comes from neo-nazis who see Zionism as a perfect way to effortlessly remove the Jewish population from their home country and move it to Israel, like it's some sort of faraway colonial gulag. reply tomNth 8 hours agorootparentneo-nazis like old-nazis were always anti-Zionism. reply dueyfinster 10 hours agoprevFascinating use of HomeAssistant. He mentioned uptime monitor in the next section - I wonder what he uses to ensure it stays online? I would guess some sort of UPS or battery backup. reply excieve 8 hours agoparentMost of us have something in place since the winter of 2022 when the power outages were systematic due to russian strikes on civilians and infrastructure, amplified by lack of air defence. Most of us needed to work though so some got UPS, EcoFlows, generators, solar systems, even DIY batteries if the budget is low. This year it's more of the same. reply Hamuko 9 hours agoparentprevI imagine UPS are necessary anyways in Ukraine since the power grid is getting constantly attacked. reply mfiro 9 hours agoprevUsing technology to improve lives is one thing, but using technology to survive missile attacks is just another level. Sometime I ask myself, will humans ever stop wars once and forever. reply EnigmaFlare 8 hours agoparentI don't think that would be stable. No war means losing the ability to fight which means eventually it'll be easy enough for just one small group to attack somebody much bigger but weaker. If war is solved by all attacked countries surrendering immediately so one aggressor rules the world, I'm sure factions would emerge within it who are competing for power again. Maybe a solution could come from some defensive technology permanently outperforming offensive technology? I think people would still find a way and the wars might be or begin by psychologically changing people's allegiances. reply kjkjadksj 6 hours agorootparentThe risk of war between sacramento and san fransisco is zero. I donâ€™t see why we canâ€™t make that true for the world over one day. reply sujal 9 minutes agorootparentHow about between Florida and New York? Or cities in red states vs their state government? Itâ€™s not zero anymore, especially when politicians challenging federal authority (eg Texas with border control) in obviously illegal ways. We have numerous examples - Jan 6th, the Bundy standoffs, Oklahoma City, the Black Wall Street bombings - the risk isnâ€™t zero. reply kwhitefoot 2 hours agorootparentprevIt's zero now. But if they ever find themselves in distinct nations then the odds will change. reply chgs 30 minutes agorootparentwars inside a single US city can be quite common, typically over â€œturfâ€ reply xyst 9 hours agoparentprevHumans are naturally inclined towards war or conflict. Itâ€™s our fatal flaw. reply JKCalhoun 7 hours agorootparentSeems to be just a few bad eggs that fuck it up for the rest of us. Everyone I know just wants to get along with their lives, deal with their own problems. reply Ylpertnodi 7 hours agorootparentprev>fatal flaw Enjoy your freedoms: paid for in blood. reply Ylpertnodi 7 hours agorootparentprev>fatal flaw Enjoy your freedoms: paid for in blood. reply egorfine 7 hours agoparentprev> will humans ever stop wars once and forever This is an overly broad and philosophical question. It's positioned far away. We could all get together for a cup of coffee and discuss this topic for ages. A more grounded and practical question would be: why didn't Biden stop the war? Now we're talking! One should expect lots of contradictory opinions, quite some hostility, a couple of MTG-like personalities with followers and of course this one specific comment downvoted to hell. But see, that's exactly the point: opinions vastly differ on the same subject depending on whether the situation is a hypothetical one far away or a physical reality. reply xyst 9 hours agoprevThatâ€™s wild. The amount of stress dealing with these attacks at any time of the day/night would likely age me by a decade. Then still expect to grind at work in a few hours or the following day. reply walterlw 5 hours agoparentIt is wild, has been since Feb 2022, it's also \"the new normal\" we really want to get out of. (Not desperately enough to give in tho). Also keep in mind that this is only one of the stressors associated with war. Others include hearing about civilian casualties every week, reading and hearing horror stories from people who escaped occupation or were liberated (e.g. Bucha, Kherson...), learning about friends and acquaintances falling in battle, military draft, uncertain, but likely dire future prospects and the list goes on. So yeah, days go like years. Don't repeat our mistakes and write to your representatives. reply nirui 10 hours agoprevIt's 2024, instead of riding our personal spaceships to habitat on Mars, we use Home Assistant software to alert us about incoming missile attacks. War is the single most unproductive activity humans can do. Sure, maybe Putin has his rationale, but spiting on a cake is never how one can secure the cake for themself, because guess what, others can also spit on it and then the cake is ruined. A greater leader knows that the only way to really solve a problem is to do something that adds (instead of removes) value, sadly some leaders never care to learn it. Rant aside, I want to ask a question: based on the article, it seemed that the system requires Telegram (thus Internet) and open source intel to work. Is it possible to make the system self-sustained? Is it physically possible to detect imminent attack based on soundwave/light signals? Because after the war started, Internet access maybe a difficult privilege. reply egorfine 7 hours agoparent> Is it physically possible to detect imminent attack Yes. Air defense does this pretty consistently. And then what? We (Ukrainians) have lost some components of the PATRIOT air defense system because we were out of interceptors. Imagine being an air defender on duty on the best hardware in the world, facing the missile incoming and being incapable of doing shit because you're empty because of... democracy. The very thing being protected right now from that specific missile. reply pjc50 8 hours agoparentprev> Because after the war started, Internet access maybe a difficult privilege. ? The war is on and people are continuing to use the internet. > Is it physically possible to detect imminent attack based on soundwave/light signals? You cannot hear a hypersonic missile coming. Horizons prevent you seeing it. You need to listen to the AWACS https://www.cbc.ca/news/world/flying-with-nato-awacs-1.66194... reply hcfman 8 hours agoparentprevNice to see people able to use tech to help reduce/manage their stress/trauma in such horrific situations. Good point about telegram. As much local control as possible is desirable. Do the text to speech interfaces work offline with the chosen devices ? If so, Iâ€™ll likely have a play. I have a project that might be able to help with your situation. A Raspberry Pi based sound localization system. Itâ€™s very accurate. Last weekend I localized an explosion (fireworks) to within 20m from the actual location with 4 recorders. two of which were 3km from each other. Unlike most ARUs (autonomous recording units) which are based on microcontrollers and need post processing to determine an event start time, the Pi system could be used as the basis for a real time localization system as the system times is sub microsecond accurate. With likely a small amount of new development and co-operation with your friends you could be alerted in real time when artillery or gunfire is getting close to you. Along with a map location of where it was fired from My license forbids government use (attaching consequences to the small developer unfriendly cyber resilience act that is stealing from small developers and giving to rich ones) but personal civilian use is just fine. https://github.com/hcfman/sbts-aru (PS. I agree on with the sentiments of the above authors about war. Itâ€™s sad that our governments instead of putting everything into driving to peace are spending our future climate change defence money on destruction and they are gunning for it with an insane appetite) reply palata 9 hours agoparentprev> War is the single most unproductive activity humans can do. Let's wait a few decades and see the results of global warming, shall we? reply toenail 9 hours agorootparentNot sure what you're trying to say. Global warming is a human activity, global warming is unproductive, global warming is caused by one human activity, that activity is unproductive? reply palata 8 hours agorootparentNot sure if you are writing this in good faith or not, but let me assume you are: The parent said \"War is the single most unproductive activity humans can do\", without giving much details about a metric (it is very productive if your business is to build weapons, but counter-productive if your business is to save lives). But assuming that the metric was something along the lines of \"doing good for society\", then global warming is a lot more counter-productive than wars. Global warming and wars are the result of human activities (in case that was not clear). So yeah, we would certainly save more human lives by keeping our wars (I mean, without nuking the whole planet) but working all together to reduce the impact of global warming. Meaning that IMHO, \"war is NOT the single most unproductive activity humans can do\". Not that it is good, quite obviously. Does that answer your question? reply mcfedr 9 hours agoparentprevSome of the telegram channels are government run, so it's not just open source intel Of course it would be possible to detect these things yourself, you would just need an extensive radar network covering 600k km2 of Ukraine, and as much of Russia as you can. You'll need quite a variety of systems to detect both hypersonic missiles and slow low flying drones. reply afiodorov 9 hours agoparentprev>spiting on a cake is never how one can secure the cake for themself, Not sure the analogy holds, Putin got a slice for himself and spits on the rest. > War is the single most unproductive activity humans can do. This war is a conflict about values; conflicting sides think human lives are worth sacrificing for the values let alone economical output. reply exe34 10 hours agoparentprev> War is the single most unproductive activity humans can do https://science.howstuffworks.com/war-drive-technological-ad... war leads to technological progress. peace leads to kerfuffles over pronouns. reply multjoy 9 hours agorootparentDirected with unerring accuracy by Moscow specifically to seed discord and division. The idea that this the inevitable direction of peace ignores the fact that the rise of the so-called culture war is part of an asymmetric conflict. reply exe34 9 hours agorootparentthat's exactly what Moscow would say. reply onethought 8 hours agorootparentMoscow would freely admit they are driving the culture war? Can you cite that? Either way, arenâ€™t you disagreeing with your own statement. What youâ€™re really saying is Russian disinformation is effective. reply kome 7 hours agoprevTelegram and its channels has been such a life saver for many, and a huge resource for the press as well. It is interesting how it is used here. I bet Russia state actors would pay a lot to controls or infiltrate those channels. reply mirekrusin 11 hours agoprevWhat a humanity fail that stuff like this is happening. reply mschuster91 10 hours agoparentnext [72 more] [flagged] yard2010 8 hours agorootparentSo does hitler. Every century we have that specific shitty decade with these specific evil shitheads reply throw38228374 10 hours agorootparentprevWe already have dozens of military bases surrounding China. There's not much more to do since China is not currently attacking foreign soil. reply victorbjorklund 10 hours agorootparentThey are indeed violating other countries waters though. reply dgoldstein0 9 hours agorootparentAnd how would you propose deterring them from doing this while also avoiding escalation? reply wood_spirit 9 hours agorootparentIsnâ€™t history showing that letting aggressors nibble away at norms and borders and letting them get away with it â€˜to avoid escalationâ€™ is just emboldening the aggressor? Peace in our time. reply waffleiron 9 hours agorootparentSo countries should have attacked the US when it committed it's illegal wars in the middle east, to stop emboldening the aggressor? I don't think that would have created a better world. It's easy to say things like this about your geopolitical enemies, but allies get away with it all the time. reply tomohawk 8 hours agorootparentIraq attacks and takes over Kuwait. And then threatens to invade Saudi Arabia. But US the the 'aggressor' for rolling this back? And the US gets many allies and works through the UN to do this, but it is somehow 'illegal'? It sounds like in your perfect world, Saddam keeps Kuwait, also gets Saudi Arabia, and the US just sits on its hands after terrorists kill thousands in NYC because being 'aggressive' is always bad no matter what. reply ajuc 9 hours agorootparentprevSanctioning US back then would be interesting. BTW war in Afghanistan wasn't illegal. reply globalnode 7 hours agorootparent> BTW war in Afghanistan wasn't illegal. and why do you say that? reply ajuc 1 hour agorootparentBecause UN approved it. reply pydry 8 hours agorootparentprevSanctions barely work even if you ARE the world hegemon. In Iraq they just made Saddam's position even more secure while killing a million children. Aginst Russia they backfired spectacularly because Putin had prepared better for the sanctions contingency than Europe did. I'm struggling to think of an example where they actually led to the desired outcome. reply FredPret 5 hours agorootparentIt played a major role in ending apartheid though it took decades and there were also other factors at work - the Berlin wall fell. reply ajuc 1 hour agorootparentprevSanctions work on the timescale of decades. They cut your GDP growth by 1-2 percent points. After 50 years you become North Korea. Let's see if Russia is a problem in 50 years :) reply pydry 1 hour agorootparentThe sanctions cut GDP growth and pushed up inflation in the first year, but that stabilized well over a year ago. Russian growth is now 5.5%, higher than all Western economies. It's difficult to see what sanctions would do that they haven't recovered from already. reply ajuc 1 hour agorootparentThis is just military production. It's like the growth you have when a hurricane destroys a city and you have to rebuilt it. It doesn't accumulate, it's just a waste. BTW look up North Korean economy growth after the war :) North Korea was always the rich part. It was developing so fast after the war. And somehow now the South Korea has Samsung and Kia and Subaru, and North Korea has starvation. https://www.researchgate.net/profile/Keun-Lee/publication/22... reply globalnode 7 hours agorootparentprevpalestine would like a word with you. reply pydry 8 hours agorootparentprevIt also showed us that you shouldn't support Nazis, but in Ukraine Right Sector and Azov have our full backing. I also showed us that stopping genocide matters more than anything - more than national borders, but we still support Israel's genocide. reply GordonS 6 hours agorootparentMembers of the Neo-Nazi Azov battalion were hosted in the British parliament just a few days ago. My jaw literally dropped when I saw the photo of bumbling buffoon Boris Johnson standing with them. reply onethought 8 hours agorootparentprevSo we should tell the US to stop driving its ships and planes right on the Chinese border? And directly through the Taiwan strait. Who is the aggressor in your mind here? Note: China donâ€™t have any military assets off the US west coastâ€¦ meanwhile then US has multi thousands of soldiers within staging distance of Chinese coast line from the very bottom to the very top. reply _djo_ 3 hours agorootparentUS ships and aircraft stay in international waters and airspace near China, or in the territorial waters and airspace of allies who give it permission. That includes the Taiwan strait. Allowing China to prevent US or other aircraft to operate in such international waters or airspace would amount to giving them control over it, which is why itâ€™s important to have regular freedom of navigation sailings and flights. Chinese ships and aircraft are violating the territorial waters and airspace of other countries in the region, especially in the South China Sea. Itâ€™s annexing territory that belongs to other countries. Itâ€™s not at all the same thing. reply mschuster91 8 hours agorootparentprevShow of force, easy as that. Pirates get deterred when cargo ships have gunmen armed to the teeth with AK-47 and look for easier targets, Russian ships get deterred from Ukrainian autonomous naval drones, and China gets deterred if random fisher boats get escorted in their territorial waters by an US carrier group. reply ajuc 9 hours agorootparentprevThe problem is that avoiding escalation with an imperialist dictatorship IS escalatory. If NATO escalated a little more in 2008 - hundreds of thousands of people in Ukraine AND in Russia would still live. Instead we made Putin think he can get away with it. reply sureIy 7 hours agorootparentprevThey are. Check the Spratly islands. They may not be â€œcertainlyâ€ owned by a specific country, but theyâ€™re definitely not Chinaâ€™s given the distance. reply rfoo 7 hours agorootparentI checked (for those unfamiliar with western terms, this is å—æ²™è«¸å³¶) and it seems like Taiwan also has territory claims there, does it mean Taiwan is also attacking foreign soil right now? reply sureIy 4 hours agorootparentTaiwan is not building cities on the islands. China is. Theyâ€™re also attacking Philippines vessels that come nearby reply blitzar 6 hours agorootparentprevChina Wants War: Look How Close They Put Their Country To Our Military Bases reply smolder 9 hours agorootparentprevWhat would you do? Install a favorable dictator? Thanks to warmongering there isn't much of a diplomatic route to peace where we still need it. Petty ulterior motives held by world 'leaders' have made it hard. reply pjc50 8 hours agorootparentMuch more international response (sanctions) to: https://en.wikipedia.org/wiki/Poisoning_of_Sergei_and_Yulia_... in 2018. https://www.bbc.co.uk/news/world-europe-28357880 MH17 shootdown in 2014. and in the UK, https://www.bbc.co.uk/news/uk-politics-62068421 \"Controversy surrounds that appointment, since it was alleged - first in a Tortoise Media podcast and then in the Sunday Times - that the peerage was granted despite a warning from the security services that it posed a national security risk.\" People were very happy to overlook Russian misbehavior so long as the money kept coming. reply mciancia 9 hours agorootparentprevA ton more sanctions, becoming less dependand on russian oil and gas, killing nordstream. But in 2014, not 2022. Probably would have helped reply jakjak123 8 hours agorootparentSome form of action should have been taken when they invaded Crimea in 2014 and Georgia 2008. But even in retrospect its hard to say what except shutting down Nordstream and stopping investments. I still find it difficult for Europe to accept going to war with Russia over Crimea, but I guess this timeline is worse. Sanctions has limits, like we see with North Korea and Venezuela. The worst part of this timeline is that we guarantee that the only way a autocrat is safe, is when he has nukes. reply ivan_gammel 6 hours agorootparentprevIn 2024 itâ€™s pretty clear that sanctions ag reply 5e92cb50239222b 9 hours agorootparentprevWell, the EU could have put a ban on selling riot control gear to Putin's forces back in 2012 when he used it to suppress massive pro-democracy protests in Moscow, not in October of 2022 like they actually did. This set the tone for everything that happened afterwards. I said this already under a (now flagged and dead) comment, but it's worth repeating â€” \"your\" (not your personally) one-sided propaganda and continuing support for Putin (if indirect) have made \"you\" lose whatever anti-war and pro-West opposition there was in Russia. I only wish we'd seen how convenient Putin is for \"the West\" a decade earlier. This was particularly obvious in June 2023 during the short and failed putsch of Wagner PMC. If you care at all, you can dig into my comment history from the beginning of 2022 and see how my own opinion has changed. It's a pretty typical example, I think. https://russiafossiltracker.com reply pas 9 hours agorootparentprevpeace unfortunately is made by deterrence. defending the potential victims of aggressors works. reply mschuster91 9 hours agorootparentprev> What would you do? Install a favorable dictator? Oh, there's a lot between not doing anything at all and repeating the mistakes from Iranian days: - provide economic / humanitarian aid contingent on progress in democratic values and actually audit where the money goes. This ended being effective around 2010 when China began hitting the global stage though. - supporting countries or democratic, pro-Western parties/groups that are threatened by an aggressor (e.g. every former Soviet state) - when supposed \"allies\" end up funding our enemies (e.g. Saudi-Arabia, who not just financed Bin Laden and is the main ideological driver in fundamentalist madrasas (religious schools) all over the world, thus being the main contributor to Islamist terrorism), cut them off. Hell the Saudis butchered a journalist (a father of U.S. citizens) in an embassy and we didn't do shit. Instead, we allow Saudi-Arabia and Qatar to host fucking World Cups. What a bunch of bullshit. - aggressive, actually effective sanctions instead of just making the lives of a few oligarchs a tiny bit more difficult - increase our own security posture in terms of military and provide a credible retaliation threat towards any potential aggressor - invest into academic research on other countries. That one got shamefully disbanded after the collapse of the USSR and the shift towards prioritizing STEM over humanities - we now lack the academic capacity for actually understanding other countries or provide actual evidence-backed advice to politicians. Instead we got completely dependent on think tanks and consultancies. - respond in-kind to Russia and China banning Western activities: they effectively force pro-democracy organizations to close shop? Fine, no more Chinese police stations in Western countries. They engage in cyberwarfare? Fine, we cut them off from the Internet. They refuse to allow Western countries fair and equal access to their markets? Fine, we ban investments from China and force-divest existing investments, and raise tariffs on their exports. The last part is the easiest... over decades we believed in \"change by trade\", we hoped that they would become similar to us culturally. That worked in certain areas - McDonald's and Coca-Cola show that - but politically, we didn't give a slightest interest in both countries getting ever more authoritarian. And now it's biting us in our collective arses. reply 5e92cb50239222b 8 hours agorootparent> supporting countries or democratic, pro-Western parties/groups that are threatened by an aggressor (e.g. every former Soviet state) Every one? I am from one of those states, and most of them are even worse democracy-wise than Russia. The only thing we have over Russia is not going after neighbors' territories, and even that's debatable (see conflicts between Armenia and Azerbaijan, Kyrgyzstan vs Tajikistan). Your governments do overlook serious human rights violations, though, when it suits them. We had widespread protests in January 2022 that were brutally suppressed by the government, which ended up killing more than 300 protesters (that's according to official figures that are thought to be undercounted). No fucks given by Western propaganda or government talking heads because several European, US, and Canadian companies have massive investments in our oil, gas, and minerals industry. About six months ago Macron visited Astana to beg for uranium fuel after France got kicked off from Niger, and a group of political activists tried to seize the rare moment and did everything they could to meet him for a few minutes and talk about human rights violations in our country. You can probably guess the result of that endeavor. One of the major gas projects (managed by Shell IIRC) ends in 2030, and I have a strong suspicion \"human rights violations\" will become a permanent theme in our relations right after that moment. reply mschuster91 8 hours agorootparent> Every one? I am from one of those states, and most of them are even worse democracy-wise than Russia. I agree, and part of the cause is that us Western countries don't give a shit. We don't even give a shit about those countries right on our border like Ukraine or Bosnia. > No fucks given by Western propaganda or government talking heads because several European, US, and Canadian companies have massive investments in our oil, gas, and minerals industry. Or because they were bought off such as in the case with the massive corruption by Azerbaijan. > About six months ago Macron visited Astana to beg for uranium fuel after France got kicked off from Niger, and a group of political activists tried to seize the rare moment and did everything they could to meet him for a few minutes and talk about human rights violations in our country. You can probably guess the result of that endeavor. My opinion of Macron is probably just as low as yours, the only thing the guy can do is talk. All talk, no act. reply vladms 7 hours agorootparent> Western countries don't give a shit People talk too easily about countries as if they are a person. I have lived in the east, I have lived in the west: every actual person has problems, everybody thinks their problems should come first, too many people have the tendency to think \"outside influence\" is very strong and lots of people think they have \"the solution\" which is different than what their government does. At the end of the day I think the (boring) truth is that many countries end acting similarly to the average citizen. Including their fears, stupidities, insecurities and knowledge. Yes, \"the west of Europe\" does not care as much as some people think about \"the east of Europe\", same way \"the east of Europe\" does not care that much about I don't know, Yemen, Myanmar or Sudan (just to name places with horrible conflicts that nobody seems to care about, unless they delay their Amazon package by a couple of days...). reply 5e92cb50239222b 8 hours agorootparentprevEh, it wasn't as much a jab against France or Macron in particular, as just an example of the general policy. Pretty much all of Europe (and US, and Canada) behave in a similar way and see us as a well of natural resources to be scooped out dry and then thrown aside. Some people here call it a new form of colonialism. Every country follows their interests and that's fine, as long as we don't hear lectures about this or that thing while those same lecturers behave in a hypocritical way contrary to what they're saying. Edit: as opposed to China and Russia that pour serious money into large infrastructure projects like the new Silk Road. Russia has only started doing this recently, though. People have their reservations about those countries, but can't help but see the difference between e.g. China that builds railroads and power plants, and Western countries that only suck out money, paying tiny salaries to local workers and circumventing things like air pollution regulations. reply ajuc 9 hours agorootparentprevAccept Ukraine to NATO in 2008 and none of this would have happened. Thank France and Germany for blocking it. reply pjc50 8 hours agorootparentAs well as not building either Nordstream, but who can turn down cheap energy? reply tomohawk 8 hours agorootparentprevThings I would not do. Basically anything that Joe did, do the opposite. In 2014, when Joe was VP and lead person on Ukraine, I would not have refused to give lethal aid to Ukraine. And when Ukraine used our training to try to take back Crimea, I wouldn't have chastised the Ukraine government for trying to resist Putin. When Putin built up forces on Ukraine's border to restart hostilities in 2021/2022, I would not have cowardly evacuated all US personnel from the country. I would have surged more in to deter. When Putin restarted invasion in 2022, I would not have conditioned lethal aid on not shooting across border, tying Ukraine's hands. Instead, I would have conditioned it on attacking any military or military supporting targets anywhere in the theatre of war. Since Russia has defined the boundaries of this as well within their country, they only have themselves to blame for how deep these weapons would reach into Russia. Then we wouldn't have the ridiculous situation we just had where Putin was able to get his forces ready for the Kharkiv offensive in plain view, but Ukraine was not allowed by Joe to attack them until they actually started crossing the border. reply onethought 8 hours agorootparentprevOr â€œwe should have stopped the USâ€? reply GordonS 8 hours agorootparentprevnext [21 more] [flagged] IsTom 8 hours agorootparentThere was a peace deal before (Minsk agreement). Agreements with Russia are not worth the paper they're signed on. Any peace deal Putin is willing to sign is just to consolidate his gains and get more time to prepare for another attack. reply GordonS 8 hours agorootparentnext [11 more] [flagged] snowpid 7 hours agorootparentThere as no coup. Selensky won a free election against Poroshenko (you know the guy, who was after the maidan revolution). Just ask random Ukrainans. reply GordonS 7 hours agorootparentNo coup? Perhaps you'd be more comfortable with the verbiage \"CIA-backed uprising/revolution\" then? reply numpad0 6 hours agorootparentIt'll make interesting Hollywood movie, but not going to matter when it's Russia invading Ukraine. US is going to let both collapse then rebuild New Ukraine where it is, and it'll be 100% Western country because of that. Plus few more around. All because of Russian footgun. reply snowpid 7 hours agorootparentprevI like to call it people's revolution. You can go to Ukraine and ask the people around what they think about the Euromaidan instead of reading conspiracy theories from Russian propaganda. reply vladms 7 hours agorootparentprevThe thing is he planned an invasion for a long time, and failed quite badly at it - the first weeks there was barely any aid to Ukraine and still Ukrainians managed to push the Russians back. This is not that much about US or Russia interests, but about Ukrainians and they are currently fighting the Russians for 2 years. Implying they have no choice or they are only manipulated seems more like propaganda (will let the reader decide for whom). Many east Europeans still have memories about what it meant to be under Russian influence and oh boy that was shitty... No need for propaganda there. US and Russia made aggression wars, but while they imagine they are \"world powers\" they don't seem to have a great track record unless the population in that country does not firmly oppose (just the most obvious examples: Afghanistan - couple of times each, Vietnam, Ukraine) reply JKCalhoun 7 hours agorootparentprev> I mean, imagine if Brazilian intelligence backed a coup in Mexico, then built several military bases, intelligence bases and black sites across the country, then used them against US interests. So you're saying the US would invade Mexico in that case? reply GordonS 7 hours agorootparentYou honestly don't think they would? Mexican passports carelessly left at the site of a \"terror attack\" should provide all the cover they need. More likely though, they'd destroy the country in a more surreptitious way, such as funding drug cartels and revolutionaries. reply mopsi 7 hours agorootparentprevThere was no \"CIA-backed coup\" in Ukraine. A president that caved in to Russian pressure to back out of tighter economic relations with the EU saw massive protests in response, ordered to shoot protesters, killed over a hundred of them, and then fled the country when he understood that he would be facing criminal charges. Ukrainian parliament deposed him with votes 328-vs-0. Even members of his own party voted against him. The joint spy bases were established after Russia invaded Ukraine to monitor what's going on in the invaded parts of Ukraine. > I mean, imagine if Brazilian intelligence backed a coup in Mexico, then built several military bases, intelligence bases and black sites across the country, then used them against US interests. Would the US really put up with that? Should they? The hypocrisy is real. Imagine if the United States invaded Sonora and Baja California under the excuse that they're protecting Americans there, looted factories and other businesses, established concentration camps, tortured and executed anyone who resisted, forced millions to flee their homes as refugees and gave their property away to settlers from landlocked states of the US (\"I've always wanted to live by the ocean!\"), and started forcibly conscripting all Mexican males from Sonora and Baja California into fighting against the rest of Mexico. And imagine that you blamed Mexico and its allies like Brazil for propping up defenses along the remaining border. A bit insane, don't you think? reply GordonS 7 hours agorootparentThere was indeed a CIA-backed uprising[0], and CIA bases were in Ukraine long before the 2022 Russian invasion. [0] https://www.realclearinvestigations.com/articles/2024/04/30/... reply mopsi 2 hours agorootparentNo there wasn't, and the article you linked is from one of those bottom-feeders who keeps circulating long-debunked anti-American conspiracy theories. And the NYT article you linked earlier says that CIA provided instructors for Ukrainian commandos in 2016, which is two years AFTER Russia invaded Crimea and Donbas in 2014. 2022 was only a renewed assault on Ukraine. reply seszett 8 hours agorootparentprev> What are they actually doing wrong on the world stage Threatening their peaceful, democratic and de facto independent neighbour, Taiwan, might count. They're doing it right now, encircling the island with military vessels. I don't know which government is yours, but in Taiwan there's no need for any FUD, China does everything it can to make people fear it. reply Kiro 7 hours agorootparentprevI've seen you touting your opinions as \"the world waking up\" but I hope the downvotes make you realize that they are in fact not representative, no matter how much your TikTok bubble tells you otherwise. reply GordonS 7 hours agorootparentYou think no opinion is valid unless it matches your own? I've never used TikTok in my life. reply Kiro 7 hours agorootparentThat's what you seem to think, when in reality your opinions are extremely controversial. I don't really need to argue about this. The downvotes and flags speak for themselves. reply GordonS 7 hours agorootparentAny opinions/arguments that go against government narrative are going to be controversial - it doesn't mean such arguments should be dismissed out of hand. FYI, you are breaking HN rules by talking about downvotes. reply Kiro 6 hours agorootparentThen don't go around claiming that your opinion is representing the majority. Good try but you're breaking the guidelines by instigating, starting flame wars and fighting ideological battles. reply GordonS 6 hours agorootparentI didn't claim that my opinion was representing the majority, you've just made that up. I can see that you are trying to start a flame war, so I won't be discussing this topic any further with you. Good bye. reply mschuster91 8 hours agorootparentprev> And please stop spreading anti-Chinese sentiment - it's bordering on racism. When was the last time China invaded another country? What are they actually doing wrong on the world stage, other than being more economically powerful than the US? There's boatloads of evidence of Chinese fishing fleet fishing illegally (and way too much) even as far away as Africa [1]. Then there's the constant saber rattling around Taiwan, going as far as to \"punish\" Taiwan for having a clean, fair election just recently. And then there's the territorial takeover of Philippine land [2]. [1] https://www.economist.com/middle-east-and-africa/2024/04/11/... [2] https://fsi.gov.ph/philippines-china-relations-beyond-the-te... reply GordonS 8 hours agorootparentChina is hardly unique in fishing waters they aren't meant to. Plenty European countries, including France and Spain, have been doing that kind of thing for decades. But the west isn't (literally!) up in arms over that; all the anti-Chinese rhetoric spewed forth by the five eyes is transparent BS, likely designed to manufacture domestic support for when the US decides China needs some \"good ole US democracy\". China building small bases in disputed territory is slightly concerning, but given how the US builds bases all over the world, it feels deeply hypocritical for the US to complain about China enhancing it's defencive posture - especially with all the anti-Chinese sentiment coming from US Congress. BTW, I liked your \"boatloads\" pun :) reply lionkor 10 hours agorootparentprevnext [10 more] [flagged] juliushuijnk 10 hours agorootparentThe invading country is as much at fault as the country being invaded? So I guess someone can claim a room in your house, and you should then negotiate. reply lionkor 4 hours agorootparentthe conflict did not start with invasion reply Luc 10 hours agorootparentprevShameful opinion. reply lionkor 4 hours agorootparentI don't really get that; did you try to understand my current before commenting, like the HN guidelines suggest? You seem to assume the worst and seem to be disregarding my opinion because of that reply lawn 10 hours agorootparentprevWhat a stupid and ignorant take. Russia is invading, murdering, torturing and committing genocide. The only thing a \"peaceful resolution\" would accomplish is: 1. Show Russia that aggression is profitable. 2. Give Russia time and opportunity to prepare for the next attack. Russia doesn't give a rats ass about any promises they make and they can and will break every single one of them if they can profit from it. reply lionkor 4 hours agorootparentare you ignoring years of conflict before the invasion on purpose, to help your argument? reply lawn 1 hour agorootparentAre you paid to promote Russian propaganda or are you just a useful idiot? reply V__ 10 hours agorootparentprev\"The rape victim never accepted a peaceful surrender to the rapist, she is just as much at fault.\" This is how you sound. reply lionkor 4 hours agorootparentIt seems disingenuous to compare a complex war with multiple participants and over more than 10 years with something as clearly one sided as rape reply snird 10 hours agoprevnext [3 more] [flagged] victorbjorklund 10 hours agoparentRussia are the ones bombing both Syria and Ukraine. And no I dont feel sorry for Iran who are the ones helping Russia bomb Ukraine. Both Iran and Russia have blood on their hands. reply af78 10 hours agoparentprevnext [2 more] [flagged] jedimind 9 hours agorootparentHistory did not start on Oct 7, that's deceptive framing. Before Oct 7, Israel was already murdering more Palestinian children. That's the main difference. 5 Feb 2024 â€” At least 507 Palestinians were killed in the West Bank in 2023, including at least 81 children, making it the deadliest year for Palestinians since the United Nations Office for the Coordination of Humanitarian Affairs (OCHA) began recording casualties in 2005. [https://www.amnesty.org/en/latest/news/2024/02/shocking-spik...] reply 10 hours agoprev [2 more] [dead] zakki 10 hours agoparent [â€“] I think Palestinian has simpler need. How to monitor if the gate is wide-opened or not. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author uses Home Assistant to monitor air alerts and threats in Ukraine, sending critical notifications via smart speakers.",
      "Various applications and Telegram channels track different types of attacks, including MiG-31K jets, suicide drones, and ballistic and cruise missiles.",
      "Automations notify the author of imminent threats, such as Tu-95 bombers taking off, helping them decide whether to seek shelter or continue daily activities."
    ],
    "commentSummary": [
      "The discussion focuses on the use of technology in conflict zones, particularly in Ukraine, where Home Assistant is employed to monitor air alarms and safety sensors against missile and drone attacks.",
      "The conversation also examines the role of decentralized information networks and simple communication methods like Telegram for timely threat updates, while balancing operational security with civilian safety.",
      "Concerns are raised about the security of single APIs and the use of Russia-affiliated apps, with alternatives like Signal and WhatsApp mentioned, alongside broader debates on the dual-edged nature of technology in war and geopolitical tensions."
    ],
    "points": 357,
    "commentCount": 135,
    "retryCount": 0,
    "time": 1716696601
  },
  {
    "id": 40480056,
    "title": "Hurl: A Unique Language Using Exception Handling for Control Flow",
    "originLink": "https://hurl.wtf/",
    "originBody": "Hurl, the Exceptional language Hurl is a language created for one purpose: to explore a language based around exception handling as the only control flow. It was sparked from conversations between Nicole Tietz-Sokolskaya and friends from Recurse Center whose identities will be withheld for their dignity. This site contains documentation around how to use Hurl. It also provides some examples and guidance for debugging and answers questions. Praise for Hurl It comes highly endorsed: I, uh, have changed my mind about ever implementing a language based on Hurl. This monstrosity is beautiful, and I must never touch it. I don't want my name associated with this in any way1. -Erika Rowland Unfortunately, I decided to make this language a reality. I'm sorry. -Nicole Tietz-Sokolskaya is \"ðŸ¤®\" an available quote? -Mary McGrath Certified unhingedâ„¢! -nate (@nmoo@mas.to) To add more praise, email Nicole (please include positive consent to include said quote on this site). Source code The source code for Hurl and for this site are both available in Hurl's repo. Emailed patches are welcome if you find a bug or an error, but you'll need to sign over all rights to the patch: I need to preserve the ability to relicense this and license it commercially. Licenses For this project, I considered joke licenses and unfortunate licenses. Ultimately, this software is licensed under the following three very serious licenses: Under AGPL-3.0 Under GAL-1.0 (Gay Agenda License) Under a commercial license You may use the software under any one of these licenses, without regard for the others. 1 Erika did consent to posting this and provided it in its current form. If someone actually does not want their name associated, I would not include it.",
    "commentLink": "https://news.ycombinator.com/item?id=40480056",
    "commentBody": "Hurl, the Exceptional Language (hurl.wtf)226 points by todsacerdoti 13 hours agohidepastfavorite82 comments z3t4 9 hours agoFor anyone designing a programming language, enforce namespace to includes/imports! and if possible, don't allow top level side effects. let foo = include \"lib/foo.hurl\" foo.init() it's much easier to reason about then, for example: include \"lib/foo.hurl\" // side effects baz(buz) // function and variable that I have no idea if they are in the standard library, or included *somewhere* That way it's much easier reply remram 4 hours agoparentPreferably enforce that the namespace matches the include/import statement, if the statement doesn't use an explicit name binding... import \"foo/bar\" should make foo.* OR bar.* available, not bazz.*. I'm looking at you, Go. reply amscanne 0 minutes agorootparent> I'm looking at you, Go. Iâ€™m so confused by this. Unless you use a dot import, isnâ€™t this just bar.*? reply mikepurvis 3 hours agorootparentprevPython has this in a slightly different spot. Most pypi packages have the name and module aligned but itâ€™s only a matter of convention, and there are some common deviations like the pyyaml package providing the yaml module. reply d-z-m 3 hours agorootparentprevThis is normally how it works, no? reply BoppreH 6 hours agoparentprevThis also allows one to pass parameters to `foo.init()`, something you cannot do with naked imports. reply Joker_vD 6 hours agorootparentimport foo(42, FULL_OF_EELS) as foo -:1:8: E0012: Initializer of module \"foo\" has 3 arguments, 2 were provided. reply Wonton56 2 hours agoparentprevI do not disagree, but I use IntelliJ for work and it shows clearly where some reference is imported from and let you navigate to it with a shortcut. VSCode does similar things with plugins and LSP, just much worse. I cannot work in VSCode because navigating code is so slow. Is this suggestion only useful when you donâ€™t have such tools? It seems impossible to me that people can live without them, at least in a professional setting. reply sspiff 2 hours agorootparentLet's not write software and especially programming languages which assume or depend on users having access to advanced tools that require a monthly subscription. reply kwhitefoot 2 hours agorootparentprev> I use IntelliJ for work and it shows clearly where some reference Useful when writing the code but not much use when reading the code. reply moomin 9 hours agoparentprevI mean, itâ€™s a language based around exceptions for flow control, I think the â€œeasy to reason aboutâ€ ship has sailed. (Donâ€™t confuse this with me thinking this project is worthless, I think itâ€™s art.) reply andypants 7 hours agorootparentThe imported files should really hurl their exported functions, and the importer needs to catch it into a variable. reply ntietz 3 hours agorootparentThatâ€™s a great idea. Iâ€™ll have to do that for the next version. reply fmbb 6 hours agorootparentprevOh, dependency injection? reply cobbal 5 hours agorootparentMaybe even dependency ejection. reply kdmccormick 6 hours agorootparentprevHa! reply groestl 7 hours agorootparentprev> I mean, itâ€™s a language based around exceptions for flow control, I think the â€œeasy to reason aboutâ€ ship has sailed. Sometimes I wonder if I'm exceptionally (haha) talented as I personally find the impact of exceptions on flow control pretty easy to grasp. But based on my understanding of other advanced computer language concepts, which is pretty lacking in some regards, I come to the conclusion that it can't be too hard, and people make a lot of fuss about it for no particular reason. reply eyelidlessness 3 hours agorootparentItâ€™s largely difficult because either: - youâ€™re working in a language that doesnâ€™t have checked exceptions, so the set of potential errors and the set of potentially error-raising calls is infinite but unknowable - youâ€™re working in a language that has checked exceptions, and you hate that it makes you do work, so you catch-rethrow runtime errors that recreate the first scenario - youâ€™re working in a language that has checked exceptions, but someone else did the second scenario so youâ€™re in the first scenario anyway reply groestl 3 hours agorootparentOther programmers tend to be bad at reliably cleaning up resources such as file handles, locks etc, so I need to inspect the whole invocation tree anyways to have an understanding of what runtime implications I've summoned by invoking other people's code. As for myself, I've lived through the hell that are checked exceptions in Java. You learn that compositionality and checked exceptions are at odds when you try to insert a remoting layer into an application that has grown without IOExceptions. Then you learn that it's actually not necessary to know the set of possible errors, just make sure that you're not a bad programmer as in my first paragraph, and everyone will be fine. This is also something that you can learn from Exceptional C++. reply fiddlerwoaroof 1 hour agorootparentYeah, Iâ€™ve never understood the complaints about exceptions either: most of the time you want the exceptions to just bubble up anyway because, in that case, you only have to think about the contracts of the functions you interact with and not about the unusual states you might be in. Return-type or return-value based error handling has always seemed to me to be significantly worse. reply xboxnolifes 3 hours agorootparentprevThe unchecked exception example doesn't seem any different than using a dynamically typed language and reading return values, and exceptions seem to get significantly more hate than those. reply eyelidlessness 3 hours agorootparentBecause even in a dynamically typed language you can generally go look at what the function returns. You canâ€™t look at what it throws without walking the entire call stack and inspecting the source code of the runtime. reply retrac 3 hours agorootparentprevFlow control involving recursion is already well into the weeds. Recursion and exceptions is probably a nightmare for someone not fond of ML or Lisp. reply groestl 1 hour agorootparentBut why? I don't get it. You call something. It can break. It will break. Treat it as such wrt to resources you've allocated. You can ignore error details here. At the highest level of your application (and at a few critical places, executors, retrying strategies etc) handle all the exceptions you know of, and implement a sane default for everything you don't know. Done. reply infogulch 9 hours agorootparentprevI agree, side-effecting imports add to the spooky action at a distance aesthetic. reply karma_pharmer 8 hours agorootparentprevi think you mean to to say \"has sunk\" reply zeroCalories 8 hours agoprevI've always kinda hated exceptions as it makes the contract between a caller and a callee hard to determine, and makes your code highly coupled. I prefer the Go or Rust style of handling it through return values. Briefly skimming the language, I'm not sure if there is anything that fixes that? I think this kind of model could be cool if your IDE could dynamically determine all uncaught exceptions for a function, and lets you jump to each possible place where the exception could be thrown. Not sure how you handle coupling though. This seems like it would result in an insanely volatile control flow graph. reply mbmjertan 7 hours agoparentThis is what IntelliJ does for Java. A problem is reported whenever you have a function that throws exceptions and isnâ€™t caught in a caller anywhere in the project, and you can jump to implementation or calls easily. However, exceptions that a function can throw are part of the function signature in Java unless they extend RuntimeException (and in that case your program wonâ€™t compile if you throw an exception without adding it to the signature). While the circumstances in Java make it much easier for IDEs to report uncaught exceptions, itâ€™s a solvable problem for non-runtime exceptions using static analysis. On the other hand, returning standardised Ok/Err-wrapped values seems like a simpler approach, both in terms of tooling support and developer convenience. reply DarkNova6 5 hours agorootparentI think once Java has finished up exception switch-case it will be a model followed by other languages. Being able to catch exceptions at both, method and transaction boundaries will be a boon for readable control-flow. reply mrkeen 3 hours agorootparent> and transaction boundaries What are transaction boundaries? Is Java getting transactions? reply throw156754228 4 hours agorootparentprevAlgebraic effects is going in completely the opposite direction. reply otabdeveloper4 5 hours agoparentprev> ...as it makes the contract between a caller and a callee hard to determine, and makes your code highly coupled. I prefer the Go or Rust style of handling it through return values. There is literally (literally!) no difference at all between throwing and exception and returning it as a variable. Except for the fact that in the exception passing style you have to write the boilerplate by hand, instead of letting the compiler do it for you. Why anybody with a sane and functioning brain would want to do that by hand in 2024 I will never understand. reply ratscylla 5 hours agorootparentI think people like it because the control flow of a given program is more obvious when you write it that way. No one can \"throw Foo\" three libraries down from their caller as an \"API\". See https://go.dev/blog/errors-are-values reply psd1 5 hours agorootparentprevAs an implementation detail, exceptions are usually much more expensive than just popping the stack, as computation is needed for each frame you traverse. Having both throw and return is like regex: now you have two problems. reply tylerhou 3 hours agorootparentExceptions are less expensive in the unexceptional case. Consuming a Result value requires a branch to see whether it holds Error. That is not necessary if the function returns a value directly (and throws an exception on error). reply NBJack 3 hours agoparentprevIf go didn't naturally eat error context, I'd like it more. But in the time I've used it, it makes errors much, much more painful to root cause without a debugger. reply kibwen 12 hours agoprev> Now let's see an example with toss. This is used mostly for passing multiple values out of the function. You don't really need it, but it's cute. Not useful? You've implemented resumable generators! Of course, getting them to do anything except resume immediately might be... exciting. :P Just need to structure your entire codebase as an inside-out stack of `toss`es... reply int_19h 10 hours agoparentNot quite, since with resumable generators you can resume at any later point in the program, while here \"return\" must be lexically scoped to the handler (whereas in e.g. Python you can call next() wherever). This is really more like passing a callback through a side channel. \"toss\" is invoking said callback, and \"return\" is, well, returning from it. reply boromisp 9 hours agoparentprevIt's more like stack based event propagation. reply 1propionyl 12 hours agoparentprevExactly my first thought after reading that. Part of me wonders if it's a bit of a joke, panning a genuinely useful feature (in any other language) as disposable and silly (in this one). reply kleiba 11 hours agoparentprevRight. Lots of fun ahead debugging a larger codebase :-) reply DeathArrow 11 hours agoparentprev>You've implemented resumable generators! Like yield in C#? reply adastra22 12 hours agoparentprevYeah that made me chuckle. I wish the languages I use had resumable exception handling. This is a ridiculously good, and extremely useful feature. Great for API callbacks, among other things. reply grumpyprole 11 hours agorootparentOCaml 5 essentially has it, as \"effect handlers\". It's how lightweight concurrency is implementated. reply masklinn 10 hours agoprevHurl seems very close to having a conditions system (Ã  la Smalltalk / CL): unwinding and resuming are just two possible restarts (https://gigamonkeys.com/book/beyond-exception-handling-condi...). reply Aeolun 9 hours agoprevNot related to the project as such, but I am firmly of the opinion that the world would be a better place if more things used the .wtf extension for their domain :) reply helix278 11 hours agoprevThis sounds like a weaker form of algebraic effects, but it is still cool to see such a language and see what you can do with it. reply levzettelin 9 hours agoparentI never understood \"algebraic effects\". But I understand the Hurl docs. Are \"algebraic effects\" basically the \"toss\" keyword from Hurl? If so, how are \"algebraic effects\" stronger than the \"toss\" keyword? reply ctenb 5 hours agorootparentMore general than the toss keyword even. If you're interested in concrete examples, you might have a look at the koka documentation reply throw156754228 4 hours agorootparentAs mentioned in another comment here, the unwind is expensive. That is, searching back through the stack finding the original call site that triggered the exception. How do algebraic effects handle that performance hit? reply fwip 2 hours agorootparentprevYou can think of algebraic effects kind of like: From callsite Foo, I call out to a function with a known name, Bar, with one or more parameters. The runtime (or sufficiently smart compiler) searches upwards in scope, for a handler Baz that provides the function with that name. Baz's Bar is then called, with both the provided parameters, and, crucially, a function that is \"the rest of Foo.\" So, an implementation of Exception with effects would ignore the resume, and look something like: define_effect Exception { // only one function provided by Exception, but could have more throw(String) } define_handler printExceptions { throw(msg, resume_func): { println(msg) } } define_func getPage(url) { request = http.get(url) if not request.ok { throw(\"Could not download\") } return page } // main entrypoint withHandlers printExceptions { page = getPage(\"https://cheese.com\") println(page.text) } But you could also write an \"on error resume next\" handler for Exception. Exceptions thrown with this handler would be equivalent to toss. (in real life you'd probably write a different effect, rather than re-using the Exception/throw effect): define_handler onErrorResumeNext { throw(msg, resume_func): { println(msg) // YOLO, call it anyways withHandlers onErrorResumeNext { resume_func() } } } withHandlers onErrorResumeNext { page = getPage(\"https://cheese.com\") println(page.text) // Probably uninitialized - a better :P } Breaking away from the Exception example, two cool examples are: // Stream - potentially infinite and/or asynchronous iterables // basically just like python generators define_effect Stream { emit(item) } define_handler toList(accumulator) { emit(item, resume_func): { if item == nil { return accumulator } else { accumulator.append(item) withHandlers toList { resume_func() } } } } define_handler take(how_many) { emit(item, resume_func) { if how_many == 0 { emit nil } else { withHandlers take(how_many-1) { resume_func() } } } } define_func fib_stream() { a, b = 0, 1 loop { emit a a, b = b, a+b } } // Usage first_five = withHandlers toList { withHandlers take(5) { fib() } } println(\"The first five fibonacci numbers are\", first_five) And this one I'm just going to lift from the Unison documentation [1]: Each.toList do a = Each.range 0 5 -- beginning of resume_func f_A b = each [1, 2, 3] -- beginning of resume_func f_B guard (a < b) -- beginning of resume_func f_C (a, b) -- yields [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)] Note that this has the same semantics as: results = [] for (a = 0; a < 5 ; a++) { // for each a, call f_A(a) foreach b in [1, 2, 3] { // for each b, call f_B(b) if not a<b { continue } // if a<b, call f_C(a, b) results.append((a, b)) } } And it is possible to do this, because these resumable functions can be resumed an arbitrary number of times - it's up to the handler. They also can pass parameters back to the resume_func. Exceptions/hurl = exactly 0 resumptions toss = exactly 1 resumption effects = 0..many resumptions [1]: https://share.unison-lang.org/@unison/base/code/releases/3.5... reply tempodox 2 hours agoprevDid I get that right that you can catch what was hurled but not what was tossed? That will take some getting used to. Also, I am concerned about how much Hurl I can write before people start calling me a tosser? reply DaveFlater 6 hours agoprevSee: https://news.ycombinator.com/item?id=36393673 reply kgeist 10 hours agoprev'Toss' sounds like an interesting language construct: it walks the stack to find an exception handler and then walks back to where it was to resume execution as if nothing happened. It looks like you can inject additional behavior at runtime using this construct. Usually in object-oriented code you do dependency injection using services's constructors, but 'toss' allows to do it using \"toss handlers\"? reply tylerhou 3 hours agoparentCheck out Koka, a â€œlegitâ€ language with an algebraic effect system. https://koka-lang.github.io/koka/doc/book.html#why-handlers reply bradrn 8 hours agoparentprevThis is quite similar to the Common Lisp conditions systemâ€¦ which I actually donâ€™t know much about, but I do know that it lets you inject behaviour at runtime like this does. reply masklinn 8 hours agorootparentIt's a very restricted form of conditions, since it only allows resuming. A conditions system would subsume both `toss` and `hurl` (because you can have an unwinding restart), as well as provide more flexibility: the condition can provide multiple user-defined restarts and the handler can pick between them (statically or dynamically), as well as feed content back into the signalling function. For instance a classic CL restart is `use-value` which is the conventional name of restarts feeding a default value in case of missing or invalid item. So let's say that you have a hashmap type, on lookup failure it could trigger a condition with a `use-value` handler to feed it a default value (possibly dynamically constructed), or abort/unwind, it could also have a restart to insert-and-return the value (so would behave as a `defaultdict`/`putIfAbsent`) reply mjbrusso 7 hours agoparentprevThis is similar `Resume Next` in VB reply zbentley 3 hours agoprevWow, I hate this. But itâ€™s â€¦ oddly almost kinda elegant? In a very hard to mentally model way, but even so. Speaking more seriously than is perhaps warranted, Iâ€™d slightly prefer it if there were syntactically different â€œcatchâ€ constructs for resumable and nonresumable exceptions, which would remove syntactic ambiguity around whether â€œreturnâ€ was sending control flow back to the thrower of the nearest immediate exception or not. Also, the stdlib shouldnâ€™t have chickened out with regular value-returning functions. Just because the dogfood gives you heartburn doesnâ€™t mean you shouldnâ€™t eat it :) reply ceving 8 hours agoprevIs it implemented using CPS conversion? reply jokethrowaway 3 hours agoprevNice thought experiment. I absolutely hate exceptions and I'd like a language without exception. They're the goto of our time. When we have Maybe/Option and Effect/Result, there is really no reason to throw exceptions and having to mentally track where that is being handled. I'm a bit worried about algebraic effects becoming more popular (and influencing frontend JS - which is already way too complex) because it's promoting throwing \"exceptions\" to control the flow. All of this to avoid the coloring problem in async/sync? Absolutely not worth it imho. reply MidhaelBollox 9 hours agoprevYou have reached the maximum number of changes allowed. Please subscribe to make more changes. reply cushpush 4 hours agoprevDon't just throw it, hurl it reply hgyjnbdet 11 hours agoprevNaming conflict with Hurl[0] a command line tool that runs HTTP requests defined in a simple plain text format. [0] https://hurl.dev/docs/manual.html reply tgv 10 hours agoparentMultiple products sharing a name is unavoidable. Github had 90,000 unique repositories in its first year. If each had to have a unique name, it would almost have exhausted the English dictionary. In 2018, it reached 100 million repositories. reply falcor84 6 hours agorootparentI have a proposal: let's accept as a given that all single words have been taken, and require all new languages/tools to be named with either multiple words, or by including a special character. Note that C# (aka C Sharp) was way ahead of its time by including both options. reply lylejantzi3rd 5 hours agorootparentIf I ever create a language, I'm calling it clang for maximum naming conflict. Am I talking about the c language? The compiler? or this newfangled language written by a completely unqualified web dev? Â¯\\_(ãƒ„)_/Â¯ reply bee_rider 5 hours agorootparentHow about clang:a markup language to describe things which could be made by blacksmiths. reply FrenchyJiby 4 hours agorootparentprevNote that the specific naming of hurl.dev is not random: hurl is a wrapper for curl, where the requests are stored in a plaintext file. So hurl.dev didn't roll dice and got hurl, but consciously got a close sounding word. In that sense, that makes one claim over the other a little more valid, in my mind, though you're right that clashes will have to occur. I did get confused extra hard by the url = hurl.wtf, when hurl.dev is so close yet about different topic. reply thegeekpirate 8 hours agorootparentprevEveryone understands that, but when the project name you're copying is popular enough (12k stars meets this threshold, personally) and is still actively used and developed, a name change should be more seriously considered as to avoid confusion (which I exhibited, fwiw). reply polytely 7 hours agorootparentWell it's a totally different category of thing (in multiple ways) so I can't imagine people getting confused about this. reply persnickety 5 hours agorootparentprevWhy do names have to come from the English dictionary? Google can't (couldn't) be found in one. reply tgv 2 hours agorootparentThe English dictionary was an example. English names are also rather popular among devs. But there aren't over 100M unique words and names in the world, and most of them would, simply put, suck as names for projects. reply persnickety 35 minutes agorootparent100000000 is 8 significant places. If you build words by choosing out of 10 viable following letters out of an alphabet, you'll hit that in 8 characters. That's not an especially long word. (I don't actually know if that's a good heuristic, but at least it gives an idea.) Maybe a lot of them suck as project names, but name collisions also suck. I'd rather have unique names rather than beautiful but hard to find ones. Collisions are fine if they happen across geographical and cultural boundaries, but the software culture, for better or worse, is pretty global. reply aredox 5 hours agorootparentprevlol This industry pumps out new model languages every week, but is unable to generate new names with simple Markov chains? Anyone giving a project a name that is already taken is a clown reply samatman 3 hours agoparentprevProgramming languages live in a separate namespace involved by passing the 'lang' attribute to your search engine of choice. reply junon 7 hours agoprevGay Agenda License 1.0 had me laughing. reply emersion 7 hours agoparenthttps://git.sr.ht/~ntietz/hurl-lang/tree/main/item/LICENSE/G... reply andrewshadura 3 hours agorootparentUnfortunately, it's not open source, but it's still hilarious :) reply NoahKAndrews 4 hours agorootparentprevThis is fantastic reply tombert 5 hours agoprev [â€“] Just rebrand this as â€œalgebraic effectsâ€ and suddenly every academic will pretend itâ€™s revolutionary. reply withoutboats3 3 hours agoparent [â€“] Also my thought. It's very interesting how the designers of this language, presumably unaware of algebraic effects, write about it as if it a terrible joke when this is actually one of the trendiest ideas in PL. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Hurl is a new programming language focused on using exception handling as the primary control flow mechanism, created by Nicole Tietz-Sokolskaya.",
      "The language is documented on its dedicated site, which includes usage instructions, examples, debugging tips, and FAQs.",
      "Hurl's source code is available in its repository, and it is licensed under AGPL-3.0, GAL-1.0 (Gay Agenda License), and a commercial license, offering users multiple licensing options."
    ],
    "commentSummary": [
      "The discussion emphasizes best practices in programming language design, such as enforcing namespaces for imports and avoiding top-level side effects to improve code maintainability.",
      "It compares exception handling in dynamically and statically typed languages, discussing the trade-offs between checked and unchecked exceptions, and debates error handling methods like Go or Rust's return values versus traditional exceptions.",
      "Advanced features like resumable generators, algebraic effects, and the \"toss\" mechanism for handling exceptions are explored, along with the challenges of naming software projects in a crowded industry."
    ],
    "points": 226,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1716703072
  },
  {
    "id": 40480323,
    "title": "Transform Your iPhone into a Minimalist Device to Curb Screen Time",
    "originLink": "https://dumbph.com/turn-iphone-into-dumb-phone",
    "originBody": "the dumphones blog home blog dumbphone finder how to turn your iPhone into a dumb phone. In this article I show you how to turn your iPhone into a dumb phone, using a handful of simple apps and settings. You donâ€™t have to purchase a new device just to simplify your screen time! You can use your existing iPhone to enjoy many of the same benefits. Table of Contents introduction minimal homescreen launcher plain wallpapers (that hide your dock) grayscale-only display disable notifications bonus: delete your apps conclusion introduction So, you want to reduce your screentime, maybe embrace some digital minimalism, but you donâ€™t want to go full-on dumbphone. Perhaps, like most people, you need a smartphone to fully engage with society (like with QR menus, the bane of the dumbphone life!). Fortunately, you can tweak your current iPhone to dumb it down and transform it from a dopamine-driven-slot-machine, into something a bit more tepid. Itâ€™s a great way to temper your screen time without requiring a new (dumb)phone. Follow along with this article to dumb-down your iPhone. This article will show you how to dumb down your iPhone, with tweaks like using a minimal homescreen launcher, choosing a plain wallpaper that hides your dock, enabling grayscale mode and disabling notifications. And of course, the final boss â€” deleting your apps. Note: The tweaks here might make your phone less appealing, but youâ€™ll still have access to social media, emails, the internet, etc. Dumbing down your iPhone is a great way to dip your toes into a more digitally minimal lifestyle, but itâ€™s not a replacement for a more limited device. I hope youâ€™re excited to get started! Letâ€™s dive in. minimal homescreen launcher The first thing I recommend is a minimal homescreen launcher â€” itâ€™s a full-screen widget you place on your homescreen which displays a plain list of selected apps (which you can customize). I use the Dumbify launcher and it works pretty well. There are a couple of similar launchers, like Blank Spaces and on point, but both have freemium models with expensive â€˜premiumâ€™ upgrades. Dumbify costs $4.99 USD upfront, but has no in-app purchases; itâ€™s what I use and itâ€™s great. The homescreen on my dumbed-down iPhone, using Dumbify. These homescreen launchers all behave the same â€” they show a plain list of app names, rather than colorful app icons, which are (hopefully!) less engaging and less likely to distract you. The freemium apps can be a good way to play around and see if this is something you want to commit to, if youâ€™re uncertain. Just be warned that theyâ€™re much more expensive to purchase vs. buying Dumbify once their trials run out. plain wallpapers (that hide your dock) A simple, plain wallpaper is another way to simplify your phone. This was a tough one for me! I love displaying pretty photos on my lockscreen, but I decided to go all-in on dumbing down my iPhone. Dumbify includes two wallpapers you can use which match the colors of the iOS dock, and Iâ€™ve included them below. By matching with the dock, you can remove all your apps from your dock for an extremely spartan homescreen (like in my screenshot above). Dark Light Just tap and hold these photos to save them, crop them to fit your phone screen, and set one as your wallpaper. You should also make sure to disable automatic light/dark mode, since that adjusts the color of the dock. You can do that via Settings > Display & Brightness > Appearance/Automatic. Tip: for a completely bare homescreen, you can also turn off the little â€œSearchâ€ badge on your homescreen under Settings > Home Screen & App Library > Search/Show On Home Screen Note: Iâ€™ve also written about using different iPhone wallpapers for light and dark mode, which is the finishing-touch on a great minimal homescreen setup. grayscale-only display The first two suggestions in this article were neat, but not that drastic. This one is! Using an Accessibility setting, you can completely gray-out your iPhoneâ€™s screen, which Iâ€™ve found has made a noticeable difference to how engaging it is. Doomscrolling on Instagram or TikTok is much less appealing without all the flashy colors! My iPhone with the grayscale filter enabled. Under Settings > Accessibility > Accessability Shortcuts, you can enable the Color Filters option. By default, this will let you enable grayscale mode by triple-clicking your iPhoneâ€™s power button. It also has the handy benefit of letting you switch back to color mode with another triple-click. If youâ€™d prefer to set this directly (maybe you use the shortcut already), you can do that in Settings > Accessibility > Display & Text Size > Color Filters > Grayscale. disable notifications I left this one until (nearly) last since I think itâ€™s pretty obvious. Disabling (most) of my notifications was one of the best things I ever did â€” itâ€™s astounding how many nuisance notifications come through on a given day. Social media pings, random promotions, spam emails â€” constant interruptions for irrelevant things. Disabling them was cathartic and a huge relief (not surprising, since notifications stress us out). I do allow a handful of notifications through â€” phone calls and text messages, as well as my banking apps. Everything else though? ðŸ™…â™‚ Apple fortunately makes it straightforward to manage your notifications via Settings > Notifications â€” you can customize your notification preferences per-app, and if youâ€™re on iOS 15 or later, you can also schedule a notification summary. bonus: delete your apps The bonus tip, the elephant in the room - your apps. You can make all the tweaks to your iPhone that you like, adjust this-and-that, but if you keep your addictive apps around, whatâ€™s the point? Different people find different apps addictive â€” social media is, of course, a huge one, but the internet (ie: your browser app) can be just as addictive, as can YouTube, Slack and more. Sometimes even Strava sucks me in! Whatever apps youâ€™re addicted to, just seeing their icons on your iPhone (or being able to search for them) can act as a cue, triggering a little dopamine-driven feedback loop in your brain which sends you spiralling into another doomscrolling session. As effective as little tweaks can be, sometimes the best intervention to break a bad habit is going straight for the cue (the app, in this case). Thereâ€™s a handful of popular techniques you can try out â€” from going cold-turkey and just deleting all your addictive apps, to trying out social-media-free weekends, to using the native iOS screen-time feature or more advanced apps like Opal and Jomo to regulate your usage of them. conclusion If youâ€™ve read this far, all the way to the end, then thank you. I have a challenge for you: Implement at least one of the things Iâ€™ve covered in this article. Even just doing a little â€œnotification auditâ€, where you go through your notification settings and disable them for unnecessary apps, can help you reduce interruptions. Likewise, social-media-free weekends can be a great way to cut back on addictive apps without having to completely give them up. I think itâ€™s important to note though â€” dumbing down your iPhone is a far cry from a panacea for smartphone addiction. You can turn your iPhone into a â€˜dumphoneâ€™ all you like, but unless you also delete some apps, youâ€™ll still have access to all your vices â€” social media, games and more (even if theyâ€™re now grayscale). Even if youâ€™re brutal and uninstall everything, you still have the app store and browser beckoning. Thatâ€™s not to say that these tweaks arenâ€™t beneficial â€” I think they are; I think theyâ€™re a great set of tweaks to nudge you away from overuse and mindless scrolling â€” but donâ€™t expect an overnight transformation. For that, you might need to take more drastic measures. Â© 2024 The Dumphones Blog written with â™¥ in ðŸ‡¦ðŸ‡º",
    "commentLink": "https://news.ycombinator.com/item?id=40480323",
    "commentBody": "Turn Your iPhone into a Dumb Phone (dumbph.com)182 points by hbroadbent 11 hours agohidepastfavorite141 comments nrvn 6 minutes agoI have turned my work iphone into a dumb phone. It has got only apps that cannot be removed, plus the apps that are provisioned through mdm. No icloud, nothing beyond what is needed for communication with my colleagues. Location services off, bluetootg is always off, wifi only connects to cirporate network. My personal phone is less so dumb but I follow the YAGNI principle there as well. reply simonbarker87 5 hours agoprevIâ€™m not sure why there is so much negativity toward this article here. Even a small amount of friction to getting to slot machine apps does wonders for reducing the amount of time spent on them. But likewise itâ€™s nice (and useful) to still have access to these apps for some people so deleting isnâ€™t a viable option. Like any other â€œeverything in moderationâ€ suggestion if itâ€™s not all or nothing, just use self control, the internet hates on it. reply dangus 3 hours agoparentProbably because the article has basically 3 suggestions that donâ€™t even scratch the surface of what the OS has built in to manage overuse. Turning off notifications is stupidly simple to a fault. Sorry, people canâ€™t just turn off notifications from their spouses or day care apps or school/kidsâ€™ phone numbers or other important stuff like that. But this article doesnâ€™t really get into the stuff that the OS has built-in to manage notification priority, it just tells you to turn it all off as if theyâ€™re telling the government to print more money to end poverty. Kind of crazy that a blog post on this subject doesnâ€™t even mention the Screen Time feature. reply mozman 2 hours agorootparentYou can setup emergency bypass, silence unknown calls, etc. I have 98% of notifications disabled both on phone and desktop. reply dangus 2 hours agorootparentWell yeah and this article didnâ€™t talk about any of that. reply SoftTalker 36 minutes agorootparentprevAnd yet our parents' generation (or our younger selves, depending how old we are) managed to get through a day without any way to receive notifications from their spouses or day care apps or school/kidsâ€™ phone numbers. You simply had to trust and rely upon the school or day care to take care of it if your kid got hurt or sick. You might have been able to get a call at work from your kid's school, but depending on your job, maybe not. reply CPLX 2 hours agorootparentprevIndeed. I have actually created a dumb zen phone, and the killer way to do it is put it in supervised mode without the browser or App Store. Then youâ€™re genuinely handicapped. My version has maps, kindle, texting, phone, Spotify, camera, and the podcasts app. Perfect for running errands or going to the park with my toddler and still being reachable. reply dot5xdev 2 hours agoprevIt's easy to break your phone addictionâ€”I've done it a 1,000 times... But, seriously, I've tried launchers, leechblock, and other software solutions. For me, they don't work long term because I end up just reverting and unblocking. I always have some justification in my head as to why I need to reinstall Discord or browse YouTube and then it's over. For me, I've had much better luck with a device where those types of slips are impossible. Mostly... although sometimes I really do need a smartphone to scan a QR code or to pay a foodtruck with Venmo. The Jelly Star seems to be the best compromise for me so far. It's still a smartphone, but the screen is so small that it's a lot harder to be on it for hours. reply SkyPuncher 23 minutes agoparentPutting my phone in black and white mode was helpful. It really brought down the engagement level reply beeboobaa3 1 hour agoparentprevTechnical solutions to a mental problem never work. reply bbarnett 1 hour agoparentprevThe food thing is a pet peeve for me. I walk if a restaurant requires any form of smart phone to use. Doesn't matter if it is for menus, ordering, or payment. Nuts to that. reply Brajeshwar 8 hours agoprevI tried the \"grayscale-only display\" for kicks, and it sucks, primarily with Apps that are better off with different colors - Maps. Besides that, I have been disabling Notifications for ages, and that is the one decision that I believe was one of the best decisions of my phone life. I wrote an article in 2014[1] that needs a serious update, but it still makes sense. Make it a habit to turn off Notifications as soon as you install a new app unless they are critical, such as Medical or Kid/school-related. My Home page has a minimal wallpaper that I did a few years back, and it stayed. I usually leave one row at the bottom for beta-testing and region-specific Apps I use while traveling. Of course, none of the Social Media Apps are on my phone. I checked my screen time to include this comment, and I've 37 minutes Daily Average. So, on most usage, I should still likely be averaging less than an hour daily. 1. https://brajeshwar.com/2014/missing-step-productivity-activi... reply Kiboneu 2 hours agoparentTry turning down the color saturation. For me ~ 25% of original saturation is sufficient for using UIs that use color information. I had the same annoyance as you, switching back and forth wasn't pleasant, and I'd forget. I think part of the reason is that switching between 0%100% saturation doesn't give room to adapt. It feels like a bandwidth of information is missing. But, if the colorspace is barely noticeable, your brain will fill in the colors for you with the information it gets... and the high-saturation default color-set would start to appear abrading and unnatural. reply cricalix 7 hours agoparentprevYou can make the greyscale toggle on triple power/home button, or via control centre. Thus, you can have it on most of the time, toggle it to look at a map, then toggle it back. reply Timothee 4 hours agorootparentYou can also have a Shortcut that toggles the setting when you open and close specific apps. I just did it and itâ€™s very simple: - in the Shortcuts app, go to Automations - add a new one and pick â€œAppâ€ as the trigger - choose the apps you want color in and pick â€œrun immediatelyâ€ and on open and close - on the next screen pick â€œnew blank automationâ€ - in the new shortcut add â€œSet Color Filtersâ€ and set to toggle You can also make different automations for open and close, but toggle works as long as you toggle the effects manually. But in this case you can just toggle it back manually. reply garof 5 hours agorootparentprevI made a Shortcut for it and added it to the home screen. I found the triple click too fiddly, and the control center option to be not present enough. reply elboru 5 hours agorootparentprevThatâ€™s a perfect solution for me, thanks for the idea! reply captn3m0 6 hours agoparentprevYou can set per-app Accessibility settings as well, but sadly Color Filter is a global configuration. reply delogos 5 hours agorootparentYou could set up an \"on app launch\" automation shortcut for Maps to alter the Color Filter setting, but I'm not sure how you'd automate switching it back after closing/leaving Maps. I don't use the automations, but instead have a shortcuts widget with \"toggle greyscreen\" (among others) which is sufficient for me most of the time. reply ksala_ 4 hours agorootparentYou can have 2 automation, one which enable grayscale when certain apps are open and one that disable it when the apps are closed. Itâ€™s under shortcuts > automation > app > is closed. reply Timothee 4 hours agorootparentI put this in a different comment but you can also have a single automation that toggles the setting for those apps on open and close. This way you have a single list of apps to maintain. reply photonthug 2 hours agoparentprevProbably a bug but my browser in dark mode actually inverts image and video into something like posterized predator vision. Since I was looking for grayscale anyway, Iâ€™ve kept it and not looked back. Even though phone manufacturers and service providers are doing everything they can to limit the availability of smaller, reasonably sized phones.. even the huge phone I get forced into using is just incredibly frustrating to browse the web with. Besides the usual gdpr harassment taking up a third of every screen, mobile just increases the thirsty demands for me to install apps, etc. Might as well drive home the point that friction is inevitable rather than making it easier to start an interaction thatâ€™s only going to annoy me. If I need to do anything other than view simple text, I already know Iâ€™ll have to get out the laptop reply Terretta 8 hours agoprevWhile deleting apps, BitWarden is built in now, including setting TOTP MFA codes and sharing. https://support.apple.com/en-nz/guide/iphone/ipha6173c19f/io... Photos and Maps, while deleting the unneeded Google apps, keep the dumb phone from informing third party adtech of your day. The minimal launcher is cool; this is built in: https://support.apple.com/en-nz/guide/assistive-access-iphon... reply 542458 3 hours agoparentIâ€™m a bit confused by â€œBitwarden is built in nowâ€ - are you saying that you no longer need the Bitwarden app to connect iOSâ€™s password autofill to my bitwarden vault? reply filoleg 2 hours agorootparentI think they meant that iCloud Keychain (which is now built-in) can functionally replace Bitwarden reply conception 5 hours agoparentprevJust wanted to toss out that organic maps is offline and really quite wonderful. reply ghostpepper 2 hours agorootparentWhat is â€œorganic mapsâ€? reply windthrown 2 hours agorootparentA specific app which displays mapping data from OpenStreeetMap: https://organicmaps.app/ reply rcarmo 4 hours agorootparentprevThis. I concur. reply knallfrosch 57 minutes agoprevMy Androids made better dumbphones. The always-on display simply showed a small Whatsapp icon. No need to unlock your phone or check an app for messages. Only unlock it at all if you have a message. Ignore the message without reading its contents. And, as LineageOS/cyanogenmod can, disable notifications also in the status bar. Use Google Maps or your train ticket app without being interrupted by the status bar icons/notification center. \"Do not disturb\" really means you won't get any notifications. 1-click toggle. iOS on the other hand, I haven't even found a way to make notifications silent while making calls ring. (Apart from toggling notification settings for 30 apps individually!) reply CharlesW 43 minutes agoparent> iOS on the other hand, I haven't even found a way to make notifications silent while making calls ring. (Apart from toggling notification settings for 30 apps individually!) In iOS you can use a Focus mode. You can either \"Silence Notifications From\" to blacklist or \"Allow Notifications From\" to whitelist (then donâ€™t whitelist any to silence all). reply coolspot 43 minutes agoparentpreviOS: Settings -> Focus -> (any focus) -> People -> Allow Calls From [Everybody, Allowed People, Favorites, Contacts] reply dewey 9 hours agoprevEasy solution: Delete apps you donâ€™t need or feel bad about (Twitter, social media, apps spamming notifications,â€¦) The described solution is just someone procrastinating by spending even more time on their phone trying to customize things and fiddle with apps. Same category as building a todo app to become more productive or building a blogging engine to write more instead of just writing. reply adamwong246 2 hours agoparentThis is the only sane approach. I have reduced my smartphone to a dumb-phone just by removing the apps that suck my attention. But the worst is youtube. You can live without social media but YT has become such a cornerstone that you cannot even uninstall it. reply toast0 1 hour agorootparentI'm not sure I fully agree about youtube. Yes --- if you're fixing stuff, you end up having to watch youtube. But that's so bad, it's easy (for me) to continue to avoid it. Although, occasionally I do get pulled in to interesting looking videos. But when they start asking me to like and subscribe (which is often!), that's a good trigger to close the thing. reply rhplus 6 hours agopreviOS has a built-in â€œsimpleâ€ mode called Assistive Access. It does a lot of whatâ€™s described here. https://support.apple.com/guide/assistive-access-iphone/welc... reply layer8 3 hours agoparentWhat it looks like: https://nerdschalk.com/use-assistive-access-iphone/#interact... It has some major limitations though, like you canâ€™t zoom into photos, and you canâ€™t use Bluetooth headphones or AirPlay. reply adamors 5 hours agoparentprevDidnâ€™t know about this, quite cool. reply 10729287 8 hours agoprevThis article is all about showing off and getting attention from people asking about your home screen. Itâ€™s all about consuming minimalism and telling people. I disable all notifications but phone, messages and calendar, install minimal applications, no sns, and only show the basics on Home Screen. No need to configure the whole minimal wallpaper, just get your phone far for eyesight. reply cocoa19 1 hour agoprevI implemented all of them. Thank you for sharing. I recently finished Atomic Habits and these actions pair well with it. Especially the points about making the bad habits less accessible and make them less satisfying. reply echelon_musk 10 hours agoprevPointless waste of time. It's still an internet connected smartphone - evidenced by the fact he has apps like Slack on the home screen. May as well rename the article to 'how I changed the appearance of my iPhone'. reply iamkonstantin 9 hours agoparentI think there is a fix for that as well, I use Focus modes to hide work apps outside 09h-16h, so there are absolutely no mentions of productivity (or badges/things that need me to do something) to be seen when I'm not on the clock. reply prmoustache 7 hours agorootparentWhen I am working, I am never far from my laptop, why would I install productivity app on my smartphone in the first place? When I was part of an on call shedule, the only app I would accept would be the one pushing the notification like pagerduty. I also found out the hard way a decade ago that having access to productivity apps such as outlook usually meant to enroll your smartphone as a device managed by your IT and it was a big no to me. reply smeej 8 hours agoparentprevCame here to make a related comment. I've had the equivalent settings active on my GrapheneOS device for at least a couple years, and I still find myself losing hours of my life to the darn thing. If you don't go after the underlying reason you want to distract yourself from real life by entering the portal in your pocket, all the tips and tricks in the world won't fix the problem. reply asimpletune 9 hours agoprevItâ€™s crazy to think that iPhones are so powerful but thereâ€™s not an easy way to repurpose them as generic computing devices at their EOL. reply Zambyte 5 hours agoparentIt's crazy that iPhones are such powerful generic computing devices that only the people who sold it (see: don't own it anymore) can use it as such. reply kome 9 hours agoparentprevi have an ipad and i would like to run a personal server on it... but how? reply cpach 3 hours agorootparentI would love to be able to do this as well. In reality Iâ€™m afraid there are lots of obstacles in the way. Too bad really, being able to do this would be so cool. reply EasyMark 2 hours agorootparentprevI don't think there is a way. maybe if you root it you can open up ports and stuff. Have you bothered looking into that? reply HenryBemis 7 hours agorootparentprevGood luck to that.. For a similar need, I turned to a small, portable device, that runs on battery (but not a laptop) to run 24/7. I got a couple of ipads, but since I can't install some OS that I want (without jumping a million hoops). So I got myself a HP Elite X2, second-hand, and it is GREAT. Then I wanted a second one, I couldn't find another HP Elite X2 (at the same price) so I got a Dell Latitude 2-in-1 (basically a Win tablet). Basically I want something to run 24/5, so even if there is a power disruption (maintenance on building, etc.) my downtime would be the 2-3 minutes until my router/wifi reconnects. (we get some once every couple of weeks and a desktop wouldn't reboot)(and I didn't want a laptop as I don't want any fans/movable/mechanical components). I've build custom base to keep them upright --> =|=|= so they can 'breathe' well, and stay cool. I also got a KVM so I got all my devices hooked on it, so when I do need to do some work on them I can do it with my big screen/keyboard/mouse. I only remember to dust them every couple of weeks, and they are golden! reply Zambyte 5 hours agorootparentprevThe easiest way is to start lobbying against this malpractice. reply carlosjobim 5 hours agorootparentIs that easier than buying another device to use as a server? reply Zambyte 4 hours agorootparentThat won't make your iPad into a server. reply dools 10 hours agoprevI just donâ€™t have any social media apps on my phone, thatâ€™s basically the only thing that sucks up screen time reply Hendrikto 9 hours agoparentHackernews is social media. reply cpach 9 hours agorootparentI guess it can be viewed as such. And at least for me itâ€™s addictive. But HN lacks a lot of the anti-patterns that are present on Facebook, Instagram etc. I find the discussions here much more interesting and useful than viewing silly reels that are produced with the sheer purpose of being addictive. Thereâ€™s also a builtin noprocrast option. reply Karrot_Kream 1 hour agorootparentThat just means HN's community and content is more relevant to you than other social media. Social media doesn't stop being social media if you find the content interesting nor does it stop being social media if it emphasizes one form of content over the other. reply cpach 1 hour agorootparentInteresting point. Does that mean that Usenet and IRC also are considered social media? reply Karrot_Kream 43 minutes agorootparentYes definitely. Again, audience and interests are different, but they are social media. Funny (sadly?) enough as a teenager I discovered IRC and was absolutely addicted and for a good 1.5 years spent every minute I could on IRC. I would use IRC at the school library between classes, at community college, at family friends' houses, in my own house, etc. We were poor at home but despite that I literally used any possible internet connected terminal to connect to IRC (and its resilience as a protocol made that really easy.) I had poor impulse control at that age but I do remember IRC a lot, and not in the most healthy way. Also interestingly enough text-based social media (HN, Reddit, Bluesky, X) addict me way more than video based ones (like Tiktok, Youtube, or Instagram) do. I don't know if it's because it takes longer to digest the information through video than text but I do know that I have no problem with looking at pictures and videos and stopping for days/weeks, but once I get hooked on text it's really hard to stop. I even spent a year in middle school addicted to reading books though I had other things going on in my life at the time and books were a bit of an escape. I've had waves of HN addiction and definitely enjoy X and Bluesky because of the textual media of the experience. As an adult I mostly grew out of these addictions but I can still feel their pull on me. Luckily I have enough going on in my offline life that digital life takes a backseat. If you want to think of these in terms of \"algorithms\", then IRC and Usenet have a simple \"chronological\" algorithm to display posts while Reddit and HN use an \"upvote\" based engagement algorithm. X and more \"modern\" social networks may use more sophisticated algorithms but they're all just algorithms to return a sorted order of items. reply yjftsjthsd-h 3 hours agorootparentprevSure, HN is less bad, but that doesn't make it not social media. reply echelon_musk 9 hours agorootparentprevIs Safari a social media app? reply Hendrikto 5 hours agorootparentIt can be, depending on how you use it. Although it could be argued that the question does not make a lot of sense. A browser is a tool. Is a kitchen knife a murder weapon? Not per se, but it can be. reply mwidell 6 hours agoprevIf the problem is social media app addiction, I have found the best solution is to turn on screen time, whitelist your most important apps like messages, calendar etc. and then enable a passcode to access any other app. Ask a friend to set a pin code for you so you cannot cheat. Another solution is to just use an apple watch with cellular as your primary phone. It has everything you need (spotify, imessage, etc.) but nothing that distracts you like youtube, tiktok etc. reply surfcao 1 hour agoparentApple watch is a 'dumb' phone. I upgraded to watch ultra for this purpose. Just leave the iphone at home or in the car (bonus: one less item to carry). I use browser to check twitter occasionally, but it helps break the habit of keeping phone around all the time. Do miss the camera though.. reply Zambyte 5 hours agoparentprevIt's important to note that music streaming and texting are also wants rather than needs. I've recently started leaving my house where the only electronic device that I go with is my compact camera. reply thallium205 4 hours agorootparentWhat compact camera do you use? reply Zambyte 2 hours agorootparentSony ZV-1. I've also got a smallrig L bracket on it for extra tripod mount points (I use it as a webcam with a wall power supply, but the built in mount is blocked by the battery compartment door when it's open) and it is still pocketable. I would say the image quality is better than my phone (Samsung S10) and worse than my DSLR (Nikon d3400). Sometimes I prefer it over my DSLR though, like for its super fast and accurate auto focus. reply eurvin 5 hours agoprevI was seriously looking into purchasing a dumb smart phone, a la Light Phone 2 or Punkt MP02. I want some messaging, audio, maps etc but keep the slot machine apps as far away as possible. This simple guide saved me at least â‚¬ 300 on the purchase of a new phone... for now. reply seam_carver 1 hour agoparentHow about an e ink phone? reply eurvin 10 minutes agorootparentLooked into this category specifically and Light Phone 2 is actually an e-ink touch phone with Android as its underlying OS. I may reconsider my choice later on, but for now these solutions will do. reply seam_carver 2 hours agoprevI like e ink phones a lot. Same screen tech as Kindle ereaders. Great for reading and text. Terrible for videos and scrolling. Hereâ€™s a video of me using one: E ink phone Android app showcaseHisense A9 review https://youtu.be/dvO9ScTdwz8 reply Lockal 9 hours agoprevThe article is not useless as many might think. It is a pity that it is not as well thought out as it appears. For example, the suggestion to remove system applications will almost immediately lead to a bootloop. I, for example, have a hard time imagining how to protect elderly parents from a text message that will send them a link that, when clicked, will bombard them with suggestions to enable notifications, and then notifications will bombard them with suggestions to do something else. reply hbroadbent 9 hours agoparentHey I'm the author. I definitely didn't mean to imply you should remove critical system apps (I don't think that's possible on vanilla iOS). More just that it's worth deleting most apps beyond the basics like calls,text,calendar,maps etc reply mikecarlton 8 hours agoparentprevApple had added assistive mode well suited for seniors â€” https://www.theseniorlist.com/cell-phones/assistive-access/ reply captaincrunch 3 hours agoprevIf you have a problem with attention, just buy a flip phone, they still exist. reply the-grump 3 hours agoparentTwo paragraphs in: \"Perhaps, like most people, you need a smartphone to fully engage with society (like with QR menus, the bane of the dumbphone life!).\" reply cpach 3 hours agorootparentIndeed. Or TOTP; parking your car; buying your tickets for the metro/train to commute to work, etc etc. reply Hoodedcrow 3 hours agorootparentIDK about parking situation as I don't own a car, but I find it hard to believe that in some place there would be no way of paying for public transport without a smartphone. I personally use a cash-paid, cash-refilled transport card. As for TOTP - this one is very universally doable on desktop, like with KeepassXC. Or you're talking about logging in outside your home, like in a library or computer club? reply CatWChainsaw 2 hours agorootparentSaw the parking thing on a trip to Pennslyvania. Lots of signs for the parking app on the street, yet none of them were kiosks or had a phone number to call and arrange parking fees that way. It boggles my mind that so much innocuous activity got sucked into smartphones. It is not actually more \"convenient\" to download yet another app that wants access to all my data, just to pay for a parking space, when my credit card is on my person and kiosks do not take up that much space. reply NietTim 8 hours agoprevI recognise the problems this 'dumbphone' trend is trying to solve but I really don't understand many of the solutions people are putting forth. What I did years ago is aggressively manage my notifications settings, deleted the apps that were a problem (twitter, reddit) and I'm assertive about not being in too many group chats + notifications off for those. And it's been working great. reply kemayo 2 hours agoparentI think it's worth viewing through an addiction lens. Some people have addictive personalities, and their brains work differently when presented with things like this. I can have just one drink, or play just a bit of a video game. But I know people who will tip into a destructive addiction spiral from a tiny impetus like that, such that completely avoiding what to me would be a harmless thing is the only way they can live a normal life. It's sort of like people with clinical depression. Advice from people who're not clinically depressed is often terrible, because it's stuff that'll work great if you're a neurotypical person. And it's legitimately hard to get in the mindset of someone whose brain works differently than yours for things like this, and understand what's incredibly difficult for them despite being trivial for you. reply pflenker 8 hours agoparentprevNotifications off by default and apps not on the Home Screen by default already goes a very long way. For me, there is no need to make my phone any dumber. reply walteweiss 5 hours agorootparentI would add that if you truly want to distract yourself, â€˜no notificationsâ€™ policy doesnâ€™t work. You may just open your distraction and update it manually, expecting for the notification to arrive. Even when you set it to never bother you. So, the best way is to explore what triggers you to distract in the first place. I donâ€™t mean turning off the notifications isnâ€™t going to work. It would, and I highly recommend turning off everything, but the urgent stuff. Youâ€™ll notice you wonâ€™t miss what you truly need anyway. And you still may distract yourself, when you want it. reply pflenker 2 hours agorootparentNot adding most apps to the Home Screen adds just enough friction for me. For heavy offenders which draw my attention, there is one sec. reply pxmpxm 8 hours agoparentprevFeigning being a victim and having no agency is trendy in certain circles. reply dave84 7 hours agoprevNo mention of the iPhoneâ€™s built in â€˜Assistive Accessâ€™ mode. That would be my first port of call for turning it into a dumb phone. reply EasyMark 2 hours agoprevjust turn it off and check your messages every few hours, that's what I do. Airplane mode is a god send if you're trying to break the habit. Yesyesyes I know that's not an option for everyone. Back in the day I did fine without being constantly online though, and so far I'm good. Seems like a reasonable compromise between smart phone and dumb phone reply squarefoot 8 hours agoprevFor Android users, take a look at BaldPhone. Fully Open Source and primarily aimed at seniors, does a pretty good job at simplifying the interface making most important actions easier to perform. It does not turn a smartphone into a dumbphone (I don't think that is even possible without removing entire parts of the system, possibly bricking the device) but the simpler and immediate interface makes it a lot more usable. https://github.com/UriahShaulMandel/BaldPhone reply Terretta 8 hours agoparentAnd on iPhone: https://support.apple.com/en-nz/guide/assistive-access-iphon... reply someluccc 5 hours agoprevA hack that has worked for me is having another person set up the code for screen time settings, in a way that there is just enough friction for the often unconscious reflex to open XYZ app and proceed to get sucked in. In my case I both set a daily time limit and block certain apps to only certain hours of the day reply eleveriven 2 hours agoprevI was trying to minimize my YouTube watch time. It was a failure. reply omeid2 8 hours agoprevRe greyscale, it really does work. And you can also add an accessibility switch with Back Tab to turn this on and off by tapping three times at the back of your iphone. reply abhayhegde 3 hours agoprevIt just feels wild to suggest turning a $1000 phone into something a $100 phone. However, I see the appeal. reply cjk2 9 hours agoprevI don't know why people do this. The reason I buy an iPhone is that I want all the non dumb things. If I wanted all the dumb stuff I'd just not bother. reply prmoustache 7 hours agoparentI guess a lot of people only need a dumbphone most of the time but a smartphone becomes a lifesaver a small fraction of the time. Like to hire a cab once in a while, get information online or buy museum tickets on a decent browser while travelling, have access to public transport app in an unknown city, navigation in a vehicle, etc. So there is a case of having the capabilities of the smartphone but not wanting the distraction that are part of the ecosystem. In my own experience, I don't have any social media accounts anymore except one one the fediverse but I only access it from the browser and don't get distracted by notifications. I just wish there was an easy way to mute everyone but a selected number of contacts (you can sorta do it but you need to go through all your contacts, it doesn't work for unknown numbers or for calls). The only real people I want a phone/message tone is my partner, my daughters and their school numbers[1]. I want everyone else to be silent and when calling being redirected to voicebox immediately. [1] which doesn't work as usually people from school use their private smartphones. reply lying4fun 8 hours agoparentprevmyb i wanted an iphone 6months ago but today i want a ~dumb phone but im stuck with this iphone i already have. i could sell the iphone but i do need the apps i wouldnt have on a dumb phone so i try to do what i can to dumb it down reply gman83 7 hours agoprevI'm using Niagara Launcher on Android, really recommend it. reply aserafini 9 hours agoprevOne problem I found with the \"delete your apps\" recommendation, is that you can't actually delete Safari on iOS. reply Synaesthesia 8 hours agoparentNo you have to disable it with parental controls. reply ibrahimsow1 7 hours agoprevdisclaimer: No relation. Adding to this clearspace app. Kicks you out of your current at after a selected amount of time. Takes time to load the app in, really good jolt to the brain. Although the apps SSO is buggy af, and it glitches out sometimes. reply Alifatisk 6 hours agoprevLooks really interesting, I'll give this a shot. reply mikae1 8 hours agoprevCan Safari be removed? I would assume: no. reply Almondsetat 8 hours agoprevHow to turn an iPhone into the perfect dumb phone: - Never log into an iCloud account - [optional] don't connect to the internet except for low bandwidth mobile data Done. reply api 5 hours agoprevI take a medium approach and turn off almost all notifications, do not install â€œsocialâ€ addictionware apps or similar junk, turn off background refresh for almost everything, and if I need some gratuitous app on a trip I uninstall it as soon as I donâ€™t. I havenâ€™t tried their lock down mode yet whatever itâ€™s called. reply epstein 4 hours agoprevTbh iphone itself is less smart than android reply zaptheimpaler 9 hours agoprev80% of the battle is notifications but iOS really sucks at this compared to Android. On Android, I could use an app like Uber, keep the important notifications on like driver/delivery arrived but turn off all the marketing trash. On iOS all you can do is turn on or off all notifications, so if you need certain notifications from an app they get a free pass to spam you all they want :/ The entire idea of any random being able to spam messages onto your phone and make it beep without consent and fine grained control is insane. reply kalleboo 8 hours agoparentApple used to forbid advertising push notifications completely but then when they pivoted to services they started doing it themselves and eventually the hipocracy got to be too much for even them and they started allowing it with no decent way to discern them reply wruza 9 hours agoparentprevThatâ€™s still miles away from being able to filter or categorize notifications by regexps or keywords at least. Both systems are designed for an â€œaverage idiotâ€, and you feel exactly like this using either. Btw, I remember that apps abused the system you mentioned or used it in a way which was annoying (e.g. a messenger not choosing my default beep for every new chat and instead using system default). reply Iulioh 9 hours agorootparent----- Thatâ€™s still miles away from being able to filter or categorize notifications by regexps or keywords at least. ----- Well, you can do it with apps like FilterBox reply wruza 8 hours agorootparentHonestly, Iâ€™m torn between â€œandroid power users can do so muchâ€ and â€œa regular app can access notifications system-wide, wtfâ€. How does it work? reply jdietrich 7 hours agorootparentAndroid apps can request very powerful permissions, but those permissions are specific, explicit and revocable. There's a fundamental trade-off between power and risk, but I think the Android security model handles that trade-off quite well. https://developer.android.com/guide/topics/permissions/overv... https://developer.android.com/reference/android/Manifest.per... reply geokon 6 hours agorootparentMy #1 issue is that I'd love to grant an app powerful permissions if I can ensure it doesn't have internet access. But default Android doesn't expose the network permission (which exists and is accessible in ROMs like LineageOS) Of course if this was exposed then people would start blocking the Google data vaccum - and that's bad for business reply idle_zealot 8 hours agorootparentprevThere's a permission with a scary warning that it needs to request and be granted to read your notifications. reply Iulioh 8 hours agorootparentYeah, same with stuff that can interact and register what is on the screen Like a few pokemon go add-ons that can read what's on your screen and be a overlay (to distinguish good pokemon from bad) reply benterix 6 hours agoparentprevThat's why I disabled all notifications, including the ones from taxi apps. When you think of it, they're completely unnecessary as you can track the moment of the car in (near) realtime anyway, so for these 3 minutes between ordering a car and it arriving I can live without any notifications. Also, for me the \"Your driver has arrived\" is not that useful anyway as I need a minute or two to actually reach the taxi starting from putting my shoes on etc., so even this notification is suboptimal. reply ninkendo 7 hours agoparentprevIâ€™ve never used an android phone so Iâ€™m curiousâ€¦ isnâ€™t the categorization of such notifications totally up to the developer? I donâ€™t see any other way it could work unless the OS is doing some ML on the notifications. If Iâ€™m an app developer I could just lie and say all my marketing trash notifications are actually time sensitive/important so that youâ€™ll still receive them. Apple has a similar thing and itâ€™s only a soft policy (that an app reviewer would have to catch) that prevents developers from abusing it. If it really is up to the app developer to categorize their notifications so that you can disable categories, then it sounds like itâ€™s just a simplified way of managing individual appsâ€™ notification preferences, no? (Not that thatâ€™s a bad thing, I wish iOS had this.) reply ignoramous 6 hours agorootparent> Iâ€™ve never used an android phone so Iâ€™m curiousâ€¦ isnâ€™t the categorization of such notifications totally up to the developer Yes, but any popular app will have implemented it. > If Iâ€™m an app developer I could just lie and say all my marketing trash notifications are actually time sensitive/important so that youâ€™ll still receive them In those cases, your users would come to distrust your app. I reckon, only a negligible percentage of 3b Android users ever turn any notification off. More likely that some have learnt to ignore them altogether (banner blindness); swipe left to dismiss those isn't exactly as hostile as cookie banners are. Or, worse uninstall your \"misbehaving\" app (some are annoyed by notifications). reply nmussy 6 hours agorootparentprevIt is up to the developers, and most of them play ball from what I've seen. What I can tell you from a user perspective is that if they don't categorize their notifications properly, I will at the very least block all their notifications, or uninstall and look for an alternative app if possible. Maybe a developer can weigh in on the incentives this behavior creates, in terms of lost engagement or userbase reply bruh2 6 hours agorootparentprevIt's up to app developers, and some of them indeed just straight up lie with their categorization. Moovit and all dating apps come to mind. They implemented _some_ categories, but none useful â€“ nothing that lets you separate wheat from the chaff reply kmlx 9 hours agoparentprevto disable spam notification from the uber app: account > settings > communication > push notifications > uncheck all one more: account > settings > privacy > offers and promos > allow personalised set to Off yes, apple needs to fix this. reply bobwaycott 8 hours agorootparentAnd in the Uber Eats app, itâ€™s Account > Communication to disable all the annoying notifications. reply stanislavb 8 hours agoparentprevOh, how much I hate the Uber notifications. Thanks for the example. They are a perfect example of abusing the system. reply drivers99 4 hours agorootparentI used Uber once, then it woke me up with a notification in the middle of the following night. So I deleted it. I still have Lyft though, without problems. reply bayindirh 8 hours agoparentpreviOS actually has two kinds of notifications. Normal and time sensitive (urgent). Itâ€™s app developers which abuse the mechanism. Itâ€™s not one size fits all. reply voytec 7 hours agoparentprevIn the Uber app, click on person icon in top-right corner, go to \"Privacy and Data\" tab, open \"Privacy Center\" and you should be able to turn off ads and promos. reply e40 5 hours agoparentprevNot true about iOS. You can make a DnD profile and let any apps you want through the filter. I use this all the time. reply c-hendricks 5 hours agorootparentThat's not what they're talking about. On Android, notifications have a \"channel\". So you can disallow certain types of notifications while still allowing others through. reply gandalfgreybeer 5 hours agorootparentThis also applies to Apple's focus modes which he was mentioning. reply c-hendricks 4 hours agorootparentSo with Focus Modes, I can allow notifications about delivery from Uber Eats while disallowing notifications about random deals from Uber Eats? reply EasyMark 2 hours agorootparentno you can't, it's kind of all or nothing. reply gryn 5 hours agorootparentprevyou're misreading the comment. this a about filtering the kind of notification from a single app. notifications from a single app are split by category, and you can disable in the phone settings notifications from a single category will keeping the rest for a single app. (though this categorizing is done by the app dev not you, so the dev can mix annoying stuff with the useful) reply kjkjadksj 6 hours agoparentprevYou can always just use the webapps and have things like uber text you. reply thunky 6 hours agorootparentFor the \"dumb phone\" target audience this probably won't work. reply onethought 9 hours agoparentprevCanâ€™t this be handled by switching off Lock Screen notifications but keeping time sensitive ones on? I take your core point but your specific example I think is handled by that. reply ssss11 9 hours agorootparentAre time sensitive notifications new? Iâ€™ve never heard of them but the setting is there for me. Using Uber as the example if I turn off Lock Screen notifications and turn on time sensitive notifications then will I get no marketing notifications, and only notifications about my driver turning up? reply darren_ 9 hours agorootparent> if I turn off Lock Screen notifications and turn on time sensitive notifications then will I get no marketing notifications, and only notifications about my driver turning up? It's up to the app developer, they get to mark notifications as time sensitive or not. So if someone decides that because a coupon is expiring soon it's \"time sensitive\" to ping you about it, then they can mark it as such. Hypothetically Apple could frown on this in app review, but it isn't something app reviewers are likely to be able to reliably catch. reply Retric 5 hours agorootparentSame is true on Android. Uber lets you disable annoying notifications in App or through settings because otherwise fewer people would use it. reply boesboes 9 hours agorootparentprevBeen there for atleast 4 years iirc reply onethought 8 hours agorootparentprevI have my Uber set that way, and yes, I just get the driver stuff. Uber eats though, I can never seem to get right, and it tries to spam a lot more. So I still agree with the original point reply bobwaycott 8 hours agorootparentUber Eats is the worst. In the app, Account > Communication is where they have you auto opted-in to endless promotional garbage. reply walteweiss 5 hours agoprev [â€“] Seriously, HN? You want a dumb phone, go get yourself used iPhone X/SE or something, and never install anything, but only the essential stuff. Without all the gazillion of apps, it would work wonders even in 2024. You have issues with you wasting your life on something like Facebook? Donâ€™t install it. Use browser when needed. Use private tab in Safari, and enter your password each time, so itâ€™s all complicated now. (Thatâ€™s how I use it, btw.) Same with any other addictives. Android users, I recommend you to get oLauncher from f-droid/gplay (or better oLauncherCF), and thatâ€™s enough already. Hide all the distractions, and Bobâ€™s your uncle. I have my phones to be the bare minimum pocket computers for years now, and Iâ€™m surprised that topic still arises and is actual. Greyscale is bullshit, isnâ€™t it? Has anyone used it seriously for over a couple of days? Even Night Shift is kinda bullshit, in a way. (Better to leave it on, though.) The way is to not use your phone in the night, if you can afford it. If thereâ€™s no nightly drone and missiles attacks from russia in your countries now. So that you need to watch out for Air Raid Alerts 24/7. And your life is at stake. If youâ€™re not there, chances are you can afford to not touch your phone since the evening till the morning. Think of it. The essential thing isnâ€™t inside your phone, itâ€™s outside of it. Itâ€™s you. Work on yourself, and those distractions wouldnâ€™t take you that easily, even when your phone is all flashy and colourful. I know, we all have that shared problem, but I thought itâ€™s kinda resolved issue for overâ€“ for years. Sinceâ€“ idk, 2017? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Dumphones Blog offers a guide to convert your iPhone into a \"dumb phone\" to reduce screen time and promote digital minimalism without buying a new device.",
      "Key steps include using a minimal homescreen launcher, setting plain wallpapers, enabling grayscale display, and disabling most notifications.",
      "The article also recommends deleting addictive apps to make the phone less engaging, helping users manage their digital habits, though it's not a complete solution for smartphone addiction."
    ],
    "commentSummary": [
      "The discussion explores strategies to convert smartphones, especially iPhones, into \"dumb phones\" to minimize distractions and overuse.",
      "Methods include disabling notifications, using greyscale mode, and adopting minimalistic home screens, with some opting for simpler devices like Jelly Star or E-ink phones.",
      "The consensus emphasizes that while technical adjustments can aid, self-discipline and understanding personal triggers are essential for reducing phone addiction and enhancing focus."
    ],
    "points": 181,
    "commentCount": 141,
    "retryCount": 0,
    "time": 1716708644
  },
  {
    "id": 40482833,
    "title": "Google Meet Introduces Adaptive Audio for Seamless Multi-Device Meetings",
    "originLink": "https://workspaceupdates.googleblog.com/2024/05/google-meet-adaptive-audio.html",
    "originBody": "Updates This official feed from the Google Workspace team provides essential information about new features and improvements for Google Workspace customers. Introducing adaptive audio in Google Meet: creating ad-hoc meeting spaces with multiple laptops Wednesday, May 22, 2024 Whatâ€™s changing In this hybrid work era, we hear from customers that finding a video conferencing room to join a meeting is often difficult. With â€œadaptive audio,â€ you and your team can join Google Meet using multiple laptops in close proximity without awkward echos and audio feedback. This is a great benefit for organizations with not enough video conferencing rooms or without resources for dedicated conference room equipment. Adaptive audio in Meet will automatically detect the presence of multiple laptops in the room and synchronize the microphones and speakers for a seamless audio experience. This allows teams to create ad-hoc meeting spaces anywhere with just their laptops where everyone can be heard clearly, without the inconvenience of crowding around a single laptop. Most importantly, adaptive audio gives users the flexibility to join meetings when meeting rooms are not available, meeting room hardware is not working, or for smaller organizations, when there isn't dedicated video conferencing equipment in every room. This also gives organizations the ability to use non-typical meeting spaces such as lounges, cafes, and other impromptu locations. The microphone and speakers of each participant are used to ensure everyone can hear and be heard well. When multiple participants are joining a meeting from the same room, â€œadaptive audioâ€ is automatically activated. Google Meet notes audio is merged and participants are grouped together in the people panel. Getting started Admins: There is no admin control for this feature. End users: This feature will be ON by default and can be turned off by the user by going to Settings > Audio > Adaptive audio. Visit the Help Center to learn more about using adaptive audio in Google Meet. Rollout pace Rapid Release domains: Gradual rollout (up to 15 days for feature visibility) starting on May 22, 2024 Scheduled Release domains: Full rollout (1â€“3 days for feature visibility) starting on June 5, 2024 Availability Available for Google Workspace customers with the Gemini Enterprise, Gemini Business, Gemini Education, Gemini Education Premium, and the AI Meetings and Messaging add-on. Resources Google Help: Use Adaptive Audio Labels: Google Meet , Rapid Release î¢Š î—„ î—ˆ Filter by product î—… î‹‡ Filter by date î—… Subscribe by feed Subscribe by email Localized Google Workspace Updates EspaÃ±ol FranÃ§ais æ—¥æœ¬èªž PortuguÃªs Useful Links Join the official community for Google Workspace administrators In the Google Cloud Community, connect with Googlers and other Google Workspace admins like yourself. Participate in product discussions, check out the Community Articles, and learn tips and tricks that will make your work and life easier. Be the first to know what's happening with Google Workspace. ______________ Learn about more Google Workspace launches On the â€œWhatâ€™s new in Google Workspace?â€ Help Center page, learn about new products and features launching in Google Workspace, including smaller changes that havenâ€™t been announced on the Google Workspace Updates blog. ______________ Google Privacy Terms",
    "commentLink": "https://news.ycombinator.com/item?id=40482833",
    "commentBody": "Google Meet rolls out multi-device adaptive audio merging (googleblog.com)173 points by tfsh 3 hours agohidepastfavorite111 comments crazygringo 45 minutes agoI just want to say that this is really actually kind of mind-blowing from an audio engineering perspective. Outputting audio from multiple laptops in the same room is easy. Perfectly syncing it is harder. Implementing echo cancellation across all of that is quite a bit trickier than regular single-device echo cancellation. But then treating all the laptop microphones as a kind of microphone array, having to deal with sync issues and phase issues and background noise issues... that's hard core. Kudos to the engineering team on this one. This is actually pretty amazing. reply nytesky 14 minutes agoparentTechnically very impressive, and meets a real need. My office is still running telecom hardware from a decade ago, all the wireless mics have dead batteries, and is reluctant to replace since so many meetings are completely virtual, so why have custom in office hardware. This essentially replaces that expensive proprietary hardware with a matrix of laptops, and essentially every user gets a mic. But it only works on laptops right, not phones? reply iandanforth 39 minutes agoparentprevDo you think they are using some kind of inaudible-to-humans signal to coordinate this or is the unmodified audio good enough? reply vineyardmike 36 minutes agorootparentUnmodified audio is good enough, but using some signaling sound would improve coordination. reply varispeed 25 minutes agoparentprevAlso imagine that 44.1kHz on one laptop will not equal 44.1kHz on another or one can run at 96kHz and others on 44.1kHz etc. that means everything has to be dynamically resampled in realtime whilst preserving quality and low latency. reply lelandfe 13 minutes agorootparentYouâ€™re making me think about what they do with malfunctioning speakers and mics. My laptopâ€™s left speaker is considerably louder than the right, and there can be bad sibilance with louder noises. They might want to treat such audio with suspicion when calculating the room. It reminds me of the Byzantine generals problem, though Iâ€™m sure itâ€™s ultimately quite dissimilar. reply paul7986 13 minutes agoparentprevEngineering team or some hard working dreamers who Google invited to do business with and stole their work https://news.ycombinator.com/item?id=18566929 That's a big part of the Silicon Valley playbook..stealing from the little guy...overall excited for chatGPT to crush Google as well looking forward to a future chatGPTt phone created alongside Microsoft (its branding should be chatGPT tho). reply jeffrallen 27 minutes agoparentprevIf you were doing this kind of multipath and array signal processing on RF signals, it would be covered by ITAR. And yet Google can ship it anywhere on the planet via HTTPS and webasm... Things that make you go hmm. reply nevir 2 hours agoprevMeet, to me, is the perfect balance of functionality and simplicity (as an end user). And features like this only make that more apparent. Zoom and Teams always frustrate me, even though they're what I use far more often. It's too bad that video conferencing is largely a game of who has the most boxes checked - IT admins and A/V folk are the ones that need to be convinced, and Meet just doesn't ...meet... their needs reply alkonaut 1 hour agoparentIt very rarely matters which product is \"better\" in any objective sense. If you are team that work with Teams, your meetings will be on teams. Teams could be much worse than Zoom or Meet, you wouldn't move your group from Teams for one meeting anyway. reply sixothree 26 minutes agorootparentWe work with a lot of external customers. Teams, GotoMeeting, GotoWebinar, Skype, Google Meet, Zoom. And honestly, they all suck. Getting logged in is always a problem. Setting my name permanently is literally always a problem (I have zero idea why). Viewing someone elses screen always stinks because the scaling is just not good. On top of that you can't compare Teams to Google Meet because literally every organization has theirs configured differently. For some organizations, I can use my phone for audio. For others I can only use my laptop. So it's never an Apples to Apples comparison. Sometimes you have access to chat history; other times if you reconnect you lose chat history. The differences inside a product go on and on. reply stavros 2 hours agoparentprevMeet frustrates me immensely because I can't just fullscreen someone sharing an HD screen onto my HD screen and get 1:1 pixels with an overlay of faces (like Zoom does). Instead, I have to either not be able to read small text, or awkwardly pan in the recently-added \"zoom\" view. reply blumomo 50 minutes agorootparentYou get near full screen watching a shared screen with Meets with these steps: 1. change Meets call layout to one video (presentation) only, disabling participant watching 2. press F11 to make browser go full screen 3. press Ctrl+Minus multiple times to decrease UI elements which makes the shared video near full screen reply stavros 44 minutes agorootparentI'll try that, thanks! reply pimlottc 25 minutes agorootparentprevIt is pretty frustrated how limited the layout options are. The best workaround is to open a second Meet window and join the meeting in \"companion mode\" [0]. Then you can at least position the windows how you like, with each focusing on a different thing. 0: https://support.google.com/meet/answer/11295507?hl=en reply CitrusFruits 1 hour agorootparentprevYeah I feel like with a couple UI tweaks or options Meet would be the best by far. It's just so much more convenient and accessible than the others. reply anon84873628 24 minutes agorootparentJust in case any Meet engineers are reading... It needs to let me put my self-view right under the webcam lens, so I can stare at myself and still be looking at the camera. reply stavros 1 hour agorootparentprevI definitely agree, needs no installation, things just work, quality is good, has nice features like push-to-talk, etc. It's great, there are just some tiny UX niggles that could be solved very easily but haven't been, yet. reply matsemann 38 minutes agorootparentIt's horrible slow on some computers/browser combos, which is my main gripe with it. Video quality is also much worse, but doesn't matter too much to me. And as with all Google stuff the UX is kinda weird and non-intuitive. What does all the different join options do? When should I use what? Why must all presentations be so small if I also want to see the presenter? Zoom is much better here. reply novok 2 hours agoparentprevMeet's GUI eats screen space and reduces the size of video feeds as a result with not being able to do anything about it. It took years for it to let you choose audio and video sources from the button itself like zoom has had forever and forced you to go into the setting panels and tap on 4 screens. Same with video feed layouts. I really dislike meet compared to zoom. Zoom also transmits much higher quality video and screen share feeds than meet does. This new feature is very impressive although, most echo cancellation is \"mute everyone except one speaker\" which leads to walkie-talkie style half-duplex talking, which really hurts normal communication flows. I wonder how they do it here. reply buro9 1 hour agoparentprevIf Meet did \"autorecord\" combined with \"autoshare recording with recipients\" (specifically including Google Group recipients)... then it would be perfect. As it is, we're gradually shifting more things to Zoom where that's either part basic functionality, or part easy to automate as things like Zapier are well integrated into the API. We only use Meet for team meetings now, and we did use Gong.io to solve the above... but Gong is pretty expensive just to allow those who were out that week to catch up on a recording when they're back and if they care to. reply samcheng 1 hour agorootparentHmm. We natively record and transcribe many meetings via Meet. Maybe itâ€™s a function of the plan weâ€™re on? I wouldnâ€™t want â€œautorecordâ€ though - itâ€™s better for culture and rapport to not feel like every conversation is â€œon the record.â€ reply buro9 1 hour agorootparentWell I'd hope that's a property of a specific meeting and not all meetings, but team weeklies where those not present want to catch up, and the recording is only going to those regular attendees (members of a specific Google Group)... sure, that's a thing we would like to have. reply nicd 1 hour agorootparentNot sure what Gong's pricing is, but we evaluated a few different notetakers and settled on https://fireflies.ai/. $18 / month gets a recording and summary sent out to all invitees to the calendar invite, uploaded into Hubspot, etc. Very valuable for our sales calls. reply Szpadel 1 hour agoparentprevI used many video conferencing systems over the years and I meet is my favourite usually there is need to some third party extension/application that have usually does not support Linux or if Linux is supported, they explicitly ban Wayland/pipewire (I'm looking at you slack) but for need they stick to web standards therefore this works in any web browser you might have also it tends to not consume every CPU cycle you have (slack again) so you can do so something while you eg screen sharing reply dgellow 46 minutes agoparentprevMy Meet calls always end up pixelated, where Zoom looks perfect. Thatâ€™s basically the only thing I care about after the audio quality, I often cannot read someoneâ€™s screen when shared via Meet. Zoom also feels lower latency but I never checked if thatâ€™s the case. Note sure if thatâ€™s because Iâ€™m not in the US. reply cloudwalking 2 hours agoparentprevAgree, I find Meet is the simplest and works the best. I really appreciate the audio filtering -- don't ever hear colleague's typing or dogs barking or lawn mowing. reply mulderc 1 hour agoparentprevI have always had way more issues with meet than zoom. Guessing it is something about browser compatibility but participants regularly have issues with mics and cameras that I donâ€™t see with zoom. reply contrarian1234 1 hour agoparentprevMeet requires a Google account to attend a video call while Zoom does not. So if your hosting a meeting with strangers, using Meet is not user friendly. At least personally I refuse to make a Google account bc it requires giving Google my phone number... But I know that's a bit of technoludditism in the current zeitgeist reply loosescrews 1 hour agorootparentThis is only true for meetings created with free gmail accounts. If use Google Workspace this limitation does not apply. reply behnamoh 44 minutes agorootparentThat's a shady tactic right there. reply jasonvorhe 21 minutes agorootparentWhat's so shady about that? It's not like they're advertising a feature to free Gmail users only to up sell them to workspace? reply whstl 1 hour agorootparentprevIs this new? I have definitely joined Meets calls from my personal laptop and I don't have a personal Google account. This includes my last job interview, and, well, I got the job. Perhaps it's meeting specific, or organization specific? reply varispeed 24 minutes agoparentprevThe organisation I worked at used Meet until someone from Microsoft convinced them to use Teams. Such a nightmare. Quality of meetings went downhill and employees were penalised for secretly using Meet for ad hoc meetings. reply bongodongobob 51 minutes agoparentprevAs an \"IT admin\", it's not that I need convincing. It's that the rest of Googles \"office\" products are absolute amateur hour and support is non-existent. reply jamesrr39 15 minutes agorootparent> the rest of Googles \"office\" products are absolute amateur hour Not quite sure about this. Gmail (both personal and company accounts) is IMO a great email client with loads of handy features, and I always felt Google Docs/Sheets/Slides/Drawings were well put together. Are they the best in class? I guess it depends what you are looking for. Could Drive be faster? Yes, that would be nice. But \"amateur hour\" sounds like we are simply using different products. reply nradov 1 hour agoparentprevThis isn't an area where simplicity wins. Zoom is targeted more towards professional use whereas Meet is more for casual or social use. It doesn't really support multiple displays, like I can't watch screen sharing on one display while moving the chat and video windows off to another display. Scaling options for screen sharing are inadequate and it doesn't even support real full screen display. Meet lacks advanced audio options that make it unusable for things like music lessons. Zoom has more third party integrations available. reply pquki4 1 hour agorootparentI think because Meet is fully browser based, some of the features like sharing audio with screen are only available via chrome or chromium based browsers -- definitely not on Firefox in my own testing. I don't know the exact reason for that, but it's kind of sad. reply ChuckMcM 50 minutes agorootparentWhich is why I don't use Meet. reply kccqzy 30 minutes agorootparentThat's exactly the reason I use Meet. I don't want native code execution; I want sandboxed JavaScript code execution. reply ChuckMcM 6 minutes agorootparentThat's fair. Everyone comes to these sorts of positions with a stack of values[1]. How that stack is ordered often determines one's choices. One of the interesting things for me from a technological perspective is whether or not we're converging on what the ideal set of features for a \"video phone\" would be. If there was a broad enough consensus on the core feature set I would hope an 'appliance' version would be available which would eliminate needing to use a general purpose processor (and all the risks that entails) for this sort of meeting. [1] From your response I infer that you value \"no native code\" and \"sandboxed javascript\" highly which guides you to the choice to use Meet, vs someone who might stack \"User Experience\" more highly than those two and end up at a different choice. reply moralestapia 33 minutes agoparentprevAgree that Meet is the superior experience. Unfortunately, it's only a matter of time until one their VPs decides to \"improve it\" with the usual imbecile ideas they come up with. >Google Meet now scans all your files so they can get shared automatically with all members on the meeting when it is appropriate to enrich the conversation. You cannot opt-out this feature. reply r00fus 2 hours agoparentprevMeetâ€™s default audio noise cancellation is pathetic compared to Zoom. Initial Teams was also poor but has improved. My daughterâ€™s school uses Zoom for her IEP where at least one attendee is remote that day. Not a fun experience. reply nh2 12 minutes agoprevI want a simpler feature: Auto-detect people not using headphones, and prevent them from speaking. Until they put some one. Ideally showing them some customisable scolding message. So far, any feedback / echo cancellation I've encountered just makes everybody's life miserable. Degradation to non-duplex voice (because all except the loudest speaker are attenuated down), \"seaside noise\" effect\", etc. This is the reason why a phone call over GSM or landline still often \"feels\" better than any HD video call with people on screens: Low-latency duplex audio. Most* of this goes away if you just wear headphones. Maybe this can be fixed by making the algorithm way more complicated, as the announced feature does. But I'd be surprised. [*]: \"Most\": 2 people with headphones sitting near each other still cause echoes for each other and other participants. Fixing that is truly novel, and needed even for headphone users. reply maliker 9 minutes agoparentAnd then there's another nag prompt if bluetooth headphones/mic are detected. The latency on those things can get horrendous, up to like 300 ms. reply pachico 1 hour agoprevGitLab offers a nice course about transitioning to remote work. One of the items in their guidelines about online meeting is not having hybrid meetings. This is, all those attending must attend from their own device rather than the meeting room one (see Jabra) precisely for the reasons this feature tries to address. reply Rastonbury 1 hour agoparentIt gets complicated when half a team is in the office taking the same call from their desks, easier for Gitlab because they are full remote reply unixhero 1 hour agorootparentThis does not complicate matters. reply emptysongglass 1 hour agorootparentIt does in ways you likely don't understand. At large enterprises with satellite offices, most of us don't want to sit at our desks and annoy our coworkers who are also in-office by taking calls at our desks. That leaves meeting rooms, which are at a premium. Full single device for everyone would mean either everyone loudly shouting at their desks from within their noise canceling headphones or the company giving everyone an office with a door. As even Google doesn't do this for their employees, this is the next best thing we can do to save the sanity of our coworkers and respect remote colleagues dialing in by including them in a shared room meeting. reply benterix 1 hour agoparentprevRules are meant to be broken. I've participated in many meetings where, for one reason or another, some participants couldn't join in person. Making it easier - for them and for us - is a technical challenge, and not something to be decided by an arbitrary rule. reply djtango 1 hour agorootparentRemote is extreme and is still not the norm. It is easier to baseline on things optimised for remote then relax than try to shoehorn in person into remote which is then doomed to fail. I worked for a company that was headquartered in London and had satellite offices in Spain and Germany. After we all went remote during the pandemic the EU offices said they felt so much more engaged with the rest of the company because they were no longer disadvantaged by default for not being in HQ and in person bad habits were penalizing them reply pquki4 1 hour agorootparent\"doomed to fail\" Its definitely doomed to fail if CEOs want you to think it's doomed. Your comment is handwavy with words like \"feel\" and \"bad habits\". There are real issues with remote work, but there are also ways to mitigate the downsides of it. It's easier for some people to just dismiss the idea entirely and pretend that in-office work is the better alternative without any problems. I have definitely seen that happen in my company and here. reply djtango 54 minutes agorootparentYes - my response was to the rejection that rules are to be broken. I have worked there fully remote jobs and the ones that did it best fully leaned into being remote. There is no hard or fast rule, I've been in a team social where I was the only person remote and it still felt relatively natural. I've done a fully remote follow a recipe and cook at home session which was also pretty fun. I've also been in places that do the bare minimum of what constitutes remote \"oh we use Zoom and screenshare\" and dictate to people where everyone is cam off. And the difference is night and day. I think that a little bit of cargo culting wrt remote etiquette is probably a net good thing because I posit many people still don't know what good looks like. reply _joel 1 hour agorootparentprev\"Remote is extreme\". Have you seen how many jobs on the boards are remote? reply unixhero 1 hour agorootparentprevIt was for 2.5-3 entire years reply pcx 2 hours agoprevKudos to Meet team for supporting this! In the video conf world, where most problems are well solved, this is such an amazing feature to differentiate and be customer first! reply indymike 1 hour agoprevI just exited my startup and now work for a much bigger company. I'm going from a Google-based productivity stack to a Microsoft one, and so far Teams is the worst and best change. Google Meet was fantastic for \"just working\" especially for less sophisticated meeting guests. The only time Meet didn't work is when corporate IT departments at customers actively blocked Meet so their minions used the \"approved meeting solution\". As far as Teams vs. Meet, it seems like Teams is great when you are working with people that have climbed it's learning curve. Teams is also filled with UX paths where it takes one or two extra clicks (and thoughts) to do simple things like share a file. reply benterix 1 hour agoparent> As far as Teams vs. Meet, it seems like Teams is great when you are working with people that have climbed it's learning curve. Can you give one example? reply stackskipton 1 hour agorootparentI can give several. Most of them are not Meet specific but how Meets integrates with rest of Google Products. This is actually overall massive problem with Google Workspaces in general IMO. 1) You can call someone in Teams. Sure, Google Chat has \"Start Meeting now\" but it's very passive. I know some will see this as negative but ringing has massive advantages around UX. 2) Chat, Teams will persist chat after meeting ends. In fact, depending on how you hold the meeting, it might dump the contents into chat channel so it's preserved in more open manner. 3) You can have visible meetings. You can start a meeting in a Teams chat channel so everyone can see the meeting is going on. It creates that in the office feeling of two people working on a whiteboard nearby that if topic interests you, you can join in. 4) Sharing Documents, Add Word Document to meeting, everyone is granted permissions. Done. The fact so many Google Workspaces companies have Slack is just frustrating. You have these two products that barely talk. reply NayamAmarshe 53 minutes agoparentprev> I just exited my startup and now work for a much bigger company. Sorry for the off-topic comment but I'm interested in learning more :D Could you please tell us about your experience and how you built a startup and sold it? reply madisp 2 hours agoprevSadly this is feature-gated behind Gemini :/ > Available for Google Workspace customers with the Gemini Enterprise, Gemini Business, Gemini Education, Gemini Education Premium, and the AI Meetings and Messaging add-on. reply crazygringo 43 minutes agoparentNot if you pay attention to that last one: > and the AI Meetings and Messaging add-on This might actually be using a decent amount of data center processing to handle the merged audio performantly. If that's the case, it could make sense that it belongs to a higher tier. reply trustno2 2 hours agoparentprevI'm not that deep into Google latest rebrand activity... how is Google Meet related to LLM model? or do they call many unrelated things Gemini? reply notatoad 33 minutes agorootparentgoogle meet is part of their office suite, called google workspace. the higher tiers of google workspace include access to the paid tier of gemeni. also, in a previous iteration of google's AI branding, meet had a feature that would create llm-generated meeting notes for you. i'm unsure if this still exists https://www.theverge.com/2023/8/29/23849056/google-meet-ai-d... reply smt88 1 hour agorootparentprevIt's not related to Gemini. I suspect they're putting non-LLM stuff behind the Gemini paywall to make Gemini look more profitable than it is. Like most LLM rollouts, it could maybe become cashflow-positive, but it will likely never be profitable because of the many billions it takes to compete with OpenAI and Meta. reply benterix 1 hour agorootparent> It's not related to Gemini. I suspect they're putting non-LLM stuff behind the Gemini paywall to make Gemini look more profitable than it is. I have yet to decide whether this is more ridiculous or sad. reply rav 1 hour agoprevMeet is nice and nicer than Teams and Zoom in my opinion, but for 1-on-1 pair programming I think Facebook Messenger actually has the best experience - when you're on the same screen resolution, the screen sharing is 100% zoom (unlike Meet which has padding around the edges), and you can move seamlessly between mobile and desktop (i.e. answer a video call on mobile, the other party sets up screen sharing, and you go to a laptop to continue the call). Too bad I'm not automatically Facebook friends with all my co-workers! reply foreigner 2 hours agoprevDo any of the video call services support full duplex audio? It feels so stifling to have to be perfectly silent while others are speaking, compared to the give and take of a normal conversation. reply crazygringo 40 minutes agoparentPretty sure literally all of them do, but generally only full duplex. Not triplex or quadruplex etc. In other words, if you're having a 1-1 video call, both of you have your audio working at all times. But as you go to 3, 4, 5, 10, 20 participants, it generally continues to be just max 2 simultaneous audio streams, determined by whoever has been the loudest recently. Unless you turn on special features like music mode etc. This is a feature, not a bug, because otherwise background noise and sounds would start adding up to become intolerable. (Why we usually try to intentionally stay on mute anyways, so we don't accidentally become even just that second audio stream.) reply stavros 2 hours agoparentprevYes, all of them. Wear headphones. reply Groxx 41 minutes agorootparentTo +1 this, yes, every single one AFAIK. What you're running into is almost certainly noise cancelling. It's turning off your incoming audio so it doesn't intrude on your microphone picking up your voice. Disabling or tweaking noise cancelling or audio modes (i.e. to \"headset\") on basically every meeting software will eventually get you a combination that doesn't do this. It's sometimes a bit hidden though, and many have chosen to just say \"everyone gets maximum noise cancelling\" rather than trying to guess based on your audio device(s) so it doesn't always do it automatically or obviously. reply stavros 33 minutes agorootparentMinor correction: it's echo cancelation, not noise canceling. reply simonbarker87 2 hours agoparentprevI feel like Zoom does the best job of the corporate offerings. Google Meet feels like the worst and most stifling. I was talking to someone who specialises in corporate communication at a conference last week and she confirmed my feeling above as well. Her thing is â€œtalking over each other is a key part of human interaction and forcing one at a time is stifling and unnaturalâ€ reply haiku2077 2 hours agorootparentI just don't understand how this can work perfectly in Discord while working so badly in Zoom. reply jerlam 1 hour agorootparentThey seem to be designed differently. The business ones try to replicate a business meeting where someone talks at the front of the room, shows slides, and prompts for questions. Discord is more like a LAN party. reply jpalomaki 2 hours agorootparentprevMight be also related to the delay in communications. There's the time the packets traverse the networks, but also delays due to buffering to accommodate poor connections. reply toast0 1 hour agorootparentTotal audio delay is from record buffering, sampling (typically 20 ms samples), encoding, packetization (1-5 samples per packet), time in transit, decode, jitter buffer, playout buffer. You could reduce sample size, and send fewer samples per packet to reduce total delay, but overhead goes way up (overhead is near 50% at 20ms samples, one per packet). In theory, you should be able to do something nice for people doing audio and video by including audio on the video packets, but it's not simple, so I think most conferences don't do it. reply pquki4 1 hour agoprevMy company has conference rooms that have specialized hardware for Microsoft Teams meetings. The audio really sucks -- everyone must project their voice for people joining online to hear. If someone speaks in a low voice, nothing can be heard on Teams even though it is clear enough for people in the room. I don't understand how we haven't solved this problem yet. The functionality here seems interesting, but I assume only works well if everyone or almost everyone brings a laptop. It probably won't work well for those situations where only one or two people take their laptops to an in-person meeting. reply anotheryou 35 minutes agoprevSurround sound from the speakers next :)? I however think (emulated) stereo sound and low latency would do wonders. Sadly this feature here will only introduce latency. Feedback cancellation for external speakers would also be amazing, so you can get rid of your headphones at home. Close up mic and noise gate works, but is fiddly (and no easy noise gate and compressor on linux...) reply deepak_sozial 11 minutes agoprevWill this work on Google Workspace Business Starter plans? reply dansimau 1 hour agoprevI've always thought it would be nice if microphones can be merged when on a phone call with AirPods in. The mics in those headphones are really far away from my face and when it's windy talking on them is almost impossible. It would be nice to be able to just talk into the mic on my phone. Then the phone could boost my voice from multiple mics and filter out background noise. reply andai 1 hour agoprevSounds imprrssive, but also overengineered? Don't headphones solve the same problem? Though I guess in a hybrid meeting they'd make it harder to hear the people in the room. (But you'd hear them through the laptop, normally? I guess there would be an uncanny delay...) reply dewey 26 minutes agoparentI think you miss-understood the feature. It fixes the issue where there's multiple people in a room joining the same meeting from their laptops while sitting next to each other. It basically combines all microphones / speakers in that room into one big speaker / microphone just like a fancy conference setup. reply mattlondon 1 hour agoparentprevNo because your voice is not constrained to headphones. reply Groxx 39 minutes agorootparentNo problem, just get everyone a Mutalk. Think of all the savings when you no longer need meeting rooms! reply okdood64 59 minutes agoparentprevWho's wearing headphones in a meeting? Good luck trying to get people to do that. reply notatoad 36 minutes agoprevdoes this mean that when a new person joins a meeting that isn't on mute by default, we won't have to deal with the echos from everybody else in the office while they scramble to find the mute button? because that sounds amazing reply krashidov 44 minutes agoprevThe fact that you can't easily go full screen on Meets is bizarre. Makes it a non-starter for pairing. Also, the dedicated app's session lasts for like a day which makes it useless, so I'm stuck having to scroll through my 3 chrome windows and 40 tabs to see where my meets tab is. Although I'm sure the session timeout is some sort of gsuite configuration reply opdahl 1 hour agoprevThis amazing news for my hybrid team. It has always been a struggle figuring out with laptop to use, moving around so you get closer to the mic etc. Hopefully it is as seamless as they portray it here in the blog. reply sMarsIntruder 1 hour agoprevAvailable for Google Workspace customers with the Gemini Enterprise, Gemini Business, Gemini Education, Gemini Education Premium, and the AI Meetings and Messaging add-on. So basically unaffordable for most organisations. reply nickpsecurity 46 minutes agoprevAnother advantage of Meet that it is under U.S. control and law. Zoom out their development team in China. That country actively targets dissidents. Itâ€™s easier when those controlling the software are easy for them to control. Better to use Meet than Zoom if the Chinese are in your threat profile or a larger threat. reply pachico 1 hour agoprevAm I the only one surprised that they keep using this blog style as it was 2005? reply echelon 2 hours agoprevMeet and Google Docs are perfect Google products. I'm disapponted when people send me Zoom meetings or want to meet on Slack. Google Meet is a 10x better experience. reply lawik 2 hours agoparentUnless you need legible screen dharing of a code editor in my experience. Zoom is awful in many ways but blows Meet out of the water for our needs. reply parpfish 1 hour agoparentprevI love meet because of how well itâ€™s integrated with google cal reply aniviacat 1 hour agoparentprevIs it possible to use Google Meet without telling Google your phone number? I know that it's possible to use Zoom and Teams anonymously. But for Google Meet, I assume providing a (verified) phone number is required. reply rav 1 hour agorootparentYou can use it with just a personal Google account - does that require a phone number? Alternatively, someone with a Google account can create a meeting (https://meet.new) and send you the link, which you can join without any Google account at all. reply worthless-trash 56 minutes agorootparentI have never given my work my number, and yet meet seems to work for all my work meetings. reply dtx1 57 minutes agoprevWe use google meet internally where i work but i often have to work with external companies using teams, zoom and whatever else. Google Meet just works, all day, everyday for us (barring a fucked up client audio setup...) and this is such a sweet feature we've struggled with, I genuinely look forward to testing this reply pawelwentpawel 2 hours agoprevDo other platforms already provide something similar? While I've been picking up calls mostly in meeting / silent rooms (times of gathering around a jabra like a camping bonfire are fortunately gone for now) - some of the users of a platform that I've built (https://flat.social) would occasionally experience the atrocious feedback whistle while being in physical proximity. reply bagels 2 hours agoprevI'm more interested in cancelling regular feedback from one laptop in the meeting. reply e_carra 2 hours agoparentNot sure if this would solve your problem, but have you tried companion mode? reply bagels 58 minutes agorootparentI think the other party would need to try it? I'm using a headset, the feedback is coming from the other party. reply parpfish 1 hour agoparentprevDo you mean audio feedback, or just one user that complains a lot? reply bagels 1 hour agorootparentI'm talking about when I hear my own voice. It happens when the person I am talking to is using speakers and a microphone, and my voice is picked up by their speakers and transmitted back to me. I didn't know this was controversial. reply crazygringo 35 minutes agorootparentFYI, that's echo, not feedback. It can happen on any service and it means the echo cancellation on their end got confused -- it's an adaptive algorithm but occasionally adapts wrong. Best way to fix it is to mute yourself for ~5 seconds and then unmute, which should reset their echo cancellation algorithm. If that doesn't fix it, then have both of you pause and not talk for ~5 seconds. This should absolutely reset it, as the echo cancellation algorithm has now definitively learned what silence is supposed to sound like. reply moomoo11 1 hour agoprevMeet is nice, but could the screen sharing view just please take 100% height/width? I hate that I have to always manually tweak it through dev tools to make it usable. How many 400k TC engineers and misguided product managers does it take to make that change? FFS reply DrammBA 21 minutes agoparentAre you using firefox? I use this extension called Stylus that lets you write custom css for pages and automatically apply it when you visit the page. There's probably something similar for chromium browsers reply kccqzy 22 minutes agoparentprevIt takes just one misguided product manager. It's easy at Google for one misguided product manager to derail a dozen engineers' work. reply sharts 58 minutes agoprev [â€“] It took this many years to get echo cancellation implemented? Many other services had this like a decade ago. reply crazygringo 38 minutes agoparent [â€“] No. Meet has had echo cancellation from the start. This is multi-device adaptive audio merging, as the title says. Completely different, and far far more impressive. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google Workspace has introduced \"adaptive audio\" for Google Meet, which allows multiple laptops in close proximity to join a meeting without audio issues like echoes or feedback.",
      "This feature is particularly useful for organizations that lack sufficient video conferencing rooms or equipment, enabling ad-hoc meeting spaces in various locations.",
      "Adaptive audio will roll out gradually starting May 22, 2024, for Rapid Release domains and from June 5, 2024, for Scheduled Release domains, and is available for specific Google Workspace plans."
    ],
    "commentSummary": [
      "Google Meet has introduced a multi-device adaptive audio merging feature, allowing multiple laptops in the same room to sync audio output and implement echo cancellation, reducing the need for expensive telecom hardware.",
      "Users compare Google Meet with Zoom, praising Meet's simplicity and no installation requirement but criticizing its slow performance, lower video quality, and non-intuitive interface.",
      "The discussion highlights the challenges of remote and hybrid work, emphasizing the importance of accommodating remote colleagues and the technical difficulties of hybrid setups."
    ],
    "points": 175,
    "commentCount": 111,
    "retryCount": 0,
    "time": 1716736922
  },
  {
    "id": 40478188,
    "title": "Zellij: A Versatile Terminal Workspace for Linux and macOS",
    "originLink": "https://zellij.dev/",
    "originBody": "Zellij A terminal workspace with batteries included linux download macOS download Try Zellij Without Installing For bash/zsh: bash <(curl -L zellij.dev/launch) Copy For fish: bash (curl -L zellij.dev/launchpsub) Copy View the script that will be executed here Would you like some Zellij stickers?",
    "commentLink": "https://news.ycombinator.com/item?id=40478188",
    "commentBody": "Zellij: A terminal workspace with batteries included (zellij.dev)163 points by thunderbong 21 hours agohidepastfavorite38 comments __MatrixMan__ 19 hours agoI really respect what the maintainer is doing: Save up, work on something awesome full time, hope that people will love it and help keep it going. Some might call it naive, I call it bold. (No affiliation, I just want to be like them when I grow up.) reply r-w 14 hours agoparentDonâ€™t wait to grow up. The sooner you fail, the sooner youâ€™ll succeed. reply _rend 18 hours agoprevZellij is pretty great, and I recommend others check it out. The UI is extremely slick, and getting a comfortable setup is nicer (to me) than tmux or screen. Unfortunately, it's missing one key feature that keeps me from using it as a daily-driver: it doesn't appear to be possible to attach to an existing session by automatically creating a new tab or pane. iTerm2 has fantastic integration with tmux that allows it to directly create a new tmux tab for every native iTerm2 split or tab, and I was hoping to recreate that with Zellij, outside of iTerm2. It _is_ possible to open a new tab with the `new-tab` action (or whatever it's called), but unfortunately, there's no way to do that \"in the background\": one of your open sessions always switches to that new tab when it opens. I don't know if this is a limitation of the session/tab system, but when I dug through the source, I couldn't for the life of me figure out why this was happening. I did spend some time trying to contribute a flag to allow attaching to existing sessions with a new tab/pane, but the actual architecture in place back then made this very difficult to support without non-trivial refactoring (and at least at the time, Zellij wasn't accepting any major contributions that weren't directly aligned with the roadmap, which I respect: there's only enough time in the day to review random PRs). I check back periodically; if this is made possible at some point, I'd love to switch to it. reply resonious 17 hours agoparentI'm a Linux user so of course I think like this, but: why use the native terminal tabs? I use Kitty with window decorations turned off, and Zellij provides all the UI I need. reply _rend 16 hours agorootparentYou're right, good question. At least partially, habit and muscle memory. I'm used to the keybindings, and the behavior for navigating tabs/splits/panes (across macOS, Windows, and Linux). But also, native splits/panes and tabs cover 90% of what I really want from a multiplexer, so it's easier for me personally to stick with familiar behavior than to integrate another tool into my workflow just to recreate it. reply DEADMINCE 10 hours agorootparentprevThat has nothing to do with you being a linux user. reply xhrpost 17 hours agoparentprevI feel similar in that there are great strengths but some things are missing. I love that mouse highlight-to-copy will wrap within the current pane rather than span panes. But mouse pane re-size like in tmux is currently not available. reply urmish 17 hours agoprevMost of the problems with zellij people have initially can be fixed if they write the config file from bottom up..just comment everything out and you'll get to your desired config in 15 minutes. Use the 'clear-defaults=true' option for each mode and build the config. E.g.resize mode for me looks like this resize clear-defaults=true { bind \"Esc\" { SwitchToMode \"Normal\"; } bind \"h\" { Resize \"Increase Left\"; } bind \"j\" { Resize \"Increase Down\"; } bind \"k\" { Resize \"Increase Up\"; } bind \"l\" { Resize \"Increase Right\"; } } Normal mode: normal clear-defaults=true { // Quit/detach bind \"Alt x\" { Quit; } bind \"Alt d\" { Detach; } // Switch modes bind \"Alt p\" { SwitchToMode \"pane\"; } bind \"Alt r\" { SwitchToMode \"resize\"; } bind \"Alt t\" { SwitchToMode \"tab\"; } bind \"Alt s\" { SwitchToMode \"scroll\"; } bind \"Alt m\" { SwitchToMode \"move\"; } // new pane or resize pane bind \"Alt n\" { NewPane; } bind \"Alt >\" { Resize \"Increase\"; } bind \"AltI think terminals are obsolete But theyâ€™re not. My colleagues and I use them every single day. My favourite shell still wasnâ€™t written. Besides a web browser, there simply isnâ€™t yet as powerful a piece of software for making a computer do anything. > Something with a real language instead of bash sh is a real language. Itâ€™s command-based programming. An example of a more programmy variant of this paradigm is TCL (Toolkit Command Language) with its tclsh: command languages are excellent for short, frequently used stuff, and then they get worse fast. So maybe I could qualify â€œrealâ€ a bit: something that is just as ergonomic for frequent stuff, but which does not get progressively worse as it veers into actual programming. > and where all the little programs that make a currently terminal work are libraries that can be used as a function or as a standalone program. Have you tried UNIX? Itâ€™s literally that! I do agree it could be improved; for example, piping around structured data is not trivial; it got better with jq, but itâ€™s not native to POSIX. reply keeganpoppen 15 hours agoparentprev [â€“] the oil shell guy is pretty ambitious. i dont really know what repl shell looks like because the shell is kind of the OG REPL, no? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Zellij is a terminal workspace designed for Linux and macOS, offering a streamlined environment for developers.",
      "Users can try Zellij without installation by running a provided script compatible with bash, zsh, or fish shells.",
      "The script is accessible online, and Zellij-themed stickers are available for enthusiasts."
    ],
    "commentSummary": [
      "Zellij is a terminal workspace known for its user-friendly interface and easy setup, offering an alternative to tmux or screen.",
      "It lacks the feature to attach to an existing session by creating a new tab or pane automatically, which some users consider essential.",
      "Users appreciate features like mouse highlight-to-copy within panes and suggest customizing the config file to address initial issues."
    ],
    "points": 163,
    "commentCount": 38,
    "retryCount": 0,
    "time": 1716674549
  },
  {
    "id": 40480258,
    "title": "Facial Recognition Error Leads to Wrongful Shoplifting Accusation in UK Store",
    "originLink": "https://www.bbc.co.uk/news/technology-69055945",
    "originBody": "'I was misidentified as shoplifter by facial recognition tech' Published 19 hours ago Share By James Clayton BBC Newsnight Sara needed some chocolate - she had had one of those days - so wandered into a Home Bargains store. \"Within less than a minute, I'm approached by a store worker who comes up to me and says, 'You're a thief, you need to leave the store'.\" Sara - who wants to remain anonymous - was wrongly accused after being flagged by a facial-recognition system called Facewatch. She says after her bag was searched she was led out of the shop, and told she was banned from all stores using the technology. \"I was just crying and crying the entire journey homeâ€¦ I thought, 'Oh, will my life be the same? I'm going to be looked at as a shoplifter when I've never stolen'.\" Facewatch later wrote to Sara and acknowledged it had made an error. Facewatch is used in numerous stores in the UK - including Budgens, Sports Direct and Costcutter - to identify shoplifters. The company declined to comment on Sara's case to the BBC, but did say its technology helped to prevent crime and protect frontline workers. Home Bargains, too, declined to comment. It's not just retailers who are turning to the technology. On a humid day in Bethnal Green, in east London, we joined the police as they positioned a modified white van on the high street. Cameras attached to its roof captured thousands of images of people's faces. If they matched people on a police watchlist, officers would speak to them and potentially arrest them. Unflattering references to the technology liken the process to a supermarket checkout - where your face becomes a bar code. Image caption, A police facial-recognition van's cameras can capture thousands of images On the day we were filming, the Metropolitan Police said they made six arrests with the assistance of the tech. That included two people who breached the terms of their sexual-harm prevention orders, a man wanted for grievous bodily harm and a person wanted for the assault of a police officer. Lindsey Chiswick, director of intelligence for the Met, told the BBC the tech's speed was extremely helpful. \"It takes less than a second for the technology to create a biometric image of a person's face, assess it against the bespoke watchlist and automatically delete it when there is no match.\" The BBC spoke to several people approached by the police who confirmed that they had been correctly identified by the system - 192 arrests have been made so far this year as a result of it. But civil liberty groups are worried that its accuracy is yet to be fully established, and point to cases such as Shaun Thompson's. Mr Thompson, who works for youth-advocacy group Streetfathers, didn't think much of it when he walked by a white van near London Bridge in February. Within a few seconds, though, he was approached by police and told he was a wanted man. \"That's when I got a nudge on the shoulder, saying at that time I'm wanted\". Image caption, Shaun Thompson says he was a victim of mistaken identity He was asked to give fingerprints and held for 20 minutes. He says he was let go only after handing over a copy of his passport. But it was a case of mistaken identity. \"It felt intrusiveâ€¦ I was treated guilty until proven innocent,\" he says. The BBC understands the mistake might have been due to a family resemblance. The Metropolitan Police declined to comment. 'Digital line-up' Silkie Carlo, director of Big Brother Watch, has filmed the police on numerous facial-recognition deployments. She was there the night Shaun Thompson was picked up by police. \"My experience, observing live facial recognition for many years, [is that] most members of the public don't really know what live facial recognition is,\" she says. She says that anyone's face who is scanned is effectively part of a digital police line-up. \"If they trigger a match alert, then the police will come in, possibly detain them and question them and ask them to prove their innocence.\" The use of facial recognition by the police is ramping up. Between 2020 and 2022 the Metropolitan Police used live facial recognition nine times. The following year the figure was 23. Already in 2024 it has been used 67 times, so the direction of travel is clear. Champions say that misidentifications are rare. The Metropolitan Police say that around one in every 33,000 people who walk by its cameras is misidentified. But the error count is much higher once someone is actually flagged. One in 40 alerts so far this year has been a false positive. Michael Birtwhistle, head of research at the Ada Lovelace Institute research group, believes the technology is so new that the laws have not yet caught up. \"I think it absolutely is a Wild West at the moment. That's what creates this legal uncertainty as to whether current uses are unlawful or not,\" he says. In Bethnal Green, although some people the BBC spoke to were worried about the use of the tech, a majority were supportive - if it helped to tackle crime. That leads to another question about the technology: will it help in the long run? As people get more used to seeing white vans parked on busy high streets, will people who know they are wanted by police simply get wise to the cameras and avoid them? Will shoplifters hide their faces? Ms Carlo says society needs to guard against facial recognition becoming normalised. \"Once the police can say this is OK, this is something that we can do routinely, why not put it into the fixed-camera networks?\" This is the dystopian future that civil-liberty campaigners are most afraid of - a China-style mass-surveillance state. Advocates dismiss such dire predictions as overblown. And it is also clear there are plenty among the public who are willing to put up with having their faces scanned - if it means safer streets. Related Topics Facial recognition Bethnal Green Metropolitan Police Service",
    "commentLink": "https://news.ycombinator.com/item?id=40480258",
    "commentBody": "'I was misidentified as shoplifter by facial recognition tech' (bbc.co.uk)154 points by rwmj 11 hours agohidepastfavorite3 comments skilled 11 hours agoOngoing discussion, https://news.ycombinator.com/item?id=40478923 reply dang 18 minutes agoparentComments moved thither. Thanks! reply ChrisArchitect 9 hours agoprev [â€“] [dupe] Discussion: https://news.ycombinator.com/item?id=40478923 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Sara was wrongly accused of theft by a facial-recognition system called Facewatch at a Home Bargains store, leading to a search and a ban from stores using the technology.",
      "Facewatch, used in various UK stores to prevent crime, apologized for the error, but the system has faced criticism for inaccuracies and potential misuse.",
      "Civil liberty groups are concerned about the accuracy and potential for misuse of facial recognition technology, fearing it could lead to a surveillance state, despite some public support for its use in enhancing safety."
    ],
    "commentSummary": [
      "A person was wrongly identified as a shoplifter by facial recognition technology, raising significant concerns about its accuracy.",
      "This incident has sparked ongoing discussions on tech forums like Hacker News, emphasizing the broader implications of facial recognition.",
      "The event underscores the need for improved accuracy and ethical considerations in deploying facial recognition systems."
    ],
    "points": 154,
    "commentCount": 3,
    "retryCount": 0,
    "time": 1716707306
  },
  {
    "id": 40478470,
    "title": "Google SRE Handbook: Emphasizing Simplicity for Reliable Software Design",
    "originLink": "https://sre.google/sre-book/simplicity/",
    "originBody": "Chapter 9 - Simplicity Table of Contents Foreword Preface Part I - Introduction 1. Introduction 2. The Production Environment at Google, from the Viewpoint of an SRE Part II - Principles 3. Embracing Risk 4. Service Level Objectives 5. Eliminating Toil 6. Monitoring Distributed Systems 7. The Evolution of Automation at Google 8. Release Engineering 9. Simplicity Part III - Practices 10. Practical Alerting 11. Being On-Call 12. Effective Troubleshooting 13. Emergency Response 14. Managing Incidents 15. Postmortem Culture: Learning from Failure 16. Tracking Outages 17. Testing for Reliability 18. Software Engineering in SRE 19. Load Balancing at the Frontend 20. Load Balancing in the Datacenter 21. Handling Overload 22. Addressing Cascading Failures 23. Managing Critical State: Distributed Consensus for Reliability 24. Distributed Periodic Scheduling with Cron 25. Data Processing Pipelines 26. Data Integrity: What You Read Is What You Wrote 27. Reliable Product Launches at Scale Part IV - Management 28. Accelerating SREs to On-Call and Beyond 29. Dealing with Interrupts 30. Embedding an SRE to Recover from Operational Overload 31. Communication and Collaboration in SRE 32. The Evolving SRE Engagement Model Part V - Conclusions 33. Lessons Learned from Other Industries 34. Conclusion Appendix A. Availability Table Appendix B. A Collection of Best Practices for Production Services Appendix C. Example Incident State Document Appendix D. Example Postmortem Appendix E. Launch Coordination Checklist Appendix F. Example Production Meeting Minutes Bibliography Simplicity Written by Max Luebbe Edited by Tim Harvey The price of reliability is the pursuit of the utmost simplicity. C.A.R. Hoare, Turing Award lecture Software systems are inherently dynamic and unstable.38 A software system can only be perfectly stable if it exists in a vacuum. If we stop changing the codebase, we stop introducing bugs. If the underlying hardware or libraries never change, neither of these components will introduce bugs. If we freeze the current user base, weâ€™ll never have to scale the system. In fact, a good summary of the SRE approach to managing systems is: \"At the end of the day, our job is to keep agility and stability in balance in the system.\"39 System Stability Versus Agility It sometimes makes sense to sacrifice stability for the sake of agility. Iâ€™ve often approached an unfamiliar problem domain by conducting what I call exploratory codingâ€”setting an explicit shelf life for whatever code I write with the understanding that Iâ€™ll need to try and fail once in order to really understand the task I need to accomplish. Code that comes with an expiration date can be much more liberal with test coverage and release management because it will never be shipped to production or be seen by users. For the majority of production software systems, we want a balanced mix of stability and agility. SREs work to create procedures, practices, and tools that render software more reliable. At the same time, SREs ensure that this work has as little impact on developer agility as possible. In fact, SREâ€™s experience has found that reliable processes tend to actually increase developer agility: rapid, reliable production rollouts make changes in production easier to see. As a result, once a bug surfaces, it takes less time to find and fix that bug. Building reliability into development allows developers to focus their attention on what we really do care aboutâ€”the functionality and performance of their software and systems. The Virtue of Boring Unlike just about everything else in life, \"boring\" is actually a positive attribute when it comes to software! We donâ€™t want our programs to be spontaneous and interesting; we want them to stick to the script and predictably accomplish their business goals. In the words of Google engineer Robert Muth, \"Unlike a detective story, the lack of excitement, suspense, and puzzles is actually a desirable property of source code.\" Surprises in production are the nemeses of SRE. As Fred Brooks suggests in his \"No Silver Bullet\" essay [Bro95], it is very important to consider the difference between essential complexity and accidental complexity. Essential complexity is the complexity inherent in a given situation that cannot be removed from a problem definition, whereas accidental complexity is more fluid and can be resolved with engineering effort. For example, writing a web server entails dealing with the essential complexity of serving web pages quickly. However, if we write a web server in Java, we may introduce accidental complexity when trying to minimize the performance impact of garbage collection. With an eye towards minimizing accidental complexity, SRE teams should: Push back when accidental complexity is introduced into the systems for which they are responsible Constantly strive to eliminate complexity in systems they onboard and for which they assume operational responsibility I Wonâ€™t Give Up My Code! Because engineers are human beings who often form an emotional attachment to their creations, confrontations over large-scale purges of the source tree are not uncommon. Some might protest, \"What if we need that code later?\" \"Why donâ€™t we just comment the code out so we can easily add it again later?\" or \"Why donâ€™t we gate the code with a flag instead of deleting it?\" These are all terrible suggestions. Source control systems make it easy to reverse changes, whereas hundreds of lines of commented code create distractions and confusion (especially as the source files continue to evolve), and code that is never executed, gated by a flag that is always disabled, is a metaphorical time bomb waiting to explode, as painfully experienced by Knight Capital, for example (see \"Order In the Matter of Knight Capital Americas LLC\" [Sec13]). At the risk of sounding extreme, when you consider a web service thatâ€™s expected to be available 24/7, to some extent, every new line of code written is a liability. SRE promotes practices that make it more likely that all code has an essential purpose, such as scrutinizing code to make sure that it actually drives business goals, routinely removing dead code, and building bloat detection into all levels of testing. The \"Negative Lines of Code\" Metric The term \"software bloat\" was coined to describe the tendency of software to become slower and bigger over time as a result of a constant stream of additional features. While bloated software seems intuitively undesirable, its negative aspects become even more clear when considered from the SRE perspective: every line of code changed or added to a project creates the potential for introducing new defects and bugs. A smaller project is easier to understand, easier to test, and frequently has fewer defects. Bearing this perspective in mind, we should perhaps entertain reservations when we have the urge to add new features to a project. Some of the most satisfying coding Iâ€™ve ever done was deleting thousands of lines of code at a time when it was no longer useful. Minimal APIs French poet Antoine de Saint Exupery wrote, \"perfection is finally attained not when there is no longer more to add, but when there is no longer anything to take away\" [Sai39]. This principle is also applicable to the design and construction of software. APIs are a particularly clear expression of why this rule should be followed. Writing clear, minimal APIs is an essential aspect of managing simplicity in a software system. The fewer methods and arguments we provide to consumers of the API, the easier that API will be to understand, and the more effort we can devote to making those methods as good as they can possibly be. Again, a recurring theme appears: the conscious decision to not take on certain problems allows us to focus on our core problem and make the solutions we explicitly set out to create substantially better. In software, less is more! A small, simple API is usually also a hallmark of a well-understood problem. Modularity Expanding outward from APIs and single binaries, many of the rules of thumb that apply to object-oriented programming also apply to the design of distributed systems. The ability to make changes to parts of the system in isolation is essential to creating a supportable system. Specifically, loose coupling between binaries, or between binaries and configuration, is a simplicity pattern that simultaneously promotes developer agility and system stability. If a bug is discovered in one program that is a component of a larger system, that bug can be fixed and pushed to production independent of the rest of the system. While the modularity that APIs offer may seem straightforward, it is not so apparent that the notion of modularity also extends to how changes to APIs are introduced. Just a single change to an API can force developers to rebuild their entire system and run the risk of introducing new bugs. Versioning APIs allows developers to continue to use the version that their system depends upon while they upgrade to a newer version in a safe and considered way. The release cadence can vary throughout a system, instead of requiring a full production push of the entire system every time a feature is added or improved. As a system grows more complex, the separation of responsibility between APIs and between binaries becomes increasingly important. This is a direct analogy to object-oriented class design: just as it is understood that it is poor practice to write a \"grab bag\" class that contains unrelated functions, it is also poor practice to create and put into production a \"util\" or \"misc\" binary. A well-designed distributed system consists of collaborators, each of which has a clear and well-scoped purpose. The concept of modularity also applies to data formats. One of the central strengths and design goals of Googleâ€™s protocol buffers40 was to create a wire format that was backward and forward compatible. Release Simplicity Simple releases are generally better than complicated releases. It is much easier to measure and understand the impact of a single change rather than a batch of changes released simultaneously. If we release 100 unrelated changes to a system at the same time and performance gets worse, understanding which changes impacted performance, and how they did so, will take considerable effort or additional instrumentation. If the release is performed in smaller batches, we can move faster with more confidence because each code change can be understood in isolation in the larger system. This approach to releases can be compared to gradient descent in machine learning, in which we find an optimum solution by taking small steps at a time, and considering if each change results in an improvement or degradation. A Simple Conclusion This chapter has repeated one theme over and over: software simplicity is a prerequisite to reliability. We are not being lazy when we consider how we might simplify each step of a given task. Instead, we are clarifying what it is we actually want to accomplish and how we might most easily do so. Every time we say \"no\" to a feature, we are not restricting innovation; we are keeping the environment uncluttered of distractions so that focus remains squarely on innovation, and real engineering can proceed. 38This is often true of complex systems in general; see [Per99] and [Coo00]. 39Coined by my former manager, Johan Anderson, around the time I became an SRE. 40Protocol buffers, also referred to as \"protobufs,\" are a language-neutral, platform-neutral extensible mechanism for serializing structured data. For more details, see https://developers.google.com/protocol-buffers/docs/overview#a-bit-of-history. Previous Chapter 8 - Release Engineering Next Part III - Practices Copyright Â© 2017 Google, Inc. Published by O'Reilly Media, Inc. Licensed under CC BY-NC-ND 4.0",
    "commentLink": "https://news.ycombinator.com/item?id=40478470",
    "commentBody": "Simplicity â€“ Google SRE Handbook (2017) (sre.google)138 points by nateb2022 20 hours agohidepastfavorite73 comments zbentley 3 hours agoMany commenters here are rightly pointing out Googleâ€™s hypocrisy in actually following the principles in this article. Fair enough. But others are throwing the baby out with the bathwater: itâ€™s a little silly to read comment after comment saying that the advice in TFA must be bad because Google does dumb/bad stuff on the regular. Companies arenâ€™t homogenous. Even misguided companies may employ people who can teach others important things. Boeing is a perfect example of this. I would absolutely read an article proposing principles of engineering reliability from a Boeing eng/QA greybeard. Even as the rest of the company spiraled due to horrible leadership and management practices, many people in engineering and quality control did their damnedest to keep those failures from causing even more harm and loss of life. Those people probably have very valuable lessons to share about how to maintain what quality you can in a deeply hostile environment. reply dangus 2 hours agoparentI donâ€™t see any validity to the alleged hypocrisy. End users making that criticism are confusing the products with the reliability practices. reply Tao3300 1 hour agorootparentIndeed, allegations of hypocrisy are a class of ad hominem. They don't necessarily weigh in on the validity. It just... feels good? I guess? People LOVE to feel like they caught a hypocrite. It's probably in the Top 5 most sought after dopamine kicks. reply burakemir 10 hours agoprevWhile the text touches on many points I would immediately sign, the paragraph starting with \"Because engineers are human beings who often form an emotional attachment to their creations, ...\" is really out of place. The cause of complexity is not emotional attachment, these are decisions being made. The decision to add feature after feature and punt on maintenance for example is something that has little to do with emotions. There is a lot of agency that engineers, SWE and SRE alike have in shaping how things are. However there can be good reasons to abandon simplicity. The real trouble here is not psychology but that as a profession we are really bad at measuring and estimating the effective cost of maintenance. Part of that is considering measures to improve simplicity and maintainability as cost that comes without gain and somehow less important than features, and then just accept giant rewrite a few years later. A continuous portion of upkeep would likely be more economical and real engineering has always included an aspect of economy - cost vs benefit. IMHO the loaded accusation of emotional attachment might be rooted in an \"us vs them\" attitude (SRE vs software engineering) that should have no place in a sober discussion on the value of simplicity and it diminishes an otherwise great text. reply CraigJPerry 10 hours agoparent>> Because engineers are human beings who often form an emotional attachment to their creations, confrontations over large-scale purges of the source tree are not uncommon. Some might protest, \"What if we need that code later?\" > the paragraph starting with \"Because engineers are human beings who often form an emotional attachment to their creations, ...\" is really out of place. FWIW Iâ€™ve definitely encountered developers clinging to things when the business context has completely changed. I totally recognise the scenario in the original text. reply burakemir 10 hours agorootparentSure, but if we argue that these values and principles should be applicable, then it should also be possible to make an argument why and not blame the irrationality on emotions. It seems more likely that bounded rationality is at play here, where different parties only know part of the picture (and fail to bring these together and find out what would be best globally.) reply philosopher1234 2 hours agorootparentI donâ€™t follow why we shouldnâ€™t blame the irrationality on emotions. Emotions are massively important, and people do irrational things because of them all the time. Why pretend thatâ€™s not true? reply kortilla 1 hour agorootparentYouâ€™re assuming the conclusion. What may appear to be irrational emotional behavior can be completely rational under a different set of information. reply burakemir 2 hours agorootparentprevThe question is not whether emotions can cause people to be irrational. They can! Not every case of irrational behavior is caused by emotions though. And when we are making an argument that people are acting against their own interests, it may help to ponder what makes them do so. All the more when we are claiming principles and values that should be accepted by everyone. \"If you don't believe me you are acting irrational / it's because you are emotionally attached\" does not seem to be an attitude that gets closer to real causes in a discussion on how to best seek simplicity, but rather a recipe for avoiding discussion or a \"thought-terminating cliche.\" There must be a better argument for convincing people to let go of code / clean up etc. reply oooyay 4 hours agoparentprevI'm a SRE and I disagree too, though, I think you're giving SREs too much credit in the category of our hegemony for an \"us vs them\" debate. Maybe at Google SWEs having relationships with their code based is a well studied thing. It could also just be someone's opinion that managed it's way unchallenged into the book. That's to say, Google SRE wasn't the best or last iteration of SRE. I personally think systems evolve the way you describe because of a system of incentives. There are more incentives for features than there exist for refactor and non top priority defect fixes. This comes from the people who hold power to shape incentives and they often do so with conflicting priorities and superficial understandings of the existing incentive structure. I'd also like to say that it's my own personal theory that systemic issues can only be caused by systemic forces. Individual mindsets cannot be to blame then; if a mindset has become systemic (example: SWEs overly attached to code and features) then your next question should be \"why?\". There's a system that enforces that, and if you don't look beyond personal obsession then you'll never find it. reply burakemir 57 minutes agorootparentI like this way of saying it. I don't think anything here is well studied at all. It is not like we are all fishing in the dark but the organizational structures that determine the conditions in which software development and operations happen are not well understood. I found Herb Simon's writings and his concept of bounded rationality very lucid. When we shift from \"reliability\" to \"safety\" we also need to shift from the individual to the system. reply intelVISA 4 hours agoparentprev> Because engineers are human beings who often form an emotional attachment to their creations Because engineers are human beings who often form an emotional attachment to their job security It's understandably very unwise to admit that Very Complex Solution that cost A Lot Of Money was A Bad Thing reply ozim 2 hours agorootparentUnfortunately complex solution we have accumulated over time is usually because business did not want to spend a bit more up front to come up with cleaner solution. In the same way business is also very reluctant to spend time/money on cleaning up stuff. I never ever had to make up complex stuff on my own. It always happens on its own. reply scott_w 6 hours agoparentprevI think the examples the paragraph gives more than backs up the statement. Iâ€™ve met people who comment out code instead of deleting it (luckily not in a long time!) and I feel the authors speak from experience here. reply burakemir 2 hours agorootparentCurious what examples do you see there. I don't doubt the experience. When I draw analogies of my past experiences to present situations, that does not mean that my past experiences are the best way to convince people of what is the right thing to do. I still need to do the hard work of pointing out what it is that is in the common interest and why eg deleting stuff and simplifying is good. In such a discussion it won't help me to say people who disagree with me are generally just emotional, does it? Even if I may have encountered people with such emotional reactions. reply arccy 10 hours agoparentprevBut people do get attached to their creations, they don't want their things deprecated/removed, since to them it may feel like their thing is thrown away or wasted work down the drain. While they may not obviously state it as such, it can be the underlying reason driving their arguments (e.g. sunk cost fallacy). reply burakemir 10 hours agorootparentMaybe this is also about the desire to create, which of course is also common in engineering. It does not contradict my argument that the cost of maintenance and operations is being ignored eg when one creates things all the time and never removes stuff. And it should be possible to measure or estimate that cost. reply mrbungie 4 hours agoparentprevI think that is being transparent with what actually happens in the real world (engineers, at least in part, being human and emotional in their decisions), rather than just talking about impossible ideals (engineers thinking about tradeoffs in a purely objective matter). NIH, CV based development, preference for shiny/new things and a myriad of other \"engineer/organizational diseases\" exist, you know. And there are even SaaS/PaaS/XaaS marketing teams exploiting such human qualities when making software sales. reply jimmySixDOF 9 hours agoparentprevWhen containers got going there was a phrase used in devops to think of servers as \"cattle not pets\" for just this reason. reply kortilla 54 minutes agorootparentNo, that had nothing to do with emotional attachment. Itâ€™s a short phrase to remind people that they canâ€™t make each device special with one-off because it needs to be repeated/destroyed all of the time. Separately, cattle vs pets is much older than containers. It got popular with ephemeral EC2 instances when people were first forced to grapple with lifetimes of VMs measured in hours and the ability to scale massively as needed. reply XorNot 6 hours agorootparentprevI never took that as dealing with emotional attachment, it was just a shorthand to express that at any moment you would kill cattle so don't do things you can't easily replicate. reply elktown 12 hours agoprevJust remember that what google writes in these kind of things is not universal. It's written from their very unusual circumstances. You can certainly pick nuggets that are more universal than others but, like in many other instances, too much unnecessary work is spent trying to imitate Google and others when it's not really needed. And no, you won't turn into Google over night, you will have time to adapt if fortune hits you. Some things are not even necessarily good advice at all, but rather a product of incentives within Google (and perhaps most tech corps) rewarding the aesthetics of \"innovation\". reply fmbb 12 hours agoparentI read the whole text (granted, a bit quickly) looking for weird or unnecessary advice but I cannot see any. This is a great text about considerations everyone operating software services should take to heart. It applies regardless of if you deploy a monolith or several smaller servers. If you are only one developer, it might apply in a smaller context. reply elktown 11 hours agorootparent\"If you are only one developer\" suggests zero interests in being nuanced. To be clear, this linked specifically to simplicity which I'm certainly in favor of emphasizing the importance of. But IME the exact opposite happens when people try to imitate Google overall in a smaller setting, where instead too much resources are spent on meta-issues instead of the product being developed. reply zbentley 3 hours agorootparentI think youâ€™re arguing with someone who isnâ€™t here. Nobody is endorsing the practices in TFA â€œbecause itâ€™s Googleâ€/in order to be like Google. Sure, people elsewhere make those claims all the time, and theyâ€™re wrong, but thatâ€™s not in evidence here that I can see. The article does seem to come pretty close to universally applicable good ideas. Not because of where its author works, but because of the content. reply elktown 2 hours agorootparent> Nobody is endorsing the practices in TFA â€œbecause itâ€™s Googleâ€/in order to be like Google. Sure, people elsewhere make those claims all the time, and theyâ€™re wrong, but thatâ€™s not in evidence here that I can see. I disagree, I think we can see this time and time a again. YMMV I guess. It's an encouragement to be vigilant for over-engineering when you don't need it because you're not google. I'm not saying that the content is bad, it's a worthy read. Just don't get overeager like the OOP craze phase where would attempt to bend everything into a maze of design pattern because people took whatever books they read way too far. Most of the chapters have YAGNI parts for smaller settings, but it's still worth knowing about what the next steps are. reply nvarsj 9 hours agoparentprevEven within Google, this is not universal. I doubt the majority of SREs at Google have even read the \"Google SRE book\". On the other hand, the book has some nuggets that make it worth reading. But it should be treated as a collection of essays from some very senior SREs rather than a manual. reply elktown 8 hours agorootparent> On the other hand, the book has some nuggets that make it worth reading Definitely! Mostly just a word of caution to not get overeager hoping to apply this everywhere, because \"here be dragons\". reply gnuser 1 hour agoprevAt the last â€œrealâ€ job I tried to help implement this as part of and later the manager of the ops team. Itâ€™s a great start, but in that case management wanted the idea of devops/sre but didnâ€™t actually support it, and it really was a shit show. If you have a bad CTO and leadership on the board level, no amount of re-tooling will paper over their lack of support for the real principles. reply wouldbecouldbe 1 hour agoprev\"Why donâ€™t we gate the code with a flag instead of deleting it?\" These are all terrible suggestions. Source control systems make it easy to reverse changes, whereas hundreds of lines of commented code create distractions and confusion.\" In most cases to delete code would be a good idea, but to say that source control systems make reverting easier. After a few months most developers will have forgot about those lines and at times uncommenting code & explaining it explicitly might be a better way to preserve knowledge then to rely on digging through GIT. reply lloydatkinson 1 hour agoparentFirst time Iâ€™m hearing that feature flags and commented out code are the same thing. reply wouldbecouldbe 1 hour agorootparentI've seen it be a company culture thing where every discussion was resolved with we'll put it behind a config/flag. It's an easy way to avoid hard choices. It's probably something like that the author refers to. reply userbinator 12 hours agoprevA lot of preaching but bears little resemblance to what Google is actually doing in reality. IMHO those who actually understand what \"simplicity\" means in software are only those who have tried to do anything in highly-resource-constrained environments. reply hiAndrewQuinn 12 hours agoparentA taxonomy of what we mean when we talk about \"resource-constrained\" might be helpful for those seeking to gain this knowledge. Limited CPU, RAM, etc are the obvious contenders - but then there's also \"resource-constrained\" as in \"I'm the solo dev of this project and have 5 hours in a good week to work on it\", or \"this runs in a weird place without Internet that I only get access to twice a year\". I've been in all of these situations, sometimes multiple at the same time, and they've been great forcing functions to find new paths towards simplicity. reply davidcbc 2 hours agoparentprev> bears little resemblance to what Google is actually doing in reality What is Google doing in reality? reply gtirloni 3 hours agoparentprevYou also have to keep in mind the scope and timeline of where these principles apply. I'm sure someone would be able to apply them to their own work most of the time but if you look at a company as a whole, unless someone at the top is really pushing for global simplicity, things are pretty messy most of the time. I'm just saying this because Google might be doing this in little islands, not as a company strategy. I don't really know and can only guess from the outside. reply kryptonomist 10 hours agoprevGlad to see those valuable principles written, even if it seems we are heading in the complete opposite. At least we can try to apply them on our side business. These were also true in the early ages of aviation: â€œPerfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.â€ â€• Antoine de Saint-ExupÃ©ry reply ChrisArchitect 9 hours agoprevSome more recent discussion: https://news.ycombinator.com/item?id=39580346 reply YokoZar 9 hours agoprevSee also the Simplicity chapter in the followup Google SRE Workbook: https://sre.google/workbook/simplicity/ reply maximinus_thrax 5 hours agoprevMaybe an unpopular opinion, but this type of content is useless and serves no other purpose than feeding the already bloated Google cargo-culting machine. reply dieortin 5 hours agoparentCould you elaborate on why you think that? Just stating that does not really add to the conversation reply stackskipton 46 minutes agorootparentNot OP but I'll give my take because I mostly agree. Because Google lives in a world few of us do. I'm SRE/DevOps and our lives are nothing like Google SREs. We have almost zero control over software that is chucked our way. Any attempt to try and control them fails with management telling us \"Just fucking ship it\". Finally, something I realized after working with various FAANG SRE types, they don't understand what bad development practices look like, they can't imagine it. reply maximinus_thrax 3 hours agorootparentprevBecause is just useless. I mean seriously, what valuable insight does anyone get from that? It's some sort of truism wrapped in a word sandwich, ready for linkedin lunatics to pat themselves on the back sharing it. Do you feel you've gained something by reading it? Is this a valuable piece of intelligence which would guide your future decisions? Will you bring this to the team during an argument to push your agenda? This feels like the same type of 'feel good' content which people read and then feel like they did something productive. But I would argue that every piece of insight coming for a mega corp, valuable inside the mega corp is actually dangerous outside when people take it as dogma and try to apply it. SRE in general is something which IMHO of working in the industry for decades has poisoned the industry with half assed cargo cult implementations. But it has Google branding, so it must be valuable, hits hard for the fanboys and obviously can and should be applied in every company and every context. I also find it ironic to see 'Simplicity' touted from the same people who let Kubernetes lose in the wild, but that's a different story for a different time reply zbentley 3 hours agorootparentIâ€™ve honestly never worked on software in an environment where the advice in the article wasnâ€™t important to keep in mind. Personal projects, single digit employee count startups, growth stage, ancient and slow moving Perl monolith shops â€¦ they all needed to keep the principles of simplicity, boringness (boring.tech is a great reiteration of this) and continually self-auditing to reduce inherited complexity in mind. Whether or not Google interprets this advice in a sane way or whether they actually follow it are separate issues, but I think the advice is timely and (at least in my experience) important for many people to hear, regardless of where itâ€™s author works. reply zbentley 32 minutes agorootparentEr, not boring.tech; boringtechnology.club is what I meant. reply gtirloni 3 hours agorootparentprevThat's circular reasoning (\"it's useless because it's useless\"). If you haven't gained any insights from reading that content, maybe it doesn't apply to you or you don't know what you don't know. > valuable inside the mega corp is actually dangerous outside when people take it as dogma and try to apply it. mega corp or not, dogmatic principles are usually bad coming from anywhere. The SRE book contains insights that apply to startup, medium-sized companies and mega corps. It's not prescriptive for a reason. reply quintes 11 hours agoprevYeah look. This may be the throw it over the wall problem. sRE says No. You build it you run it but may work at their scale reply OutOfHere 12 hours agoprevDoes this include instructions on accidentally deleting a customer's account? Because that's what Google does. I don't think I want to take any advice from Google on anything. reply gtirloni 3 hours agoparent> Because that's what Google does Your argument would be stronger if you could list a few cases like that latest high profile one where GCP deleted some enterprise customer's account. A single one won't cut it for \"that's what Google does\". reply OutOfHere 1 hour agorootparentWith Google, the deletions almost always are intentional, not accidental, and this is a huge problem with it. Google (not GCP) deleted ten years of my data without warning or notification or remorse or recourse even though I was doing nothing illegal. Amazon would never do something like it. To Google, once a customer or service becomes just 1% inconvenient, it's time to get rid of the customer or service. It's a very valid concern. reply dieortin 5 hours agoparentprevI challenge you to find an organization that has never made a mistake. Truth is the uptime and reliability of Google services is very good, while operating at huge scale. And I have no association with Google whatsoever. reply infinityplus1 9 hours agoparentprevCloud computers are just someone's else computer. Amazon and Microsoft engineers can make the same mistake too. Take backups and test them regularly and you'll be OK. reply postepowanieadm 12 hours agoparentprevIt's from 2016 when google was less trash. reply kubb 9 hours agoprevSRE has got to be one of the organisations that have done the most damage in the big G. They were given a license to mandate things based on philosophical musings backed with no science, and they can decide what's best and should be done without any data, just based on feels. They also have a culture of misanthropy, patronization and contempt towards devs. From what I can tell anyway. reply gtirloni 3 hours agoparent> they can decide what's best and should be done without any data, just based on feels. The book is exactly the opposite of this. The Principles chapter alone talk about many things that involve actually dealing with numbers (SLO, measuring complexity, etc). reply kortilla 34 minutes agorootparentâ€œIt has numbers attachedâ€ does not mean something is backed by data. Unless they are testing correlations between these target metrics and business success or some other external cost metric, itâ€™s still â€œjust feelsâ€. Iâ€™ve seen internal crusades against cyclomatic complexity that resulted in massive engineering waste to reduce and reliability saw no improvement. reply makerofthings 3 hours agoparentprevBe google SRE. Elite software engineer. Cool under pressure. Pager goes off! Grab pixel. Press finger print reader until it lets me enter my passcode. Ack page. Put down whisky. Shake self. 5 minutes to be logged in and dealing with the problem. Password. gnubby. password. gnubby. gnubby. gnubby. Check alert, see playbook, ignore playbook. Check which cell the problem is in. Correlate with rollouts. See a match. Roll back poorly tested dev promo project. Charts recover. Alert not firing. Log out. Back to whisky. reply kubb 2 hours agorootparentThe drinking culture is also pretty weird. reply joshuamorton 27 minutes agorootparentIt's also outdated. I don't think I've seen real are drinking culture since like 2018. reply alienchow 6 hours agoparentprevWhy don't you give Mission Control a try for 6 months? reply sgarland 6 hours agoparentprev> culture of misanthropy, patronization and contempt towards devs. When youâ€™re being paged for the Nth time because of an idiotic problem that youâ€™ve pointed out repeatedly, you too might exhibit these traits. reply bru 9 hours agoparentprev[citation needed] reply randmeerkat 7 hours agoprev [â€“] Googleâ€™s â€œbest practicesâ€ lead them to deleting an entire customerâ€™s $135 billion pension account [1]. Iâ€™m surprised anyone is still reading anything Google writes. 1. https://arstechnica.com/gadgets/2024/05/google-cloud-acciden... reply klabb3 7 hours agoparentYouâ€™re assuming that those systems were all implemented to the letter of that guide. Thatâ€™s never the case. Often these type of guidelines are written to address recurring problems found in an organization. reply dieortin 5 hours agoparentprevIf we should only read things written by organizations that make no mistakes, then we will never read anything. reply randmeerkat 3 hours agorootparent> If we should only read things written by organizations that make no mistakes, then we will never read anything. That was a â€œmistakeâ€ that should not have even been possible. If the pension fund had not used a multi cloud strategy the entire business would have been lost. A mistake is not configuring Kafka correctly and losing some data, deleting an entire account should not be given a pass. reply joshuamorton 1 hour agorootparentThe recent postmortem says they were able to recover from backups on gcp, so I don't think this is true. reply thirteenfingers 7 hours agoparentprevThat was seven years later. Maybe the problem is that Google stopped reading what Google wrote. reply randmeerkat 3 hours agorootparent> That was seven years later. Maybe the problem is that Google stopped reading what Google wrote. The problem is that it was never that good. Anyone who has used K8s at scale will tell you at length how it doesnâ€™t scale. People should stop focusing on tech companies like celebrities and focus instead on domain problems related to their business. reply lima 28 minutes agorootparentThe funny thing with k8s is that Google doesn't use it (except GKE, and there's a reason it's one cluster per customer). Their internal tooling scales just fine, but all it shares with k8s is some of the underlying concepts. Unlike, say, Bazel, gVisor or Gerrit, which are the real thing (minus some secret sauce tied to internal infra). k8s is good software, and best-in-class when it comes to open source options, but the idea that it is \"open source Borg\" is silly. reply passion__desire 6 hours agorootparentprevGoogle : We will breach the rules we preach. reply gtirloni 3 hours agoparentprev [â€“] Oh, completely ignoring anything anyone from Google ever writes again? This is akin to the cancel culture which we all know is how society should work. /s reply randmeerkat 1 hour agorootparent [â€“] > Oh, completely ignoring anything anyone from Google ever writes again? This is akin to the cancel culture which we all know is how society should work. /s Maybe if Google focused on doing actual work instead of writing feel good engineering pieces, they wouldnâ€™t have the Google graveyard and an unstable cloud offering that may spontaneously delete multi-billion dollar accounts. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The book on Site Reliability Engineering (SRE) emphasizes simplicity to achieve reliability, covering key topics like risk management, service level objectives, automation, release engineering, and troubleshooting.",
      "It advocates for \"boring\" software that predictably meets business goals by minimizing accidental complexity, maintaining clean code, and promoting smaller, simpler projects to reduce defects.",
      "Published by Google under a CC BY-NC-ND 4.0 license, the book underscores the importance of modularity, simplicity in design, incremental releases, and careful API management for reliability and innovation."
    ],
    "commentSummary": [
      "The Google SRE Handbook (2017) has sparked mixed reactions, with some criticizing Google for not adhering to its own principles, while others find valuable lessons despite perceived hypocrisy.",
      "Key themes include the importance of simplicity in engineering, emotional attachment to code, and the impact of organizational incentives on code maintenance, highlighting systemic issues over individual mindsets.",
      "The debate questions the universal applicability of Google's practices, emphasizing the need for context-specific implementation and management support, and critiques Google's internal practices, particularly regarding Kubernetes and cloud services."
    ],
    "points": 138,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1716678089
  },
  {
    "id": 40478923,
    "title": "Facial Recognition Error Leads to Wrongful Shoplifting Accusation and Ban",
    "originLink": "https://www.bbc.com/news/technology-69055945",
    "originBody": "'I was misidentified as shoplifter by facial recognition tech' 20 hours ago By James Clayton, BBC Newsnight Share BBC Sara needed some chocolate - she had had one of those days - so wandered into a Home Bargains store. \"Within less than a minute, I'm approached by a store worker who comes up to me and says, 'You're a thief, you need to leave the store'.\" Sara - who wants to remain anonymous - was wrongly accused after being flagged by a facial-recognition system called Facewatch. She says after her bag was searched she was led out of the shop, and told she was banned from all stores using the technology. \"I was just crying and crying the entire journey homeâ€¦ I thought, 'Oh, will my life be the same? I'm going to be looked at as a shoplifter when I've never stolen'.\" Facewatch later wrote to Sara and acknowledged it had made an error. Facewatch is used in numerous stores in the UK - including Budgens, Sports Direct and Costcutter - to identify shoplifters. The company declined to comment on Sara's case to the BBC, but did say its technology helped to prevent crime and protect frontline workers. Home Bargains, too, declined to comment. It's not just retailers who are turning to the technology. On a humid day in Bethnal Green, in east London, we joined the police as they positioned a modified white van on the high street. Cameras attached to its roof captured thousands of images of people's faces. If they matched people on a police watchlist, officers would speak to them and potentially arrest them. Unflattering references to the technology liken the process to a supermarket checkout - where your face becomes a bar code. A police facial-recognition van's cameras can capture thousands of images On the day we were filming, the Metropolitan Police said they made six arrests with the assistance of the tech. That included two people who breached the terms of their sexual-harm prevention orders, a man wanted for grievous bodily harm and a person wanted for the assault of a police officer. Lindsey Chiswick, director of intelligence for the Met, told the BBC the tech's speed was extremely helpful. \"It takes less than a second for the technology to create a biometric image of a person's face, assess it against the bespoke watchlist and automatically delete it when there is no match.\" The BBC spoke to several people approached by the police who confirmed that they had been correctly identified by the system - 192 arrests have been made so far this year as a result of it. But civil liberty groups are worried that its accuracy is yet to be fully established, and point to cases such as Shaun Thompson's. Mr Thompson, who works for youth-advocacy group Streetfathers, didn't think much of it when he walked by a white van near London Bridge in February. Within a few seconds, though, he was approached by police and told he was a wanted man. \"That's when I got a nudge on the shoulder, saying at that time I'm wanted\". Shaun Thompson says he was a victim of mistaken identity He was asked to give fingerprints and held for 20 minutes. He says he was let go only after handing over a copy of his passport. But it was a case of mistaken identity. \"It felt intrusiveâ€¦ I was treated guilty until proven innocent,\" he says. The BBC understands the mistake might have been due to a family resemblance. The Metropolitan Police declined to comment. 'Digital line-up' Silkie Carlo, director of Big Brother Watch, has filmed the police on numerous facial-recognition deployments. She was there the night Shaun Thompson was picked up by police. \"My experience, observing live facial recognition for many years, [is that] most members of the public don't really know what live facial recognition is,\" she says. She says that anyone's face who is scanned is effectively part of a digital police line-up. \"If they trigger a match alert, then the police will come in, possibly detain them and question them and ask them to prove their innocence.\" The use of facial recognition by the police is ramping up. Between 2020 and 2022 the Metropolitan Police used live facial recognition nine times. The following year the figure was 23. Already in 2024 it has been used 67 times, so the direction of travel is clear. Champions say that misidentifications are rare. The Metropolitan Police say that around one in every 33,000 people who walk by its cameras is misidentified. But the error count is much higher once someone is actually flagged. One in 40 alerts so far this year has been a false positive. Michael Birtwhistle, head of research at the Ada Lovelace Institute research group, believes the technology is so new that the laws have not yet caught up. \"I think it absolutely is a Wild West at the moment. That's what creates this legal uncertainty as to whether current uses are unlawful or not,\" he says. In Bethnal Green, although some people the BBC spoke to were worried about the use of the tech, a majority were supportive - if it helped to tackle crime. That leads to another question about the technology: will it help in the long run? As people get more used to seeing white vans parked on busy high streets, will people who know they are wanted by police simply get wise to the cameras and avoid them? Will shoplifters hide their faces? Ms Carlo says society needs to guard against facial recognition becoming normalised. \"Once the police can say this is OK, this is something that we can do routinely, why not put it into the fixed-camera networks?\" This is the dystopian future that civil-liberty campaigners are most afraid of - a China-style mass-surveillance state. Advocates dismiss such dire predictions as overblown. And it is also clear there are plenty among the public who are willing to put up with having their faces scanned - if it means safer streets. Facial recognition Bethnal Green Metropolitan Police Service",
    "commentLink": "https://news.ycombinator.com/item?id=40478923",
    "commentBody": "'I was misidentified as shoplifter by facial recognition tech' (bbc.com)123 points by gnabgib 18 hours agohidepastfavorite225 comments ajb 9 hours agoSeems like an opportunity for the lawyers to me. Being evicted from a store is necessarily a public act. Telling someone wrongly that they are a thief, in public, seems like libel. Since most people go to stores in their neighbourhood, this could easily happen in front of your friends, neighbours, parents of other kids at your school, fellow members of social clubs or worship clubs, etc. If this happened to me, I'd be going and seeing if I could get any lawyers to take this on a no-win no fee basis. It seems like businesses are increasingly failing to think through what their process will look like to real human beings. reply Latty 9 hours agoparentWhen I worked on analysis software for police & intelligence agencies, it quickly became clear that no matter how much you present something with clear \"this is a heuristic, it can give you leads\", a scary number of people will take it as \"this will tell you whodunit\" and just assume it's infallible. If people are going to treat these things like they are forensic evidence and not lead generation, then they shouldn't be legal. Some precedent that people need to check these things before acting on them would be very good. reply kreyenborgi 8 hours agorootparentFrom The flaws of policies requiring human oversight of government algorithms https://www.sciencedirect.com/science/article/pii/S026736492... : human oversight policies provide a false sense of security in adopting algorithms and enable vendors and agencies to shirk accountability for algorithmic harms. And the better The Algorithm is, the less people check, and the more of its faults pass through. Having worked on systems that required human oversight, I've seen first-hand, and analyzed data on, how people click the \"LGTM\" button without reflecting. We even noticed how when we improved our predictor with expert input, so that it performed better according to experts who worked with it, it would perform worse when we benchmarked on the previously \"manually checked\" data set. Analysis showed that the manual checks had let through so many of the algorithm's faults, that when the algorithm improved, it got a worse score. See also https://predictive-optimization.cs.princeton.edu/ : We present seven flaws of predictive optimization. Our aim is to outline a set of objections inherent to predictive optimization that cannot be easily fixed using a design or engineering change. Taken together, these critical flaws undermine the legitimacy of applications of predictive optimization. 1. Good predictions may not lead to good decisions 2. It's hard to measure what we truly care about 3. The training data rarely matches the deployment setting 4. Social outcomes arenâ€™t accurately predictable, with or without machine learning 5. Disparate performance between groups canâ€™t be fixed by algorithmic interventions 6. Providing adequate contestability undercuts putative efficiency benefits 7. Predictive optimization doesn't account for strategic behavior reply Latty 6 hours agorootparentTrue, \"check\" was poor phrasing, because these things don't produce evidence, they produce alerts to guide investigation. It should be a given that these systems don't produce anything actionable, they are a guide for a user to look more closely, of course, that requires someone in the chain stops and says \"this isn't usable evidence\". reply ajb 9 hours agorootparentprevVery interesting - thanks for giving us the benefit of your experience. In the case of store workers, it's not obvious what other checking they could do. The only reasonable use I can see is for them to keep an eye on the person that has been flagged. But I expect that the entire purpose of this tech is to reduce the number of store guards they need to pay, so they are likely not to have the manpower. If the policy is 'don't let them in the store', I don't see how a store worker can avoid making false accusations. reply namaria 8 hours agorootparentThere's something fundamentally wrong with these probabilistic analysis tools being sold currently as \"artificial intelligence\". The nuance in \"probabilistic\" is quickly lost and the output is taken as deterministic. Any piece of software that puts out data that is acted upon should have clear disclaimers attached. Calling it \"intelligent\" is irresponsible. reply tomNth 8 hours agorootparent\"Calling it \"intelligent\" is irresponsible.\" How so ? If a human of animal behaving the same were to be describe as intelligent, than so are those systems. reply namaria 7 hours agorootparentHow so? People take it at face value and harm other people based on its outputs, as per the article linked. > If a human of animal behaving the same were to be describe as intelligent, than so are those systems. I cannot parse this sentence. Behaving the same as what? What bearing do claims of human or animal intelligence have on me stating that generating liability by trusting probabilistic analysis, and actively harming people, by calling software \"intelligent\", is not responsible behavior? reply tomNth 6 hours agorootparentThe bearing is on the claim that calling software \"intelligent\" have anything to do with trusting or liability. Dumb or not, no one is supposed to blindly trust it. reply exe34 7 hours agorootparentprevwe can call it frediness, but the problem isn't what it's called, the problem is that the profit motive only works when there's competition. if there were several shops nearby and one of them started rejecting 80% of customers based on frediness, they'd go out of business and the others who prefer having a human guard would prosper. if it's the only shop within a 10 mile radius, and it only flags out 1% of innocent people as shoplifters, then the profit motive doesn't provide the balancing force. that's what regulation is for. reply dec0dedab0de 6 hours agorootparentprevSimilar to story points and task estimates suddenly becoming deadlines reply thfuran 7 hours agorootparentprev>If people are going to treat these things like they are forensic evidence Are most kinds of forensic evidence actually any better? reply Latty 6 hours agorootparentWell, plenty of bunk stuff (bite mark analysis, hair analysis, etc...) has been used in the past, but in theory anything used today should be backed up by significant evidence and rigorous methodology, and obviously it'll vary based on jurisdiction, but in theory courts should require that background. Certainly, more transparency than \"we bought some facial recognition software, no, you can't see the code, that's a trade secret\". reply mcherm 5 hours agorootparentprevI can think of one possible regulation that I think would produce the proper behavior incentives. Require that the system intentionally produce false positives (selected at random) at approximately the same rate as the true positives. This means that the users of the system will be aware that any indication has only a 50% chance of being \"real\", and therefore can be used as an indicator to increase caution but NOT on it's own as a signal of guilt. reply exe34 40 minutes agorootparentWhy not just flip a coin then? It would be much cheaper? reply BLKNSLVR 6 hours agorootparentprev> no matter how much you present something with clear \"this is a heuristic, it can give you leads\", a scary number of people will take it as \"this will tell you whodunit\" and just assume it's infallible. That's precisely my anecdotal experience. Subtlety and nuance are easily ignored where their absence appears to provide easy answers and the avoidance of responsibility for their outcomes. Similarly to \"It Is Difficult to Get a Man to Understand Something When His Salary Depends Upon His Not Understanding It\". reply cogman10 6 hours agorootparentI don't trust a sales person or marketer to not hype such a system as being flawless whodonit machine. I certainly don't trust that the people purchasing these machines won't communicate to their staff that it's a flawless whodonit machine. That's because the step from \"potential leads\" to \"flawless machine\" is a relatively small leap easily hidden by throwing out bad stats and case studies about people caught red handed. Even if you say the machine is 80% accurate, a lot of people will happily accept harming the 20% on the chance they might be in the 80%. (Though, I'm willing to bet the false identification percentages are both not public and not kept up to date, if they are even known). reply btasker 9 hours agoparentprev> Telling someone wrongly that they are a thief, in public, seems like libel Slander. Libel is published, Slander is spoken. If they put a picture of her on a sheet that said \"shoplifter\" and posted in on the wall (or the net), it'd be libel. But, I don't think you'd win a case based on Slander either: * you'd still need to show it was published to a third party (though as you say, maybe you had friends present) * They can show that they reasonably believed it to be true (the system told them so). Their wording then becomes incredibly important - did they say \"you're a shoplifter\" or \"you've been identified by our shoplifter recognition system\" They might also try to argue that stopping shoplifting is in the public interest and that this was a statement of opinion related tot hat. I agree though, if this happened to me, I'd definitely be sending a letter or two to dissuade them from making a similar mistake in future (I think I'd also be trying my luck with Facewatch given that their system disseminated that \"information\") reply ajb 8 hours agorootparentYes, I'd forgotten that libel is published information. Although, given that this is third party tech, maybe Facewatch counts as the publisher. reply davidhbolton 6 hours agorootparentWouldn't there be a better outcome for those misidentified and publicly slandered and inconvenienced if they sued for stress? Some unlucky sod could have a heart attack from this. reply prepend 6 hours agorootparentprevLibel and slander must have malicious intent. I think the better legal tactic would be defamation as it doesnâ€™t require intent. reply SapporoChris 7 hours agoparentprevIt seems that the proponents of this technology believe the benefits far outweigh the harms. Why not have a standard generous payout to anyone misidentified by the system. The payout would be funded by all parties involved, store, police, tech company. If the benefits really do outweigh the harms and the compensation is enough, I think most people would begin welcoming the program. If the system got gamed (people with a history of false positives seeking to be misidentified), fine, it would encourage the technology to improve and eliminate false positives. reply thfuran 7 hours agorootparentThe payout would have to be at least enough to both fund and cover the inconvenience of moving to a new neighborhood closer to stores you aren't yet banned from. Of course, that becomes impossible if the tech is widespread enough. reply calewis 6 hours agoparentprevIt doesnâ€™t really work like that in the UK. I doubt youâ€™d get anyone to take it on, let alone for feee. Proving the material impact would be hard. Sheâ€™s not been named publicly, no lost earnings etc. I would like to think this sort of thing means we get better regulation, but who am I kidding. reply krisoft 8 hours agoprevI understand that my viewpoint differs from that of many here. I donâ€™t see the problem with the live face detection. What I see as a problem is the process followed after the detection. Simply saying with any system like this there will be mistakes. The reaction should be designed such that we account for these mistakes. It sounds like the system as designed has at least three unhandled exceptions: - your system thinks I am someone who stole something but I am not that someone. (Mis-identification) - your system thinks I am someone who stole something, and I am that someone but I did not stole anything ever. (Mistake in the database) - your system thinks I am some who stole something, and I did, but I have already been properly punished for it. (Rehabilitation) If you just bar people from the shop automatically on a positive identification you are going to make the above mistakes on a massive scale. And because of the nature of these system if they made a mistake once with someone it is possible they will make the mistake again and again, so you better handle the exceptions in a gracefull and sensible maner. And shops will absolutely not do the right thing on their own. Because it is just so much cheaper to hassle the few who has fallen off from the happy path than build in the proper safeguards, so shops on their own will just decide to â€œeatâ€ the losses caused by persecuting innocents. And that is the part which is not right. That is where laws should come in and mandate proper procedural safeguards. What are the proper safeguards? I donâ€™t know. I have ideas on how that could go, but this comment is already getting very long. What I am saying is that I think the correct solution is not â€œno cctv with facial detection allowedâ€ as many here seems to propose, but it is also not letting shops persecute innocent victims of the above exceptions. There is a third way with regulated and safeguarded procedures where I think we should be looking. reply bcrosby95 4 hours agoparentAin't no one gonna use the tech if they have to spend 30 minutes doing a background check after it flags someone. I also guarantee this is not how sales and marketing are pitching it. reply pc86 6 hours agoparentprevStrictly to your point about rehabilitation, that doesn't mean the store necessarily needs to let you shop there again. So unless there is a statutory requirement to the contrary stores would still get that information and presumably there would be a chain-specific SOP about whether or not that person was allowed on the property. reply lkramer 6 hours agorootparentThat is perhaps reasonable if it's one store, or even a chain, but the article spoke about this applying across multiple chains, whichever used this software. If we end up banning people for life from shopping in physical sto ed because they shoplifted once when they were young, we are creating a deeply disturbing society. reply lsaferite 6 hours agorootparentprevI think the danger in systems like this is in the article. They said the shopper was banned from all establishments running that system. So, even if the accused person is not accused of doing anything in that particular establishment, they are now capable of being globally banned. That should 100% be prohibited. reply data-ottawa 7 hours agoparentprevI'm guessing unless you go to the press these issues will never get resolved for you and you'll just be banned from random stores. So a 1% error rate will over time creep up to a 5% surprisingly quickly. How many grocery stores will tell you what's security system they use when they already assume your a thief? reply bsenftner 7 hours agoparentprevI don't believe these systems are ready for mass, non-expert use. I spent 7 years as lead developer of one of the globally leading FR systems, and I've left the industry. It is fundamentally unsafe in the hands of ordinary people, ordinary people who are not scientifically and rationally discriminate in their day to day activities. Ordinary people treat FR like an AI Gawd, and the police are hopeless with it. The straw that broke my camel's back was learning of the wide spread practice of police asking crime victims \"what celebrity does the perpetrator look the most alike?\" And then the police would put that celebrity's photo into their FR system and start harassing people in their city that look like the celebrity. So, mind numbingly stupid, I got angry at clients doing this, got barred from talking to clients, and soon there after quit the industry. The industry believes it is \"not their problem\". reply EnigmaFlare 8 hours agoparentprevMaybe a solution is the cost of lawsuits from false positives vs the cost of theft from false negatives means shopkeepers or their insurance companies have to make a reasonable trade-off in how they use that information that keeps most people happy. The odd incorrectly identified person can still get cleared after a bit of inconvenient legal procedure and be paid for their trouble. reply huhtenberg 9 hours agoprevThe UK has been trying for decades to become the surveillance society, hasn't it? I remember being taken aback by the amount of street CCTV cameras back in the early '00s. Coming from Canada for a visit that feeling of being observed nearly constantly was really uncomfortable and bizarre. For Brits it looked like a norm (or they didn't show it). Also the parallels with 1984 were uncanny, especially given that Orwell was English. reply tazjin 9 hours agoparentDon't forget the incredible posters that used to be up in London! http://soerenkern.com/web/wp-content/uploads/2014/06/uk-met1... reply moffkalast 7 hours agorootparentThat's gotta be satire right? Looks straight out of V for Vendetta. I'm really glad the EU just completely banned predictive policing. reply tazjin 5 hours agorootparentIt's not satire! It really was an official poster campaign (some 20 years ago). reply ecjhdnc2025 5 hours agorootparentIt was an official campaign but itâ€™s worth noting that the satirical element of it is there, deliberately, because we are way, way funnier as a nation. Almost nobody worries about these transport safety cameras because we donâ€™t fear or tolerate overpolicing in the same way. Of course there should be safety cameras on public transport! And if a US tourist was on a night bus in London they too would be happy there were cameras. A nation of drivers has a very different calibration, I suspect. reply tazjin 4 hours agorootparentI gotta say that I didn't feel very safe on night buses in London, despite the cameras. Besides Brussels, London is the only other city in which I've occasionally felt like I was in danger. It's still a fun city, to be clear, and it probably helps that it isn't a 24/7 city so that you don't end up in weird situations at night too much. In the end the CCTV doesn't actually prevent anything from happening ... reply ecjhdnc2025 3 hours agorootparent> In the end the CCTV doesn't actually prevent anything from happening ... The question of whether it prevents things from happening is a question of statistics. I suspect the data doesn't support your claim, and that certain categories of crime have indeed been deterred. But neither of us can know without that statistical analysis. reply _joel 6 hours agorootparentprevIt's got a red bus on it, must be one of Boris's... reply gcanyon 5 hours agoparentprevJohn Varley in the science fiction novel The Golden Globe envisioned a future where there are two separate AIs: one that is solely designed to help people, that knows everything, and a separate AI designed for law enforcement that is constrained to a limited set of inputs. I don't know if that's practical, or palatable, but it was an interesting thought experiment, although he doesn't dig into it too deeply. https://en.wikipedia.org/wiki/The_Golden_Globe reply kyleyeats 8 hours agoparentprevThis is a propaganda piece by the state-funded BBC. Notice that the focus of the article is whether the technology is accurate enough, not whether they should be doing it at all in the first place. It's an Overton nudge, a softball position that's easy to take-- because of course the tech will get better. reply switch007 6 hours agorootparentSpot on. It's amazing how much the BBC is riding on its reputation and how many people are ignorant or just turn a blind eye to the fact it's Tory crony central at the top, and has been for years reply Hnrobert42 6 hours agorootparentprevThe better it gets, the worse the experience for the people who are mistakenly identified. reply ecjhdnc2025 5 hours agorootparentprevYou do not understand the BBC or its level of independence or funding model. Yes, the tory government have been trying to stack the governance of the BBC with their own people, but it doesnâ€™t always go the way they expect. reply pjc50 9 hours agoparentprevOrwell understood the authoritarian streak in the national character. reply ecjhdnc2025 5 hours agoparentprevThis idea that the UK is a surveillance society that is meaningfully different to other western societies is somewhat misplaced, based on motivated misreadings of a US article about surveillance in Kingâ€™s Lynn in the 90s. The vast, vast majority of CCTV systems in the UK, that are part of this â€œcultureâ€, are just store and private CCTV systems that police can get access to with a warrant, by going door to door. The same as in almost all western countries. https://en.wikipedia.org/wiki/Mass_surveillance_in_the_Unite... Thereâ€™s almost no police CCTV network, and thereâ€™s no reality to the fantasy element of police being able to see you wherever you go in the UK in real time (with the exception of a few crowded high crime areas where tourists get robbed, ironically, and a few high violence and terrorism risk areas, public transport facilities and live road traffic cameras). There are some council-owned networks in high crime areas which are pretty contentious, and then there are these police facial recognition vans which are clearly offensive bullshit overreach. In particular a lot of visitors misunderstand the prevalence of cameras pointed at our roads, which are not live feed cameras at all but speed-triggered safety cameras. Basically itâ€™s important to understand that the vast majority of cameras in the UK are people and businesses legally protecting their own shit, just like in the USA. One key cultural difference is ANPR. In America the general perception is that privacy includes where you go in your car, because you treat it as a portable living room. Thereâ€™s never been that presumption here. ANPR systems probably can track cars in metropolitan areas and on some motorways, but live traffic cameras are unusual in most of the country. There is definitely a slightly less self-centred lean to the balance of individual rights compared to community safety compared to North America. But this is also part of why we donâ€™t have to put up with anywhere near the same risk of violence or crime, even in areas that are significantly more densely populated. We also have pretty good laws governing this stuff. In short, Hot Fuzz ainâ€™t real, and I think North Americans like to project this idea of a surveillance culture onto the UK without considering that they are likely under the exact same sorts of surveillance in the same sorts of places, without as many of the same legal protections. (And with plainly discriminatory surveillance systems like Shotspotter to boot) Do you think retailers in the USA and Canada are not using the systems described in the article? Because you would be wrong if you do. https://www.dailymail.co.uk/sciencetech/article-12592563/wal... reply ItsBob 9 hours agoprevFor me the solution is clear: require written authorization from everyone you want to capture with facial recognition software. It prevents privacy issues and doesn't stop research. Exceptions could be made in gov buildings perhaps due to national security but the idea of unlimited private companies taking my photo, or using video for gait analysis, facial analysis etc is abhorrent. I'm not against tech and love what AI can do but private companies using my images for facial recognition is a step too far. reply lambdaxyzw 9 hours agoparent>It prevents privacy issues Next step: every big company/store requires a written authorization to enter. Back to square one. reply ItsBob 23 minutes agorootparentNot if you outlaw that practice. It's easily countered by creating a law that prevents discriminating on the basis of opting into tracking, AI and whatnot. Problem solved. reply hgyjnbdet 8 hours agorootparentprevThat was what I was going to say. All the stores need to do is warn potential customers that by entering the stores premises the potential customer agrees to x technology being used for the purpose of y. It's the potential customers choice then, leave or enter. reply ysavir 6 hours agorootparentIs \"We don't use automated identification technology\" enough of a market advantage to win over customers? reply KronisLV 5 hours agorootparentPresumably only if the average consumer cares about this enough. reply ysavir 5 hours agorootparentI could see it playing out like organic foods, honestly. reply JohnFen 3 hours agorootparentEven just that would be an improvement. reply JohnFen 3 hours agorootparentprevMaybe that would encourage people to stop shopping at big companies and stores and go back to supporting small businesses. (I do think the idea isn't a good one and am not defending it.) reply exe34 9 hours agoparentprevPersonally I'd go the other way - you can do it, but you must make it public. It also has to be reciprocal. You can look up stuff on me, but your stuff should also be available for me to look up. E.g. tracking private jets/yachts and publicizing their cost to the environment should be legal. reply ckocagil 6 hours agoparentprevThen what's the course of action when every store in the city requires your written authorization to shop from there? reply ItsBob 22 minutes agorootparentAs I mentioned above: outlaw the practice of preventing people from shopping if they haven't opted into your dystopian facial recognition software. It will essentially kill it immediately but still allow research. reply throwaway14356 17 hours agoprevI would like to put our officials under cameras 24/7 with the footage publicly available complete with the means to put them on trial and lock them up. When we've accomplished that im fine with monitoring everything always forever. But no sooner. reply froh 10 hours agoparentI would rather like to put people prone to stealing from all (tax fraudsters) under cameras 24/7 with the footage publicly available complete with the means to put them on trial and lock them up. we can limit it to those where the amount of individual stealing is relevant. not the long tail but the fat creamers. reply kingkawn 16 hours agoparentprevWhy should public service be even more inhumane ? reply hyperhopper 16 hours agorootparentWhen you talk about a post office clerk or military draftee, that's when you can use this public service argument. He is talking about the ruling class with power over all of us, so they should have more oversight than any normal person. reply kingkawn 5 hours agorootparentWe are making it impossible for anyone but sociopaths to run for office by believing that abusing them is the key to getting them to behave well. This attitude is as responsible for our state of affairs as everything else. reply morkalork 16 hours agorootparentprevWhat's good for the goose is good for the gander, no? Besides, stealing a random item from a super market shelf is much less damage than what a corrupt politician could do. Perhaps we should prioritize them instead.. reply philipov 16 hours agorootparentprevPeople who want power are the ones who can be trusted the least to have it. reply kingkawn 5 hours agorootparentMaybe the people who run for office are so bad because only someone who can accept constant abuse from the public can stand it. Maybe this attitude is the problem. reply philipov 1 hour agorootparentNo, the problem is that those who don't play ball with their political machine's interests are shut out from opportunities to advance. Tammany Hall is a famous historical example that goes back much farther than the public has had as strong a voice as it does today, and though the faces have changed this is still how things get done. The game is rigged at the level of who gets to stand for election, particularly in safe-seat districts that get decided in the primary. Very few people are able to get elected without help from their local political machine getting out the vote - enough to provide plausible deniability, but not enough to create an effective opposition. Remember the monopsony of Sheldon Silver? He used his position to control which politicians would receive contributions for their campaigns, creating a network of people dependent on him for political survival. It's that kind of power broking that's the problem. The clear and present danger of entrenched power is why politicians must not be allowed a shred of privacy. reply from-nibly 15 hours agorootparentprevBecause they are being paid by public money. reply kingkawn 5 hours agorootparentAhh so you believe in wage slavery. reply johnnyanmac 56 minutes agorootparentWhen you can give half your waking life to a billion dollar corporation and not even have the privilege of being able to pay for a roof over your head; yes. reply jordansmithnz 16 hours agoprevWhen I was 18 years old, a security guard kicked me and a friend out of a grocery store, much to our confusion. After talking to them and requesting the store manager, it turns out they had a photo of a shoplifter that looked very similar to me. Eventually we were let back in the store and it was all OK. So, itâ€™s not an entirely new problem? Although with facial recognition I guess there is less recourse; a manager is not as likely to believe they got it wrong if their computer tells them otherwise. reply vector_spaces 16 hours agoparentThere isn't much recourse anyway, you were entirely lucky that they were willing to be reasonable. At least if you live in the US, not sure what laws are like around this in Europe I don't think this status quo should be empowered further by error prone tech reply uni_baconcat 9 hours agoparentprevEven without the facial recognition system, security guys can ask customers out, since those are private property. And you are lucky that store manager helped you with the issue. Most cases I heard around me are that the security guy and the manager just gives no explanation. reply cm2187 8 hours agoprevIn my experience, when face recognition gives you a false positive, it's because there is a high likeness in the first place, and a human would likely have made the same mistake. How different is it from a police officer stopping someone in the street based on some photo on his most wanted cheat sheet? Or a shopkeeper denying entry to a customer based on the likeness to a list of mugshots held under the counter. Those are faillible processes too. Where face recognition is really useful is where it can match faces that would have otherwise fooled the human eye, just because it focuses on specific traits and ignores others like hairstyle. reply Macha 7 hours agoparentThe difference is scale. \"You look a bit like a shoplifter from across the country\" is not a productive use of a police officer's time, so will basically never happen. Whereas the people in this article are going to get challenged, if not outright refused or arrested, in an increasing number of stores as this tech spreads. reply JohnFen 3 hours agoparentprev> How different is it from a police officer stopping someone in the street based on some photo on his most wanted cheat sheet? There's a big difference. The cop knows that the resemblance could be coincidental and will (usually) do further investigation before actually harming the suspect. If an automated system fingers someone, the assumption is that the system is correct and innocent people caught up will suffer harm. reply bsenftner 7 hours agoparentprevThe problem is the dumb ass users of FR think an FR Match has authority, AND the industry does not discourage that attitude, not at all. reply BLKNSLVR 6 hours agorootparentAnd there's a lack of, for want of a better word, punishment for false positives for all of: the law enforcement officers, the software publishers, the policy makers. reply takinola 15 hours agoprevThere seems to be a misunderstanding of the place of technology in the criminal justice system. There is nothing wrong with using technology to sift through a mass of data points to narrow down suspects or point the investigation in a particular direction. However, this does not obviate the need for investigation to actually verify that the initial identification is correct. There should never be a case where people are arrested or prosecuted solely on the word of a database query. reply garspin 13 hours agoparentAgree. A better response to '80% chance that this is a known shoplifter' is for security to keep an eye on them. It should very quickly become apparent that it's a false positive (or not). reply hnbad 9 hours agorootparentThe problem is that this technology is not sold that way, it's sold as a way to detect shoplifters. It's also extremely important how the result is phrased and presented: even \"80% chance that is is a known shoplifter\" simply means \"this is a known shoplifter\" to a layperson. But even a 99.9% or 100% confidence might be wrong so this isn't even an 80% chance - at best it's 80% times the statistical likelihood of this not being a false positive at 100% confidence, and that can never be a 100% chance. The (psychologically) correct way to think of this is as a colleague making a claim and telling you how certain they are. But this tech is not sold as a colleague, it's sold as a machine that is better than humans. It's not a perfect super cop but that's how it is marketed and why people buy it. reply jimmySixDOF 9 hours agorootparentI am afraid the Appeal to Authority fallacy is one we as a society are about to be exposed to on a massive level and recognize as a side effect of integrating AI into our daily lives. reply ozzcer 9 hours agoprevThe jakes have recently started parking these facial recognition vans up at protests and introduced a brand new imaginary law making face coverings illegal if they so deem it. We really aren't ok over the here. reply defrost 9 hours agoparentWhat about the Old Bill and the Rozzers then? Same result https://www.youtube.com/watch?v=R5Cw043lPCE ? reply BLKNSLVR 6 hours agoparentprevWith physical access to the camera, disabling them can be delightfully low tech. reply exe34 9 hours agoparentprevN95 masks for everybody? reply e40 5 hours agorootparentNC (USA) just made masks illegal in public. reply JohnFen 3 hours agorootparentIt's easy enough to avoid going to North Carolina. Let's hope that madness will not spread much. reply blindriver 17 hours agoprevHow is this not slander? Falsely telling someone that you're a thief with real worldly consequences like getting kicked out of a store should have real legal consequences. reply OptionOfT 17 hours agoparentSlander requires a third person. The person from the store telling you you're a thief might be wrong, but it's not slander. I'm not sure about the computer program though. It telling a third person (i.e. the person from the store) would be libel, but since it is the result of a calculation, I'm not sure if it's considered libel. reply prepend 16 hours agorootparentFacewatch is telling the store. Technically, itâ€™s probably saying â€œthereâ€™s an 80% chance this person matches a thiefâ€ and the store is interpreting that as â€œban them.â€ I donâ€™t know UK slander laws, but in the US, it has to be incorrect to be slander. So this probably wouldnâ€™t pass the test. reply michaelmrose 16 hours agorootparentprevIf its said in public the general public is the audience that hears the slander. If the store had even the slightest amount of brains they would have simply asked the person to leave without saying anything about the cause. reply mytailorisrich 9 hours agorootparentprevAs long as the accusation was made in public with other customers around it can be slander. In the UK it would be for the defendant (I.e. security guard/store) to prove that the claim was actually true. So in this case they would be stuffed. The person should definitely contact a solicitor. reply acheong08 17 hours agoparentprevOnly if you have the money to sue. Things being the way they are, rather than fixing the issue, they would more likely simply increase the confidence threshold based on whether you look wealthy enough to sue reply nothercastle 17 hours agoparentprevThis is the uk, you probably donâ€™t have much rights to stop intrusive public private rights violations reply whimsicalism 16 hours agoparentprevmistaken arrests arenâ€™t slander reply ajb 9 hours agorootparentIn the UK, only police ('sworn constables') have legal protection when conducting an arrest. Ordinary people conducting a 'citizens arrest' are committing a crime if they make a mistake (false imprisonment). Store workers are not usually sworn constables. In any case, the article is not about an arrest. Making someone leave is not an arrest, it's the opposite (an arrest is detaining someone). reply michaelmrose 16 hours agorootparentprevFrom the story. \"Within less than a minute, I'm approached by a store worker who comes up to me and says, 'You're a thief, you need to leave the store'.\" Knowing that one in 40 people so flagged aren't guilty of a crime means they are deliberately imposing upon those so flagged. The choice to use a faulty tech isn't itself a mistake its a choice. EG if you exposed a million people to this tech daily you would falsely arrest 11,000 people. reply throwaway14356 17 hours agoparentprevshe should get a free candybar. reply jagrsw 7 hours agoprevThe trespassing laws for commercial establishments are very problematic. I'm in favor of laws that prohibit refusing service when selling openly offered goods or publicly offered services, with clear exceptions such as aggressive behavior, outrageously bad hygiene, requirements for proper attire etc. Rude behavior, shoplifting and other annoyances fall under separate laws. This should apply even to past criminals. Such laws protect against racism and other forms of discrimination, and they help integrate convicts back into society, at the cost of \"commercial freedom\". In jurisdictions with these laws (I know at least one), it's impossible to create, for example, bars only for men or only for women or refuse service to people we don't like (also, because they belong to some group, incl. morally reprehensible groups). There are some hacks around this and exceptions, but generally, it works and solves more problems, than it creates. Private gatherings or clubs are likely ok (nondiscrimination laws should still apply). UK and US are outliers here with their \"can refuse service to anyone\" approach. reply Waterluvian 7 hours agoparentCan you name the â€œat least oneâ€ jurisdiction? Iâ€™m curious where thereâ€™s a law saying you canâ€™t reject service to, say, Nazis. Iâ€™ve only known examples where youâ€™re free to reject anyone for any or no reason as long as itâ€™s not because theyâ€™re one of a very small list of protected groups. reply jagrsw 6 hours agorootparentPoland is one: 138 misdemeanor law: Whoever, professionally engaged in the provision of services, demands and collects a payment higher than the applicable fee for the service, or intentionally, without a justified reason, refuses to provide the service to which he is obliged, shall be subject to a fine. Some forms of propagation of fascism, communism and nazizm is prohibited in Poland, but I guess it probably would be illegal to refuse service to someone who otherwise declares support for some reprehensible ideas, and does that privately, so it doesn't fall under hate or other laws. reply Waterluvian 6 hours agorootparentThanks for the example and name, so I can look it up and read further. reply lifeisstillgood 8 hours agoprevNot this case specifically, but the harm done by misidentification by a computer is seemingly no different for the harm done by a human misidentification - if the doorman / security guard / croupier thinks you are a miscreant then the same harm applies What might matter is the actions taken - but would they be any different if a human said â€œoh look thatâ€™s the well known shoplifter, keep her outâ€ reply BLKNSLVR 6 hours agoparentHumans apply much more judgement to their own choices, and actions resultant from them, than instructions from the infallible machine. Humans may also be disciplined for not attending to an instruction from the infallible machine, whereas there are no stats or electronic records of human judgement of \"is that the lady who shoplifted the other day? Hmmm, maybe... Maybe's not really good enough for how little I'm paid\". reply withinboredom 7 hours agoparentprevThe difference is if this shitty doorman worked at every shop. reply Retr0id 7 hours agoprevThe best silver-lining of COVID was that, for a while, we'd normalized covering our faces in the presence of CCTV. Unfortunately it didn't stick. If you wear a mask these days, you only stand out more. reply jessamyn 4 hours agoprevIn the United States local drug store Rite Aid got in some serious trouble for using AI facial recognition. Looking at some of the Federal Trade Commission's complaints against them can give you some creepy insight into how the technology supposedly works and how few checks for accuracy or oversight there are in place. https://www.ftc.gov/news-events/news/press-releases/2023/12/... reply defrost 11 hours agoprevFrom the same article, meanwhile, out on the street in public space: On a humid day in Bethnal Green, in east London, we joined the police as they positioned a modified white van on the high street. Cameras attached to its roof captured thousands of images of people's faces. If they matched people on a police watchlist, officers would speak to them and potentially arrest them. reply swarnie 10 hours agoparentThat seems perfectly reasonable? reply jjbinx007 10 hours agorootparentIt places a burden on someone to somehow prove their innocence, if they can. What if a person refused to speak to the police? Or what about this? A man covered his face when walking past one of these vans in a public street. He protested and was then fined Â£90 for swearing (swearing is not illegal but The Pubic Order Act is another law that is often abused by police but that's tangential) https://www.independent.co.uk/news/uk/crime/facial-recogniti... reply foldr 9 hours agorootparentThis is the same burden a person would be under if a police officer simply noticed someone on the street who looked like a wanted suspect (without computer assistance). I agree that the automated system makes this situation more likely to occur, but it has always been the case that you can potentially be arrested because you look a bit like someone else. And in that situation you would have to do your best to convince the police officer that you were in fact someone else. reply johnnyanmac 50 minutes agorootparentThat's generally why you're only required to provide ID to police in the US (at least in a car. Don't think you can force anyone off the street to show ID). The right to remain silent, or to deny entry into your home cannot put you on a Arrest list. Of course, all this assume US police have consequences for breaking the rules. So this is unfortunately moot. reply ConsiderCrying 10 hours agorootparentprevIt's perfectly reasonable to harvest thousands of photos of unknowing people and then accost them based on faulty software that can produce an erroneous match? How so? reply swarnie 8 hours agorootparentNothing in OPs post said anything about accosting people or using faulty software to drive that interaction. Simply going out looking for people of interest in east London is perfectly fine, we call it \"police work\" and have done it for bloody ages. Maybe instead we could issue officers with a deck of cards with 52 faces on them and they can use that as a comparison point? Seems pretty inefficient to me but im only a tax paying pleb what would i know. reply nmeagent 8 hours agorootparent> Seems pretty inefficient to me Police surveillance should be inefficient. People do not exist to be arbitrarily inspected at scale; it should be an expensive, manual process and you should be forced to choose carefully whom you target, by necessity keeping that list small and limited to those for whom you can articulate cause. reply swarnie 8 hours agorootparentI'm sorry but i strongly disagree. If you're taking money from the public and spending it you should be legally bound to use it in the most efficient and effective way possible. reply johnnyanmac 46 minutes agorootparentThe most efficient way to survey is to not survey. Nothing more efficient than 0 runtime overhead. Snark aside, surveys are quite literally the least efficient means of gathering a sample. Scanning random people on the street when a known criminal is likely to lay low and stay inside. I can't imagine expensive surveillance cameras is cheaper than paying an investigator to track down a suspect. reply pixxel 2 hours agorootparentprev> I'm sorry You should be. And your comment should have ended there. reply swarnie 1 hour agorootparentThis one officer. reply defrost 10 hours agorootparentprevSure, it may be reasonable, it's still worth pointing out that the article is not just about people entering a specific chain of shops, it's also mentioning police vans sitting in the middle of pedestrian concourses outside such shops doing the same face scanning. reply theodric 10 hours agorootparentprevDragnet surveillance meets fishing operation. I do not find it so reasonable. reply hnbad 9 hours agorootparentprevIt sounds like they had weren't looking for any specific person (just anyone on \"the watchlist\") and they were simply mass processing faces to find potential matches. Let's ignore the privacy implications as not all countries have an expectation of privacy outside windowless closed private spaces. How is this meaningfully different from a general stop and frisk policy? Sure, this adds a non-physical filter before the physical police interaction but it's still a widespread warrantless search. How does this work with the presumption of innocence? reply foldr 9 hours agorootparentThe counterpoint would be to ask how this is meaningfully different from a group of police officers standing on the street comparing the faces they see to a set of photos of known suspects. The efficiency of the automated system obviously makes it feel very different. However, fundamentally, being arrested for looking like someone else is not a new phenomenon. I do not like what is going on here, but Iâ€™m not sure that your particular line of argument against it is very strong. reply johnnyanmac 41 minutes agorootparentSame deal as LLMs. Police don't get to automatically input facial data into a database when on the streets. If there was some guarantee all that data wasn't going into some government sanctioned back end, we can start to compare it to police out on the street. >However, fundamentally, being arrested for looking like someone else is not a new phenomenon. Was always wrong and still is wrong. But if you want a modern difference: companies these days (even minimum wage) are really strict about arrests. Even a false arrest can cause complications in a background check, so there is more potential (albeit indirect) slanderous effects from mistaking people nowadays. reply foldr 9 minutes agorootparent> Was always wrong and still is wrong. I donâ€™t understand this comment. The police sometimes have to arrest people based on descriptions and other fallible data points. Itâ€™s unfortunate when the wrong person is arrested (and false arrests should obviously be minimized), but itâ€™s not reasonable to expect police to get this right absolutely 100% of the time. If someone is a fugitive then they are very unlikely to reveal any information that identifies them with certainty. reply fwlr 14 hours agoprevIâ€™m worried that opponents of facial recognition are shooting themselves in the foot with the inaccuracy argument. Sure, maybe face rec ends up like Siri or self-driving cars. Even if it ends up like DallE or ChatGPT they probably still have a point. But Iâ€™m a little bit afraid that it might have an AlphaGo moment and just become extraordinarily superhuman at facial recognition, becoming much more dangerous while simultaneously dismantling the case theyâ€™d been building against it. reply int_19h 12 hours agoparentThis is in UK. The \"but what about privacy?\" argument has been lost there a long time ago, so they make do with what they have. reply anonshadow 16 hours agoprevHaven't UK learnt anything after unjustly accusing and imprisoning all those people that the Postmaster thoughts had stolen money when it turned out eventually to have been a software bug? reply dspillett 10 hours agoparentAll the people who need to learn from that seem to be learning, is new and interesting ways to pass the buck. reply varispeed 9 hours agoparentprevI don't think it was a \"bug\", but it is probably described as such to minimise what happened. My understanding is that people with admin access were manipulating Postmaster transactions which resulted in creating artificial losses and Post Office was denying it was possible, despite having knowledge it was happening. reply leke 7 hours agoprevI'm wondering if this woman is still barred from stores that use Facewatch. It would be a terrible inconvenience to only be allowed in a select few shops. Where is the line defining certain private businesses as essential resources for day to day life? I think this sentence sums it up perfectly... > \"It felt intrusiveâ€¦ I was treated guilty until proven innocent,\" he says. I don't want to live in this kind of society. reply kolinko 6 hours agoparentIn EU there is a ban on this kind of tech (face/gait recognition based on cctv, by private companies, plus separate laws forbidding acquisition of personal data without consent) reply leke 4 hours agorootparentI guess government can still use it though? reply subroutine 17 hours agoprevA few questions here... How did they know she shoplifted in the first place? Does the tech also identify shop lifting, or do they just search a database of people convicted of shoplifting (in which case they could have just checked this person's ID and realized it was mistaken identity). Is being caught shoplifting a credible reason to deny someone access to basic goods indefinitely? What if all supermarkets in a town use the same facial rec service? reply crooked-v 16 hours agoparent> How did they know she shoplifted in the first place? She didn't. reply abdullahkhalids 10 hours agoparentprev> they could have just checked this person's ID If random store employees start walking up to people and asking them to show ID, is that an acceptable state for society? reply johnnyanmac 39 minutes agorootparentIt is at Costco /s But note that this is the UK. Different issues from the States (where this wouldn't ever pass. We have weak social security specifically becsuse citizens rejected a national ID). reply foldr 7 minutes agorootparentThere isnâ€™t any national ID in the UK either. reply justincormack 10 hours agoparentprevUK does not have ID cards and you do not have to carry ID. Also they may not have ID for the shoplifters often they are just pictures from cctv. reply asveikau 16 hours agoparentprevSeems like they're trying to match against known people and it has false positives. reply michaelmrose 16 hours agoparentprevIt uses facial recognition ergo a computer flagged her face as similar to the face of someone known to be banned from the store. This tech is known not to be good enough for this use case. If you match a large population of users you are going to get an unacceptable level of false positives. Even putting a human being in the loop is trouble prone because people aren't on average good enough at this. It would be more useful to require a free membership to shop there and validate allowed users via bluetooth and ban users devices and phone numbers. reply vector_spaces 16 hours agoprevLet's say this technology was basically infallible: only known shoplifters were flagged. What then? Should shoplifting once mean that a person is banned from all stores that use this service for life? Also: I assume that this service wouldn't just impact shoplifters, but anyone that a store saw fit to ban for any reason. What about people who experience mental health crises? I had a friend who had psychotic breaks while her issues were still undiagnosed and untreated I know that this ultimately depends on the store's own policies, the facial recognition tech just provides information. but frankly I don't want to live in a world where making such a minor mistake in your youth could basically ruin your life reply fwlr 15 hours agoparent> Should shoplifting once mean that a person is banned from all stores that use this service for life? I mean, it depends, right? Barred from buying any groceries for stealing a candy bar is obviously wrongâ€¦ but if you walk out the door with a five-figure watch you didnâ€™t pay for, Iâ€™m happy for you to be banned from Rolex shops for life, yeah. reply withinboredom 7 hours agorootparentUnless you already went to jail for it? People do change over the timelines of an entire life. reply smusamashah 9 hours agoprevIs there a better way to avoid shoplifting or catch shoplifters using tech? reply rwmj 9 hours agoparentPrivate shops largely have a right to bar whoever they want from being a customer, except in protected categories (\"shoplifter\" isn't one of those). The problems here are (a) no one understands type I / type II errors, (b) everyone trusts computers must be right all the time, and (c) there's no easy way for this particular customer to prove that she's not the shoplifter. (c) could be fixed by a process. (a) and (b) are very hard nuts to tackle. reply mytailorisrich 9 hours agorootparentShe can contact a solicitor and go after the store/security guard for slander if they made the claim in public. Under UK slander law it would be for the store to prove that the claim was true, not for her to prove that it was not. reply hugh-avherald 7 hours agorootparentThe damages for defamation would be severely limited. Considering that most people in the store would barely notice, and would probably not even remember the following day, you'd be entitled to zero damages, and probably not even costs, for defamation. You might be entitled to a bus fare (not a taxi) to a different supermarket, but that's about it. reply pjc50 9 hours agorootparentprevYou can't get legal aid for that, so the astronomical cost wouldn't be worth it. reply mytailorisrich 9 hours agorootparentThere are steps. A good solicitor letter may prompt a financial settlement and would serve its purpose, not least as the story is making headlines... In any case, contacting a solicitor does not hurt. reply JohnFen 3 hours agoparentprevHumans watching CCTV cameras, maybe? reply _joel 6 hours agoprevI think another part to this is the police not attending shoplifting incidident (amongst many others) due to the reduction in the police numbers. It's definitely out of order, what the tracking company is doing, of course. Perhaps if we had a functioning police service and reduced the need for people to shoplift (yes, a lot of this is run by gangs now, but still some steal to feed). reply skywhopper 6 hours agoparentYouâ€™ve listened to a lot of misinformation about this topic. There arenâ€™t huge gangs of shoplifters, and police force numbers have been growing in recent years. If anything is to blame for whatever increase there has been in shoplifting, itâ€™s the stores who have tried their best to eliminate every bit of human staff. reply _joel 1 hour agorootparentShow me the data to back that up as everything being reported is completely the opposite of what you suggest. https://www.bbc.co.uk/news/uk-england-london-67742042 reply throwaway14356 17 hours agoprevThe Chinese solved this by adding more cameras. If you can lookup where the potential suspect came from and pull their full details from the fuzzy query false positives become unlikely. More data is the answer! lol reply perihelions 9 hours agoparentNot sure why this comment's gray; it's a good point (and a sobering one). In the very near feature, Western countries likely won't be relying on individual surveillance cameras; we'll have end-to-end chains of cameras that will confirm, with confidence, which house a person walked out of 2 hours ago, right down to their interior flat entrance inside an apartment block. (As the PRC is currently trialing). We'll have near-perfect panopticon identity systems, associating facial recognition with place of residence, and dozens of other factors. It's very important to ponder what the PRC is pioneering today because we're about three years behind doing exactly the same things, and for the same reasons. It's only going to be a brief time before things we're horrified about, and vitriolically condemn totalitarian states for, are things we're going to fully normalize within our own culture. reply johnnyanmac 36 minutes agorootparentPoe's law. Given a few comments here, some may parade the idea. Fully giving up privacy for security. I'd hope we give a better fight than that. reply nurple 9 hours agorootparentprevThis is why predator drones orbiting for days over protests is so scary, this is exactly the functionality their payload powers. https://en.wikipedia.org/wiki/ARGUS-IS https://yewtu.be/watch?v=CpLdL8ONEm4 reply nitwit005 16 hours agoparentprevIt's essentislly impossible to eliminate false positives. With billions of people on the planet, the odds of someone looking extremely similar is high. Plenty of actual twins around as well. reply int_19h 11 hours agorootparentI'm sure there are other things that could be captured and analyzed aside from images. Gait, perhaps? It's similar to web tracking - each individual method might be very unreliable, but the intersection of them can be extremely specific. Or just implant RFID into every citizen at birth. It's for your safety, after all - if you get lost or abducted, that's how they'll find you. reply mr_toad 15 hours agoprevâ€œ The Metropolitan Police say that around one in every 33,000 people who walk by its cameras is misidentified. â€œ Given the UK population of 67 million, thatâ€™s about 2000 false matches. reply alex_young 13 hours agoparentPer time they venture near one of these camerasâ€¦ reply akdor1154 10 hours agoparentprevIt's an absolute bullshit statistic. There is no way they have established ground truth to evaluate accuracy at this scale. $100 says they've taken the numerator of 'people we detained where it turned out we dun goofed' over the denominator of total people scanned. reply viking123 10 hours agoprevThe Hikvision facial recognition camera in my previous condo sometimes recognized me as an Indian man, and sometimes it scrolled through tons of faces and unlocked the door. I am from northern Europe btw. Sometimes it also had difficulty recognizing me when my hair grew longer. reply Aeolun 9 hours agoprevDo they think itâ€™d be better if the police did not use the facial identification tech? If theyâ€™re standing there with a van and immediately stopping you the only thing you have to do is pull out your ID? reply btasker 8 hours agoparentEasy answer: yes it'd be better. TFA says that it has a failure rate of 1:33,000. That's a \"do not ship\" rating for almost anything else. > immediately stopping you the only thing you have to do is pull out your ID? Someone I know was detained on the side of the M25 for an hour sorting things out after being pulled over. He presented the police with his ID and they decided it was a fake. His name was almost identical to someone who was wanted - his middle name and date-of-birth were different. The Police said that was common on fake IDs - just change a few small bits of information - and that they'd have to take him to the station where he could sort it. The only reason he didn't get taken in in the end is because the description of the wanted person noted that he had tattoos on his chest. On the side of the M25, at night, the only thing that stopped my mate being hauled into a London police station was taking his top off. Anecdotes don't make data, but the idea that a copper will simply accept ID despite a system saying \"this is your guy\" is incredibly naive and suggests you've not had to interact with them much. reply Aeolun 8 hours agorootparent> suggests you've not had to interact with them much. Or the opposite is true and this has been enough to solve all my police problems? Iâ€™ll admit it is not in the UK, but I doubt they have a significantly less professional police force. > TFA says that it has a failure rate of 1:33,000. That's a \"do not ship\" rating for almost anything else. For anything where failure means death, sure. For situations where failure means a minor inconvenience, maybe not so much. To me, the only relevant point of comparison here is the rate of misidentification by officers while _not_ relying on the face id tech. Because thatâ€™s the alternative, not having no arrests or searches at all. reply btasker 8 hours agorootparent> Iâ€™ll admit it is not in the UK, but I doubt they have a significantly less professional police force. Ah, that explains a point that I'd didn't bother to pull you up on. Carrying ID is not a routine thing here in the way that it is in some other countries (there have previously been attempts to introduce a national ID but they were staunchly opposed). So, it's not a given that you'll have ID on you to show them. Drivers probably have their driving license in their wallet, but even that's not guaranteed (because you don't have to have it on you when driving). The \"quality\" of police varies by force (and, of course, by officer). The Met, though, have had some pretty serious issues with misconduct (including sexual assault and murder) and are still working through the processes of identifying personnel who shouldn't be in uniform at all (the Met themselves found there were hundreds of officers who should have been sacked previously). They're working to fix things (or claim to be), but you probably don't want a force that's been described as \"institutionally racist, sexist and homophobic\" to be entrusted with something like this. > For anything where failure means death, sure. For situations where failure means a minor inconvenience, maybe not so much. I would still say the failure rate is too high given that the outcome of interactions with the Police varies quite significantly (par. > To me, the only relevant point of comparison here is the rate of misidentification by officers while _not_ relying on the face id tech. I'd also be interested to know this. But, I don't think it'll go quite the way you expect. I'd expect there'd be _fewer_ overall stops: coppers simply won't (mis)recognise as broad a range of people. If they're only stopping people they recognise (or based on stuff that's been radioed through), their success rate is probably better reply flumpcakes 8 hours agorootparentprev> TFA says that it has a failure rate of 1:33,000. That's a \"do not ship\" rating for almost anything else. I find statements like this interesting, from a risk analysis point of view. In the UK there are breast cancer screening programmes and the risk of a radiation-induced cancer for a woman attending full field digital mammographic screening is between one in 50,000 to 100,000. That puts the rate of inducing cancer vs finding cancer at 1 in 400 to 1 in 800 (because the majority of scan results find no cancer). Should we \"not ship\" breast cancer screening? reply cess11 8 hours agorootparentprev\"The Metropolitan Police say that around one in every 33,000 people who walk by its cameras is misidentified. But the error count is much higher once an someone is actually flagged. One in 40 alerts so far this year has been a false positive.\" I think it's a good idea to make it clear what you mean by \"failure rate\". reply flumpcakes 7 hours agorootparentOne in forty false positives still isn't bad for a system to automatically sift out wanted criminals. That's going to be orders of magnitude better than police stopping people who 'fit a description'. reply JohnFen 3 hours agorootparent> One in forty false positives still isn't bad for a system to automatically sift out wanted criminals. It's an absolutely disastrous false positive rate when the consequences to those who are falsely identified are more than trivial. reply kolinko 6 hours agorootparentprevThat one in fourth will be banned from using nultiple stores and establishments without due process and without a clear way to clear themselves up. reply cess11 7 hours agorootparentprevOK, can you show the numbers you are using? reply cess11 8 hours agoparentprevYeah, like in the USSR when you wanted to enter the metro and a cop asked to see your ID. Very nice, nothing tyrannical about demanding that people submit to the authorities whenever the authorities want them to. reply AndrewDucker 10 hours agoprevCan happen without technology too, of course. I was nearly thrown out of a pub before I opened my mouth and the staff realised I wasn't the person who caused trouble there the week before. reply reify 10 hours agoprevLive CCTV offenders here on Airstrip One John Lewis, Co-op, Tesco, Sainsbury's, Waitrose, Next, Marks & Spencer, Boots Primark reply skywhopper 6 hours agoprevâ€œit is also clear there are plenty among the public who are willing to put up with having their faces scanned - if it means safer streets.â€ Unfortunately it doesnâ€™t mean anything of the sort. This tech doesnâ€™t prevent typical street crime like muggings or assault. And the chance of getting hurt or killed by a police officer whose dispatcher just identified you as a criminal is much higher than what the random folks who skipped bail that are in this system would do to you (ie nothing). Then thereâ€™s the â€œlowâ€ false positive rates. They say only one of 33,000 people scanned is falsely identified. Okay, thatâ€™s pretty high. If they scan one percent of the UK population with these devices each day, thatâ€™d be 20 false positives a day, and 20 more potentially violent encounters with police a day. Compared to whatâ€™s likely a much smaller number of correct identifications of actual wanted individuals, most of whom could probably be found by much cheaper, less problematic methods. reply seanmcdirmid 16 hours agoprevI donâ€™t know. Whenever I see those amber alerts to be on the lookout for a grey Nissan with license plate number something, I think isnâ€™t that a great opportunity to use at least OCR or something. Or be on the look out for some kidnap victim kid who looks like other kids, asking people to do what technology can already do much better sounds dumb. Machines are going to come up with false positives, but so will human beings who are asked to be on the lookout for some kid of some redacted race in a hoody. reply ghaff 16 hours agoparentThe amber alert stuff seems useless. Maybe Iâ€™m a bad person but I just have that disabled. The emergency weather warnings are also pretty high false positive with respect to things like flash flooding but at least worth being aware of. reply r2_pilot 16 hours agorootparentOh it is quite useless where I am. Before I disabled it, I would routinely get ear-shriekingly loud alerts at 4:30 in the morning for events happening hundreds of miles away. Worst waste of resources that are mandatory on phones, ever, except for the presidential alert. reply int_19h 11 hours agoparentprevThe difference here is that people are asked to be on the lookout at some specific moments when a crime is known to be occurring, while cameras can - and are, per TFA - being used for straight up fishing expeditions. That said, yes, it would be nice if there was a way for my car to automatically scan car plates around, linked to my phone so that when an amber alert comes in and I explicitly choose to enable the scanner at that point, it would report matches for that particular number automatically. But we all know that's never going to happen. Well, the automatic plate scanners in every car will probably happen eventually - it's too easy technologically for someone to not come up with a bright idea to mandate them \"for safety\". But they will be enabled and effectively controlled by law enforcement 24/7. reply richrichie 16 hours agoprevWe have many studies that show vulnerabilities of these image classification models to noise (adversarial or otherwise). The confidence levels are just not enough to fit into our \"innocent until proven guilty (beyond reasonable doubt)\" justice system. The danger is that big tech/AI can pump enough money into politics that justice system parameters will be rewritten. reply reify 10 hours agoprevLive CCTV offenders here on Airstrip One John Lewis, Co-op, Tesco, Sainsbury's, Waitrose, Next, Marks & Spencer, Boots Primark reply Lio 9 hours agoparentWaitrose self-checkouts point a camera at your face when pay so that you can see yourself on screen. I dislike shoplifting and petty crime but I also dislike this form of cheap, petty intimidation. I donâ€™t want to live in this dystopia. reply JohnFen 3 hours agorootparentThat's the second reason I avoid self-checkouts whenever possible, honestly. The odds of me being hassled because of some sort of surveillance messup or because I did something wrong at the checkout are substantially lower if an employee is the one ringing up my purchases. reply YeGoblynQueenne 9 hours agorootparentprevWhoever designed the Waitrose self-checkout was a master in the art of annoying one's customers. Not only there's a camera pointed at you, the machine will urge you to bag an item \"or press finish and pay\" as soon as you take a few extra seconds e.g. to solve a Backpack Problem with a can of sardines and a packet of pasta etc. And they're supposed to be the up-market chain? reply Aeolun 8 hours agorootparentI was stopped several times to get my bag searched in the Dutch upmarket chain. I wouldnâ€™t say it means anything. (Though people told me that was exceptional and I was just unlucky) reply YeGoblynQueenne 8 hours agorootparentIs that Albert Heijn? They have nice freshly squeezed orange juice and pindakaas. I remember automated checkouts when I was in Amsterdam but I also seem to remember they were out of order. Small blessings, I guess? reply stoneman24 9 hours agorootparentprevThe large Asda near me does this, too. Not happy about it but not sure what can be done to stop it. Probably needs either Scottish Parliament or Westminster to enact a privacy law and I canâ€™t see that happening. Perhaps itâ€™s already covered under the European convention on human rights, but I donâ€™t know if that still applies. reply YeGoblynQueenne 9 hours agorootparentThat's the one the Tories tried to tear down as a \"villain's charter\" isn't it? And Labour are very keen to show they're \"tough on crime\". So I guess, not. reply gizajob 8 hours agorootparentprevI think Asdaâ€™s is so bad and intrusive that Iâ€™ve long since stopped shopping there. Also the worst of supermarkets on the quality front. Even Lidl is better. reply gizajob 8 hours agorootparentprevJust make sure you pocket stuff before reaching the checkout then. reply swayvil 16 hours agoprevIt's better than being identified as somebody who has a high probability of becoming a thief in the future, I suppose. Do we do that? Do we want to do that? reply johnnyanmac 34 minutes agoparentI don't think we have that tech yet (outside of good ol' racism, of course). Given current controversies around Her, I'm sure some techie will see Minority Report and view it as a dream to pursue rather than a cautionary tale. reply kwhitefoot 10 hours agoparentprevTony Blair wanted to do exactly that with psychological profiling of kindergarten children. reply smitty1e 17 hours agoprevIn ancient times, one was innocent until proven guilty. But, hey: Progress. reply mr_toad 15 hours agoparentUp until the last couple of centuries most countries didnâ€™t have any sort of pro-active policing, beyond posting a bounty or a wanted notice. Unless you were caught red handed it was up to private citizens - thief takers, bounty hunters, or the aggrieved victims and family - to attempt to apprehend wanted criminals. reply throwaway14356 17 hours agoparentprevThat was not long ago. In ancient times you wouldn't be on trial if you were innocent. reply upon_drumhead 16 hours agorootparentSalem might want a word... reply dspillett 10 hours agorootparentThat is the sort of thing Mx Throwaway was getting at: the fact that you were on trial was often seen as a sign of guilt, because why would an innocent person be on trial? Almost everybody else on trial was found guilty, so why should this trial be any different? reply eesmith 10 hours agorootparentprevThe Code of Hammurabi says otherwise. Quoting from http://www.general-intelligence.com/library/hr.pdf, linked-to from https://en.wikipedia.org/wiki/Code_of_Hammurabi: 1. If any one ensnare another, putting a ban upon him, but he can not prove it, then he that ensnared him shall be put to death. 2. If any one bring an accusation against a man, and the accused go to the river and leap into the river, if he sink in the river his accuser shall take possession of his house. But if the river prove that the accused is not guilty, and he escape unhurt, then he who had brought the accusation shall be put to death, while he who leaped into the river shall take possession of the house that had belonged to his accuser. 3. If any one bring an accusation of any crime before the elders, and does not prove what he has charged, he shall, if it be a capital offense charged, be put to death. reply whimsicalism 16 hours agoparentprevi think you might have an overly romanticized view of justice in ancient times reply smitty1e 7 hours agorootparent\"In ancient times\" was intended as sarcasm, but labeling this as \"Progress\" made that point too subtly, I realize. reply forrestthewoods 17 hours agoprev> The Metropolitan Police say that around one in every 33,000 people who walk by its cameras is misidentified. But the error count is much higher once an someone is actually flagged. One in 40 alerts so far this year has been a false positive. A 97.5% accuracy rate seemsâ€¦ really really high! Obviously facial recognition shouldnâ€™t be the only bit of evidence. But thatâ€™s remarkably accurate. reply defrost 11 hours agoparentIt lacks context, it could misidentify half of the people scanned and still have the police report that number. eg: 33,000 people walk past cameras but only two are flagged as matching a person of interest on the watch list. One of those is a mistake, the other was correctly identified. From the Police PoV that's one mistake in 33,000 .. but whose to say the remaining 32,998 people were correctly identified? Perhaps they were all criminals that weren't identified, perhaps they were all not criminals but not correctly matched. Perhaps 2,000 were criminals and on the watch list but not identified. reply Nextgrid 16 hours agoparentprevSo high in fact that either the numbers are cooked or the threshold required for a positive match is set really really high, so they get a lot of false negatives, which opens the possibility that the threshold can be lowered in the future. reply nullc 16 hours agoparentprevIt should also get worse as more people are added: In a large enough population almost every person has some look alike who happens to be a thief. Another way to look at it is for the worst case person what is their false positive rate? It's going to be 100%: Joe Blow, who did nothing wrong to no one, will go from place to place getting kicked out for the rest of his (/the system's) life. The failures aren't random (or at least not entirely)-- some people will get a heap of error in their lap. So while getting punted 1:10000 times you go somewhere unfairly isn't too bad, getting always punted is awful. The unequal distribution of errors creates bad incentives: the system is almost risk-less for those of us who aren't the victims of false hits, so why should we demand improving or banning it? reply viraptor 17 hours agoprevHN yesterday: EU is so silly trying to regulate AI usage, \"The Banned and High-Risk lists read like a call for startups (outside the EU).\" https://news.ycombinator.com/item?id=40473533 HN today... reply betaby 17 hours agoparentGov exempts themselves and the powerful from regulations. reply armchairhacker 16 hours agoparentprevAs always, it's the details of the regulation that matter. Or perhaps more important, how it gets enforced. reply louwrentius 7 hours agoprevI firmly believe that the harm done to misidentified people is not worth the capture of people who are sought after. In the story I also noticed that people flagged are not treated as innocent until their identity has been truly established. What kind of society do we want? Was the money spent on facial recognition systems better spent on â€œpreventionâ€? Probably not as this money would not have gone to the police so we canâ€™t have that! /s reply jellicle 16 hours agoprevIf China surveils people, it's because they are evil and authoritarian. If we surveil people, it's because we're just keeping the public safe. reply altcognito 16 hours agoparentNobody here is cheerleading this, I think the overwhelming sentiment is that it is invasive (and inaccurate but thatâ€™s beside the point) reply Nextgrid 16 hours agorootparent> Nobody here is cheerleading this By \"here\" do you mean in the UK? Somehow the UK is consistently the first non-China nation where this authoritarian surveillance crap takes hold. Other countries make pushes towards it, but UK appears to be consistently leading. reply altcognito 1 hour agorootparentjust this particular post on hn. I'm not from the UK so I can't fully comment, but based on the stories I read here, I'd agree with your general sentiment. reply daveoc64 10 hours agorootparentprevAs the article points out, given the rampant levels of shoplifting in the UK (and the associated abuse of staff), all of the major retailers and a lot of their staff are going to be on board with this. For the government and police, it's a cheap option to deal with the problem. reply dspillett 9 hours agorootparentThe staff don't really care about lifting: they really aren't paid enough for it to be their problem, or cared for enough by the employers such that they care if the employer looses a bit through shoplifting. The few that do care see the heavy end of the abuse you mention, and those that don't see abuse anyway, and if it isn't on CCTV the employers don't seem to care (it is far too much hassle to prosecute) despite the higher-ups pretending otherwise: that is why the staff support CCTV and related monitoring, not the lifting. The abuse is a very real problem, I know a few who work in shops, all of whom have been verbally abused and physically threatened at various times. One of them was not long ago punched in the face in front of witnesses. Tesco, ever caring, had her working the next day, just a few hours later (incident happened on late shift, next shift was early morning, \"are you sure you can't come in?, it'll be hard to find someone to cover\") and seemed to put as more effort into investigating what she might have done wrong as they put into helping the police gather evidence to investigate the abusive individual, so she was glad of the CCTV. She got out off Tesco as quick as she could. She has had notification from the police that the individual involved is being prosecuted, but for a number of other offences also so it is unlikely she'll need to testify or otherwise be involved further. The staff want the CCTV because they don't trust the managers and higher to look after their interests otherwise. reply int_19h 11 hours agorootparentprevAs the article points out, most people they've asked around those cameras were provisionally supportive of them (so long as they \"help with crime\"). reply jellicle 15 hours agorootparentprevThe BBC is, for one. reply tgv 10 hours agoparentprevThe Chinese government is evil and authoritarian. As a result, they do like surveillance. That does not exclude you can use the same technology or same measures for other purposes. reply aurareturn 10 hours agoparentprevThis tech can really help San Francisco recover. reply DavidPiper 16 hours agoprev [â€“] I have deliberately not clicked on the link yet. My thought process just based on the title: 1. Okay well maybe the technology was wrong. 2. Or maybe the shoplifter is lying? 3. Surely \"my word against yours\" in the case of \"human vs. computer\" is solved by believing the human? 4. Isn't the whole point of this technology to catch humans who lie? 5. Then surely, if it's a shoplifter, there is video footage and that will clear up the issue. 6. But what if there isn't footage. What if it's just an AI that's detected someone as a shoplifter based on their face? 7. The technology for this is really mature, now I'm inclined to believe the computer. 8. But what about the guy? (Yay, gender assumption based on the word \"shoplifter\") 9. Well, in order to believe him I would want to understand why the AI was wrong. 10. Oh, the whole thing with AI in many contexts is that YOU CAN'T KNOW THIS. 11. This is why people care about understanding how AI makes decisions and have serious reactions to technology that just \"magics\" a decision out of thin air, even when it's the right one this time. 12. But what about the guy? Well, I've just newly understood some things about the social impacts of pervasive AI. Time to read the article. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Sara was wrongly accused of shoplifting by the facial recognition system Facewatch at a Home Bargains store, leading to a search and a ban from stores using the technology.",
      "Facewatch later apologized, but the incident highlights concerns about the accuracy and potential misuse of facial recognition technology, which is used in various UK stores and by the police.",
      "Critics argue that the legal framework for such technology is underdeveloped, raising fears of mass surveillance, while some support its crime-prevention benefits for increased safety."
    ],
    "commentSummary": [
      "A BBC article highlights a case where facial recognition technology wrongly identified an individual as a shoplifter, causing public embarrassment and potential libel.",
      "Critics argue that over-reliance on facial recognition systems is problematic due to errors, lack of accountability, and high false positive rates, calling for regulation and human oversight.",
      "The discussion explores the ethical and legal implications of AI in surveillance, emphasizing the need for transparency, responsible use, and balancing security with privacy."
    ],
    "points": 123,
    "commentCount": 225,
    "retryCount": 0,
    "time": 1716684304
  },
  {
    "id": 40478976,
    "title": "SpinRite's Diminished Relevance in the Era of SSDs and Advanced HDDs",
    "originLink": "https://computer.rip/2024-05-25-grc-spinrite.html",
    "originBody": ">>> 2024-05-25 grc spinrite (PDF) I feel like I used to spend an inordinate amount of time dealing with suspect hard drives. I mean, like, back in high school. These days I almost never do, or on the occasion that I have storage trouble, it's a drive that has completely stopped responding at all and there's little to do besides replacing it. One time I had two NVMe drives in two different machines do this to me the same week. Bad luck or quantum phenomenon, who knows. What accounts for the paucity of \"HDD recovery\" in my adult years? Well, for one, no doubt HDD technology has improved over time and modern drives are simply more reliable. The well-aged HDDs I have running without trouble in multiple machines right now support this theory. But probably a bigger factor is my buying habits: back in high school I was probably getting most of the HDDs I used second-hand from the Free Geek thrift store. They were coming pre-populated with problems for my convenience. Besides, the whole storage industry has changed. What's probably more surprising about my situation is how many \"spinning rust\" HDDs I still own. Conventional magnetic storage only really makes sense in volume. These days I would call an 8TB HDD a small one. The drives that get physical abuse, say in laptops, are all solid state. And solid state drives... while there is no doubt performance degradation over their lifetimes, failure modes tend to be all-or-nothing. I was thinking about all of this as I ruminated on one of the \"holy grail\" tools of the late '00s: SpinRite, by Gibson Research Corporation. The notion that HDDs aren't losing data like they used to is supported by the dearth of data recovery tools on the modern shareware market. Well, maybe that's more symptomatic of the complete hollowing out of the independent software industry by the interests of capitalism, but let's try to dwell on the positive. Some SEO-spam blog post titled \"Best data recovery software of 2024\" still offers some classic software names like \"UnDeleteMyFiles Pro,\" but some items on the list are just backup tools, and options like Piriform Recuva and the open-source PhotoRec still rank prominently... as they did when I was in high school and my ongoing affection for Linkin Park was less embarrassing [1]. Back in The Day, freeware, shareware, and commercial (payware?) data recovery software proliferated. It was advertised in the back of magazines, the sidebar banner ads of websites, and even appeared in the electronics department of Fred Meyer's. You also saw a lot of advertisements for services that could perform more intensive methods, like swapping an HDD's controller for one from another unit of the same model. These are all still around today, just a whole lot less prominent. Have you ever seen an Instagram ad for UnDeleteMyFiles Pro? First, we should talk a bit about the idea of data recovery in general. There are essentially two distinct fields that we might call \"data recovery\": consumers or business users trying to recover their Important Files (say, accounting spreadsheets) from damaged or failed devices, and forensic analysts trying to recover Important Files (say, the other accounting spreadsheets) that have been deleted. There is naturally some overlap between these two ventures. Consumers sometimes accidentally delete their Important Files and want them back. Suspects sometimes intentionally damage storage devices to complicate forensics. But the two different fields use rather different techniques. Let's start by examining forensics, both to set up contrast to consumer data recovery and because I know a lot more about it. One of the quintessential techniques of file system forensics is \"file carving.\" A file carving tool examines an arbitrary sequence of bytes (say, from a disk image) and looks for the telltale signs of known file formats. For example, most common file formats have a fixed prefix of some kind. ZIP files start with 0x504B0304, the beginning of which is the ASCII \"PK\" for Phil Katz who designed the format. Some formats also have a fixed trailer, but many more have structure that can be used to infer the location of the end of the file. For example, in ZIP files the main header structure, the \"central directory,\" is actually a trailer found at the end of the file. If you can find the beginning and end of a file, and it's stored sequentially, you've now got the whole file. When the file is fragmented in the byte stream (commonly the case with disk images), the problem is a little tougher, but still you can find a lot of value. A surprising number of files are stored sequentially because they are small, some filetypes have internal structure that can be used to infer related blocks and their order, and even finding a single block of a file can be useful if it happens to contain a spreadsheet row starting \"facilitating payments to foreign officials\" or, I don't know, \"Fiat@\". You end up doing this kind of thing a lot because of a detail of file systems that all of my readers probably know. It's often articulated as something like \"when you delete a file, it's not deleted, just marked as having been deleted.\" That's not exactly wrong but it's also an oversimplification in a way that makes it more difficult to understand why that is the case. There's a whole level of indirection due to block allocation, updating the bitmap on every file delete is a relatively time-consuming process that offers little value, actually overwriting blocks would be even more time consuming with even less value, etc. Read Brian Carrier for the whole story. Actually, screw Brian Carrier, I've written before about the adjacent topic of secure erasure of computer media. My point is this: these forensic methods are performed on a fully functional storage device (or more likely an image of one), where \"recovery\" is necessary and possible because of the design of the file system. The storage device, as hardware, is not all that involved. Well, that's really an oversimplification, and points to an important consideration in modern data recovery: storage devices have gotten tremendously more complex, and that's especially true of SSDs. Even HDDs tend to have their own thoughts and feelings. They can have a great deal of internal logic dedicated to maintaining the disk surface, optimizing performance, working around physical defects on the surface, caching, encryption, etc. Pretty much all of this is proprietary to the manufacturer, undocumented, and largely a mystery to the person performing recovery. Thinking of the device as a \"sequence of bytes\" throws out a lot of what's really going on, but it's a necessary compromise. SSDs have gone even further. Flash storage is less durable than magnetic storage but also more flexible. It requires new optimizations to maximize life and facilitates optimizations for access time and speed. Some models of SSDs vary from each other only by their software configuration (this has long been suspected of some HDDs as well, but I have no particular insight into Western Digital color coding). Even worse for the forensic analyst, the TRIM command creates a whole new level of active management by the storage device: SSDs know which blocks are in use, allowing them to constantly remap blocks on the fly. It is impossible, without hardware reverse engineering techniques, to produce a true image of an SSD. You are always working with a \"view\" of the SSD mediated by its firmware. So let's compare and contrast forensic analysis to consumer data recovery. The problem for most consumers is sort of the opposite: they didn't delete the file. If they could get the sequence of bytes off the storage device, they could just access the file through the file system. The problem is that the storage device is refusing to produce bytes at all, or it's producing the wrong ones. Techniques like file carving are not entirely irrelevant to consumer data recovery because it's common for storage devices to fail only partially. There are different ways of referring to the physical geometry of HDDs, and besides, modern storage devices (HDDs and SSDs alike) abstract away their true geometry. Different file systems also use different terminology for their own internal system of mapping portions of the drive to logical objects. So while you'll find people say things like \"bad cluster\" and \"bad sector,\" I'm just going to talk about blocks. The block is the smallest elementary unit by which your file system interacts with the device. The size of a block is typically 512B for smaller devices and 4k for larger devices. A common failure mode for storage devices (although, it seems, not so much today) is the loss of a specific block: the platter is damaged, or some of the flash silicon fails, and a specific spot just won't read any more. The storage device can, and likely will, paper over this problem by moving the block to a different area in the storage medium. But, in the process, the contents of the block are probably lost. The new location just contains... whatever was there before [2]. Sometimes the bad block is in the middle of a file, and that sucks for that file. Sometimes the bad block is in the middle of a file system structure like the allocation table, and that sucks for all of the files. More complicated file systems tend to incorporate precautionary measures against this kind of thing, so the blast radius is mostly limited to single files. For example, NTFS keeps a second copy of the allocation table as a backup. Journaling can also provide a second source of allocation data when the table is damaged. Simpler file systems, like the venerable FAT, don't have any of these tricks. They are, after all, old and simple. But old age and simplicity gives FAT a \"lowest common denominator\" status that sees it widely used on removable devices. PhotoRec, while oriented towards the consumer data recovery application, is actually a file carving tool. It's no coincidence that it's called PhotoRec. Removable flash devices like SD cards have simple controllers and host simple file systems. They are, as a result, some of the most vulnerable devices to block failures that render intact files undiscoverable. What about the cases where file isn't intact, though? Where the block that has become damaged is part of the file that we want? What about cases where a damaged head leaves an HDD unable to read an entire surface? Well, the news isn't that great. Despite this being one of the most common types of consumer storage failure for a decade or more, and despite the enormous inventory of software that promises to help, your options are limited. A lot of the techniques that software packages used in these situations lack supporting research or are outright suspect. Let's start on solid ground, though, with the most obvious and probably safest option. One of the problems you quickly encounter when working with a damaged storage device is the file system and operating system. File systems don't like damaged storage devices, and operating systems don't like file systems that refuse to give up a file they say exists. So you try to copy files off of the bad device and onto a good one using your daily-driver file browser, and it hits a block that won't read and gets stuck. Maybe it hangs almost indefinitely, maybe you get an obscure error and the copy operation stops. Your software is working against you. One of the best options for data recovery from suspect devices is an open-source tool called ddrescue. ddrescue is very simple and substantially similar to dd. It has one critical trick up its sleeve: when reading a block fails, ddrescue retries a limited number of times and then moves on. With that little adaptation, you can recover all of the working blocks from a device and so likely recover all of the files but a few. Besides, just retrying a few times has value. Especially on magnetic devices, the result of reading the surface can be influenced by small perturbances. An unreadable sector might be readable every once in a while. This doesn't seem to happen as much with SSDs due to the dynamics of flash storage and preemptive correction of weak or ambiguous values, but I'm sure it still happens every once in a while. At the end of the day, though, this method still means accepting the loss of some data. Losing some data is better than losing all of it, but it might not be good enough. Isn't there anything we can do? HDDs used to be different. For one, they used to be bigger. But there's more to it than that. Older hard drives used stepper motors to position the head stack, and so head positioning was absolute but subject to some mechanical error. Although this was rarely the case on the consumer market, early hard drives were sometimes sold entirely uninitialized, without the timing marks the controller used to determine sector positions. You had to use a special tool to get the drive to write them [3]. It was common for older drives to come with a report (often printed on the label) of known bad sectors to be kept in mind when formatting. We now live in a different era. Head stacks are positioned by a magnetic coil based on servo feedback from the read head; mechanical error is virtually absent and positioning is no longer absolute but relative to the cylinder being read. Extensive low-level formatting is required but is handled completely internally by the controller. Controllers passively detect bad blocks and reallocate around them. Honestly, there's just not a lot you can do. There are too many levels of abstraction between even the ATA interface and the actual storage to do anything meaningful at the level of the magnetic surface. And all of this was pretty much true in the late '00s, even before SSDs took over. So what about SpinRite? SpinRite dates back to 1987 and is apparently still under development by its creator Steve Gibson. Gibson is an interesting figure, one of the \"Tech Personalities\" that contemporary media no longer creates (insert comment about decay in the interest of capitalism here). Think Robert Cringely or Leo Laporte, with whom Gibson happens to cohost a podcast. In my mind, Gibson is perhaps most notable for his work as an early security researcher, which had its misses but also had its hits. Through the whole thing he's run Gibson Research Corporation. GRC offers a variety of one-off web services, like a password generator (generated, erm, server-side) and something that displays the TLS fingerprint of a website you enter. There's a user-triggered port scanner called ShieldsUp, which might be interesting were it not for the fact that its port list seems limited to the Windows RPC mapper and some items of that type... things that were major concerns in the early '00s but rarely a practical problem today. It's full of some gems. Consider the password generator... What makes these perfect and safe? Every one is completely random (maximum entropy) without any pattern, and the cryptographically-strong pseudo random number generator we use guarantees that no similar strings will ever be produced again. Also, because this page will only allow itself to be displayed over a snoop-proof and proxy-proof high-security SSL connection, and it is marked as having expired back in 1999, this page which was custom generated just now for you will not be cached or visible to anyone else. ... The \"Techie Details\" section at the end describes exactly how these super-strong maximum-entropy passwords are generated (to satisfy the uber-geek inside you). You know I'm reading the Techie Details. They describe a straightforward approach using AES in CBC mode, fed by a counter and its own output. It's unremarkable except that just about any modern security professional would have paroxysms at the fact that he seems to have implemented it himself. Sure, there are better methods (like AES CTR), but this is the kind of thing where you shouldn't even really be using methods. \"I read it from /dev/urandom\" is a far more reassuring explanation than a block diagram of cryptographic primitives. /dev/urandom is a well-audited implementation, whatever is behind your block diagram is not. Besides, it's server side! My point is not so much to criticize Gibson's technical expertise, although I certainly think you could, but to say that he doesn't seem to have updated his website in some time. A lot of little details like references to WEP and the fact that the PDFs are Corel Ventura output support this theory. By association, I suspect that GRC's flagship product, SpinRite, doesn't get a lot of active maintenance either. Even back around 2007 when I first encountered SpinRite it was already a little questionable, and I remember a rough internet consensus of \"it likely doesn't do anything but it probably doesn't hurt to try.\" A little research finds that \"is SpinRite snake oil?\" threads date back to the Usenet era. It doesn't help that Steve Gibson's writing is pervaded by a certain sort of... hucksterism. A sort of ceaseless self-promotion that internet users associate mostly with travel influencers selling courses about how to make money as a travel influencer. But what does SpinRite even claim? After a charming disclaimer that GRC is opposed to software patents but nonetheless involved in \"extensive ongoing patent acquisition\" related to SpinRite, a document titled \"SpinRite: What's Under the Hood\" gives some details. It's undated but has metadata pointing at 1998. That's rather vintage I see several reasons to think that there have been few or no functional changes in SpinRite since that time. SpinRite is a bootable tool based on FreeDOS. It originated as an interleaving tool, which I won't really explain because it's quite irrelevant to modern storage devices and really just a historic detail of SpinRite. It also \"introduc[ed] the concept of non-destructive low-level reformatting,\" which I won't really explain because I don't know what it means, other than it seems to fall into the broad category of no one really knowing what \"low level formatting\" means. It's a particularly amusing example, because most modern software vendors use \"low level formatting\" to refer explicitly to a destructive process. SpinRite \"completely bypasses the system's motherboard BIOS software when used on any standard hard disk system.\" I assume this means that SpinRite directly issues ATA commands, which probably has some advantages, although the specific ones the document calls out seem specious. In reference to SpinRite's data recovery features, we read that \"The DynaStat system's statistical analysis capability frequently determines a sector's correct data even when the data could never be read correctly from the mass storage medium.\" This is what I remember as the key claim of SpinRite marketing over a decade ago: that SpinRite would attempt rereading a block a very large number of times and then determine on a bit-by-bit basis what the most likely value is. It seems reasonable on the surface, but it wouldn't make much sense with a drive with internal error correction. That's universal today but I'm not sure how long that's been true, presumably in the late '90s this was a better idea. That's probably the high point of this document's credibility. Everything from there gets more suspect. It claims that SpinRite has a proprietary system that models the internal line coding used by \"every existing proprietary\" hard drive, an unlikely claim in 1998 and an impossible one today without a massive reverse engineering effort. Consider also \"its second recovery strategy of deliberately wiggling the drive's heads.\" It seems to achieve this by issuing reads to cylinders on either side of the cylinder in question, but it's questionable if that would even work in principle on a modern drive. You must then consider the use of servo positioning on modern drives, which means that the head will likely oscillate around the target cylinder before settling on it anyway. This gives the flavor of the central problem with SpinRite: it claims to perform sophisticated analysis at a very low level of the drive's operation, but it claims to do that with hard drives that intentionally abstract away all of their low level details. A lot of the document reads, to modern eyes, like pure flimflam, written by someone who knew enough about HDDs to sound technical but not enough to really understand the implications of what they were saying. The thing is, though, this document is from '98 and the software was already a decade old at the time! The document does note that SpinRite 3.0 was a complete rewrite, but I suspect it was the last complete rewrite and probably carried a lot of its functionality over from the first two versions. I think that SpinRite probably does implement the functionality that it claims and that those features might have been of some value in the late '80s and much of the '90s. Then technology moved on and SpinRite became irrelevant. Probably the only thing that SpinRite does of any value on a modern drive is just rewriting the entire addressable area, which gives the controller an opportunity to detect bad blocks and remap them. That should also happen in the course of normal operation, though, and even tools dedicated to that purpose (like the open-source badblocks) are becoming rather questionable in comparison to the preemptive capabilities of modern HDDs. This type of bad-block-detecting rewrite pass is probably only useful in pathological cases on older devices, but it's also the only real claim of the vast majority of modern \"hard drive repair\" software. It seems a little mean-spirited to go after GRC for their old software, but they continue to promote it at a cost of $89. The FAQ tells us that \"SpinRite is every bit as necessary today as it ever was â€” maybe even more so since people store so much valuable personal 'media' data on today's massive drives.\" I resent the implication of the scare-quoted \"media,\" Mr. Gibson, but what I do with my hard drives in my own home is none of your business. The FAQ tells us \"SpinRite is often credited with performing \"true miracles\" of data recovery,\" but is oddly silent on the topic of SSDs. Some dedicated Wikipedia editor rounded up a number of occasions on which Gibson said that SpinRite was of limited or no use with SSDs, and yet the GRC website currently includes the heading \"Amazingly effective for SSDs!\" There is no technical explanation offered for how SpinRite's exceptionally platter-centric features affect an SSD, nor mention of any new functionality targeting flash storage. Instead, there's just anecdotal claims that SpinRite made SSDs faster and a suggestion that the reader google a well-known behavior of flash storage for which SSD controllers have considerable mitigations. It is an odd detail of the GRC website that most of the new information about the product is provided in the form of video. Specifically, videos excerpted from recent episodes of Gibson and Laporte's podcast \"Security Now.\" Security Now is weekly, so I don't think that SpinRite promotional material makes up a large portion of it, but it does seem conspicuous that Gibson uses the podcast as a platform for 15 minute stories about how SpinRite worked miracles. These segments, and their mentions of how SpinRite is a very powerful tool that one shouldn't run on SSDs too often, absolutely reek of the promotional techniques behind Orgone accumulators, Hulda Clark's \"Zapper,\" and color therapy. It is, it seems, quack medicine for the hard drive. I don't think SpinRite started as a scam, but I sure think it ended as one. A lot of this was already apparent back in the late '00s, and I can't honestly say that bootleg copies of SpinRite every improved anything for me. So why did I love it so much? The animations! SpinRite's TUI was truly a work of art. Just watch it go!. [1] I recently bought the 20th anniversary vinyl box set of Meteora, which emphasizes that (1) 20 years have passed and (2) I am still a loser. [2] This kind of visible failure seems uncommon with SSDs, likely because SSD controllers tend to read out the flash in a critical, suspicious way and take preemptive action when the physical state is less than perfectly clear cut. In a common type of engineering irony, the fact that flash storage is less reliable than magnetic media requires aggressive management of the problem that makes the overall system more reliable. Or at least that's what I tell myself when another SSD has gone completely unresponsive. [3] Honestly this doesn't seem to have been typical with any hard drives by the microcomputer era, which makes perfect sense if you consider that these hard drives were sold with bad sector lists and therefore must have been factory tested. The whole \"low level formatting\" thing has been 70% a scam and 30% confusion with the very different technical tradition of magnetic diskettes, since probably 1990 at least.",
    "commentLink": "https://news.ycombinator.com/item?id=40478976",
    "commentBody": "GRC SpinRite (computer.rip)109 points by todsacerdoti 18 hours agohidepastfavorite103 comments pxx 32 minutes agoThis whole \"discussion\" indicates only one real thing: people who have been scammed by a sales tactic will most likely double down on their past poor decisions instead of reevaluating the facts, as they are now emotionally invested in their past decisions. reply jccalhoun 3 hours agoprevThe article states, \"By association, I suspect that GRC's flagship product, SpinRite, doesn't get a lot of active maintenance either.\" However, Gibson released 6.1 a month or so ago https://www.grc.com/sr/spinrite.htm reply torgoguys 2 hours agoparentYes, he did. However, that was the first release in close to 20 years. reply starttoaster 2 hours agorootparentIf you listen to the Security Now podcast, Steve Gibson often says it hasn't seen an update because it hasn't needed an update. I'd imagine there's at least some truth to that. Drives change all the time, but does hard drive interface technology change all that much? reply torgoguys 34 minutes agorootparentYes, he SAYS that but it's not true which is part of what irks people. It has needed an update for a long time. He or Leo on the podcast have long said or implied 6.0 is more or less \"bug free.\" But for example, read spinrite forums about unrecoverable division overflow errors, divide by zero errors that pop up with a red background. \"Try updating your bios\" or \"try it in another computer\" is the typical advice given, not a fix. And I think there is a drive size limit that has long been an issue. reply HankB99 56 minutes agorootparentprevYears ago I bought Spinrite. Past the 30 day return policy I was disappointed to learn that it was limited to 2TB HDDs. At that time most of my HDDs were larger. I asked about an upgrade and was told \"Real Soon Now.\" Years ago. I asked for a refund and was told (paraphrasing) \"you took too long to determine that Spinrite doesn't meet your needs.\" Back in the day before integrated drive electronics, Spinrite was very useful for adjusting the sector interleave to improve disk performance. With drive electronics and management firmware improvements, Spinrite was useless. > Steve Gibson often says it hasn't seen an update because it hasn't needed an update. That's the worst kind of gaslighting. reply downrightmike 21 minutes agorootparentprev~~~~~There weren't any bugs~~~~~~~ reply nuancebydefault 2 hours agoprevI remember more than 20 years ago, there used to be a website grc.com as well as grcsucks.com, a site that was very much criticising the former. Grc contained, next to a link to hdd recovery software, a section titled 'shields up' that you could use to do a port scan on your own IP address with some advice by Gibson and some 'rants' about Microsoft supporting raw sockets, even though he warned them that it was a very bad idea. The whole Gibson franchise felt snake oilish back then, for a big part because it sounded snobbish, very 'listen to me the smart guy!'. But still I have no idea whether or not it was legit info...? reply mindslight 19 minutes agoparentMy recollection of his networking utilities is similar. The raw sockets thing was obvious nonsense and demonstrated a fundamental inability to understand security (software/capabilities of remote parties are completely independent from your local environment - removing a feature from Windows that can facilitate attacks would not affect Windows's defensive vulnerabilities!). You'd meet plenty of types of these people in the 90's/00's, possessing security \"certifications\" but no actual mental model of how anything worked. I once had to suffer a university head of IT who was scared of individuals running Linux connected to the campus network because \"there was no company to sue\". Gibson's whole schtick felt like a snake oil salesman that got a cult following of a bunch of Windows noobs that found his simple utilities useful (perhaps SpinRite was one of these) and then extrapolated from that into believing the vacuous technobabble marketing. In the circles I ran in, \"Gibson\" and \"Shields Up!\" were more punchlines for jokes than anything else. The concurrent \"Hack the Gibson\" meme didn't help that either. I've thoroughly enjoyed posts on this blog. Based on the title I was actually worried that this post was going to be talking about GRC uncritically, and was greatly relieved when it did not. reply sillywalk 2 hours agoparentprevI remember GRC for DCOMbobulator, that disabled DCOM. reply grymoire1 5 hours agoprevWhile Gibson is overly pompous, I should point out that SpinRite works below the file system structure, and not all filesystems are robust like ZFS, etc. Second - there are two main SpinRite modes - Read/Check and Read/Write/Correct. SSD's should obviously never use the second mode. I suppose the first mode might be used to check if there are problems on a SSD. SpinRite - last time I used it, was painfully slow - like days or even weeks to run. He's been working on a faster SpinRite 6.1 for at least 10 years now. FWIW, here's the current (2021) roadmap - https://www.grc.com/miscfiles/GRC-Development-Roadmap.pdf reply epcoa 58 minutes agoparentWhat does Spinrite actually do that is materially different than ddrescue? And the idea of repairing a failing disk and not just making an image is usually insane. > I should point out that SpinRite works below the file system structure This is not the flex that you seem to think it is. reply pessimizer 10 minutes agorootparent> What does Spinrite actually do that is materially different than ddrescue? Pretty sure Spinrite repairs/recovers, as you imply in your very next sentence (which I agree with, it's not a good idea to play with the filesystem of a failing disk.) I've never used it, though, so I may be wrong. The real question for me is why would somebody pay for it over using ddrescue to get an image, and TestDisk/PhotoRec to do the filesystem recovery (on the image)? They're free and very good. https://en.wikipedia.org/wiki/Ddrescue https://en.wikipedia.org/wiki/TestDisk reply stavros 2 hours agoparentprevSpinRite 6.1 is out: https://www.grc.com/sr/spinrite.htm reply userbinator 15 hours agoprevI haven't RE'd SpinRite myself, but I remember reading from some others who did and concluded that it was basically very similar to ddrescue's algorithm, but with some additional use of \"read uncorrected\" commands and statistical analysis. The latter is implemented by other DR software too: https://www.deepspar.com/blog/Read-Ignoring-ECC.html reply MarkSweep 13 hours agoprevWhile I understand some of the vibes the author picks up (can one guy who writes all his programs in assembler really have the answers to hard drive maintenance and recovery?), the article does not seem to go much beyond this vibe and speculation based reasoning. It would be more convincing if there were experiments testing the claimed benefits of using SpinRite, specifically around performance improvements caused by running a scan. Personally I think the claimed data recovery capabilities of SpinRite are less relevant these days due to file systems like ZFS that have scrubbing and data recovery built in. Distributed block and blob storage systems that clouds are built on have similar systems as well. I'd like to recommend Security Now, the podcast the the author of SpinRite, Steve Gibson, hosts. While at times Steve has a non-consensus take on things (other commenters have noted his preference for out-of-support versions of Windows), he is pretty good at explaining the technical details about the topics he covers. It's a good way to keep up with security news. Probably only the Security, Cryptography, Whatever podcast is better (more in-depth discussions of low level topics with experts), but it less consistently published. reply KennyBlanken 10 hours agoparentWhen someone makes extraordinary claims, it is their responsibility to prove those claims, not for others to disprove them. Further: there are numerous people who worked in the hard drive industry who say he's spouting bullshit with Spinrite. ZFS scrubbing is designed to counter issues that crop up with bit flips caused by extremely unlikely hardware errors and things like cosmic rays - which are extremely rare, but when you have petabyte scale storage, they actually become plausible risks. It has nothing to do with \"refreshing\" the data on-disk like Gibson claims, and it is only possible because it uses two layers of checksums to detect such bit-flips, comparing the file's checksum with the parity data used in the stripe (or the mirror.) That checksumming is integral to the filesystem. Spinrite doesn't have any similar function. It couldn't possibly \"correct\" data on a drive. The fact that you don't understand the difference between what amounts to a very dressed-up bad-block scan and ZFS scrubbing shows how under-qualified you are to be forming opinions on these subjects. Which is odd given you often listen to his podcast - how curious that you're not an expert /s reply zbentley 3 hours agorootparentCould you edit your comment and remove the last paragraph? Itâ€™s interesting info until you veer into personal insults, which doesnâ€™t help you inform others. reply asveikau 2 hours agorootparentprev> ZFS scrubbing is designed to counter issues that crop up with bit flips caused by extremely unlikely hardware errors and things like cosmic rays - which are extremely rare, but when you have petabyte scale storage, they actually become plausible risks. It's not rare at all and you don't need petabytes to hit it in your home. I also doubt it's caused by cosmic rays. People seem to have this view that hardware is rock solid all the time. It isn't. Components fail. reply toast0 2 hours agorootparentprev> ZFS scrubbing is designed to counter issues that crop up with bit flips caused by extremely unlikely hardware errors and things like cosmic rays - which are extremely rare, but when you have petabyte scale storage, they actually become plausible risks. Scrubbing has multiple purposes. Sure cosmic rays, but it also helps detect poor cabling (if somehow that didn't throw checksum errors in regular use), wild writes and degrading media. Reading every sector with filesystem data is similar to a function of SpinRite that seems to read all sectors. Of course, SpinRite won't know if a good read holds bad data. But ZFS scrub doesn't read all sectors. According to claims, it sounds like SpinRite could issue uncorrected reads to a weak sector multiple times, run statistics and guess at the right value and write it back? That seems possibly useful, especially if the drive is likely to reallocate the sector when it's written to. Issuing writes to all sectors of a spinning disk can help the drive firmware with reallocating problematic sectors, although there's free tools to do that. reply MarkSweep 4 hours agorootparentprev> The fact that you don't understand the difference between what amounts to a very dressed-up bad-block scan and ZFS scrubbing shows how under-qualified you are to be forming opinions on these subjects. I thought I was pretty clear that I thought SpinRite was no longer relevant because of better file systems being available. Perhaps I should have elaborated in my comment that specifically the checksumming and redundancy provided by ZFS (and other filesystems) are what makes it scrubbing able to recover corrupted data. Data corruption that obviously SpinRite would be blind to. reply ThePowerOfFuet 1 hour agorootparentprev>Which is odd given you often listen to his podcast - how curious that you're not an expert /s Be nice. reply MarkusWandel 7 hours agoprevIsn't part of the reason modern hard disks seem more reliable, that they have much more sophisticated file systems on them? In the old days, merely turning a machine off at the wrong moment might introduce inconsistencies that could cause data corruption later. Or on Lin*x, when's the last time you've had to look for the wreckage of files in the lost+found directory? Does anyone even remember what it's for? I've had even modern HDs go gradually bad and the remaining undamaged files are generally readable without trouble. reply Majromax 4 hours agoparent> Or on Lin*x, when's the last time you've had to look for the wreckage of files in the lost+found directory? Does anyone even remember what it's for? Files that still existed by reference to an orphaned inode, one that was not linked to from a directory entry. The need for it greatly diminished with the widespread implementation of journaling filesystems. reply ValentineC 16 hours agoprevMany years ago, I made the mistake of using SpinRite once to try and recover a hard disk failing with bad sectors. It was only through the process that I realised that instead of letting the hard disk run and get worse, I should have instead tried to image off all the data ASAP with ddrescue. That was a very dear lesson in data loss. reply Springtime 2 hours agoparent> I should have instead tried to image off all the data ASAP with ddrescue. It's interesting since for those familiar with the claims of SpinRite and how 'it'll keep working as long as it takes to read a bad sector' (a key part of its promotion) ddrescue can do the same thing (and resume where it left off) but unlike SpinRite it's simultaneously making an image of the drive as it does so. reply BrianGragg 14 hours agoparentprevIt usually gives you a very large warning that a drive is about to physically fail and advises you to try and backup the data if you haven't already. reply pessimizer 0 minutes agorootparentBut if you already knew the drive was damaged, why push it to the point when you can't possibly have the time to image it, which will take forever? Feels like advising somebody to push through their asthma until they're about to lose consciousness. reply aappleby 15 hours agoprevThe original SpinRite was a lifesaver back in the days of 100 meg magnetic disks, I paid for a copy and used it to resurrect both my own and my friends' hard drives a few times. It was indeed able to (usually) recover bad sectors that the OS refused to fix. reply LVB 12 hours agoprevI get the huckster vibe he described as that was my impression long ago when Iâ€™d see it advertised all over, hear Steve speak, etc. I did in fact buy Spinrite once when my HDD was pretty well screwed. It didnâ€™t improve things, but credit where due: GRC did immediately honor the money back guarantee. reply KennyBlanken 10 hours agoparentIt's easy to have a money back guarantee on your expensive miracle cure-all oil if it's just canola oil. reply jszymborski 5 hours agoprevI will always be nostalgic about Steve Gibson and Leo Laport on Screen Savers airing on G4. I loved the GRC website as a kid, but was not surprised many years ago when I learned that Gibson sometimes spoke from a place of authority where he was a bit out of his depth. The way he has spoken about Vitamin D cones to mind. reply pcdoodle 4 hours agoparentThat was in 2015, he might have been ahead of the curve on that one. reply jszymborski 2 hours agorootparentThe metadata from this page [0] is from 2009 and makes some, uh, interesting assertions about how Big Pharma is why folks don't \"know\" about Vitamin D. [0] https://www.grc.com/health/vitamin-d.htm reply asveikau 1 minute agorootparentIt's kind of hilarious that he's also distributing that in bin/cue with the expectation that some people will burn it to an audio CD. Flac would serve the need for raw PCM quality just fine, though I don't think we generally need that for podcasts. reply stavros 1 hour agorootparentprevWell, the assertion is just \"pharma companies don't research it because there's no money in it, because it can't be patented\", which makes sense. reply jszymborski 22 minutes agorootparentAccording to this page, there is plenty of research to show that Vitamin D is a cure-all that folks just don't know about: > We see expensive commercials every night during prime time for expensive and patented pharmaceuticals ... but we never see any similar advertisements mentioning that study after study has shown that simply (and inexpensively) maintaining sufficient levels of Vitamin D can work to prevent rickets (that's well known) but also 17 types of cancer ... lower blood pressure, improve immune system function (prevents colds and flu), autoimmune function, inflammation, multiple sclerosis, autism, allergies, preeclampsia, both type 1 and type 2 diabetes, osteoporosis (also well known) depression, muscle and bone weakness and generalized pain. The natural supplement industry is a multi-billion dollar industry, and has been for a long while. If Vitamin D was the panacea that Mr. Gibson is representing it to be here, I'm sure that GMC would be running ads about treating \"autism and cancer\" with Vitamin D non-stop. Further, if Vitamin D did all of the above, I can assure you that pharmas would be researching the mechanism of action to create effective derivatives. If a treatment is effective and it isn't a super rare disease, you'll find a pharma somewhere selling it somehow. reply asveikau 2 hours agoprevI've found ddrescue does a good job recovering data from bad media by doing strategic retries. But mostly ... I don't have need of a utility like this since I started using zfs. I don't think less demand for this type of tool means hard drives are better now. I think in today's world of periodically trashing broken devices rather than attempting repair, most normies just ignore this problem space. They might put something really important on an online service, other than that they accept data loss when shit breaks, and get a whole new laptop or whatever. reply beefnugs 4 hours agoprevThere is something strange to what the article says about modern drives dying hard and fast now. They used to just slow down a whole bunch and you knew you had time to grab info off them. (i assume the seal just broke eventually and they lost the special inert gas in there?) But now they just die sudden, which i feel is worse. I think i have seen USB drives that die in a fashion where they become read-only which seems like a half decent idea reply r1ch 4 hours agoparentModern SSD drives typically die to controller failure, e.g. unclean power offs corrupting internal state that crashes the firmware, internal counters overflowing after time, memory errors on the internal DRAM, etc. All from to the complexity of needing the FTL to pretend it's a regular disk to the OS. reply bigB 16 hours agoprevIm guessing the author of this has somewhat of an issue with Steve Gibson and GRC, and has obviously spent some time mulling over how to write a very wordy and seemingly in-depth bashing of the their Spinrite software. However if you like myself have seen it work, and actually take a previously unusable hard drive to a usable state to allow a successful recovery of data, or in recent times, take an SSD with poor performing read and write speeds to a significant improvement after running Spinrite on the drive, you will be able to skip much of the diatribe in this post and actually see that it more of a character assassination on GRC and Gibson himself. Is the software 100% guaranteed to work, nope and I probably wouldn't recommend it for critical enterprise data recovery if you have the budget to spend on commercial recovery services, but as a low price maintenance tool it works well for many. The Author of this posts seems pretty knowledgeable, and probably has alot of offer, which is why its a pity his ego and spiteful nature seeps into his writing. reply johnkizer 15 hours agoparentThis article didn't read like character assassination to me, personally - most of the time spent on GRC/SpinRite (after the overall topic of disk recovery is introduced) seems to be either observations about Gibson's style with which I think many would agree - e.g. \"It doesn't help that Steve Gibson's writing is pervaded by a certain sort of... hucksterism. A sort of ceaseless self-promotion that internet users associate mostly with travel influencers selling courses about how to make money as a travel influencer.\" Or substantive critical points about the software, e.g.: \"This gives the flavor of the central problem with SpinRite: it claims to perform sophisticated analysis at a very low level of the drive's operation, but it claims to do that with hard drives that intentionally abstract away all of their low level details.\" And I think it's fair to ask someone who is selling a piece of software for $89 to provide some backing for their claims beyond ones that would only pertain to largely-obsolete hardware. reply at_a_remove 13 hours agorootparentI think you are dead on. I recall -- perhaps incorrectly -- that Gibson has been just silly amounts of incorrect on some things, but SpinRite itself, I've never heard anything but \"... and then everything worked like a minor miracle.\" And you're correct, Gibson has a certain, uh, Wolfram-y habit of selling himself whenever possible, which doesn't help matters, but I hope people can manage to separate the personality from the product. reply Gormo 13 hours agorootparent> Wolfram-y Wolfram has already gone from alpha all the way to upsilon? reply pdonis 13 hours agoparentprevIf you want an even less flattering portrayal of Steve Gibson, try this: https://radsoft.net/news/roundups/grc/ Previously discussed here: https://news.ycombinator.com/item?id=3890168 reply Dylan16807 14 hours agoparentprevDid you try anything else on those drives first? Just reading or reading then writing an entire drive could do a lot to smooth out flaky sectors. reply wmf 16 hours agoparentprevHas Gibson ever explained how SpinRite works? Many people won't believe in magic even if it works. reply paulryanrogers 16 hours agorootparentListen to the \"Security Now\" podcast. He explains how SpinRite works every 3rd or 4th episode, with testimonials on every show. He seems open minded and mostly harmless, both in his tool (which I find works better than free alternatives), and in his armchair security analysis. Sometimes though he oddly contradicts his own best practices, like nearly blind faith in LastPass for years based on (IIRC) a white paper and the early execs being very chummy and accessible. Thankfully the audience calls out the questionable stuff. reply 8372049 10 hours agorootparentIf you think of Steve Gibson as more of a technical minded journalist and less of a \"security expert\", then the show is very enjoyable. There's a lot less grave errors now than there used to be, his voice is pleasant and he usually covers relevant and interesting news. reply naikrovek 15 hours agorootparentprevThe podcast is called â€œSecurity Nowâ€ but what it should be called is â€œprivacy nowâ€ because Mr. Gibson fails to understand a lot of contemporary security problems yet is quite sure that Windows collecting telemetry is the most severe problem on the planet today. unless you use his software to fix it, that is. Every episode having a 15-minute commercial for spinrite (via testimonials which all sound like they were written by the exact same person) should be more than enough for anyone to start to question the guy. reply TeeMassive 15 hours agorootparentI didn't listen to that show for a while now; but it seemed that it was the only show out there that explained in details computer security news. I remember him explaining the speculative execution exploits when they first appeared really well when they first appeared. Does the people I know who works on blue and red teams listen to him? No, they already know that stuff, and yeah he could be more up to date, but he does his researc, does his homework and is a great pedagogue. reply pcdoodle 4 hours agorootparentHe has had some very fun episodes over the years. Blue pill back in the Vista days blew my mind. Another episode: \"Blue Keep\", had me calling everyone I knew in charge of Windows Domains, with many thanks coming back my way because it was a pretty big deal to get patched on unsupported systems. I highly recommend the weekly podcast. reply naikrovek 14 hours agorootparentprev> he does his research, does his homework Is that why he ran Windows XP unpatched as his primary computer because â€œitâ€™s fine, this is all I need; I have a firewall, nothing can get in.â€ That is not the behavior of a security expert. If you donâ€™t know why that is bad, you do not understand entire classes of attack, today. reply Gormo 13 hours agorootparentIf he has implemented mitigations for all of the applicable risks of the software he's using, how is that \"not the behavior of a security expert\". To my mind, a security expert is someone who understands the functional details of specific vulnerabilities, and explains how to mitigate them, not someone who makes vague, cargo-culty judgments about entire applications or OSes. reply paulryanrogers 6 hours agorootparentHe was browsing the web, that's pretty high risk. And sticking to reputable sites isn't enough when their ads could contain malware. While it sounds like he doesn't use XP anymore, (IIRC) he was using it for the Internet well beyond its EOL. He also admitted to having trouble getting his dev environment working on newer OS's. My guess is he was rationalizing the choice to stick with XP to avoid the friction of upgrading development tools. Which is odd since he's not afraid to delay things for years and ultimately has upgraded his environments anyway. reply userbinator 14 hours agorootparentprevThat is the behaviour of a security expert who isn't afraid to challenge the dogma perpetuated by Big Tech. reply LeoNatan25 1 hour agorootparentTo all the downvoters, this is sarcasm. reply bigB 15 hours agorootparentprevThere is in depth information on its workings, on the website itself, in the newsgroups and in the podcast. If the author of the article were to look it would remove any \"magic\" of its workings. The author apparently has an axe to grind, for whatever reason , having said that , it may be for a very good reason but for transparency sake this should be included in the article. Instead its just a weird ramble about what he thinks of other tools and that he thinks Spinrite is a \"scam\" without technically explaining why, boiling it down to essentially a technically worded opinion piece. reply johnkizer 14 hours agorootparentThe in-depth information on the website appears to be this link: https://www.grc.com/files/technote.pdf Which, while not directly dated in the content of the document, references a \"screaming Pentium II 333 MHz\", which would theoretically put it ~1998. Is the claim that operating at a \"low level\" on hard drives in 1998 is the same as in 2024? reply jjeaff 12 hours agorootparentthe simplest explanation for what spinrite does that I have heard is that on spinning rust drives, it simply tries to access the same bad data over and over until it finally (sometimes) gets a result. which makes sense that it would work (sometimes) because hard drives that are going bad tend to do so intermittently. reply Hakkin 11 hours agorootparentThis is more or less also what (GNU) ddrescue does[0]. It first tries to do a linear copy of the full disk, skipping any errors, then goes back and tries to re-read the error sectors until you either cancel or it succeeds. It also keeps track of everything it's doing so you can stop and start the process without it redoing work. [0]https://www.gnu.org/software/ddrescue/manual/ddrescue_manual... reply KennyBlanken 10 hours agoparentprevMy issue with Steve Gibson is that he spews technobabble, exploiting the delta between \"stuff people who work at drive manufacturers know\" and \"stuff computer users, even highly educated ones, know about how hard drives work\", in order to sell what basically amounts to a commercial version of badblocks with a bunch of fancy graphical animations. Spinrite kinda worked back in the days of MFM drives where they had to be low-level formatted with sector track information the controller then uses to figure out where the head is on the drive, and that sector information is refreshed during writes. But it was still quasi-snake oil, using a lot of mumbojumbo to say \"I just note the original value of a sector, write it a zillion times, and then move to the next. This causes the MFM controller to refresh the sector tracks.\" Yes, those drives did benefit from low-level formats done in the condition the drive would be operated in - with that particular controller, at that temperature range. He claimed that spinrite could detect not just whether a particular bit was a 0 or 1, but get the analog value directly from the drive by \"bypassing\" the BIOS to talk to the controller directly. And Spinrite used to have an ASCII \"graph showing these supposed values. Post MFM - IDE, SCSI, SATA, FC, etc - controllers are built-in to the drive, and low level formatting was handled by the drive's controller itself. The drive is sent a low-level format command. Gibson might have still had some claim to legitimacy left there. But then...drives shifted to using servo tracks written at the factory. The drive itself is physically incapable of doing anything to those servo tracks, and if you degauss the drive, you permanently destroy the drive because the servo tracks are wiped. The drive certainly doesn't expose via its IDE/SATA/SCSI interface any of the super-duper-low-level stuff he continued to claim to be accessing. He kept spewing the same nonsense...that his utility would boost the strength of the analog 'signal' on the drive by writing it a whole bunch. People who worked at drive manufacturers tried to work with Gibson because they were under the impression that he simply hadn't kept up with changes in hard drive technology, when the reality was (probably) that his product was snake oil and he knew it, or he was deluding himself. Example: https://radsoft.net/news/roundups/grc/20060123,00.shtml Any value Spinrite has is achieved via simply trying to read the same data over and over. If there's a failing block, the drive will remap it, and boom, your not-quite-fully-failed drive is \"working\" again. Huzzah! Except...you can do the exact same thing by simply running badblocks - free and open source - or if you're trying to recover data, use ddrescue or one of its variants, also all open source. It's basically a \"dd\" that doesn't give up - hoping that the drive might successfully read a particular area if you try enough. The better variants use a binary search to try and get every possible sector. I've used it, and it works well - I've had drives where I was able to get everything except well less than 1MB worth of data, if you gave it enough time to run. These days he's even claiming that Spinrite can improve SSD performance by repeatedly reading/writing data, which is absurd. All that is happening is Spinrite is a)wearing out the flash and b)maybe influencing what drive sectors are migrated to the SSD's SLC cache (most drives use an area of flash configured as SLC as a cache for reads/writes because it's significantly faster and more wear tolerant than areas configured as MLC, TLD, or QLC.) As a flash cell's electrical charge is reduced with each read, flash controllers automatically refresh a flash cell when necessary when a sector is read. reply ikiris 1 hour agorootparentThank you for being the voice of reason in this... mess of a thread reply jkhanlar 12 hours agoparentprev\"I feel\" are the first two words, therefore it is opinion article, the kind of opinion that does not stick to the facts, and rewards opinionated hivemind consent manufacturing. I stopped reading after those two words cuz it's dangerous signaling of ideologies in my nonfactual nonobjective opinion. reply fragmede 10 hours agorootparentI feel that jkhanlar's still going to read the rest of this comment where I call that behavior short sighted and stupid even though they said they wouldn't, because I also started my comment with \"I feel\". But the problem is, not only did they stop reading there, but they felt it necessary to inform the rest of us about it. Which only makes them look even more like an idiot. Thankfully, by applying their own logic to their post, and halting reading of their comment after the first two words, which are also \"I feel\", we can save ourselves the trouble. Unfortunately, we don't know to stop there unless we've read the comment, so we're stuck in a paradox. reply 8372049 10 hours agorootparentprevFor reference, the rest of the sentence is: [I feel] like I used to spend an inordinate amount of time dealing with suspect hard drives. reply TeeMassive 15 hours agoparentprevThis is what I was about to say. I've used it some drives and it worked 4 out of 5 times for drives that I had given up all hopes for. These hit piece articles are all the same: very well contrived phrases that stops short of making definitive statements and overly rely on the reader making assumptions as a mean to avoid libel lawsuits. reply sirtaj 10 hours agoprevI remember running Spinrite regularly on my 286 as a kid in the early 90s like some sort of maintenance ritual, watching the magical blob pulsing like it was doing something deeply important. Meanwhile, each time it ran it would either 1) test a sector that had been marked bad and then unmark it as ok, or 2) test the same sector and mark it bad again. The idea that that same app is doing something useful 30+ years later strains credulity. reply downrightmike 18 minutes agoparentThe way drives work, hasn't really changed at the low level, they've just been crammed with space. reply Modified3019 14 hours agoprevFYI, if your SSD suddenly stops showing up (especially after a power off event), then the first thing to try is power cycling it: https://dfarq.homeip.net/fix-dead-ssd/ reply userbinator 10 hours agoparentThat's basically \"let the firmware try to sort itself out\", which might work if there was temporary corruption in the FTL metadata and it knows enough to try to recover that by doing some sort of block-scanning, but if there's further damage beyond that, it won't have any effect. Still worth a try, however. reply wnevets 2 hours agoprevIt has saved a many of hard drives for me over the years. The new release is also making my SSDs faster reply nelsonic 5 hours agoprevTo all the sceptics: been using SpinRite since 2007 on many HHDs and it has saved us _many_ times. Steve Gibson knows hard drives and their recovery better than anyone. Highly recommend it if you need to recover a drive. reply epcoa 49 minutes agoparent> Steve Gibson knows hard drives and their recovery better than anyone No he doesnâ€™t. Heâ€™s a charlatan. http://www.hddoracle.com/viewtopic.php?f=181&t=2929 He uses the same marketing speak since 40 years ago when MFM drives were the norm even though hard drive technology has changed fundamentally at all layers. If you have questionable media the safest thing to do is make an image, not try to â€œrepairâ€ the device in place. Iâ€™m not a sceptic, I just know what Iâ€™m talking about. Anyone with a slightly detailed knowledge of modern hard drives knows that the SpinRite claims are hogwash. It would be harmless if it didnâ€™t actually waste precious time on marginal media not simply trying to make an expedient image. reply paulryanrogers 5 hours agoparentprevYet there are testimonials here in this thread that it can make a damaged drive worse. For some use cases the professionals are worth their high fees. SpinRite is for low stakes situations or folks who cannot afford better. https://news.ycombinator.com/item?id=40479468 reply nelsonic 2 hours agorootparentDisagree. SpinRite is for a hard drive that still runs but the computer does not recognise. i.e. it's a great diagnostic tool! If the drive doesn't power-up or \"clicks\" (because the reader broken) then yes, of course take it to \"pros\" first to see what they can do. But the \"pros\" use SpinRite and charge you $50/hour. And if you live somewhere remote where there are no competent technicians ... Â¯\\_(ãƒ„)_/Â¯ I've used SpinRite to recover \"photo backup\" drives for relatives where their local PC repair shop said \"nothing can be done\". For that relative it's their life on the HHD, couldn't be more high stakes than that (to them) and I trust it without any hesitation. SpinRite just goes to work and a few hours (sometimes days) later it magically works again. Easily worth the $89 Steve charges for it. reply epcoa 41 minutes agorootparent> â€œpros\" use SpinRite and charge you $50/hour. Data recovery experts definitely do not use SpinRite (I cannot speak for every corner computer shop and random 13 year olds on the next claiming to be data recovery experts) > Easily worth the $89 Steve charges for it. ddrescue and photorec are free. reply paulryanrogers 1 hour agorootparentprevI didn't mean unqualified repair shops. Rather professional recovery services who specialize in getting data off of damaged and failing drives. reply 8372049 59 minutes agoparentprevHave you tried ddrescue? reply ikiris 1 hour agoparentprevMy anti tiger rock also has kept my life tiger free. reply iwontberude 24 minutes agoprevIn 2006 I worked for a company that regularly used SpinRite for recovery and it did indeed work miracles. I wouldn't assume it has any utility today however. reply downrightmike 19 minutes agoparentIt does. Because we still have drives. reply guilhas 1 hour agoprevI would definitely recomend Steve and Leo's podcast 'Security Now' quite good at explaining CVEs and other security news I don't know about SpinRite but I would imagin it is just like any tool, useful for someone reply upon_drumhead 16 hours agoprev> One time I had two NVMe drives in two different machines do this to me the same week. I had been buying silicon power drives and they all failed prematurely (9 months at the longest). I switched to Samsungs and never had a single drive fail in years now. reply Modified3019 14 hours agoparentThe cheap Samsung enterprise m.2 drives you see on eBay have been trouble for me and others. The things have a tendency to suddenly fail with the firmware version displaying as â€œERRORMODâ€ (error mode) and only showing 1GB of unusable space. They can potentially be put back into a usable state, but itâ€™s 100% data loss when you see that message. Samsungâ€™s consumer and enterprise SSD departments were (unsure if still true) basically separate entities that didnâ€™t talk with each other, which was further confused and compounded by the OEM customized firmware nonsense which results in a lot of great hardware essentially having buggy firmware with no fixes. I believe their very latest (non OEM) enterprise m.2 drives have streamlined the availability of updating the firmware, so the problem is seemingly less for those. For the silicon power drives, if they just suddenly stopped showing up, then you may try doing a power cycle to see if that brings them back: https://dfarq.homeip.net/fix-dead-ssd/ Iâ€™ve had Intel and consumer Samsung drives Iâ€™ve brought back with power cycling. Older NVMe Drives seem especially prone to becoming unresponsive in older NVMe enclosures. Seems like less of an issue these days though. reply jjeaff 12 hours agorootparentI would never trust a drive bought on eBay or Amazon unless I could verify the specific seller. There are a lot of Samsung fakes out there. reply upon_drumhead 11 hours agorootparentprevThe silicon power drives all went read-only. Power cycling never brought them back, and they had various levels of lost. It was clear at least one chip failed and the drive was doing it's best to at least let me recover what I could off of it, but given how many went this way, I just gave up entirely on the brand. I've only bought the pro level of the Samsung consumer drives (nvme m.2) and they've been stellar. I have no experience with their enterprise drives. I also wouldn't buy drives off of eBay. I don't think of eBay as cheaper than amazon/b&h/etc, and the risk of a fake is just so much higher on eBay. reply PreInternet01 10 hours agoprevBefore talking about whether SpinRite was ever any good or not, it's good to consider the hard drives that were in use at the time it became popular. These early drives pretty much all came with a ST506 interface, as well as in MFM and RLL variants (there were also ESDI and SCSI drives, but since these were exclusively used on high-end systems, they're safe to ignore due to their rarity. The distinction between MFM and RLL can also be ignored, as RLL drives were really only differently-specced MFM drives that allowed the controller to do some rudimentary compression on the bitstream in order to expand usable capacity). The thing about the ST506 interface is that it was really, really simple: you (the disk controller) could seek to a track, the drive would tell you when that was done, then you could select a head, and the drive would tell you when the start of the track passed under that, and then you could read or write bits to the thus-selected cylinder. Again ignoring some finer points like precompensation and read recovery, you really only cared about three drive parameters: the number of tracks, the number of heads (multiplying these gave you the number of cylinders), plus how many bits you could approximately write to each cylinder. If you take a look at the OEM manual for the ST225 (a very popular ST506 drive at the time), the simplicity just jumps at you: https://archive.org/details/seagate-st-225-oem-manual-oct-85 You'll also notice, though, that there is no real mention of 'sectors' anywhere just yet. That's because that wasn't a drive concept, but something managed by the controller, which was responsible for dividing cylinders into sectors holding 512 bytes of user data. That division would mostly be timing-based, but to allow for error detection and recovery, the controller would add some metadata to each sector: typically, a sector number and simple checksum, which was sufficient to perform timing recovery and retry reads as required. After connecting a new drive to a given controller, the user would therefore need to run a 'low level format', typically by invoking some code in the controller card ROM BIOS, or by running a vendor-supplied utility: this would then go through all cylinders and write the metadata, including all-zero user data, for each sector. For some sectors, this would yield a write fault, and such sectors would be added to a bad sector list, resulting in a drive with a capacity slightly below that advertised. Another parameter used for this low-level format was the 'sector interleave': instead of dividing a cylinder into sectors 1-2-3-4-5 and so on, the controller would do something like 1-100-200-300-400-2-101-201-301-401-3, with the exact numbers depending on the capacity of the drive, obviously, but mostly the speed of the host system. Because PCs were really slow at the time, demanding tasks like 'reading 2 sectors sequentially' would result in a miss on the second sector, meaning having to wait for an entire disk rotation before trying again. By interleaving sectors, this miss could be avoided, greatly improving performance, but also hindering performance in case the selected interleave never or no longer (i.e. after an upgrade) matched the host speed. Now, let's turn to SpinRite. Its author, Steve Gibson, understood the relationship between disk, controller and BIOS really well, and cleverly improved on the default experience, which only provided destructive low-level formatting and virtually no diagnostics tools. By combining this understanding with a database of drive parameters and controller BIOS details (mainly: what is the address and calling convention of the per-sector read, write and format routines) and a fancy GUI, he provided some real value to early hard drive users. Initially setting up a drive with SpinRite required no obscure DEBUG commands or utilities, nor guessing of the optimal sector interleave: SpinRite would perform some tests to figure the latter out, and then perform the low-level format, with a progress bar and all, which was unheard of in vendor tooling. Even better, Gibson figured out how to do a non-destructive low-level format, and that was the true SpinRite superpower. Upgraded to a faster system and now stuck with a nonoptimal sector interleave? SpinRite could fix that for you! Did your drive degrade a bit (due to platters/heads getting out of alignment and/or the stepper motor wobbling), SpinRite could literally restore it to factory-fresh performance! So, fancy GUI and incredibly impressive marketing aside (which Gibson was really good at as well), the basic algorithm that gave SpinRite its legendary reputation was quite simple: invoke the controller BIOS to read all sectors for a few tracks into a ring buffer in RAM (employing as many retries as needed to recover the data if at all possible), re-order those sectors if changing the sector interleave, invoke the controller BIOS low-level format for the first half of these sectors (because you don't want to low-level format too close to data you haven't touched yet!), then write back the data. Rinse, repeat, with some clever handling of bad sectors and saving checkpoint data to an unused disk sector, so restarting the system during a SpinRite run rarily resulted in data loss. This worked really well for a long time, but broke down completely when disks stopped using ST506 and migrated to \"Integrated Drive Electronics\" (IDE) interfacing. When using IDE, the responsibility for managing \"sectors\" moves from the controller to the disk itself. This greatly simplified the controller-to-disk interface, as the former no longer needed to know about track or head counts: instead, the disk simply presented sequential sector numbers, LBAs. LBA-to-physical-sector mapping became a disk vendor responsibility, which it remains to this day in newer interfaces like SATA, SAS and NMVe. IDE did away with a number of things, including sector interleave, which due to the increase in host speeds was no longer relevant. But it also made it impossible to perform a 'low level format' type operation, since that was now fully a drive responsibility. Of course, the drive firmware might provide equivalent functionalty to the controller, but, especially in the early days of IDE, it definitely didn't do so. This meant that SpinRite's magic no longer worked on IDE drives. Sure: it could still attempt to read all your data (and with enough retries, that did allow for data recovery in some situations), then write it back (which might trigger a sector re-allocation in the IDE drive, but who knows), but that was about it. This did not stop Gibson from continuing to market it, and 'The Internet' from continuing to embrace it. There were rumors of SpinRite having special backdoor access to IDE controllers and such, but that was basically all nonsense. SpinRite was now `ddrescue` with some `chkdsk` and `smartmontools` thrown in, just with a much nicer user interface. So, SpinRite started out as an extremely useful tool that was worth its money, then degraded to a no-longer-magical shell of its former self that continued to be over-hyped, often passionately, for about a decade after the point it should have faded into obscurity. There is a lot of hazy discussion around these facts, but simply by looking at how the underlying tech evolved, the picture becomes pretty clear... reply cjk 14 hours agoprevI found myself agreeing with much of this article, but I have to say, I used SpinRite to great effect maybe 20 years ago on a drive that had the â€œclick of deathâ€. I tried all kinds of methods of recovery, and nothing worked until I tried SpinRite. I canâ€™t speak to how it did what it did (who knows, maybe it was a total fluke), but it gave me the opportunity to scrape all of my data off of it before buying a replacement drive. reply rasz 9 hours agoparentClock of death means HDD bootloader is unable to find service area and load actual firmware/setup data from the platters. The only software able to fix that will have a database of drive models and firmwares for reinitialization (PC-3000). Spinrite does none of that, its just an MFM formatting utility that grew to be a snake oil over the years. reply raggi 13 hours agoprevDisk encryption is what kills off these kinds of tools, they're useless on encrypted volumes. Some disk vendors themselves still ship specialized tools for smart block image recovery, if you've gone looking for recovery tools and don't want to fork out on forensics tools that's a good place to start when tools like ddrescue fail. reply ck2 4 hours agoprevBack when hard drives were MFM and up to 20 MEGAbytes and then RLL controllers came to make 20MB into 30MB and drives would constantly fail because they didn't even auto-park the heads on powerdown, SpinRite saved my butt many times. I bought it up to version 5 if I vaguely remember correctly and I think I still have a sealed spare copy around somewhere (used to resell to customers). If SpinRite was \"fake\" it sure did something for me. reply solarpunk 14 hours agoprevhttps://attrition.org/errata/charlatan/steve_gibson/ https://radsoft.net/news/roundups/grc/ https://radsoft.net/news/roundups/grc/20060123,00.shtml reply sircastor 13 hours agoparentThese get trotted out every time Gibson is mentioned in any capacity. For the most part, this stuff is 2+ decades old. It feels like character assassination because it's written exclusively as \"debunking\" or calling out Gibson's missteps. It makes no effort to followup and state if he's corrected himself, changed his opinion or shared further information. These folks have it out for this guy - whether or not he's wrong. reply mixmastamyk 13 hours agorootparentIndeed, would not love to see my list of mistakes over the decades, especially putting on a live show. The perfect-forward-podcast will not ever exist. reply KennyBlanken 10 hours agorootparentprevIt's two decades old, but so is the stuff on his site. Go look at Shields Up - it's all written like people are still plugging their computers directly into their DSL modems and cablemodems. I couldn't find a single acknowledgement that his service isn't necessary for 99% of users on the internet who are behind a NAT router. Nor does he acknowledge that most ISP's have long since adopted policies of blocking traffic on common windows network service port numbers. Anyone behind a NAT router doesn't need to worry about any of this unless they've modified its configuration to forward some ports. He's also now hawking spinrite for people with SSDs, claiming it helps their reliability. It's complete nonsense. reply filchermcurr 9 hours agorootparentFor what it's worth, the FAQ has a section about NAT. If you click on 'Help' it also specifically mentions the use case of: \"... checking and verifying your NAT router's WAN-side security...\" reply Joel_Mckay 13 hours agoprevAnyone that had to deal with the aftermath of a failed HDD Raid set certainly was glad SpinRite was around. After the rise of shingled writes and SSD, the software was not as applicable to modern systems. Notably, most good SSD manufacturers provide automated hidden maintenance tools built into the firmware. Thus, some may be surprised to learn leaving an SSD with no power for more than a year is a really bad practice. Flushing the SSD cache after a system update is usually good practice once a week in off peak service hours. Most Linux distros will similarly defer the trim operations to a scheduled weekly cleaning cycle as well (lowers drive wear). If you still run old spinning HDD in equipment, than SpinRite can still save you a $2k recovery bill. Cheers =) reply mixmastamyk 13 hours agoprevThe author of this piece seems to think highly of his abilities but by his own admission doesnâ€™t understand how spinrite works. Information thatâ€™s not that hard to come by or imagine. On SN, Gibson explains for SSDs that SR rewrites marginal cells to avoid subsequent error correction delays, speeding things up. Notice the author doesnâ€™t say, I tried it on ten dead drives heading for the garbage heap and it did nothingâ€¦ no, he says basically I donâ€™t think it could work. Unless you actually wrote similar code youâ€™d have no idea. Did this person even attempt to develop a low level disk tool of any capacity, much less one of production quality? Also complains about the website and SG being old-fashionedâ€”well letâ€™s see your website when youâ€™re 70? and had decades of career behind you. I still prefer vintage to a react/electron monstrosity. reply rasz 8 hours agoparent>Gibson explains for SSDs that SR rewrites marginal cells Gibson knows this is a lie, but he keeps repeating this. You cant target particular flash cell on SSD, its impossible. There is FTL between you and raw flash. What you can do is force SSD to reinitialize whole flash with ATA Secure Erase or NVMe Secure Erase. You dont need to spend $80 on snake oil software pretending to do something else to do Secure Erase. reply mixmastamyk 1 hour agorootparentI used that word because they arenâ€™t actually sectors, but itâ€™s immaterial if it is a cell or the enclosing sector. They can be overwritten as a full block of course. Whether this actually resets the voltages might vary by drive, who knowsâ€”would need to see hard data to properly verify. Without that data, both Gibson and critics are talking out their asses. Gibson is a known quantity and more reliable than internet nobodies however. It sounds feasible and I (so far) have no tangible reason to disbelieve him. If you want to prove him wrong, do the work. reply annoyingnoob 14 hours agoprevSpinRite saved my bacon a couple of times, many moons ago. reply erros 10 hours agoprev [2 more] [flagged] untitaker_ 5 hours agoparent [â€“] people complain about character assassination in this thread, but then, what is this supposed to be? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The decline in hard drive recovery needs is attributed to advancements in HDD technology, better purchasing habits, and the shift to SSDs, which fail completely rather than gradually.",
      "SpinRite, a once-popular data recovery tool, has lost relevance due to the complexities of modern storage devices, especially SSDs, which complicate recovery efforts with proprietary logic and the TRIM command.",
      "The author critiques SpinRite's effectiveness on modern drives and SSDs, suggesting that its current marketing relies on outdated claims and lacks technical substantiation, questioning its relevance and value today."
    ],
    "commentSummary": [
      "The discussion evaluates GRC's SpinRite software, created by Steve Gibson, highlighting mixed opinions on its value and effectiveness, especially given its outdated methods and limitations like a 2TB HDD cap.",
      "Critics argue that modern file systems and SSDs, which have built-in maintenance tools, reduce the need for SpinRite, and compare it to free alternatives like ddrescue and TestDisk/PhotoRec.",
      "Despite skepticism about Gibson's credibility and marketing, some users report positive experiences with SpinRite, particularly for older systems, balancing nostalgia with current relevance concerns."
    ],
    "points": 109,
    "commentCount": 103,
    "retryCount": 0,
    "time": 1716684863
  },
  {
    "id": 40482328,
    "title": "Harnessing the Feynman Algorithm: A Brain's Natural Problem-Solving Process",
    "originLink": "https://www.marginalia.nu/log/a_108_feynman_revisited/",
    "originBody": "Posted: 2024-05-26 The best description of my problem solving process is the Feynman algorithm, which is sometimes presented as a joke where the hidden subtext is â€œbe smartâ€, but I disagree. The â€œalgorithmâ€ is a surprisingly lucid description of how thinking works in the context of hard problems where the answer canâ€™t simply be looked up or trivially broken down, iterated upon in a bottom-up fashion, or approached with similar methods. Feynmanâ€™s thinking algorithm is described like this: Write down the problem Think real hard Write down the solution (This algorithm may or may not have actually been used by Feynman, itâ€™s as far as I can tell Murray Gell-Mannâ€™s account of Feynmanâ€™s approach.) The trick is that there is no trick. This is how thinking works. It appears that when you feed your brain related information, without further active involvement, it starts to digest the information youâ€™ve fed it. Thinking is a background process. Thereâ€™s no Sherlock Holmes-style string of brilliant deductions; the brain is a connection-making machine. If you feed it data points, it will find ways of connecting the dots. So to solve a problem, you start by feeding your mind the relevant information in a fairly literal sense. Itâ€™s a direct parallel to how youâ€™d prompt a LLM. Just bring up all the things you think are relevant. Imagine if you were to task someone else with solving the problem, imagine what they might have use of knowing, really go over anything you think might be useful. Itâ€™s good to write that down in the simplest way possible. It should be very clear to you what question you are attempting to answer. What is written on paper is not the important thing, the act of assembling the question is the work! To answer the question, what you do next is to remove yourself from further inputs. As long as you keep feeding your brain with more data, the queries never resolve, and eventually the stuff you fed it first will fall out of the context window and amount to nothing. For this reason, itâ€™s crucial to step away from the keyboard. Go for a walk, or sit down in a quiet place, take a shower; whatever you choose to do, just keep thinking about the problem. As you do this, all the background processing you kicked off earlier will begin to resolve. Not immediately, it may take a whileâ€”hours, sometimes daysâ€”but as it does you get sudden insights into the problem domain. You may or may not immediately find a solution to the problem, but youâ€™ll often at least find a deeper understanding. The conclusions must be written down. Not only because these insights are fleeting and can be hard to recall, it also appears to act as a sort of feedback to the brain that the information is important, that itâ€™s on the right track, to keep going. The perhaps most inspired period of my life was sometime in 2021, before Iâ€™d moved in with my girlfriend. What Iâ€™d inadvertently ended up doing was to arrange my life into something very similar to the algorithm above. Iâ€™d grind away and work on the search engine all week, filling my brain with all manner of information related to the work I was doing, and then Iâ€™d go visit her over the weekend, not bringing a computer. Without exception, by the time the weekend was over, Iâ€™d have several pages worth of new ideas written down in a notebook that Iâ€™d implement over the following week, rinse and repeat. I keep coming back to the gardening metaphor of thought. What you think today is the result of what you read yesterday. If you want to have relevant, interesting, useful thoughts; use your reading as a template. It will not only model the topics you are thinking about, but the very thoughts themselves. Itâ€™s as much pruning gossip and irrelevant noise as it is planting the interesting and insightful and well thought-out. Previous: Experiment in Java native calls 2024-05-16",
    "commentLink": "https://news.ycombinator.com/item?id=40482328",
    "commentBody": "Feynman's Garden (marginalia.nu)106 points by EvgeniyZh 4 hours agohidepastfavorite46 comments j2kun 3 hours agoFor me writing is also a much bigger part of the process. Writing out my explanation of the problem (its symptoms and my theories) to a colleague, even if I don't send it off, can spur me to come up with a new idea. Writing blog posts or an outline of such a blog post can help me spot gaps in my understanding and justifications. And writing down the solution, for myself two weeks ago as the intended audience, helps me internalize the important bits while filing away the minutiae for later reference. Publishing it on my blog also ensures that I spend enough time on the writeup that it is actually helpful for myself later, and not just a mess of notes. reply Sn0wCoder 3 hours agoparentI have often thought about writing a blog from my experiences, but after I write the thoughts down seem like common sense in nature or just plain ranting. Writing it down gets it off my chest / mind, but publishing has never happened. I do keep all the notes so I can revisit them. Often do this with emails too but I delete them if I do not send them after 48 hours. It has taught me to never send an angry email in the â€˜heat of the momentâ€™ and to reflect on the content as if I were to receive such an email. The best one I have is letting others fail, they are going to anyway. When put on a new project with a new team who has been working together for a while, they are NOT going to listen to you no matter how much experience you have even if you consider yourself a SME. I often find myself fighting against what I think is the correct solution as the team will want to do the opposite of the â€˜new guysâ€™ suggestionsâ€¦ reply marginalia_nu 3 hours agoparentprevTo be fair, two thirds of the algorithm is writing things down, and in many cases just clearly formulating the question is enough to find enough gaps in your understanding to answer it as well. reply lynx23 3 hours agoparentprevI don't know how many emails I actually never sent, and also never filed into the drafts folder. The mondane version being fending of rage. But other times, you just develop the answer to your question while writing the question down. On a similar thought, this is why coding is an inherent part of my way of dealing with problems. The rigour required to get a piece of code to work helps me understand concepts. So when learning things, I sometimes end up writing a piece of code to model the domain, just to help me understand it. reply j7ake 2 hours agoprevIn research, reaching the point of \"writing down the problem\" is already a huge accomplishment. What distinguishes the first-rate researchers and the second is their (1) ability to identify which problems are worth their finite time in solving, (2) defining the problem so that it is manageable but impactful, (3) using approaches other people in th field have not thought of to tackle the problem. reply shiomiru 2 hours agoprevI would also add a step 1.5: write down the wrong solution. Too often I find myself wondering about what later turns out to be the most trivial part of the problem. The best antidote is to write a naive half-solution to \"throw away\"; yes, it may be unusably bad, but now I know what sub-problem is worth thinking about when I'm away from the computer. reply namaria 2 hours agoprev> What you think today is the result of what you read yesterday. I really need to reinforce this. And follow it. I try to read good books and stay away from random tidbits of novelty but sometimes it's really hard and days pass by in which I don't read anything substantial, just blogs and news. We can't eat just candy and we can't read just fun little pieces of novelty. We also need the protein and fat of dense long form content like books. reply jes5199 2 hours agoparentand yet here we are in the comment section reply namaria 2 hours agorootparentCan't spend the whole of Sunday with my great great book collection ;) reply BostonFern 2 hours agorootparentprevBillions of others are not ;-) reply sonabinu 3 hours agoprevIn Feynman's 'Surely You're Joking, Mr. Feynman!' there is a chapter where he describes his observations on 'how does it feels to go to sleep' as part of an essay for a class. This and other lectures/writings from Feynman gives cues to his technique and also the almost impish curiosity with which he approaches a problem. IMHO the best way to master or learn from him, is read/watch his works/lectures. reply GlenTheMachine 2 hours agoprevâ€œWrite down the problemâ€ is hugely underrated as part of the algorithm. In my experience, at least when doing research, if you can precisely and rigorously define the problem you actually need to solve youâ€™re probably halfway to a solution. Iâ€™ve been working on robot control using physics-based computing devices for about a year. Not yet able to write down the problem clearly enough to attempt a solution. reply whb101 3 hours agoprevfor those curious about the neuroscience -- \"stepping away from the keyboard\" takes your Default Mode Network off the project like a burned-out employee that's just running it into the ground when the DMN is highly active - fixating, ruminating - its focus is narrow and it's less likely to produce as many creative insights or dredge up as many relevant memories if you make it less active - doing something else, letting your mind wander, shutting it off entirely with sleep or substances - it will keep trying to solve the problem, but also make farther-flung connections that might solve it these connections can then be picked up and used more effectively by your executive and salience networks reply ilaksh 2 hours agoprevNot to make everything about AI, but.. he did mention LLMs. What happens if, after clearly defining the problem and listing all potentially relevant clues as to how to solve it, you first give that information to an LLM, before taking a walk or a weekend off? This is probably another case where the answer depends on the attitude towards LLMs and maybe technology overall. For me I think that this is largely how I use LLMs for programming. I use the aider program, add the relevant source files, explain what I want to do and the approach I want, and ask it to do it. It does routinely miss obvious things. But then it's also often fairly easy to ask it to correct itself. It depends on the nature and complexity of the problem though. But theoretically the LLM would have a couple of useful ideas or feedback if you really give it all of the context. But maybe defining the problem and the relevant information is the hard part. Perhaps having significantly larger context windows is a bigger deal than some people might realize. If the LLM or multimodal model has a very large context window and also enough computing resources to constantly or routinely decide what the goal is.. Then the other part would be having a large pool of potentially relevant information to select from in approaching the problem. But basically we might be able to skip the step where we select the relevant information and let the AI do that, if we have a large enough context window. Which might lead to the question, why did we even get out of bed. But that's another problem. I get the impression that diffusion transformers are a big deal. Do they allow for more sophisticated/developed problem solving or \"cognition\" in some way? reply anonymousiam 2 hours agoprevIn the shower is where I have solved my most challenging problems. Taking a shower is just mindless routine, so my brain's \"background processing\" goes into overdrive. reply tcsenpai 3 hours agoprevSaved this in multiple archives, will be one of my \"read me when you are not motivated\" reads reply petermcneeley 3 hours agoprevYou had me until >Itâ€™s a direct parallel to how youâ€™d prompt a LLM. reply marginalia_nu 3 hours agoparentIt's hard to observe your own mind, or indeed others, it's intangible and generally difficult to observe thinking. Because of this drawback, LLMs are actually a decent model for this sort of process since we can observe how they operate. I'm not claiming they're actually intelligent like we are, but rather that they model the process of drawing connections and making associations close enough to how we think to the point where it's an useful analogy. reply mortify 3 hours agoparentprevThere are parallels. You feed an LLM context data and then tell it what to focus on so it can pull relevant data. Maybe the entire process isn't like feeding an LLM, but that step is. Relevance identification is an interesting part of the process. The LLM can do a decent job of making connections, but it doesn't know what is relevant. In the longer time frame of the thinking process, we constantly throw out data as irrelevant or identify previously unknown relevant data that needs to be added. It's a part of the process completely outside of the LLM. reply conradolandia 2 hours agorootparentBut we really don't know that, do we? reply the__alchemist 3 hours agoparentprevI think, if you adopt this mindset, acutely any process that involves precise instruction could be dismissed. Or more generally, your standards for analogy may be so stringent as to render that concept invalid. reply scubbo 3 hours agoparentprevI'm as AI-wary as they come, but - it's a completely factual, relevant, and helpful statement. To say that any relation or comparison with AI ruins the comparandum is as absurd as saying that anything coloured red is bad because the Nazis used the colour red in their iconography. reply gregschlom 3 hours agoprevSee also rubber duck debugging, where explaining the problem (verbally or in writing) is essentially the first step of Feynman's algorithm, and allows your brain to figure out the solution in the background. reply gist 3 hours agoprev> Thinking is a background process. If you try to remember what you are trying to remember on the spot often you can't. Then you stop trying and all the sudden (and later) the answer comes to you. (One example: Happens often when trying to remember the name of an actor 'I know who that is' then later 'ok it was...') I think this is also related to why some people don't test well. A question in a test format or information requested formulated as a question (that need an immediate answer) doesn't work for many people with facts that are memorized. In fact extreme pressure can sometimes prevent recall just because of the anxiety alone that that produces. reply gist 3 hours agoprev\"To answer the question, what you do next is to remove yourself from further inputs. As long as you keep feeding your brain with more data, the queries never resolve, and eventually the stuff you fed it first will fall out of the context window and amount to nothing.\" Similar/Related: If you are trying to fall asleep, and you mind is filled with thoughts, a solutions is to count (does not need to be sheep just count numbers). Counting distracts and occupies your mind from being distracted with whatever your anxiety (or excitement) thoughts are. (Source: It works for me). Anything can really be substituted for counting as long as it's not exciting or anxiety producing. reply jyunwai 3 hours agoparentFor insomnia and sleep problems, a good approach is to try out additional techniques from the lists in CBT-I (Cognitive-Behavioral Therapy-Insomnia) treatment manuals. This is a well-studied, non-medication approach, with large parts that a person can learn independently. A specific technique that helped me was to challenge the thought that \"If I don't sleep for 8 hours, the following day will be ruined,\" as that was a common thought that kept me up. There are a couple of PDFs of treatment manuals online that list the techniques: UNC School of Medicine: https://www.med.unc.edu/neurology/wp-content/uploads/sites/7... United States Veterans Affairs: https://www.mirecc.va.gov/docs/visn6/Improve_Your_Sleep_Self... reply block_dagger 2 hours agoprevThe garden metaphor seems tacked on. reply Ecoste 4 hours agoprevWhen this doesn't work, does it mean that you're simply stupid? Asking for a friend. reply marginalia_nu 4 hours agoparentI think the most common failure mode is neuroticism; getting stressed and frustrated with the lack of progress, thinking about the progress toward the outcome rather than the problem to be solved. Stress in particular is extremely poisonous to thinking. The expectation should be that it takes as long as it takes, and you need to be calm and well rested. reply wizzwizz4 3 hours agorootparentIf you find yourself choosing between working on the problem and taking a nap, always take the nap. (Given the choice between remaining in bed, and taking another peek at the problem, usually take a peek at the problem, after which you should do what feels best.) Some experimentation should convince you that this is how human minds work (well, most of 'em, and yours is probably one of them), after which you can employ this strategy without guilt during a crisis. reply jyunwai 3 hours agoparentprevA lack of necessary prior knowledge is often a major reason for struggling with a problem. As a relatable example, suppose you're taking an exam. There's a problem near the end that you don't know how to solveâ€”and the reason is that you haven't studied that topic enough. No matter how smart (as in, fast at learning) you are, you need to practice with similar or related problems to solve that issue. But suppose you're outside of an exam environment and have time to look up the relevant material. I've known a PhD candidate in a non-mathematics field who had to find a mathematical solution to a certain research problem. That person is smart but still needed a few months to learn the mathematical fundamentals to understand and solve the problem. In contrast, someone with a math background could have solved this far more quickly. But that person would have taken at least some months to get up to speed on the research literature for the non-mathematics part of the research problem, in order to properly understand its constraints and bigger-picture significance. Lara Alcock's book \"How to Study as a Mathematics Major\" touches upon this topic more directly. She encourages readers not to be too intimidated if other students in a course seem really smart: much of the time, the reason is not due to an innate difference in smartness, but rather prior exposure by other students to concepts in the course. Students who seem to find the material effortless often have already studied many of the topics in another course or could even be retaking the course after a previous attempt. reply mortify 3 hours agoparentprevWhile thinking is somewhat of a background process, our brains don't just solve the mysteries of the universe while we eat a ham sandwich. We tell our brains which problems are of high importance and it focuses on them. If you've ever laid down to go to sleep and told yourself to wake up at 6:30 and it worked, you've witnessed an obvious application of this. The problem comes when we fail to point out the importance of a problem, or when we do so reflexively which means that we tell our brain that everything is important and it simply cannot process all of the requests. Setting your thinking requests before doing a non-thinking activity is a good way to start. Think about the problem consciously and then specifically ask for an answer to a question. Then go do something physical or mechanical: take a walk, sleep, mow the lawn, watch a non-challenging movie, etc. Be prepared to accept whatever result you get. A common response is: non enough information, but it should point you toward what that additional info looks like. reply mandmandam 3 hours agoparentprevThis is a very interesting question. When you plant a seed in a garden, there's many factors at play - is the season right? Is the climate right for that seed? Is the soil the right type? Are there pests or varmints roaming that might eat it prematurely? Etc. The garden of thought has analogous factors: Is this a question your brain actually cares about right now? Do you have the background knowledge necessary to work it out? Is your brain calm enough to process that question? Are there distractions or anxieties that disturb the process? That said, some people truly are stupid. I recently read John Cleese's autobiography, and he tells a story from when he was a Geography teacher... There was a lad who he was teaching countries and their capitals. Even when given direct attention, the kid simply wasn't able to name any capitals whatsoever. He would smile and nod, giving no indication of difficulties... But he couldn't recall the info even after being told it 8 seconds previously. This particular type of data slid off his brain. At the end of the term, the kid got one question right on the final exam, probably by accident. Cleese posted the paper in the teacher's room, attracting the comment from one teacher \"The sad thing about true stupidity is that you can do absolutely nothing about it\". Perhaps that kid had a genius for engines or something, but he was never going to be able to understand geopolitics. He lacked even the awareness to know that he was stupid (at least about countries and capitals). He would never have asked if he was stupid, because he was truly stupid. If your friend is ever curious about their intelligence, they're probably ok and can develop the skill of thinking like this. reply mortify 3 hours agorootparent>some people truly are stupid. This is a difficult fact to accept. We have all been told that people are generally equal, especially in intelligence, if given the same opportunities, but it becomes more clear in time that some problems are intractable to some people and no amount of training or exposure can change that. However, it's a better answer to the problem of why some people like Cleese's example do not absorb information. The alternative is to apply malice and laziness to them when it just isn't so. We all have these intelligence holes that gives some insight into the mechanism. Eg. I'm bad at remembering names. As in the example, if you tell me someone's name, I'm likely to forget it 5 minutes later. I just spent 3 years reading Douglas Hofstadter's book and had to look up his name to type it here. This seems to happen because I don't see an application to remembering the name. I'm never going to meet Doug and rarely will anyone need to be told about the book, so why remember it? There's definitely a parallel to state capitals in that example. reply kreeben 2 hours agorootparentWell said about not realizing it's important therefore names get down prioritized. Here's a counter point. I'm a movie geek. Yet when I reach for a name of someone from the cast I almost always end up describing, y'know, that guy who played together with that other guy in that movie, y'know, the one with the weird story line? Him! Yes, him. Love him. reply lordgrenville 3 hours agoparentprevAnother possible failure mode is that the problem is in fact unsolvable. reply ajkjk 4 hours agoparentprevYes, it does. reply marginalia_nu 4 hours agorootparentDon't be like that. reply swayvil 3 hours agoprev [â€“] Ok, a solution appears. But does the solution manifest (a flower grows in the garden) or does it become apparent (the fog clears to reveal it)? Because the phenomenon we're discussing could be attributed to either cause. But they are quite different causes. And imply quite different stuff going on there. reply argiopetech 3 hours agoparentMore like the flower, I'd say. Your first problem statement plants the seed. The solution (and the shortcomings in that solution and in the original problem statement) are the seed clearing the dirt. As you write, think, and write again, the plant grows and takes form until the time is right for the flower to bloom. Then the bloom slowly dies, unnoticed by the majority (beautiful in their place, but with no generalizable characteristics), or as the work becomes common knowledge and is integrated into better and more complex solutions to bigger and harder problems. The most beautiful flowers are mass produced for public consumption ($e=mc^2$, and the like), but those are rather few and far between. reply swayvil 1 hour agorootparentOr. Your first consideration of the problem is your first glance into the fog, revealing the superficial. Then, as you continue to peer in that direction, more is revealed. One phenomenon, 2 perfectly good explanations. Like, is it a variable or a reference to a variable? Hard to say. reply inciampati 3 hours agoparentprevYou eventually get to the solution if you keep thinking long enough. The trick is to not stop thinking in the background about it. That's the process. I think that hours or days, like the author mentions, even seems very short. Many of the kinds of things that I have experienced, which yielded to this kind of process, took months to years. Sometimes big problems can be broken down into many small ones and only take those minutes to hours to days to complete. But still, the big problem takes a long time to work through. reply dev_tty01 3 hours agoparentprevWell, it is both of course. Why assume a binary process? Several solutions are probably grown, considered, and evaluated and one begins to gain precedence. That one then finally becomes apparent and is revealed. reply ilaksh 2 hours agoparentprevMost cognition is subconscious. I believe there is an unsung gardener hero working in the background to cultivate the candidate flowers and then put spotlights on a few of the best ones that emerge. You then evaluate them as you walk down your path of consciousness. reply marginalia_nu 3 hours agoparentprev [â€“] A solution may manifest as a series of insights, but the insights themselves are quite binary. You suddenly find yourself having them. For me at least they appear as a thought like any other. reply swayvil 3 hours agorootparent [â€“] That is my experience also. Which sorta suggests option 2. Option 2 is heavy. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author discusses using the Feynman algorithm for problem-solving, which involves writing down the problem, thinking hard, and then writing down the solution.",
      "They highlight that this method aligns with how the brain processes information subconsciously, suggesting that taking breaks can lead to productive insights.",
      "The author emphasizes curating reading material to foster relevant thoughts, comparing it to gardening where irrelevant information is pruned to nurture insightful ideas."
    ],
    "commentSummary": [
      "The discussion highlights the importance of writing in problem-solving, aiding in clarifying thoughts, identifying knowledge gaps, and internalizing solutions.",
      "It explores the role of AI, particularly Large Language Models (LLMs), in providing feedback and making connections, despite their struggle with relevance.",
      "Techniques for managing anxiety and insomnia, such as Cognitive-Behavioral Therapy for Insomnia (CBT-I), are mentioned, emphasizing the importance of rest and cognitive limitations in problem-solving."
    ],
    "points": 106,
    "commentCount": 46,
    "retryCount": 0,
    "time": 1716732675
  },
  {
    "id": 40477653,
    "title": "MAJORANA DEMONSTRATOR: Unveiling Neutrinos' True Nature with Neutrinoless Double-Beta Decay",
    "originLink": "https://newscenter.lbl.gov/2012/05/16/majorana-demonstrator/",
    "originBody": "The helicity, or handedness, of neutrinos has only been observed in two states, left-handed neutrinos and right-handed antineutrinos. Whether these are really the only two neutrino handedness states depends on whether neutrinos are their own antiparticles. In a cavern almost a mile underground in the Black Hills, an experiment called the MAJORANA DEMONSTRATOR, 40 kilograms of pure germanium crystals enclosed in deep-freeze cryostat modules, will soon set out to answer one of the most persistent and momentous questions in physics: are neutrinos their own antiparticles? If the answer is yes, it will require rewriting the Standard Model of Particles and Interactions, our basic understanding of the physical world. â€œThe best way to learn whether neutrinos are their own antiparticles would be to observe a certain kind of radioactive decay, called neutrinoless double-beta decay. It has never been detected conclusively, and if it occurs at all, itâ€™s exceedingly rare,â€ says Alan Poon of the Nuclear Science Division at the U.S. Department of Energyâ€™s Lawrence Berkeley National Laboratory (Berkeley Lab). Poon is the current executive-committee chair of the MAJORANA Collaboration, which is comprised of more than 100 researchers from 19 institutions in the United States, Canada, Russia, and Japan, and whose efforts are focused on the experiment now under construction at the Davis Campus of the Sanford Underground Research Facility (SURF) in Lead, South Dakota. Beta decay, single and double Ordinary beta decay is a common kind of radioactivity: an atomic nucleus changes into a different kind of element, a neighbor on the periodic table with lower mass, by emitting a beta particle â€“ an electron or positron â€“ plus a neutrino or an antineutrino. For example, carbon-14 transforms to nitrogen-14 when one of its neutrons turns into a proton, emitting an electron and an antineutrino. It was beta decay that led to the proposal that there must be a particle like the neutrino, since an electron alone could not account for all the energy lost in the decay. Carbon 14 decays to nitrogen 14 by emitting an electron and an antineutrino, while changing one of its neutrons to a proton and transforming the nucleus one place higher in the periodic table â€“ a common kind of single beta decay. In a rare double-beta decay, for example when germanium 76 changes to selenium 76, two neutrons change to protons while emitting two electrons and two antineutrinos, transforming the nucleus two places higher in the periodic table. (Click on image for best resolution.) â€œDouble-beta decay is also possible and has been observed in a dozen different isotopes since 1986,â€ says Poon. â€œBut it happens at a really low rate, and not too many nuclei can do it.â€ The only conclusive double-beta decays seen so far involve two neutrons that change into two protons while emitting two electrons and two antineutrinos. Itâ€™s an uncommon situation, in which single beta decay is blocked because the decaying isotopeâ€™s immediate neighbor has a nucleus thatâ€™s too heavy, but the nucleus of the neighbor two places away on the periodic table does have lower mass â€“ even though its atomic number is two places higher. Getting there requires double-beta decay. One of the relatively few nuclei that can transform by double-beta decay is germanium-76 (76Ge), an isotope that accounts for less than eight percent of naturally occurring germanium. Germanium-76 canâ€™t change to its neighbor, arsenic-76, but it can change to selenium-76, two places higher on the periodic table. Many reference works refer to germanium-76 as stable, but double-beta decays of 76Ge have been observed since the 1990s, and its half-life has recently been estimated at 1.3 x 1021 years, or roughly one and a third sextillion years. Thatâ€™s 100 trillion times the age of the universe. Not quite stable. How do you detect such a rare event? If you watch a single germanium-76 atom for one and a third sextillion years, the chances are 50-50 youâ€™ll see it decay. On the other hand, if you watch one and a third sextillion germanium-76 atoms for just one year, the chances are 50-50 that youâ€™ll catch at least one of them decaying. In essence, thatâ€™s what MAJORANA proposes to do. The full MAJORANA concept calls for a metric ton or so of germanium diode detectors, enriched to 86 percent 76Ge. Over the course of a year, a detector that size has a good chance of catching double-beta decays, although most will be accompanied by a pair of antineutrinos. Searching for an absence of neutrinos Identifying neutrinoless double-beta decays depends crucially on getting rid of background from cosmic rays and natural radioactivity in the surroundings. Thatâ€™s the purpose of the MAJORANA DEMONSTRATOR: to show that achieving a low enough background is indeed possible. A mile of rock overhead is an effective shield against most cosmic ray debris, but radioactivity from the environment, including from impurities in the experimentâ€™s own components, is harder to avoid. Individual detectors made of pure germanium are assembled in strings and remotely loaded into the lead- and copper-shielded MAJORANA DEMONSTRATOR. Jason Detwiler of the Nuclear Science Division, who has been involved with the MAJORANA project since 2005, says, â€œWeâ€™re spending a lot of time modeling every one of the DEMONSTRATORâ€™s thousands of individual parts, to make sure we can achieve the lowest backgrounds of any experiment of this kind ever â€“ a hundred times lower.â€ The MAJORANA DEMONSTRATOR will be shielded with multiple layers of copper and lead against radioactive elements in the surrounding rock, and the detector will be built from ultrapure materials. Copper components are being formed underground in special facilities at SURF, to remove natural radioactivity and prevent contamination from cosmic rays. Equally important is the detectorâ€™s ability to distinguish the background from double-beta decays inside the detector itself. Pure germanium is ideal for this purpose, both as a source of double-beta decays and, says Detwiler, as a detector that â€œcan register the signal of nuclear decays cleanly, beautifully, and in high resolution.â€ Nuclear decays and other events create charge carriers that drift toward the collecting electrode on the surface of the germanium diode. The way the carriers drift â€“ their â€œpulse shapeâ€ â€“ will clearly distinguish background events from a neutrinoless double-beta decay. Why Majorana So far the only known particles that are their own antiparticles are all bosons, particles that often carry force or mediate interactions, such as the photon, the pi-zero, or the Z. Ettore Majorana, a brilliant Italian theoretician who had a brief career in the 1920s and 30s but vanished mysteriously at the age of 32, was the first to propose that some fermions, particles of matter, might also be their own antiparticles. That these hypothetical particles are today known as Majorana fermions is due to Enrico Fermi. Majorana considered his work â€œbanalâ€ and was famously blasÃ© about promoting it. Earlier Fermi had urged him to write up his ideas about a neutral particle with the mass of the proton, but he didnâ€™t bother, and the credit (and a Nobel Prize) went to James Chadwick for the discovery of the neutron. When it came to Majoranaâ€™s theory that fermions could be their own antiparticles, Enrico Fermi took no chances: he wrote the paper himself and signed Majoranaâ€™s name to it. Majorana suffered increasing depression and in 1938 boarded a ferry from Palermo to Naples. He never arrived. Speculation has ranged from suicide, to escape to Argentina, to retreat to a monastery. Although matter and antimatter annihilate when they meet, no one has yet suggested that Ettore Majorana met his anti-Majorana on the fateful voyage. â€œBerkeley Lab developed germanium detectors decades ago, so we have a history of strength and expertise in design and manufacture,â€ Detwiler says. â€œWeâ€™re working with a U.S.-based commercial vendor to turn germanium-76, enriched at an isotope separation facility in Russia, into working detectors. Weâ€™ll mount them with low-noise electronics developed here.â€ The first pure germanium in the DEMONSTRATOR will be a natural mix of isotopes, setting a baseline for response to background events. Eventually 30 kilograms of the detectorâ€™s 40-kilogram total will be enriched to 86-percent germanium-76, narrowing the chance that background signals could compete with the discovery of an actual neutrinoless double-beta decay event. Such an event would be easy to identify, because the energy of its two electrons would add to precisely 2.039 million electron volts (2.039 MeV), and none would be shared with antineutrinos. With a low enough background, MAJORANA will be able to easily separate the sharp spike of a 2.039 MeV two-electron event from a broad smear of energies shared among four different particles. Rewriting the Standard Model Mass is essential to oscillation among the three neutrino flavors, but no one knows the precise mass of any of the flavors or why itâ€™s so small. Neutrinoless double-beta decay offers a unique window on that question. If MAJORANA can go beyond showing that neutrinoless double-beta decay exists to showing how often it occurs, it may be able to establish the mass scale of neutrinos directly. The key is their handedness, or helicity (which refers to how their linear momentum and quantum spin are aligned). If neutrinos and antineutrinos are two distinct particles, each could be either right-handed or left-handed, for a total of four quantum states. If neutrinos and antineutrinos are just one particle, however, it has only two states of handedness. In fact only two states, left-handed neutrinos and right-handed antineutrinos, have ever been observed. A diagram of neutrinoless double-beta decay shows a right-handed antineutrino emitted when a neutron decays (also emitting an electron). The antineutrino flips its handedness and is absorbed by a second neutron, which also decays (and emits a second electron). Only a single antiparticle/particle is involved. How fast it can flip its handedness depends on its mass: the more massive, the easier the flip, and the more often this kind of decay will occur. In neutrinoless double-beta decay, a single particle would be emitted as one neutron changes to a proton. This right-handed antineutrino would be absorbed as a left-handed neutrino by a second neutron, causing it too to change to a proton. Two electrons account for the total difference in energy between the nuclei. But thereâ€™s a catch, says Poon. â€œThe fascinating thing about neutrinoless double-beta decay is that it would violate one of the basic principles of the Standard Model, in which all interactions supposedly conserve lepton number. Electrons and neutrinos are both leptons, so if an interaction produces two electrons, thatâ€™s a plus two. In the usual kind of doubleâ€“beta decay, two antineutrinos are also emitted â€“ antiparticles with minus lepton numbers, which is a minus two. Lepton number is conserved at zero.â€ Not so with neutrinoless double-beta decay, however, which raises the lepton number from zero to two. â€œThe Standard Model leaves many outstanding questions, and we know it needs revision,â€ Poon says, â€œbut we cannot write a new theory until we know if neutrinos are their own antiparticles, or how weâ€™re going to accommodate the loss of lepton number conservation if they are, and a number of other questions, including neutrino mass.â€ In the race to answer these questions, the MAJORANA Collaboration is competing with another important germanium experiment, the GERDA experiment at the underground Gran Sasso National Laboratory in Italy. But itâ€™s a competition with a twist: â€œGERDA has a different shielding concept, using liquid argon and water, and between us weâ€™ll find out which has the lower background,â€ says Poon. â€œWe may join forces to build the final one-ton detector.â€ Germanium-76 is not the only element that can undergo double-beta decay. Other detectors use isotopes of tellurium, xenon, neodymium, or other elements. Poon says, â€œItâ€™s important to establish that any instance of neutrinoless double-beta decay really reflects the property of the neutrino. If the process is seen in more than one element, thatâ€™s very strong evidence that the neutrino is indeed its own antiparticle.â€ ### Berkeley Lab members of the MAJORANA Collaboration include Yuen-Dat Chan, Jason Detwiler, James Loach, Ryan Martin, Alan Poon, and Kai Vetter of the Nuclear Science Division, and Mark Amman, Paul Barton, Paul Luke, and Harold Yaver of the Engineering Division. The MAJORANA Collaboration home page is at http://www.npl.washington.edu/majorana/ More about the MAJORANA DEMONSTRATOR and neutrinoless double-beta decay is at http://en.wikipedia.org/wiki/MAJORANA and at http://www.sanfordundergroundlaboratoryathomestake.org/index.php?option=com_content&view=category&layout=blog&id=18&Itemid=54 For information on another major research project at the Sanford Underground Research Laboratory, the Large Underground Xenon experiment, the most sensitive search yet for weakly interacting massive particles, or WIMPs, see http://newscenter.lbl.gov/feature-stories/2012/05/23/lux-lz/ More about the Sanford Underground Research Laboratory is at http://newscenter.lbl.gov/feature-stories/2012/05/16/surf-intro/ and at http://www.sanfordundergroundlaboratoryathomestake.org/",
    "commentLink": "https://news.ycombinator.com/item?id=40477653",
    "commentBody": "Majorana, the search for the most elusive neutrino of all (2012) (lbl.gov)106 points by bilsbie 22 hours agohidepastfavorite17 comments fch42 28 minutes agoWhat I'm missing in the article is actually the crucial point: How do you distinguish between the \"ordinary if rare\" conventional double-beta (that has reproducibly been observed for Ge76 -> Se76 + 2Î² + 2 anti-Î½) and the hypothetical neutrino-less one ? In \"ordinary\" beta decay, the (anti)neutrino takes part of the decay energy and hence the energy spectrum of the electron emitted is \"blurry\". \"ordinary double beta\" would imply the same, both of the (seen) emitted electrons should show an energy spectrum. If at least some of these double-betas were neutrinoless, the two electrons would take the entire decay energy. If you observe a lot of double-beta, you should therefore see the \"smooth\" ordinary (non-neutrinoless) spectrum ... with an excess at the top end (neutrinoless). Is that correct? I.e. we're basically trying to measure enough double beta to get an energy distribution spectrum, and then hope/expect to see a \"majorana peak\" at the top end? reply mmastrac 19 hours agoprevThe article takes about 66% of its content before it actually explains why \"Majorana\" -- from the theoretician Ettore Majorana: > So far the only known particles that are their own antiparticles are all bosons, particles that often carry force or mediate interactions, such as the photon, the pi-zero, or the Z. Ettore Majorana, a brilliant Italian theoretician who had a brief career in the 1920s and 30s but vanished mysteriously at the age of 32, was the first to propose that some fermions, particles of matter, might also be their own antiparticles. https://en.wikipedia.org/wiki/Ettore_Majorana reply omgJustTest 19 hours agoparentAs is typical of LBL, they donâ€™t also note the leading theories place majorana characteristics in a very small probability regime (particles are more and more demonstrating Dirac characteristics). Demonstration of neutrino less double beta decay would prove majorana conjectures and point to fractures in the â€œstandard model of physicsâ€ meaning new fundamental particles would be needed. In my opinion whoever measures the CvB (cosmic neutrino background) will be more compelling because it isnâ€™t a nullification result, itâ€™s a result that would tell us far more about the Big Bang than we know now. Neutrinos are hard to measure, have been the source of a lot of Nobel prizes! Disclaimer: I use to work at lbl reply dphidt 5 hours agorootparentIf there's a prior in the community, my impression (as a neutrino physicist) is that if anything it's more toward Majorana than not, in the absence of evidence either way. It is surely nicer from a theory perspective, with a (seesaw) mechanism to help explain the very light neutrino masses, and lepton number violation that helps in the case for leptogenesis as an explanation for the universe's matter-antimatter asymmetry, etc. One way I think about it is that it's pretty interesting either way: Majorana demands physics beyond the Standard Model, while Dirac would seem to suggest that lepton number is more than an accidental symmetry of the Standard Model, implying some unknown quantum number. Meanwhile, many experimental searches for neutrinoless double beta decay go on, with many new/clever ideas to carve through the quite large allowed parameter space. reply jessriedel 16 hours agorootparentprevThe CvB is the holy grail. But it is an insanely challenging detection problem. I think the (multidecade?) PTOLEMY experiment is the only serious proposal, and particle physicists I knew were pretty skeptical it could actually pull it off for SM neutrinos. https://arxiv.org/abs/1902.05508 reply SaberTail 5 hours agorootparentI used to work in neutrino physics, and I will consider myself lucky if I see a detection of the cosmic neutrino background in my lifetime (roughly the next 50 years). reply initramfs 13 hours agorootparentprevInteresting, I read about neutrinos a while back https://arxiv.org/pdf/2304.14995 https://www.universetoday.com/13052/do-advanced-civilization... (I was reminded of this recently after watching the Three Body Problem - Tencent's version, interstellar quantum communication) reply antirez 4 hours agoprevThanks to the authors for remembering in a highlighted section the disturbed genius of Ettore Majorana. He was from Catania, Sicily, where I live: if not for a few schools with his name he is hardly remembered by young generations. reply SaberTail 17 hours agoprev2012. They released their final results last year: https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.13... reply i_k_k 15 hours agoparentLEGEND is the follow-on project. https://legend-exp.org/ reply EdwardDiego 11 hours agoparentprevSo... no luck this time? But they know how to look better next time? I think? I'm bad at reading science papers. reply SaberTail 6 hours agorootparentYeah, they didn't observe the decay, but set lower limits on the half life of the decay, which translates into upper limits on a neutrino mass. Next time will mostly involve getting more germanium 76, but also improving the techniques they use to beat down backgrounds. reply dphidt 4 hours agoparentprevJust to add for reference, the strongest bounds (for any NLDBD candidate isotope) are from KamLAND-Zen using Xenon-136, also last year: https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.13.... reply smokel 13 hours agoprevAn interesting story in this context is that a research group in Delft thought they observed the Majorana particle (2018), but then it turned out they didn't (2021). https://delta.tudelft.nl/en/article/majorana-not-fraud-confi... reply SaberTail 5 hours agoparentThe more interesting one was the Klapdor-Kleingrothaus claim of observing neutrinoless double beta decay in germanium 76 in the early 2000s. That was a major impetus for the generation of double beta decay experiments like this that ran in the 2010s. The MAJORANA experiment used the same isotope and was significantly more sensitive, and pretty thoroughly excluded the half life Klapdor-Kleingrothaus claimed. reply YakBizzarro 55 minutes agoparentprevDespite the similar name, in Delft they were not looking at fundamental particles, but at quasiparticles in a solid state system. So, similar equations, but completly different physics reply aaronblohowiak 17 hours agoprev [â€“] One step closer to synthetic astrophage reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The MAJORANA DEMONSTRATOR experiment aims to determine if neutrinos are their own antiparticles by detecting neutrinoless double-beta decay, potentially challenging the Standard Model of Particle Physics.",
      "The experiment uses germanium-76 detectors and extensive shielding to minimize background noise, enhancing the chances of identifying this rare decay.",
      "Success in this experiment would offer crucial insights into neutrino mass and lepton number conservation, with the MAJORANA Collaboration potentially combining efforts with the GERDA experiment for a more advanced detector."
    ],
    "commentSummary": [
      "The article explores the search for Majorana neutrinos, particles that are their own antiparticles, as theorized by Ettore Majorana.",
      "Distinguishing between conventional double-beta decay and hypothetical neutrinoless double-beta decay is crucial, as the latter would indicate the existence of Majorana particles and challenge the Standard Model of physics.",
      "Despite extensive experiments like MAJORANA and KamLAND-Zen, no conclusive evidence has been found, but research continues with enhanced techniques and materials, aiming to detect the elusive cosmic neutrino background."
    ],
    "points": 106,
    "commentCount": 17,
    "retryCount": 0,
    "time": 1716669359
  },
  {
    "id": 40478294,
    "title": "Nissan Faces Challenges in Next-Gen LEAF Electric Vehicle Production",
    "originLink": "https://electrek.co/2024/05/24/bladeless-rooftop-wind-turbines-box-buildings/",
    "originBody": "Nissan preps for next-gen LEAF EV production, but â€˜a real challengeâ€™ awaits Peter Johnson May 24 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40478294",
    "commentBody": "Startup is about to install bladeless rooftop wind turbines on box buildings (electrek.co)105 points by peutetre 20 hours agohidepastfavorite54 comments Animats 17 hours agoThis needs a third-party evaluation. Nobody gets that much power from rooftop wind with small devices. Usually you need at least 16 square meters of intake area to get 5KW. Some similar devices with iffy claims: - EIP - encased turbine for rooftop mounting [1] - Sheerwind (active about 2014-2017) Really big funnels. [2] Critique: [3] If ducting a wind turbine would help, everyone would be doing it. [1] http://eiptechnologies.com/ [2] https://web.archive.org/web/20171221050330/http://sheerwind.... [3] https://www.youtube.com/watch?v=HtjKXb5gko0 reply bruce511 13 hours agoparentWhen we talk about solar it doesn't really matter if you want to generate 100w, 100kw or 1mw. You're pretty much using the same tech, and the pre-requisite is simple \"sunshine\". But wind is more complex. If you want to generate a lot, then you need space (to build a tower), height (higher is better) and size (bigger is MUCH better.) And wind. But if you just need a little, say 3kw, then you're not looking for the best possible outcome, you're looking for local outcome. Most of us are location bound. I want to generate energy here - because I use it here. There are constraints (noise, size, height etc.) that I live with. Sure, I've got solar, my roof is full of that. Let's stipulate that economically I'm better off adding more solar. Let's also stipulate that my roof is \"full\". I get quite a few windy days (and windy nights) a year. If I harvest 1kw/h, I'd be happy. If I generate excess I can sell it to the grid. The obvious answer is still a 3 or 5 bladed conventional wind turbine. But that is both visual, and can be noisy. Personally, I don't need it to compete economicly with solar. I don't need it to be \"perfect wind efficient\". All I need is around 3kw capacity (for 1kw output) in a residential friendly package. Solar has shown that individuals are prepared to spend capital on residential generation. And in sufficient volume to move the grid needle. I'd love to see similar opportunities for those with more wind and less sun. reply kibwen 12 hours agorootparentNote that wind is a good complement to solar, because it's largely driven by the heat from the ground rising upward, so it tends to start picking up in the afternoon/evening as solar starts to dip. reply readyman 10 hours agorootparentprevWhat is kw/h? reply _Microft 7 hours agorootparentWhat is kw/h with a lowercase w? Iâ€™m familiar with W which stands for Watt, a unit of power. Could it simply be a typo like in GPâ€™s comment who misspelled kWh? reply ericpauley 6 hours agorootparentI want a setup that generates 1 KÏ‰/H. reply perilunar 5 hours agorootparentprevThe rate of change of your power consumption? reply IshKebab 11 hours agorootparentprev> 1 kw/h Try again... reply paulryanrogers 4 hours agorootparentCan you elaborate? Some of us flunked out of EE. reply IshKebab 2 hours agorootparentIt's kWh. Kilowatts multiplied by hours, not kilowatts per hour. The analogy with units you are familiar with: watts=speed (e.g. knots), energy=distance (e.g. (nautical) miles). So a kWh of energy is kind of like saying a knot-hour. Or 1 knot for 1 hour, which equals 1 nautical mile. You can say \"I have travelled a distance of 1 knot-hour or 1 knot for an hour\". It doesn't make any sense to say \"I have travelled a distance of 1 knot/hour or 1 knot per hour\". Knot/hour would be a unit of acceleration not distance. Ok that's probably clear as mud. I also feel like I should make a power units quiz website because so many people get this wrong. reply margalabargala 1 hour agorootparentOP was not trying to say kWh. They were trying to say kWh per hour. reply ErikBjare 1 hour agorootparent1 kWh per hour is 1 kW reply __alexs 10 hours agoparentprevI spent 5 years working in wind microgeneration (but with helical turbines) and entirely agree. Rooftop solar works because it's cheap and simple to set up. Wind is not that. The structural and installation requirements result in relatively high fixed costs. To offset that you need to scale the size of the turbine, and maximise the time they spend spinning. You can only go so big on buildings and the built environment reduces your capacity factor because there's loads of buildings blocking the wind. reply gumby 2 hours agorootparentIn an urban environment is there enough updraft from \"heat island\" effects to harvest the energy? I kinda assume not else someone would have done it already, but maybe my assumption is wrong because it wasn't economic before and could be now. reply BMc2020 17 hours agoparentprevThis agrees with what little I remember. Energy you can get out depends on swept area, and these don't have much of that (different rules apply to funnel designs like this one but the concept is still applicable). Wind close to the ground is too turbulent to get much power out of as well (imagine how many times it can change from blow to suck and back in a minute). They could have solved these problems, but I didn't see anything very different at their website, just creative funneling of air through a turbine. I wish them luck though. reply klunger 10 hours agoparentprevIn 2013, I had an internship at a kind of industrial incubator and fund in Kongsberg, Norway[https://kongsberginnovasjon.no/?lang=en]. Although that was 11 years ago now, and a lot has certainly changed in the industry, physics has not. At the time, they had an explicit focus on alternative energy technologies, so recieved a lot of proposals similar to this. I do not remember the details of my analyses anymore, but I do remember that every single one of them was rejected because none of them passed a basic back-of-the-envelope plausibility evaluation. These projects basically fail because their output is poor compared to other solutions of similar or even lower cost. It is also important to consider how much energy it takes to manufacture their solution in the first place. How long does it take for them to actually become net carbon negative? Does it even happen in the lifetime of the product? Sometimes the answer is no (in which case, what is even the point?) reply vasco 9 hours agorootparentThe point might be as simple as a big building wanting reduced bills or energy independence without thinking one iota about the environment. It can also be to just signal that your big building is progressive and innovative, to attract companies to your commercial real estate. reply goda90 17 hours agoparentprevHere's another one, Ventum VX175: https://ventumdynamics.com/ Regarding what you said about ducting, I don't think that's a fair assessment. Really big turbines are the biggest bang for your buck, but they aren't exactly duct-able. And on the flip side, really big turbines can't be built in a lot of places. So the question is, does ducting help smaller scale turbines, and will placing smaller scale turbines where big turbines won't fit going to be worthwhile? reply Animats 15 hours agorootparent> So the question is, does ducting help smaller scale turbines, and will placing smaller scale turbines where big turbines won't fit going to be worthwhile? Simple ducting does help some. A group at Clarkson has been working on this. They have a wind tunnel, so they can get solid data. [1] They have a simple duct around a standard wind turbine. This gives the effect of more intake area, and they get almost twice the output power. Unclear if this is cheaper than just increasing the blade length. Many people have been down this road. There are many, many variants on experimental ducted wind turbines. Just search for \"ducted wind turbine\". There are very few installations. Here's one of the few.[2] They're demo installations on college campuses. [1] https://www.youtube.com/watch?v=EXxA-RkwuRY [2] https://www.ductedwind.com/blog reply userbinator 9 hours agoparentprevFor those who are looking for a more intuitive understanding of what 5kW is, that's 6.7HP. reply _Microft 7 hours agorootparentMore comparisons: the power of water cookers, (a single) electric stove top and fan heaters are usually in the order of 2kW (at least in Europe with 230V AC) reply quickthrowman 4 hours agorootparentprev5kW is just enough power for a 5 HP motor at 230v 3-phase (12.5A), and not quite enough power for a 5 HP motor @ 208v 3-phase (13.8A). If #14 wire was allowed for branch circuits in commercial construction, you could use those as your conductors, thatâ€™s how small these things are. NEMA motor ampacity table: https://www.galco.com/circuit/fla_rate.htm reply aorloff 11 hours agoparentprevThey also have a hurricane upgrade package. Now we're cookin with gas reply metadat 17 hours agoparentprevYes, their generation numbers are not definitively defined in TFA, not even as a concrete typical range. reply KennyBlanken 17 hours agoparentprevI was going to say the same - there was a big fad for building-top wind generators and then everyone figured out that the airflow over a building is really turbulent, which makes it pretty shit for power generation. Ask anyone who sails; trees and buildings shield a lot of wind out to surprisingly far away. The reason the big boys work well is because they are much higher above the ground where the wind is stronger and more consistent. That's also why companies are trying to make kite and blimp based generators work. Only place I've seen the rooftop turbines work was at an airport where the giant open space around the terminal buildings means winds are more even and lower to the ground. It feels like off-grid people mostly use it as a supplement for the stormy bouts where winds are often strong when solar yield is low...or as a backup in case their solar system breaks. They're happy if they meet the needs of their fridge, for example. Modern fridges use an average of less than 100W; lower if they're not self-defrosting. reply erie 15 hours agoparentprevThere has been several startups for the past decades who have tried this an disappeared afterwards.The real and legitimate research, development and improvement of wind turbines have been plagued by fad wind turbines. Fad wind turbines fly around Amazon selling big claims at breakneck speeds. reply gmokki 11 hours agorootparentI've been interested in this company that has made vertical axis wind turbines for harsh conditions for 40 years: https://windside.com/gallery/ They have very slowly started to sell to wider market. Clearly they have never aimed at being cheapest, but their advertised maintenance free installation is a big plus. And also that the models can generate electricity at wind speeds from 2m/s to 60m/s. reply zo1 11 hours agoparentprevThe evaluation just needs to be for longevity, repairability and maintenance needs/costs. The big purpose of wind for a lot of small scale installs is to augment solar for night time and/or continuous base load assistance to it, and not as a primary source of generation. I'd immediately get something that just gives me a tiny 300w on average as it means my 5kwh battery lasts 5 hours at night instead of 3 (made up numbers). That puts me soooo close to being full off grid it's not even funny. People talking about return on investment, payback periods etc are completely screwing over the uptake of solar and other non renewable sources. reply amanzi 19 hours agoprevThe PDF linked to in the article explains how it works: https://26011849.fs1.hubspotusercontent-eu1.net/hubfs/260118... Obviously, it's not bladeless - you just can't see the blades. Page 4 of the PDF explains how it works: the airfoils create a vacuum above the propeller, which then sucks air from below, which generates the power. reply sunshinesnacks 16 hours agoprevPaul Gipeâ€™s website [1] is always worth checking out when it comes to unusual wind turbine designs. He knows a ton about the history of wind energy, and lots of things have been tried before. And this NREL report [2] is also relevant. It reviews a number of rooftop wind projects. None of them met their energy goals. And the report also recommends sticking with 3rd party certified horizontal axis wind turbines (but those still underperformed because rooftops are not great for wind energyâ€¦). [1] https://wind-works.org/wind/small-wind/rooftop-and-urban-win... [2] https://www.nrel.gov/docs/fy16osti/65622.pdf reply walthamstow 19 hours agoprevThese devices are a lot like the cooling towers on ancient and modern Persian buildings https://en.m.wikipedia.org/wiki/Windcatcher reply kumarvvr 17 hours agoprevIts not \"bladeless\". Its \"no visible blades\" That aside, I do remember a different design that allows for omnidirectional wind capture. A tall funnel structure that directs wind from all directions to a turbine below the structure. It seemed like a good idea, and some installations were made. However, I think the efficiency and costs did not work out. reply userbinator 15 hours agoparentThank Dyson for popularising the \"bladeless\" term. These seem like the reverse of their fans. reply applied_heat 17 hours agoprevIâ€™ve had good results deploying both wind and solar at remote off grid sites, when there was a week of clouds due to a storm system moving through there was quite often a lot of wind and the batteries would stay fully charged. reply jes5199 15 hours agoparentwhat kind of hardware do you use to capture wind energy? Itâ€™s pretty easy to get into solar as a hobbyist but wind seems to have a higher barrier to entry (?) reply applied_heat 15 hours agorootparentSome $300 wind turbines off Ali baba that put out 300 watts or something. It was kind of like a propeller diameter 1m mounted to a little dc motor that was mostly bearings. We mounted it on a pile to a shed made of metal covered foam panels, the whole shed blew over. Guyed it down after that. reply lm28469 6 hours agorootparent300w for 1m diameter is probably the rating for the absolute best case scenario, the average could be closer to 10x less depending on the location https://solar.lowtechmagazine.com/2009/04/small-windmills-pu... reply applied_heat 2 hours agorootparentMaybe 1m was the radius, this project was more than 15 years ago. The point was instead of dead batteries during cloudy times the wind complemented nicely and the batteries were charged and our load powered. reply leecoursey 15 hours agoprevOh, dear. I read as far as \"Its generator system is a rotor-stator system with a highly efficient 5 kW permanent magnet generator\", then immediately thought of the Turbo Encabulator: https://youtu.be/Ac7G7xOG2Ag?si=WSdQIhyki2IDzqVm reply thinkcontext 19 hours agoprevAnother article says the company is claims > The scalable, â€œmotionlessâ€ wind energy unit can produce 50% more energy than rooftop solar at the same cost, said the company. https://pv-magazine-usa.com/2024/05/23/bladeless-wind-energy... reply fragmede 14 hours agoparentput solar panels on top of the wind unit reply pedalpete 18 hours agoprevI wonder if they could also use these as mounting platforms for mobile tower antennae? We have a bunch of buildings where I live that are covered in black panels for antenae, rather than competing for space, it would be nice to see these as dual use. reply quickthrowman 4 hours agoprevThese things donâ€™t generate very much power, 5kW @ 208V 3-phase is only 13.88A which means it canâ€™t even run a single 5HP motor. Itâ€™s equivalent to ~25 200w solar panels. Youâ€™d need 30 of these just to power a single 208v three phase 400A panel, and the size of building these would be installed on will typically have a 2000A or larger electrical service. Assuming it runs at full capacity for an entire year and electricity costs $0.10/kWh, it would save $4,380 a year, but obviously it wonâ€™t generating at 100% all the time. I fail to see how these would ever pay themselves back, Iâ€™d guess one of these units is between $30-50k installed, possibly more. The roof might need structural reinforcements which could push the cost higher. There will be electrical distribution equipment to transfer loads between the wind powered generators and utility power. reply numpad0 11 hours agoprevSo it's those pumpkin shaped rooftop ventilation thing with a shroud and generator? reply ElectricBoogie 18 hours agoprevI'm glad they're sticking these only on box buildings, other shapes might not work so well. reply shmerl 16 hours agoprevNext - windtraps for water. reply Tagbert 15 hours agoparentFollowed byâ€¦ stillsuits. reply jncfhnb 19 hours agoprevWhatâ€™s the meaning of a 50kW unit with a 5kW generator? reply renewiltord 19 hours agoparentYou put ten of them in a row. Click through to the PDF. \"50 kW system of 10 units occupying 50 m\" reply neilv 17 hours agoprev [â€“] Will they contribute to noise pollution? My neighborhood seems to have dramatically increasing noise pollution in the last couple years. The abuses have gotten ridiculous (and often gratuitously obnoxious) enough that I suspect backlash is imminent. Until there's serious regulation, I feel like I have to ask, since the noise environment seems to be a reckless free-for-all at the moment. reply omnimus 11 hours agoparentBy far most noise pollution in cities is due to cars. Better start with that. reply Tagbert 15 hours agoparentprevAre your neighborhood noise levels caused by wind turbines or something else? reply hampelm 17 hours agoparentprev [â€“] That is spoken about in the article. reply neilv 17 hours agorootparent [â€“] Where? I saw the word \"noiseless\" tossed out there, but could just be journalist translating some marketing copy about some aspect of the system, not the entirety of its effect on noise pollution. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nissan is gearing up for the production of its next-generation LEAF electric vehicle.",
      "Significant challenges are anticipated in this process, as noted by Peter Johnson on May 24, 2024."
    ],
    "commentSummary": [
      "A startup's proposal to install bladeless rooftop wind turbines has raised doubts about their efficiency, with critics noting that small devices often generate insufficient power compared to scalable solar energy.",
      "Effective wind energy generation requires specific conditions such as space and height, and the feasibility of bladeless turbines still needs third-party evaluation.",
      "The discussion highlights challenges in urban wind energy, including high costs, reduced efficiency due to turbulence, and practical issues like noise pollution and higher entry barriers compared to solar power."
    ],
    "points": 105,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1716675991
  },
  {
    "id": 40477604,
    "title": "Efficient and Accurate Floating-Point Summation Techniques in Rust",
    "originLink": "https://orlp.net/blog/taming-float-sums/",
    "originBody": "Taming Floating-Point Sums 2024-05-25 Suppose you have an array of floating-point numbers, and wish to sum them. You might naively think you can simply add them, e.g. in Rust: fn naive_sum(arr: &[f32]) -> f32 { let mut out = 0.0; for x in arr { out += *x; } out } This however can easily result in an arbitrarily large accumulated error. Letâ€™s try it out: naive_sum(&vec![1.0; 1_000_000]) = 1000000.0 naive_sum(&vec![1.0; 10_000_000]) = 10000000.0 naive_sum(&vec![1.0; 100_000_000]) = 16777216.0 naive_sum(&vec![1.0; 1_000_000_000]) = 16777216.0 Uh-ohâ€¦ What happened? The problem is that the next 32-bit floating-point number after 16777216 is 16777218. So when you compute 16777216 + 1, it rounds back to the nearest floating-point number with an even mantissa, which happens to be 16777216 again. Weâ€™re stuck. Luckily, there are better ways to sum an array. Pairwise summation A method thatâ€™s a bit more clever is to use pairwise summation. Instead of a completely linear sum with a single accumulator it recursively sums an array by splitting the array in half, summing the halves, and then adding the sums. fn pairwise_sum(arr: &[f32]) -> f32 { if arr.len() == 0 { return 0.0; } if arr.len() == 1 { return arr[0]; } let (first, second) = arr.split_at(arr.len() / 2); pairwise_sum(first) + pairwise_sum(second) } This is more accurate: pairwise_sum(&vec![1.0; 1_000_000]) = 1000000.0 pairwise_sum(&vec![1.0; 10_000_000]) = 10000000.0 pairwise_sum(&vec![1.0; 100_000_000]) = 100000000.0 pairwise_sum(&vec![1.0; 1_000_000_000]) = 1000000000.0 However, this is rather slow. To get a summation routine that goes as fast as possible while still being reasonably accurate we should not recurse down all the way to length-1 arrays, as this gives too much call overhead. We can still use our naive sum for small sizes, and only recurse on large sizes. This does make our worst-case error worse by a constant factor, but in turn makes the pairwise sum almost as fast as a naive sum. By choosing the splitpoint as a multiple of 256 we ensure that the base case in the recursion always has exactly 256 elements except on the very last block. This makes sure we use the most optimal reduction and always correctly predict the loop condition. This small detail ended up improving the throughput by 40% for large arrays! fn block_pairwise_sum(arr: &[f32]) -> f32 { if arr.len() > 256 { let split = (arr.len() / 2).next_multiple_of(256); let (first, second) = arr.split_at(split); block_pairwise_sum(first) + block_pairwise_sum(second) } else { naive_sum(arr) } } Kahan summation The worst-case round-off error of naive summation scales with ð‘‚ ( ð‘› ðœ– ) O(nÏµ) when summing ð‘› n elements, where ðœ– Ïµ is the machine epsilon of your floating-point type (here 2 âˆ’ 24 2âˆ’24). Pairwise summation improves this to ð‘‚ ( ( log â¡ ð‘› ) ðœ– + ð‘› ðœ– 2 ) O((logn)Ïµ+nÏµ2). However, Kahan summation improves this further to ð‘‚ ( ð‘› ðœ– 2 ) O(nÏµ2), eliminating the ðœ– Ïµ term entirely, leaving only the ðœ– 2 Ïµ2 term which is negligible unless you sum a very large amount of numbers. All of these bounds scale with âˆ‘ ð‘– âˆ£ ð‘¥ ð‘– âˆ£ âˆ‘iâˆ£xiâˆ£, so the worst-case absolute error bound is still quadratic in terms of ð‘› n even for Kahan summation. In practice all summation algorithms do significantly better than their worst-case bounds, as in most scenarios the errors do not exclusively round up or down, but cancel each other out on average. pub fn kahan_sum(arr: &[f32]) -> f32 { let mut sum = 0.0; let mut c = 0.0; for x in arr { let y = *x - c; let t = sum + y; c = (t - sum) - y; sum = t; } sum } The Kahan summation works by maintaining the sum in two registers, the actual bulk sum and a small error correcting term ð‘ c. If you were using infinitely precise arithmetic ð‘ c would always be zero, but with floating-point it might not be. The downside is that each number now takes four operations to add to the sum instead of just one. To mitigate this we can do something similar to what we did with the pairwise summation. We can first accumulate blocks into sums naively before combining the block sums with Kaham summation to reduce overhead at the cost of accuracy: pub fn block_kahan_sum(arr: &[f32]) -> f32 { let mut sum = 0.0; let mut c = 0.0; for chunk in arr.chunks(256) { let x = naive_sum(chunk); let y = x - c; let t = sum + y; c = (t - sum) - y; sum = t; } sum } Exact summation I know of at least two general methods to produce the correctly-rounded sum of a sequence of floating-point numbers. That is, it logically computes the sum with infinite precision before rounding it back to a floating-point value at the end. The first method is based on the 2Sum primitive which is an error-free transform from two numbers ð‘¥ , ð‘¦ x,y to ð‘  , ð‘¡ s,t such that ð‘¥ + ð‘¦ = ð‘  + ð‘¡ x+y=s+t, where ð‘¡ t is a small error. By applying this repeatedly until the errors vanish you can get a correctly-rounded sum. Keeping track of what to add in what order can be tricky, and the worst-case requires ð‘‚ ( ð‘› 2 ) O(n2) additions to make all the terms vanish. This is whatâ€™s implemented in Pythonâ€™s math.fsum and in the Rust crate fsum which use extra memory to keep the partial sums around. The accurate crate also implements this using in-place mutation in i_fast_sum_in_place. Another method is to keep a large buffer of integers around, one per exponent. Then when adding a floating-point number you decompose it into a an exponent and mantissa, and add the mantissa to the corresponding integer in the buffer. If the integer buf[i] overflows you increment the integer in buf[i + w], where w is the width of your integer. This can actually compute a completely exact sum, without any rounding at all, and is effectively just an overly permissive representation of a fixed-point number optimized for accumulating floats. This latter method is ð‘‚ ( ð‘› ) O(n) time, but uses a large but constant amount of memory ( â‰ˆ â‰ˆ 1 KB for f32, â‰ˆ â‰ˆ 16 KB for f64). An advantage of this method is that itâ€™s also an online algorithm - both adding a number to the sum and getting the current total are amortized ð‘‚ ( 1 ) O(1). A variant of this method is implemented in the accurate crate as OnlineExactSum crate which uses floats instead of integers for the buffer. Unleashing the compiler Besides accuracy, there is another problem with naive_sum. The Rust compiler is not allowed to reorder floating-point additions, because floating-point addition is not associative. So it cannot autovectorize the naive_sum to use SIMD instructions to compute the sum, nor use instruction-level parallelism. To solve this there are compiler intrinsics in Rust that do float sums while allowing associativity, such as std::intrinsics::fadd_fast. However, these instructions are incredibly dangerous, as they assume that both the input and output are finite numbers (no infinities, no NaNs), or otherwise they are undefined behavior. This functionally makes them unusable, as only in the most restricted scenarios when computing a sum do you know that all inputs are finite numbers, and that their sum cannot overflow. I recently uttered my annoyance with these operators to Ben Kimock, and together we proposed (and he implemented) a new set of operators: std::intrinsics::fadd_algebraic and friends. I proposed we call the operators algebraic, as they allow (in theory) any transformation that is justified by real algebra. For example, substituting ð‘¥ âˆ’ ð‘¥ â†’ 0 xâˆ’xâ†’0, ð‘ ð‘¥ + ð‘ ð‘¦ â†’ ð‘ ( ð‘¥ + ð‘¦ ) cx+cyâ†’c(x+y), or ð‘¥ 6 â†’ ( ð‘¥ 2 ) 3 . x6â†’(x2)3. In general these operators are treated as-if they are done using real numbers, and can map to any set of floating-point instructions that would be equivalent to the original expression, assuming the floating-point instructions would be exact. Note that the real numbers do not contain NaNs or infinities, so these operators assume those do not exist for the validity of transformations, however it is not undefined behavior when you do encounter those values. They also allow fused multiply-add instructions to be generated, as under real arithmetic fma â¡ ( ð‘Ž , ð‘ , ð‘ ) = ð‘Ž ð‘ + ð‘ . fma(a,b,c)=ab+c. Using those new instructions it is trivial to generate an autovectorized sum: #![allow(internal_features)] #![feature(core_intrinsics)] use std::intrinsics::fadd_algebraic; fn naive_sum_autovec(arr: &[f32]) -> f32 { let mut out = 0.0; for x in arr { out = fadd_algebraic(out, *x); } out } If we compile with -C target-cpu=broadwell we see that the compiler automatically generated the following tight loop for us, using 4 accumulators and AVX2 instructions: .LBB0_5: vaddps ymm0, ymm0, ymmword ptr [rdi + 4*r8] vaddps ymm1, ymm1, ymmword ptr [rdi + 4*r8 + 32] vaddps ymm2, ymm2, ymmword ptr [rdi + 4*r8 + 64] vaddps ymm3, ymm3, ymmword ptr [rdi + 4*r8 + 96] add r8, 32 cmp rdx, r8 jne .LBB0_5 This will process 128 bytes of floating-point data (so 32 elements) in 7 instructions. Additionally, all the vaddps instructions are independent of each other as they accumulate to different registers. If we analyze this with uiCA we see that it estimates the above loop to take 4 cycles to complete, processing 32 bytes / cycle. At 4GHz thatâ€™s up to 128GB/s! Note that thatâ€™s way above what my machineâ€™s RAM bandwidth is, so you will only achieve that speed when summing data that is already in cache. With this in mind we can also easily define block_pairwise_sum_autovec and block_kahan_sum_autovec by replacing their calls to naive_sum with naive_sum_autovec. Accuracy and speed Letâ€™s take a look at how the different summation methods compare. As a relatively arbitrary benchmark, letâ€™s sum 100,000 random floats ranging from -100,000 to +100,000. This is 400 KB worth of data, so it still fits in cache on my AMD Threadripper 2950x. All the code is available on Github. Compiled with RUSTFLAGS=-C target-cpu=native and --release I get the following results: Algorithm Throughput Mean absolute error naive 5.5 GB/s 71.796 pairwise 0.9 GB/s 1.5528 kahan 1.4 GB/s 0.2229 block_pairwise 5.8 GB/s 3.8597 block_kahan 5.9 GB/s 4.2184 naive_autovec 118.6 GB/s 14.538 block_pairwise_autovec 71.7 GB/s 1.6132 block_kahan_autovec 98.0 GB/s 1.2306 crate_accurate_buffer 1.1 GB/s 0.0015 crate_accurate_inplace 1.9 GB/s 0.0015 crate_fsum 1.2 GB/s 0.0000 The reason the accurate crate has a non-zero absolute error is because it currently does not implement rounding to nearest correctly, so it can be off by one unit in the last place for the final result. First Iâ€™d like to note that thereâ€™s more than a 100x performance difference between the fastest and slowest method. For summing an array! Now this might not be entirely fair as the slowest methods are computing something significantly harder, but thereâ€™s still a 20x performance difference between a seemingly reasonable naive implementation and the fastest one. We find that in general the _autovec methods that use fadd_algebraic are faster and more accurate than the ones using regular floating-point addition. The reason theyâ€™re more accurate as well is the same reason a pairwise sum is more accurate: any reordering of the additions is better as the default long-chain-of-additions is already the worst case for accuracy in a sum. Limiting ourselves to Pareto-optimal choices we get the following four implementations: Algorithm Throughput Mean absolute error naive_autovec 118.6 GB/s 14.538 block_kahan_autovec 98.0 GB/s 1.2306 crate_accurate_inplace 1.9 GB/s 0.0015 crate_fsum 1.2 GB/s 0.0000 Note that implementation differences can be quite impactful, and there are likely dozens more methods of compensated summing I did not compare here. For most cases I think block_kahan_autovec wins here, having good accuracy (that doesnâ€™t degenerate with larger inputs) at nearly the maximum speed. For most applications the extra accuracy from the correctly-rounded sums is unnecessary, and they are 50-100x slower. By splitting the loop up into an explicit remainder plus a tight loop of 256-element sums we can squeeze out a bit more performance, and avoid a couple floating-point ops for the last chunk: #![allow(internal_features)] #![feature(core_intrinsics)] use std::intrinsics::fadd_algebraic; fn sum_block(arr: &[f32]) -> f32 { arr.iter().fold(0.0, |x, y| fadd_algebraic(x, *y)) } pub fn sum_orlp(arr: &[f32]) -> f32 { let mut chunks = arr.chunks_exact(256); let mut sum = 0.0; let mut c = 0.0; for chunk in &mut chunks { let y = sum_block(chunk) - c; let t = sum + y; c = (t - sum) - y; sum = t; } sum + (sum_block(chunks.remainder()) - c) } Algorithm Throughput Mean absolute error sum_orlp 112.2 GB/s 1.2306 You can of course tweak the number 256, I found that using 128 was â‰ˆ â‰ˆ 20% slower, and that 512 didnâ€™t really improve performance but did cost accuracy. Conclusion I think the fadd_algebraic and similar algebraic intrinsics are very useful for achieving high-speed floating-point routines, and that other languages should add them as well. A global -ffast-math is not good enough, as weâ€™ve seen above the best implementation was a hybrid between automatically optimized math for speed, and manually implemented non-associative compensated operations. Finally, if you are using LLVM, beware of -ffast-math. It is undefined behavior to produce a NaN or infinity while that flag is set in LLVM. I have no idea why they chose this hardcore stance which makes virtually every program that uses it unsound. If you are targetting LLVM with your language, avoid the nnan and ninf fast-math flags.",
    "commentLink": "https://news.ycombinator.com/item?id=40477604",
    "commentBody": "Taming floating-point sums (orlp.net)105 points by todsacerdoti 22 hours agohidepastfavorite49 comments radford-neal 2 hours agoExact addition using accumulators has progressed since the work of Zhu and Hayes in 2010. See my paper at https://arxiv.org/abs/1505.05571 (repository at https://gitlab.com/radfordneal/xsum), which is used in the Julia xsum package (https://docs.juliahub.com/General/Xsum/stable/). There's also recent work by Marko Lange at https://web.archive.org/web/20220616031105id_/https://dl.acm... I think these methods are probably faster than the exact methods you benchmark. reply Infinity315 20 hours agoprevA method which this article doesn't mention is stochastic rounding or probabilistic rounding. Rather than striving for exact values for every computation, we make it so that the expected value is exact. For example, suppose our number system was restricted to the integers and we have incoming value 1.1, with stochastic rounding we'd round down to 1 90% of the time and 2 10% of the time giving an expected value of 1.1! Further reading: https://nhigham.com/2020/07/07/what-is-stochastic-rounding/ reply tzs 19 hours agoparentIt's not really related, but that reminds me of how some games handled slow moving objects on the Mattel Intellivision console. Your code that runs every frame to update the graphics logically wants to do something like this: X += Vx Y += Vy where (X, Y) is the location of the object at the start of the frame, and (Vx, Vy) is x and y velocities of the object in pixels/frame. To allow for velocities that aren't an integer number of pixels per frame and that are slower than 1 pixel per frame you'd want to actually store X in a fixed point format, say (Xi, Xf) where Xi is the integer part of the X position, and Xf is the fractional part times 256, so X = Xi + Xf/256. Similarly for Y. The object only actually moves on the screen when Xi or Yi changes. Similarly velocity would also be in that format: Vx = Vxi + Vxf/256, and similar for Vy. With that, the position update in your loop would be something like this: Xf += Vxf if that wrapped Xi += 1 Xi += Vxi and similar for Y. For each object you end up needing 8 bytes (1 byte for each of Xi, Xf, Yi, Yf, Vxi, Vxf, Vyi, Vyf). That doesn't sound like much but the Intellivision only had something like 240 bytes in the console available. (If you couldn't get your RAM requirements down to that it was possible to have extra RAM in the cartridge but that would raise the cost). So someone figured out that you didn't actually need to store Xf and Yf. Just generate then at random as needed! The loop then becomes something like this: rb = random_unsigned_byte() if Vxf + rb wraps Xi += 1 Xi += Vxi and similar for Y. That turns out to work quite reasonably. Essentially it is interpreting Vxf as meaning that the object has a Vxf/256 chance of crossing a pixel boundary on a given frame. Thinking of it that way then suggests getting rid of the addition of the random byte with a wrap check and just doing a compare instead: if Vxf > random_unsigned_byte() Xi += 1 Xi += Vxi and similar for Y. Net result: we've cut the RAM for storing position and velocity from 8 bytes per object to 6, at the cost of needing to generate 2 random bytes per object per frame. reply teo_zero 9 hours agorootparentInteresting. I know this is a purely academic question as these constraints are something of the past, but was it really necessary to have 16 bits for the velocity? Was the ratio between the quickest and the slowest objects more than 256 times? reply kevin_thibedeau 3 hours agorootparentOn 8-bit micros without a barrel shifter you'd naturally want to constrain number formats to byte boundaries. Much better to have excess fractional precision than deal with extra bit twiddling. Even with 16-bit Intellivision, the scarcity of RAM would drive the use of the smallest practical representation. reply orlp 20 hours agoparentprevInteresting, I haven't seen that before in the context of numerics. It is used all the time however in audio and image processing, where it is called dithering. reply magicalhippo 15 hours agoparentprevIsn't this essentially what dithering in ADCs[1][2] is all about? [1]: https://www.allaboutcircuits.com/technical-articles/what-is-... [2]: https://www.analog.com/en/resources/analog-dialogue/articles... reply vlovich123 19 hours agoparentprevDoesn't that require a call to generate a random number for every floating point number you encounter? That seems expensive... reply KMnO4 19 hours agorootparentA lot of hardware has built in RNGs, but even using a software algorithm (eg Xorshift) is extremely inexpensive. Also, sometimes youâ€™re not limited by processing speed, but by the destination data structure (eg quantized to integers). https://en.wikipedia.org/wiki/Xorshift reply vlovich123 18 hours agorootparentI'm aware of fast RNGs, but even compared to HW floating point operations, I believe they're still more expensive than Khan summation. HW circuits maybe could do well. I see that most of the interest is around LLMs and doing quantized sums (gathering from the fact that Intel has shipped this in their accelerator), but this came up in the WiFi positioning code I was working on 10 years ago (we were using \"classical\" f64). reply teo_zero 9 hours agoprevI think TFA is too quick to dismiss the fadd_fast intrinsic as \"incredibly dangerous\". In many cases you do know that your numbers are not infinities nor NaNs. I'd be curious to see the performance of hypothetical block_pairwise_addfast and block_kahan_addfast. reply SuchAnonMuchWow 9 hours agoparentIt doesn't really makes sense for kahan summation, as the compiler would just make it similar to a naive summation because the errors terms would be zero under the assumptions of fadd_fast. 2sum would also break. This is exactly what you are loosing when using fadd_fast: fine control over the errors terms of floating point operations that do matter in a lot of cases. An other thing you are loosing is reproducibility: depending on the machine, compiler version, etc, your program will compute differently and for example may switch from linear to quadratic errors terms when you recompile. It could be the difference between a numerical algorithm converging or not, this kind of things. reply nsajko 20 hours agoprevI recommend the \"Handbook of Floating-point Arithmetic\" if this piques interest. I think it's freely available on HAL. reply greenyoda 20 hours agoparentI found the link to it on HAL, but clicking \"Consult the full text\" only seems download the table of contents and preface: https://hal.science/hal-01766584 A new copy costs $112 on Amazon: https://www.amazon.com/Handbook-Floating-Point-Arithmetic-Je... reply ashpil 19 hours agoprevAnother alternative that the author omitted is just casting everything to doubles and summing naively (or vectorized) in double precision, then casting the final result back to a float. Would be curious to see how this compares to the other methods and whether itâ€™s on the Pareto frontier. reply touisteur 0 minutes agoparentOn some archs, e.g. non A/H100 (and non A30) NVIDIA GPUs this is a 1:64 slow-down. Avoiding double precision is crucial there... reply orlp 19 hours agoparentprevI omitted this because you only have this option for f32, not for f64. I only really chose f32 as the focus point of my article because it makes the numbers a bit more readable. That said, I should have included it, because it is on the Pareto frontier. On my machine it is ~28.9 GB/s, with 0 error (note that this doesn't mean it always produces a correctly-rounded sum, just in this benchmark test input). I'll add it to the article tomorrow or the day after. reply gpderetta 12 hours agorootparentOn x86 you have the option of using 80 bit long doubles for the accumulator. Performance is till quite decent. Not sure if rust supports them though. reply clausecker 7 hours agorootparentYou don't get SIMD with this approach though, so it's about a quarter of the speed of using vectorized arithmetic (assuming an AVX vector of doubles). reply bee_rider 19 hours agorootparentprevDoes rust have float128 support? This is probably memory bound anyway, so software (rather than hardware) support might be fine(?). reply LegionMammal978 18 hours agorootparentNo, it doesn't. Regardless, without hardware support, adding together intermediate f128s would basically be the same as Kahan summation, except performing even more work to convert the representations around. reply zokier 12 hours agorootparentThere is some support behind feature flag: https://doc.rust-lang.org/nightly/std/primitive.f128.html reply kardos 17 hours agoprevWhy is pairwise summation 1/5th as fast as naive? I would expect these to be essentially the same speed, there is only one more addition and a logic operation which is surely negligible .. reply pixelesque 17 hours agoparentIt's a lot more asm instructions than the tight loop of the naive one, as it's got to track more state (working out the middle of the slice, etc)... https://godbolt.org/z/917o7oT8r reply kardos 17 hours agorootparentAha. So it could be optimized into two tight loops. The linked wikipedia on pairwise says the numpy implementation is same speed as naive reply orlp 10 hours agorootparentNumpy also uses blocked pairwise summation, with a block size of 128: https://github.com/numpy/numpy/blob/a6e9dc7152098182b45ecd6e... . reply kardos 17 hours agoprevHow does it compare to converting each number to a large fixed-point integer (implemented as N 64-bit integers), summing them with exact integer math (order-invariant), and converting back to floating point at the end? The sum part can be done with AVX-512 [1] if N=8, and N=8 is probably enough for a lot of real world summations. The conversion back to floating point at the end is only done once so not very costly. The conversion to fixed point is probably the worst part. Is there a faster way to do it than a loop that extracts one 64-bit integer per iteration? If not we could convert several input numbers at a time with SIMD. But it would be nifty to be able to convert one double to N integers with SIMD instead of a loop. [1] http://www.numberworld.org/y-cruncher/internals/addition.htm... reply moonchild 16 hours agoparentsee xsum https://gitlab.com/radfordneal/xsum reply kardos 55 minutes agorootparentThanks! Yes this is exactly it. Interesting about the choice of 32 bits for carries. N=67 is pretty high. I suspect N could be tuned down significantly depending on the problem. Eg global sums in geophysics models -- the range of values being summed does not span the full double range. But that would require analysis to decide about, while the full sized superaccumulator works directly. I wonder how it stacks up in terms of performance w/r/t the methods in the blog post reply zokier 12 hours agoparentprevN=5 should cover easily single precision float range. Doubles are more tricky, you'd need N=33 reply kardos 51 minutes agorootparentAgree if we need exact for any range of inputs. It should be possible to get by with fewer for real life problems, for ex, https://www.sciencedirect.com/science/article/abs/pii/S01678... reply RhysU 8 hours agoprevA extension of the article showing the impact of pathological input for each algorithm would be interesting. reply DeathArrow 12 hours agoprevUse doubles, use Kahan summation, use 2Sum algo, use larger precision floating point library? reply janwas 56 minutes agoparent+1 for TwoSum [1]. To expand on that: Kahan summation is an approximation which is a bit cheaper, but not great if some inputs can also be negative. That's because it is basically FastTwoSum(a,b) in a loop, which only works if the exponent of a >= that of b. TwoSum removes this requirement and is not that much more expensive. [1] https://en.wikipedia.org/wiki/2Sum reply floxy 17 hours agoprevSeems like there is a rust priority queue (https://doc.rust-lang.org/std/collections/binary_heap/index....). Would be interesting to see a version where you pop off the two smallest values, and push the sum back, until there is only one element left. reply aardvark179 17 hours agoparentThat works just great if your numbers are positive, but if they are both positive and negative, and in almost but not quite equal pairings it will fail to give the best answer even if you prioritise by magnitude. reply recursive 3 hours agorootparentIf it works for positives, then you can add all the positives in one bin, add all the negatives in one bin, and finish off with a single subtraction. reply caturopath 20 hours agoprevThe motivating example is a mess. 15_000_000 would have been a less distracting example, as this one has more-visible problems unrelated to the problem they're trying to solve. (Further, with default options, the opening example won't have the result shown: it will crash your program.) reply orlp 20 hours agoparentI don't follow. Why is 15_000_000 less distracting? What problems unrelated to what we're trying to solve? And what 'default options' are you referring to? reply exmadscientist 19 hours agorootparentThe motivating examples read like nonsense to me. (I don't really speak Rust, but I think I'm reading them correctly? I don't know.) They seem to be saying that 1 + 1,000,000 = 1,000,000; or 1 + 100,000,000 is 16,777,216? With no remark? That's not right even for 32-bit floats. reply orlp 19 hours agorootparentvec![1.0; 1_000_000_000] is Rust notation for an array that contains 1.0 one billion times. I can understand it's a bit confusing/frustrating if you're unfamiliar with Rust syntax, sorry. reply exmadscientist 19 hours agorootparentThat makes things make a lot more sense, thanks! Kind of unfortunate that that syntax is so trivial to misread, but it is what it is. reply caturopath 17 hours agorootparentprevSorry, I misread the ; as a ,. reply screcth 19 hours agoprevYou could also use SIMD to compute N independent Kahan sums in parallel and reduce them at the end. reply orlp 19 hours agoparentI tried this, it was the same speed as orlp_sum with worse accuracy. reply RhysU 8 hours agorootparentHow was the final reduction performed? Also Kahan? reply orlp 8 hours agorootparentYes, although to be fair I did discard the c values for the final reduction I perhaps should've incorporated somehow. The code from the blog post is all on Github, feel free to try and add/benchmark it yourself: https://github.com/orlp/sum-bench/. reply rwmj 11 hours agoprev [â€“] Isn't sorting (smallest first) then summing another method, distinct from the ones given? reply anonymoushn 5 hours agoparent [â€“] If you're going to do something like this, it seems like the TFA's suggestion of bucketizing by exponent and having one accumulator per exponent is cheaper (it doesn't require you to sort \"all the way\") and more correct (e.g. the input of a billion 1s was already sorted, but naively computing the sum gave an incorrect result). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Summing floating-point numbers naively can lead to significant rounding errors, especially with large arrays; methods like pairwise summation and Kahan summation improve accuracy but vary in speed.",
      "Rust's compiler limitations in reordering floating-point additions hinder autovectorization, but intrinsics like `std::intrinsics::fadd_fast` and `fadd_algebraic` enable efficient summation with AVX2 instructions.",
      "Benchmarking on an AMD Threadripper 2950x shows that autovectorized methods using `fadd_algebraic` are both fast and accurate, with Pareto-optimal implementations being `naive_autovec`, `block_kahan_autovec`, and `crate_accurate_inplace`."
    ],
    "commentSummary": [
      "The discussion focuses on improving the accuracy of floating-point summation, highlighting advancements by Radford Neal and Marko Lange in exact addition using accumulators, and stochastic rounding by Infinity315.",
      "Various methods such as Kahan summation, pairwise summation, converting to fixed-point integers, and the xsum library are evaluated for their efficiency and accuracy, with practical applications like geophysics models considered.",
      "The use of Rust's priority queue and SIMD (Single Instruction, Multiple Data) for parallel Kahan sums is debated, addressing concerns about accuracy and performance, alongside techniques like sorting versus bucketizing numbers by exponent for efficient summation."
    ],
    "points": 105,
    "commentCount": 49,
    "retryCount": 0,
    "time": 1716668918
  }
]
