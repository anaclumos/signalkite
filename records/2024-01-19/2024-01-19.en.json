[
  {
    "id": 39043871,
    "title": "The Demise of Ello: A Disappointing End for an Ad-Free Social Network",
    "originLink": "https://waxy.org/2024/01/the-quiet-death-of-ellos-big-dreams/",
    "originBody": "The Quiet Death of Elloâ€™s Big Dreams Posted January 18, 2024January 18, 2024 by Andy Baio Ello launched on August 7, 2014 with big dreams and big promises, a new social network defined by what it wouldnâ€™t do. They laid it all out in a manifesto, right on their homepage: Your social network is owned by advertisers. Every post you share, every friend you make and every link you follow is tracked, recorded and converted into data. Advertisers buy your data so they can show you more ads. You are the product thatâ€™s bought and sold. We believe there is a better way. We believe in audacity. We believe in beauty, simplicity and transparency. We believe that the people who make things and the people who use them should be in partnership. We believe a social network can be a tool for empowerment. Not a tool to deceive, coerce and manipulate â€” but a place to connect, create and celebrate life. You are not a product. From its launch, Ello defined itself as an alternative to ad-driven social networks like Twitter and Facebook. â€œYou are not a product.â€ (The â€œI Disagreeâ€ button linked to Facebookâ€™s privacy page.) Iâ€™d link to that manifesto on Elloâ€™s site, but I canâ€™t, because Ello is dead. In June 2023, the servers just started returning errors, making nine years of member contributions inaccessible, apparently forever â€” every post, artwork, song, portfolio, and the community built there was gone in an instant. How did this happen? What happened between the idealistic manifesto above and the sudden shutdown? Itâ€™s a story so old and familiar, I predicted it shortly after Ello launched. Elloâ€™s Funding and Launch Ello, for those who donâ€™t remember, described itself as a â€œsimple, beautiful, and ad-free social network created by a small group of artists and designers.â€ It launched with a distinctly minimalist monochrome interface and an even more minimalist set of features. Like Diaspora and App.net before it, Ello partly defined itself by its opposition to the exploitive business models and content moderation practices of major social networks, so quickly found itself deluged by people fleeing Facebook and dubbed by media outlets as an â€œanti-Facebookâ€ or â€œFacebook killer,â€ something the Ello team never intended it to be. It was an uncomfortable balancing act, but they leaned into the publicity, at least for a while. Elloâ€™s invite-only beta In September 2014, one month after it opened its invite-only beta, I wrote a post about Ello on Ello. Digging through SEC filings, I discovered that the newly-launched indie social network had taken nearly half a million in seed funding from a venture capital firm, which seemed counter to its indie manifesto. Since nobody else mentioned the funding, including Ello themselves, I wrote about it. Hereâ€™s what I wrote: Building something like Ello costs money. They have a team of at least seven people, and have worked on it for months. That doesnâ€™t come cheap. The About section makes it seem like Ello was built independently, a group of artists making something for themselves, presumably funded by volunteer effort and maybe a seed investment from Ello president and CEO Paul Budnitz, who also founded Kidrobot and Budnitz Bicycles. But a little digging shows a much more predictable source: they took a $435,000 round of seed funding in January from FreshTracks Capital, a Vermont-based VC firm that announced the deal in March. Why is this a problem? The Ello founders are positioning it as an alternative to other social networks â€” they wonâ€™t sell your data or show you ads. â€œYou are not the product.â€ If they were independently-funded and run as some sort of co-op, bootstrapped until profitable, maybe thatâ€™s plausible. Hard, but possible. But VCs donâ€™t give money out of goodwill, and taking VC funding â€” even seed funding â€” creates outside pressures that shape the inevitable direction of a company. Before they opened their doors, Ello became hooked on an unsustainable funding model â€” taking cash from VCs â€” and will almost certainly take a much larger Series A round once that $435,000 dries up. (Which, at their current burn rate, should be in a couple months.) And theyâ€™ll have no trouble getting it. Thereâ€™s a lot of money out there right now, and it will be extremely tempting to take it, especially if refusing it would mean closure or layoffs. The problem, of course, is that VCs arenâ€™t like Kickstarter backers, or even like angel investors. Kickstarter or Patreon backers just want the thing being made. Angel investors may have other reasons to invest beyond equity: fame, insider access, or maybe just the joy of helping something exist. VCs may invest in things they think are interesting or want to exist, but they primarily invest money in startups to get a return on their investment, on behalf of their limited partners. That return usually takes the form of an exit: an acquisition or an IPO. Unless they have a very unique relationship with their investors, Ello will inevitably be pushed towards profitability and an exit, even if it compromises their current values. Sometimes, this push comes subtly in the form of advice and questions in emails, phone calls, and chats over coffee. Sometimes, as more direct pressure from the board. (FreshTracksâ€™ Managing Director sits on their board.) Or, if things go bad, by replacing the founders. The Ello team knows that how a startup is funded shapes how it behaves. They spend a good chunk of their About pages talking about how theyâ€™re not going to make money (not ads or selling your data), and a little bit about how they hope to (paid premium features). I hope theyâ€™re right â€” itâ€™d be great to have more startups that arenâ€™t reliant on ads. But they completely fail to disclose how Ello is being funded now, which matters just as much, if not more, as any future revenue plans. I love seeing people build new stuff. More people trying to build crazy experimental communities on the Internet is a very good thing. And nothingâ€™s more audacious than trying to build a new social network. Social networks become the glue that connect people together â€” the foundation for friendships, relationships, and new works of creative expression. Building a social network is like opening the doors to a huge party and inviting everyone in. Without a way to get your stuff out, shutting down a social network is like locking the door and burning the place down. At the moment, Ello is a free, closed-source social network, with no export tools or an API, fueled by venture capital and a loose plan for paid premium features. I think itâ€™s fair to be skeptical. Like everyone else here, I hope Ello can stick to their principles, resist outside pressure, fight market forces, and find a unique and sustainable niche. Letâ€™s hope their investors feel the same way. The Founders Respond That post quickly blew up on Ello, and then went far beyond it, with coverage in articles from The Verge, The Guardian, VICE, The Atlantic, and Business Insider, among others. Elloâ€™s CEO, co-founders, and investors dismissed the concerns I raised, starting with co-founder and CEO Paul Budnitz, who told Betabeat it was â€œsilly.â€ â€œIn fact, Ello is controlled executively by its 7 founders, who own a majority share in the company,â€ wrote Betabeatâ€™s Jack Smith IV. â€œThey say that the cynical claim that theyâ€™ll sell out eventually, or that anyone can tell them what to do, is ridiculous.â€ Co-founder Todd Berger laughed at a GigaOm writer who asked him about my post. â€œThereâ€™s seven founders and we own 82 to 84 percent of the company, so we can do whatever the hell we want,â€ Berger said. â€œWeâ€™re not going to sell out our soul to grow our company,â€ continued Berger. â€œMaybe itâ€™s hard to believe.â€ I followed up with a second Ello post: Iâ€™ve received a dozen emails in the last day and a half from journalists looking for quotes about Ello. I didnâ€™t reply to any of them. I have no interest in being the anti-Ello poster boy, for one main reason: I think Elloâ€™s pretty neat, and I want them to succeed. Like I said in my post, more experimentation with online communities is a very good thing. Weâ€™ll only break away from the dominant players by trying new crazy shit, and I think it should be applauded. (And, yes, I even like the design.) But I think taking VC was a bad idea that works against their ethos, and will inevitably lead to a much larger Series A by yearâ€™s end. I think the intentions of the team are pure, and they genuinely believe in what theyâ€™re building. But Iâ€™m not sure intentions matter unless they can wean themselves off outside funding. I really, really hope their revenue plan works out, and quickly. Series A and the PBC One month later, Ello announced theyâ€™d raised significantly more money: a $5.5 million Series A round co-led by TechStars and Foundry Group, who took a board seat, with participation from FreshTracks Capital, who already sat on the board. Coinciding with this funding, and perhaps anticipating the backlash, Ello also announced they had converted the company to a Public Benefit Corporation. In a public letter signed by their founders and investors, they wrote: There has been some speculation in the press since our launch that Ello will someday be forced to allow paid ads on our social network. With virtually everybody else relying on ads to make money, some members of the tech elite are finding it hard to imagine there is a better way. But 2014 is not 2004, and the world has changed. Effectively, Ello would be a for-profit corporation required to pursue social good as part of its charter, instead of solely maximizing shareholder value. Unlike a B Corp certification, this would enshrine their values in their legal structure, which is a pretty big deal. They were the most notable technology company to form as a PBC until that point, preceding Kickstarterâ€™s conversion by nearly a year. A dedicated page on their site explained the significance of the PBC, and the charter they were now bound by: To assure that Ello always remains ad-free, Ello converted to a Public Benefit Corporation (PBC). A Benefit Corporation is a new kind of for-profit company in the USA that exists to produce a benefit for society as a whole â€” not just to make money for its investors. The Ello PBC charter states in the strongest legal terms possible that: Ello shall never make money from selling ads; Ello shall never make money from selling user data; and In the event that Ello is ever sold, the new owners will have to comply by these terms. Ello exists for the benefit of the creative community, and we will never serve ads or sell personal data. The signatures from the PDF of their PBC letter This was a commendable change, though somewhere along the way, all the public debate about raising professional money and profit maximization became solely about switching to a paid advertising model and selling user data. This was a straw man argument that was easier to knock down. But there are many, many ways for a social network to become worse for their users than running ads. My concern wasnâ€™t that Ello would start running paid ads. I donâ€™t even mind ads, as long as theyâ€™re done thoughtfully and with privacy in mind. (I ran ads from The Deck here for years.) I was worried that, by taking outside funding, Elloâ€™s values were no longer fully-aligned with the community: they were aligned with their investors. In time, given more money and more pressure, they would be inclined to do something the community, or even the original founders, didnâ€™t want to do. Series B and CEO Changes In April 2015, six months after their Series A, Ello took another $5 million in a Series B round from their previous investors, giving a board seat to TechStars, and bringing their total raised to $11M. Later that year, in December, Budnitz wrote a new post on Ello looking back on their first year and looking ahead to 2016: This past week I gave a few interviews to online news organizations. One of the journalists scoffed when I told him that Ello is built on principles we believe in, and that in 2015 we did everything we could to grow slowly. Rather than sell out and make another giant network the world doesnâ€™t need, we decided to take our time to build the beautiful and inspiring place we have today. I felt sad for the guy. Itâ€™s awful going through life never believing in anything. So in the spirit of the New Year, and because it was clear that this journalist wasnâ€™t going to believe anything I told him anyway, I figured Iâ€™d publish a short list of things Ello will never do: Diverge from our mission to empower and support creators to inspire one another, and move the world forward. Tolerate hate. Ello has many tools, some visible and others not, that help keep this network positive. Sell ads or user data to third parties. Sell out. Suck. Three months later, in March 2016, Paul Budnitz stepped down as CEO, citing the distance between his home in Vermont and the rest of the team in Boulder. He was replaced by Todd Berger, one of Elloâ€™s co-founders and lead designers. Under Berger, Ello refocused its efforts on artists and creators. From a May 2016 press release: In recent months Ello has doubled down on its mission to support creators everywhere, becoming the premiere community for the worldâ€™s leading edge and contemporary artists, photographers, designers, illustrators, architects and GIF makers to share their work and ideas, connect with others, and build organic reach. In a September 2016 interview with Wired, he said that was what Ello was always meant to be: Berger had originally intended Ello to cater to artists, but the founding team was split on the idea. â€œTo Paul [Budnitz] it sounded limiting. To our investors it sounded very limiting,â€ says Berger. As its new CEO, Berger continued fundraising, but the SEC filing from March 2017 indicates a struggle, raising only $2.5M of the available $4M. In an interview with TechCrunch in November 2017, Berger said he was looking to raise more cash. â€œWe have a lot of investment opportunities coming in from actually some fairly heavy-hitting firms that I hope to close.â€ Ello in 2017 In the same interview, Berger said Ello now had 400,000 monthly active users, with 625,000 artists on the site. It seemed like Ello finally found its niche as â€œThe Creators Network,â€ a community of artists and designers using its visual-heavy design to show off their portfolios and promote their work. Their original freemium model never worked out, but sponsored content was handled thoughtfully, with like-minded brands offering giveaways. It was paid advertising, but it didnâ€™t violate privacy or sell user data. â€œA lot of people thought we died and went away and the whole time weâ€™ve been cultivating a really niche and creative community thatâ€™s gotten more focused as Iâ€™ve been able to enact my vision,â€ Berger said. The future of Ello seemed bright. The Acquisition Five months later, in March 2018, Ello was quietly sold to Talenthouse, a Los Angeles-based company whose primary business was running design contests for brands, in which independent artists competed against each other for a cash prize. I only know the sale date because it was mentioned in the annual report of a venture capital firm who invested in their Series A. The acquisition was never announced publicly, as far as I can tell, mentioned only in this October 2018 interview with Talenthouse co-founder Maya Bogle, where she said that â€œearlier this year we acquired Ello.co.â€ As an Ello user, I was never notified about the ownership change, even though they sold all my data to an entirely new company. As far as I can find, none of the original founders mentioned the sale publicly when it happened. There were telltale signs, though: Elloâ€™s social media started regularly promoting design contests from â€œour friends at Talenthouse,â€ while never disclosing the sale. The Ello homepage prominently featured Talenthouse â€œartist invitesâ€ to compete in their design contests from brands like Absolut Vodka, Amazon Prime, Pabst Blue Ribbon, Adidas, and Miller Lite. This isnâ€™t an ad, itâ€™s an opportunity! And theyâ€™re just friends, really. The Founders Leave The following month, in September 2018, the remaining two of Elloâ€™s original remaining co-founders announced they had left the company. In a cryptic post on Ello and Instagram, Elloâ€™s then-CEO Todd Berger and fellow co-founder Lucian FÃ¶hr wrote: Over the course of the past years we did our best to steer Ello per our vision, always with the intent of putting artists first. At times we succeeded, often we failed. Which brings us to today. Weâ€™re no longer at Ello, we canâ€™t elaborate as to why, but itâ€™s time for us to move on and return to studio life.â€¦ If we let you down along the way, weâ€™re sorry. If we didnâ€™t, all the better. On a July 2019 podcast, Berger and FÃ¶hr spoke candidly about their time at Ello, when Berger took over CEO duties and FÃ¶hr became the Chief Product Officer. Todd Berger: The beginning of it was super exciting, super pure, 100% authentic. We built a lot of digital products, worked with lots of startups. We felt like we knew how to do this. We got a lot of momentum. People were stoked. And then investors got interested and there was pressure to do all these other things. The CEO at the time [Paul Budnitz] got maybe a little overzealous about making lots and lots of money and turning it into a crazier thing than we ever imagined. And it kind of got out of control real fast. And then we were just kind of holding on, trying to steer it as best possible back to its original kind of the real place we wanted it to live in. And it was tricky, that fast-paced real startup ecosystemâ€” once thereâ€™s VC money in there and thereâ€™s a lot of press and thereâ€™s a lot of attention and youâ€™re not necessarily meeting expectations per the media, per your investors, etc etc. As for the acquisition, it doesnâ€™t sound like it was a big payday for the original founders. (As preferred shareholders, VCs are typically paid from an acquisition before founders, employees, or other common stockholders.) Interviewer: Do you feel that the sale of the company justified the time and effort and blood and sweat? Berger: No, no. Frankly, it wasnâ€™t a lucrative exit. It was more of a, letâ€™s carry this thing on, someone wants it. And it wasnâ€™t about that for us. Like, had it been something different, who knows what weâ€™d be doing now? But the experience, by and large, was justified. It just, by the nature of taking money in and building a company and a lot of pressure and responsibility, it went on longer and turned into a bumpier grindier thing I think than we wish it would have. On August 22, 2018, then-CTO Colin Gray deleted the Manifesto, the foundational statement that was part of Ello since before it launched, along with all references to the Public Benefit Corporation and its charter. Ello PBC was officially dead. The End In December 2019, Ello, Talenthouse, and Zooppa merged into TLNT Holdings, a new holding company backed by UK private equity firm AEDC Capital. TLNT was then sold to Swiss investment firm New Value AG, which renamed itself, confusingly, to Talenthouse AG. In December 2021, Ello changed their logo to finally acknowledge what everyone on the site had figured out long ago. â€œOur new logo represents our parent company, Talenthouse, who yâ€™all are already familiar with as we cross promote creative briefs on the Talenthouse platform all the time,â€ they wrote on the official blog. â€œYouâ€™re creative, you understand the way businesses develop.â€ Behind the scenes, Talenthouse was struggling financially. A February 2023 report in The Observer exposed that Talenthouse was withholding funds from artists who won their creative briefs. A month later, The Guardian reported their parent company was â€œclose to failure as debts mount,â€ with most of their subsidiaries closed and staff laid off. Talenthouse, whose clients have included Netflix, Coca-Cola, Nike and the UN, is facing legal action by creditors in the UK and is understood to have laid off most of its workforce, with top executives also departing its parent company in recent days. Its parent company, Talenthouse AG, has also announced the closure of four other subsidiaries saying they cannot afford to pay outstanding bills, including staff wages. In May 2023, the company released a statement that it was facing a â€œcritical financial situation,â€ restructuring the company while finding outside investors. As a result of the upheaval, Elloâ€™s website started seeing significant downtime starting in June 2023, delivering 500 errors on every page for days at a time. It came back online for a few days in July, and then more errors. On July 18, 2023, it shut down for good and never recovered. On August 9, the web app was apparently deleted, leaving nothing but a Heroku error. The Ello homepage in July, August, and September 2023 The Talenthouse corporate site is still online, but the platform is offline, and they havenâ€™t posted anything on social media since January 2023. Elloâ€™s social media team stopped posting in October 2022. After leaving Ello in 2016, Budnitz returned to his Kidrobot roots with the launch of Superplastic in 2017, a vinyl figure company that expanded into NFTs and the metaverse in 2022, raising a total of $68M in seven rounds of funding, led by Amazon. Superplastic appears to have abandoned its NFT projects last year as the market cratered, and Budnitz stepped down from his CEO role in September, replaced by the former president of blockchain gaming company Dapper Labs. They are now focused on â€œsynthetic celebritiesâ€ and AI influencers. Todd Berger and Lucian FÃ¶hr reopened their Boulder design studio, which had shuttered for five years while they worked on Ello. Berger described running Ello as the â€œlow point of my creative career,â€ so I hope theyâ€™re doing better. As for Elloâ€™s users, theyâ€™re out of luck. The shutdown spawned a confused exodus of sorts, former community members trying to figure out what happened on the Ello subreddit, on X/Twitter, and the comment section of the only other blog post about it. â€œyears of my writing down the drainâ€ â€œHeartbreaking. I upload my artwork in there and I love the site because it really focused on art.â€ â€œItâ€™s really messed up that there was NO warning to allow us to download our content. That was a very personal space for me and now itâ€™s gone forever? It was my online diary ffs!â€ â€œI had two groups. One had over 18k followers and the other 17k+. No warning at all. Just gone, along with 8 years of content updated a couple of times a week.â€ â€œDid you find a way? It has basically my entire diary :(â€œ â€œ18k followers and a few years worth of educational posts on fiction writing craft essentials gone.â€ Some people tried to contact Ello or Talenthouse directly, but the emails bounced. Some former members set up a Tumblr group to try to find each other again, â€œan attempt to maybe preserve and/or recapture what little magic Ello still had for us.â€ You Were The Product From the moment it launched, I liked Ello and wanted it to succeed. Experimentation in social networks is critically important, and thereâ€™s enormous value in making new online communities for creative people. I even loved Elloâ€™s minimalist monochrome design, which some people bounced off of. But from the moment I read about their seed funding, I worried that they wouldnâ€™t be able to build a long-term sustainable business if they were hooked on professional funding and busy chasing growth. The day after I wrote my first Ello post that blew up, Rose Eveleth published an article in The Atlantic with the blunt headline, â€œEllo Says Youâ€™re Not a Product, But You Are.â€ The fact that you, the user, even exist and use their site makes you a product. Ello already has some amount of seed funding from VCs, which means it will need to return to them with something in hand if it wants more. And when it does, or when it is eventually bought by a larger company, you are part of that transactionâ€”a key line in the sales pitch. Your existence on that site is a unit of currency, and itâ€™s a unit that Ello is selling to whoever will give them money for it. Elloâ€™s founders wrote in their manifesto that, with other social networks, â€œYou are the product thatâ€™s bought and sold.â€ They believed, Iâ€™m sure sincerely, that Ello would be different. â€œWe believe that the people who make things and the people who use them should be in partnership. You are not a product.â€ Despite their idealist manifesto and their Bill of Rights, I donâ€™t believe they could ever truly be in partnership with their community once they were taking large amounts of venture funding. All of their ideals and big dreams were easily undone, even the legal restrictions they defined in their Public Benefit Corporation charter: Ello made money from selling ads to third parties; Ello made money selling their user data to a third party; Ello was sold, and the new owners didnâ€™t comply with those terms. In the end, Ello was sold to a third party without notifying its users or giving them the opportunity to opt out of handing over all their content and data, then resold to a new company, and finally shut down and deleted with no notice or recourse. Would things have been different if they hadnâ€™t taken funding? Itâ€™s impossible to say. In all likelihood, it never would have been built in the first place. But if it had, I doubt it would have ended like this. ðŸž Elloâ€™s homepage on July 3, 2023, shortly before it closed for good. â€œBuilt by artists, for artists.â€",
    "commentLink": "https://news.ycombinator.com/item?id=39043871",
    "commentBody": "The quiet death of Ello's big dreams (waxy.org)413 points by waxpancake 17 hours agohidepastfavorite210 comments sirspacey 10 hours agoExcellent, balanced post. Weâ€™re at the end of a grand experiment of â€œyou can take VC money and deliver a tech with new values, one that people want.â€ The only people still claiming you can just havenâ€™t run out of their last funding roundâ€¦ yet. We have 20 years of evidence on what tech businesses can be built on the Internet that make money. Itâ€™s narrow and mostly canâ€™t solve the problems that remain. The escape hatch is always subscription revenue. Itâ€™s true you can build a unique business on unique values for a unique community. But itâ€™s a long slog in the MicroSaaS world where anyone can & many will straight up copy you - forever. X.com is probably the only & last experiment on whether switching to subscription rev is achievable at scale. Looks pretty clear so far that itâ€™s not. This might seem a negative outlook, but it could be quite positive if founders know & accept it. The secret is out now that, mostly, founders make the same amount of money in the same amount of time whether they go the VC or bootstrapped route (when itâ€™s a winning business). There will always be opportunities for finance-backed cartel-busting mega runs. But if you are a founder that cares about anything - anything - the route that gets you there is founder control, patience, and a customer base that pays. reply eterevsky 31 minutes agoparentI think Substack is a pretty clear example of subscription model working well. There's also Patreon that is doing very well. I wouldn't discount YouTube Premium and Twitter subscriptions. They don't cover the majority of users, but are a viable option if you (like me) can't tolerate ads. reply FormerBandmate 9 hours agoparentprevYouTube and Hulu did it very successfully. Twitter has just done it in a really stupid way, because their management values politics over the actual business of running a social media platform (moreso now than before, but still very much before) reply DeathArrow 2 hours agorootparentX switches to subscription exactly because politics forces them to, by trying to scare and shame advertisers. Once subscription revenue is enough, scare and shame won't work and politics won't have anything to do with the future of the business. reply moomin 42 minutes agorootparentIâ€™m not sure you understand what advertising cares about. They care about reach and brand value, both of which have dropped for Twitter. â€œPoliticsâ€ is a component of brand value, but itâ€™s got nothing to do with reach, which is falling through the floor. But equally â€œpoliticsâ€ doesnâ€™t explain the drip in brand value, either. The FIFA World Cup has _dreadful_ politics, advertisers donâ€™t care because itâ€™s still a great brand with a huge reach. Musk is rich and connected enough to be able to ignore commercial reality for a basically unlimited amount of time, but I seem to recall you were arguing elsewhere on this thread that company owners should only care about the money a company makes. reply dopeboy 10 hours agoparentprev> Weâ€™re at the end of a grand experiment of â€œyou can take VC money and deliver a tech with new values, one that people want.â€ This is an extreme position. More likely, we are seeing repricing occur. There are still worthy, venture backable ideas. Probably less of them than in the past. reply DeathArrow 2 hours agoparentprev>But if you are a founder that cares about anything - anything - the route that gets you there is founder control, patience, and a customer base that pays. Most successful founders, from Edison to Gates and Bezos went in the business to make money, not to change the world. Changing the world for better or for worse is mostly a side effect. The goal of a business is profit, not ideology. reply danjac 40 minutes agorootparentHow much profit does Amazon make these days again? reply draaglom 2 minutes agorootparent$26 billion (Q4 2022 through Q3 2023) reply moomin 1 hour agorootparentprevYouâ€™re all over this thread but I think you need to read it a bit more carefully. Thereâ€™s no reference to any belief system in the post youâ€™re replying to, thereâ€™s an assertion about expected profit and control. You can disagree with that assertion, and indeed have on another thread, but within the context of the assertion the poster is correct. I think youâ€™re wrong to even think this is about â€œideologyâ€, which is presumably a set of beliefs you are against. It applies as much to _variance_, which 100% is something a founder should care about. reply DeathArrow 1 hour agorootparentThe post I replied to, was talking about founders that care about anything. As opposed to founders that do not care and are in it just for the money. That's how I read it and you have the right to disagree. That's why we are on a discussion forum. To share ideas and speak our minds freely, regardless if we agree or not. I hope you have fun tracking and counting my posts and it represents a good spending of your time. reply throwaway167 5 hours agoparentprevFew web businesses have a truly huge minimum efficient scale. For those that do, it's huge. For those that don't, it's quite small. And for the small ones, Wordpress or similar powers their laundromat. A good small business. As you say, one that takes effort to run. Stripes the banks POS, perhaps someone has some mid scale in Tide sales in the middleware SaaS, there can be a franchise that doesn't fully adapt to how many socks Vs fur local customers have. But think laundromat. Local restaurant. Which are fine businesses. reply DeathArrow 2 hours agoparentprev>The secret is out now that, mostly, founders make the same amount of money in the same amount of time whether they go the VC or bootstrapped route (when itâ€™s a winning business). I pretty much doubt it is the same amount of time. And I doubt the same percent of businesses survive nevermind win. reply bko 7 hours agoparentprevWhy can't you take VC money and run the business the way you want? They can't force you to do anything. Sure they can pressure you, but if you have ownership and they have a minority stake, you can do what you want. Ello could have stopped at any time. Why did they raise 5 million only 6 months after their first round and another 5 million 6 months after that? What were they spending their money on? I don't see how this would have worked if they hadn't taken money > X.com is probably the only & last experiment on whether switching to subscription rev is achievable at scale. Looks pretty clear so far that itâ€™s not. I don't know. X showed that you can fire ~80% of your employees and the product could still exist. Not only exist but push product at a faster pace. In the last year you got editable comments, subscriptions, revenue sharing, blue checkmark for sale, alternative check marks for govts and org, culling of old accounts, API restrictions, forcing people to put parody identify themselves, longer videos, just to name a few off the top of my head. I noticed more large changes in the last year than the last 5. You don't need a lot of people to run a SaaS company and you can cut a lot of bullshit. And all tech companies are coming around to that conclusion. Maybe if Ello had raised only a few million and kept around a dozen employees or so, it could have succeeded. reply bruce511 6 hours agorootparent>> Why can't you take VC money and run the business the way you want? Because taking VC money let's you defer the revenue question. And by deferring it, you then have to bait-and-switch the users. Let me be clear. It's OK to get startup money. Businesses need capital to get going. But revenue should be the original business plan. In other words, who is paying for this site, and how? Ello ruled out advertising and data sale - that's fine, but that leaves subscriptions, donations, premium features, whatever. For a \"regular\" business, each wants to become sustainable, its important to become profitable ASAP. The team is focused on revenue, keeping costs down and so on. Once it can pay expenses and salaries it can run forever. The obvious revenue here is subscriptions. Income rises with expenses. But of course if you charge you'll grow slowly. So you start free, which means customers will rebel later. (Anyone see parallels to Open Source companies here?) VC money allows you to kick this can down the road. Small angel investment? Sure, no problem. You still have majority control. But if you are using that money to pay salaries, then it'll quickly run out. If you don't have enough revenue, you could just close up, but you dont, you go get a series A. Then B. Then C and so on. The implication is you are selling equity. One day that investor equity exceeds 25%. A round or two later it's over 50%. You've lost control. (And I'm assuming all the founders are in agreement all the time - in reality one wants to cash out, and joins the investors camp well before the 50% is reached.) So, you can grow slowly, and sustainably. Or you can take money, grow fast, and \"hope\". But make no mistake, when you sell -equity- you are selling control. You are selling your right to dictate \"principles\". That is -what- you are selling-. Since you are selling to people who are in it for the financial return, the end result is like night following day; inescapable. If you want to build a business on principles, not profit, you HAVE to answer the revenue question first. reply DeathArrow 1 hour agorootparentBut depending on agreement, founders can have much more voting power than investors, regardless of shares they hold. reply DeathArrow 1 hour agorootparentprev>If you want to build a business on principles, not profit, you HAVE to answer the revenue question first. From Wikipedia: \"Business is the practice of making one's living or making money by producing or buying and selling products (such as goods and services).\" reply DeathArrow 1 hour agorootparentprev>Maybe if Ello had raised only a few million and kept around a dozen employees or so, it could have succeeded. I doubt it. It seems like a poor product market fit. I think there aren't a lot of creators willing to pay to have a small social network just for them. They won't probably be active users even if the small social network was completely free. reply DeathArrow 2 hours agorootparentprev>X showed that you can fire ~80% of your employees and the product could still exist. Most fired employees weren't producing profit. Most were censoring, making politics or concerned themselves with corporate bureaucracy, drawing charts and making presentations. reply moomin 36 minutes agorootparentYou say that, but the company valuation and revenue fell through the floor, to an extent that everyone can tell, even though the reporting burden is much less now the firm is private. Maybe some of the activities you decry as censorship and corporate bureaucracy have more to do with the bottom line than you think? reply mplewis 3 hours agorootparentprevYou canâ€™t raise much VC money with ownership and a majority stake in this climate. Youâ€™re a budding social network. You need corporations to pump money in and you need user growth. Who is running your sales and marketing teams for free? Twitter hasnâ€™t launched features of note since the Elon takeover that werenâ€™t visibly in development before the takeover. Unless you count an $8 Boolean flag as a meaningful feature. reply Aeolun 9 hours agoparentprev> X.com is probably the only & last experiment on whether switching to subscription rev is achievable at scale. Looks pretty clear so far that itâ€™s not. Twitter could. MuskX can not. reply FormerBandmate 9 hours agorootparentTwitter Blue was a total flop before Musk. I'd bet Twitter's subscription revenue has grown astronomically (although not nearly enough to make up for $1.3 billion in stupid debt payments and a $3 billion shortfall in advertising revenue) reply dghlsakjg 7 hours agorootparentTwitter blue was launched less than six months before Elon started his takeover bid. Itâ€™s hard to call a six month old niche product a flop. Iâ€™d bet that subscription revenue has grown astronomically because the business strategy pre Musk was advertising based instead of subscription based. He destroyed the advertising business, and is trying to make subscriptions work. reply skybrian 10 hours agoparentprevThe founders themselves could also lose interest over the years if the website isn't as popular as they hoped, and it's still a slog. reply aleph_minus_one 9 hours agorootparent> The founders themselves could also lose interest over the years if the website isn't as popular as they hoped, and it's still a slog. Rather: the founders are lying and deceiving if they talk about their great vision and its importance for mankind, if in reality they are just looking for popularity, and are eschewing the slog. reply skybrian 8 hours agorootparentThat's one scenario. There are others. reply MichaelZuo 10 hours agoparentprevâ€œyou can take VC money and deliver a tech with new values, one that people want.â€ Well you can... just that there's no guarantee that the 'people who want' will also want to pay enough, on average, for it to be sustainable. reply wideopenjake 11 hours agoprevEarly on in Ello's life, possibly year 1, I interviewed for a job with them - back when their office was basically one floor of a residence, and all the engineers pretty much worked at a single dinner table packed with monitors. I probably scored the interview because of my previous experience as CTO of a startup social network for people who wanted social change (which we sold to Gaiam, and that's how it eventually died a few years later, but at least I ended up in the Denver/Boulder area). Anyway, the code test part of the interview involved pairing with another engineer on a small portion of the ello User model (their application was built with Ruby on Rails at the time), and I remember being rather underwhelmed by what they asked me to do, at least in terms of whether it provided a decent test of my abilities. I ended up sending a follow-up email expressing that, along with numerous polished samples of other project work. They ended up passing on me, but I stayed a member of ello for a while longer because I thought the idea might have promise. Maybe I left too early, but I eventually ditched it because... there was no \"there\", there. I liked their general idea, but... they could have done so much more with it, even with a small team. As it was, I left before ello ever got out of its \"tumblr clone with way too much empty space\" phase - if it ever did. RIP reply DeathArrow 1 hour agoparent>They ended up passing on me Sounds like a win for you. reply larodi 15 minutes agoprevMy dream is of one day being in position to borrow some 5, 10 mil, if not more from some bank, VC, whatever. And then manage to somehow.... mismanage it, burn the money. And then get away from all the troubles by filing bankruptcy! Yes, this has ever been my wet dream growing in a country that didn't have the notion of personal default and until only recent years. Where mobs were chasing oneself if he had any debts to like... anyone. I really envy you guys burning VC capital on \"dreams\", while others have to solve the complex \"differential equation\" of markets and competition and planning, and you know managing things properly to be sustainable without external injections. Our story is very sad, your story is a dream indeed. reply dopeboy 14 hours agoprevI'm a recovering founder after winding down my startup a couple months ago. I've been thinking about getting back on the saddle and in service of that, meeting with folks who could be potential co-founders. One of the first ~5 questions I ask is whether they want to bootstrap or go down the VC route. Because they are very different paths, with different levels of pressure and mostly importantly, expectation. You _have_ to know that from the outset, else it's just trouble. reply laurex 12 hours agoparentBootstrapping social tech ainâ€™t easy. Expectations that this tech is free, plus the immediate need for support and safety for general populations mean that itâ€™s very different than say, B2B SaaS. reply DeathArrow 1 hour agorootparentSocial networks don't seem to be a great business idea regardless if you want to bootstrap or get outside money. And regardless of monetization model. reply aleph_minus_one 9 hours agorootparentprev> Bootstrapping social tech ainâ€™t easy. Expectations that this tech is free, plus the immediate need for support and safety for general populations Start with and focus on an audience that has different expectations than the general population. reply dopeboy 11 hours agorootparentprevGood points - social communities have less of an autopilot component than b2b SaaS. reply Dig1t 10 hours agoparentprevWhich path do you want to go with in your next startup? reply dopeboy 10 hours agorootparentLeaning venture backed. reply mawise 14 hours agoprevI started building an open source private blogging system[1] when my first kid was born, and it eventually evolved into the skeleton of a social network--but fully decentralized using RSS and self- (or paid-) hosting. I concluded the only way for a network to actually avoid selling out was for there to be nothing to sell. If I give away the software, and don't control the network then there is no need for users to trust me. It continues to be an interesting journey as a side-project (not raising money means I'm still working a day-job). [1]: https://havenweb.org reply ilrwbwrkhv 11 hours agoparentMost of these platforms will never reach \"popular\" scale. You need to think about the killer article or feature. reply Aeolun 9 hours agorootparent> You need to think about the killer article or feature. Well, no. I think the point is kind of that they donâ€™t. reply ilrwbwrkhv 8 hours agorootparentThen they will never get popular. reply lacrimacida 7 hours agorootparentThey avoid it getting so popular such that the audience does not grow faster than the ability to cater to the expectations from new users. Finding niches works out pretty well where they do and for longer periods of time with a lot less friction. reply gameshot911 12 hours agoparentprevFYI, clicking the \"Try the Demo\" button doesn't do anything for me in Chrome or Firefox. reply mawise 12 hours agorootparentWell that's awkward. Thanks for the tip--fixed now. reply throwaway14356 10 hours agoparentprevmaybe there is a fitting product to be found. first thing that pops to mind is hardware. Something like a tiny home server that works out of the box. Could go the piratebox route (a single website wifi hotspot) could have it do something mesh networking. perhaps stick a webcam on it. reply paxys 5 hours agoprevNo amount of manifestos, bills of rights, public benefit designations, PR campaigns, taking VC funding, not taking VC funding, not selling out or whatever the hell else we want to talk about can make up for one simple fact â€“ a company needs to bring in more money than it costs to run. Ello tried for 8+ years but could not manage to do that. This post is focusing solely on the VC funding aspect and proclaiming it as the cause for failure but ignoring the fact that Ello was dead in the water regardless of it. The company had no users and no business model. Heck a reasonable amount of ethical advertising may actually have done some good for the community and helped the product survive. reply DeathArrow 1 hour agoparent>Ello tried for 8+ years but could not manage to do that. Ditto. Retrospectively it seems a fiasco from the start. I wonder why investors bought it and Talenthouse. Maybe investors in the first round were hoping to find some suckers in the future and offload the \"business\" to them. But what about the final buyers? Didn't they smell anything wrong? You got to ask how did they make the money they lost on Elo / Talenthouse in the first place. reply hiAndrewQuinn 3 hours agoparentprevI often wonder about the long tail of small startups that must exist with minimal operating costs, down to a single VM, Django backend and SQLite database, that are still operating but not recieving updates because their owner is focused on something else, but which still make a hefty profit because of the domain knowledge baked in or something. It seems to me like the sustainable winning combination is domain expertise + moderate programming skills. reply moomin 32 minutes agorootparentThe closest thing I can think of is patio11â€™s Bingo Card Creator. But he moved on toâ€¦ venture funded payments processing. I think, though, the people who can and do bootstrap small businesses like that donâ€™t necessarily hang out here. The site is literally VC-owned, after all. reply DeathArrow 1 hour agorootparentprevCan you give us examples of such startups? Also, the founders of Elo were creatives, not programmers. So they couldn't throw a microSaaS on a VM, forget it and go write the next microSaaS, rinse and repeat. reply hiAndrewQuinn 47 minutes agorootparentNo, that's why I asked. Where are they? What are they doing? reply danjac 28 minutes agoparentprevI mean Mastodon exists, each instance requiring just a small amount of funding to keep the lights on. There is also Tildes, which I think is a nonprofit registered in Canada. It depends on what your aim is. Had Ello followed a proper nonprofit structure from the start, they could have continued indefinitely with a small staff and volunteers maintaining an open source code base and handling moderation. It would not necessarily be easy, but it would be doable. They didn't though, and the fact that the original CEO later got into into NFTs and now something-AI maybe shows he was something of a bandwagon-jumper. Back then everyone wanted to be the next Facebook, so that was what he jumped into. reply DeathArrow 2 hours agoprevThe article somehow states that money from private equity and venture capital is poison that will kill new companies and harm the public. I wonder how you can grow a company without outside investors? Either you are a very rich founder or you can try to grow it organically but very slowly. If you attempt to do the later you'll find yourself in a position where is very hard to succeed, moreso if your company doesn't do anything new and the competition has lots of cash to succeed. If you are in a internet business, you either charge users for the service or sell ads. Until now there's no better proven way to monetize. If you intend to charge users for the service without selling ads, then you can do it regardless of how the money came to finance the business. In retrospect, it seems like a bad business prospective from the start, with low potential. Had the potential been better, VC wouldn't force them to sell ads and wouldn't have tried to exit the business so fast. reply throwuxiytayq 2 hours agoparent> I wonder how you can grow a company without outside investors? Either you are a very rich founder or you can try to grow it organically but very slowly. If you attempt to do the later you'll find yourself in a position where is very hard to succeed, moreso if your company doesn't do anything new and the competition has lots of cash to succeed. Hard is fine. The point is, taking VC money makes building the company (you wanted to build) straight up impossible. Turns out building companies is very difficult. If the first thing you do is sell out, perhaps you donâ€™t have what it takes. reply DeathArrow 1 hour agorootparent>Hard is fine. The point is, taking VC money makes building the company (you wanted to build) straight up impossible. What if you and the venture capitalists are on the same page and have the same goals? Or what if you keep control, have a good money making plan and you don't ask for funding just to pay expenses and acquire unpaying users but use those funds for growth? reply throwuxiytayq 1 hour agorootparentIsn't that arguably what Ello thought they were doing? reply Kye 12 hours agoprevMakes me think about how Bluesky is also a Public Benefit Corporation and took $8m in funding. reply StreetChief 12 hours agoparentThose who don't learn history are doomed to repeat it, or whatever the saying is. reply skybrian 10 hours agorootparent\"History Does Not Repeat Itself, But It Rhymes\" - possibly Theodor Reik [1] I expect Bluesky to make their own mistakes. [1] https://quoteinvestigator.com/2014/01/12/history-rhymes/ reply StreetChief 10 hours agorootparentThis is the quote I believe: \"Those who cannot remember the past are condemned to repeat it\" - George Santayana [1] https://en.wikipedia.org/wiki/George_Santayana reply skybrian 10 hours agorootparentYes, but I like the other one better. reply StreetChief 8 hours agorootparentAh I assumed you were correcting me, apologies. reply caboteria 11 hours agorootparentprevThat, mixed with \"there's a sucker born every minute\". reply omoikane 9 hours agoparentprevI don't think Bluesky was launched with a manifesto, so the user expectations are different. That, and the fact that the lifespans of new social networks appear to be getting shorter and shorter with each new generation. If Bluesky were to disappear in a few months, the general reaction might be \"Oh no! Anyway, what's next?\" reply Analemma_ 9 hours agoparentprevI mean Bluesky is founded by Jack Dorsey, who made a fortune for shareholders with his last social media company by conning an idiot into paying way above market value for it. Of course it'll be hard to make that particular lightning bolt strike twice, but it's not like he doesn't have a good track record. reply DeathArrow 1 hour agorootparent>conning an idiot into paying way above market value for it. That idiot, how you call him, bought the user base and the market position of Twitter. Either he has a plan to make it profitable or he doesn't care, as long as he doesn't loose too much money. reply steveklabnik 4 hours agorootparentprevDorsey is not involved anymore; he technically has a board seat, but he deleted his account, and does not appear to care about BlueSky anymore. reply Aeolun 8 hours agorootparentprevFor investors anyhow. It could be argued that he ransomed his users. reply Lerc 13 hours agoprevTaking investor money means users will required to pay, one way or another. Without an explicitly capped profit, I can't see how this doesn't eventually lead to exploitation of the users. I would like to see a donation/optional subscription model with tiered features as is seen in Patreon/Kickstarter etc. with the distinction that the tiers are community wide instead of being bound to the individuals donating. Display an income bar. If it drops to zero the servers turn off. If it drops below 1 nobody can post. If it is above 1 you have Direct messaging, above 2 you have more features, etc. Keep the communication clear as to what is being provided and how it is being paid for. Most people won't pay, but if nobody pays there is no service. Its survival would depend upon providing a service that satisfies enough people to sustain the support. This certainly wouldn't be as lucrative as a exploit the users model, but the idea is not to make a fortune, but to simply run a sustainable enterprise. reply lmm 4 hours agoparent> Display an income bar. If it drops to zero the servers turn off. If it drops below 1 nobody can post. If it is above 1 you have Direct messaging, above 2 you have more features, etc. Keep the communication clear as to what is being provided and how it is being paid for. This is a fairly normal way to run old-style forum hosting - I remember forums that would display a bar for \"this month's hosting costs\" or a \"hosting costs are paid until [date], donate now!\" > Without an explicitly capped profit, I can't see how this doesn't eventually lead to exploitation of the users. I don't see what difference capped profit would make. Exploitation of users doesn't usually happen during the starry-eyed \"this is going to be a billion-dollar company\" stage, it happens in the \"is there anything we can do to keep the lights on for another few months and maybe turn it around\" stage. IMO the problem isn't investment per se, it's debt, in a broad sense: spending money now that you're expected to repay in the future, and then struggling to repay it. There are bootstraped, sustainable organisations operating in this area similar to what you're asking for, e.g. Dreamwidth. But those are never going to be able to \"blitzscale\" or market themselves to the same extent; marketing almost by definition involves spending money now that you hope to recoup in the future, at which point you've already sown the seeds of your ruin if that future revenue doesn't materialize. reply gamepsys 7 hours agoparentprev> I would like to see a donation/optional subscription model with tiered features as is seen in Patreon/Kickstarter etc. with the distinction that the tiers are community wide instead of being bound to the individuals donating. Discord has a bit of this. Each 'server' can be 'boosted'. Boosted servers have access to more emoji slots, better audio/video quality for calls, and larger file upload limits. reply bruce511 6 hours agoparentprev>> I would like to see a donation/optional subscription model with tiered features as is seen in Patreon/Kickstarter etc. with the distinction that the tiers are community wide instead of being bound to the individuals donating. Can you rephrase this as; \"I'd like to see a model where I can pay a lot, and thus allow 10 other users for free\" ? How about something along the lines of \"it costs $10 per useful per month to make the platform sustainable. A subscription is $100. When you subscribe you pay to keep 9 other users on a free account.\" In other words, my question is, are upu in the 10% paying for everyone, or are you in the 90% getting it for free? reply d0gsg0w00f 11 hours agoparentprevMost people won't pay, but if nobody pays there is no service Wouldn't this be at risk of Bystander Effect? reply rgbrgb 12 hours agoparentprevIncome bar / donation thing sounds extremely stressful and precarious if you're paying anyone a salary. Capped profit is interesting since it doesn't limit the business model, just the likelihood of enshitification. reply wavemode 11 hours agorootparentRunning a startup AT ALL is extremely stressful and precarious if you're paying anyone a salary. 90% of startups die in flames. Stress and danger are table stakes, I would think. reply ChrisMarshallNY 12 hours agoprevI'm a participant in a community that explicitly refuses money from outside its membership. If that means we can't grow fast, or have fancy digs, so be it. The reason for that, is to avoid having influence from outside. Even \"angel\" investment can be problematic, as the \"angel\" has the ear of the leadership. I have found that even well-meaning outsiders can have highly destructive influence, because they don't understand the culture and they aren't the ones on the hook, if things go pear-shaped, as opposed to the ones that have a real, personal, stake (like all those Ello users, who lost so much). reply laurex 12 hours agoparentItâ€™s very interesting and telling that most of the technology that connects us does not have us as a customer, or a financial beneficiary. One of the key aspects of technofeudalism is the extractive nature of most of our platforms. reply klipt 12 hours agorootparentBecause given the choice it seems many people prefer free with ads to paid? I'm just thankful that mobile phone networks haven't switched to a \"free with ads interspersed into your texts\" model yet. (Of course there are still ads in my texts, but at least those are officially spam rather than network endorsed.) reply laurex 12 hours agorootparentThis is an argument for standards. You can switch messaging clients. Platforms own you. reply KRAKRISMOTT 12 hours agorootparentYes, and Ì¶GÌ¶mÌ¶aÌ¶iÌ¶lÌ¶ email is such a successful example. reply NoraCodes 11 hours agorootparentIt is. I switched away from Gmail; many have. reply kelnos 10 hours agorootparentSame, but I realize that nearly everyone I correspond with uses Gmail, so Google has all my emails regardless. (Ok, they don't get my transactional email, since those are usually sent through something like Sendgrid, but... yeah.) reply aleph_minus_one 9 hours agorootparent> Same, but I realize that nearly everyone I correspond with uses Gmail, so Google has all my emails regardless. I know some very privacy-focused person (a friend of mine) who will stop being willing to be in contact with you (or being your friend) if you use an email address at one of these big spying email providers to write him an email. So, it is just a matter of being consequential. reply thereisnospork 11 hours agorootparentprevImagine if the progenitors of email thought to require e-stamps, say a thousand emails for a buck. There's a parallel universe where 'Email co.' is a major tech player comparable to Google. Not sure it's a better universe, but bears consideration. reply StreetChief 10 hours agorootparentThis effectively does exist https://www.jpay.com/PEmessages.aspx reply ChrisMarshallNY 11 hours agorootparentprevIn the late 1980s, I worked for a company that wanted to do exactly that. It was an X.400-based nightmare, and never took off. reply unholythree 11 hours agorootparentprevI remember a joke (or conspiracy theory) from the 90â€™s that the US Postal Service wanted to charge people per email. reply steveklabnik 12 hours agorootparentprevIt is always so tragic to me that, for over a decade, I would have paid for Twitter. But by the time they rolled that out, enough had changed that there's no way I was going to pay for Twitter. Market timing is hard. reply renewiltord 12 hours agorootparentprevThat's a customer choice. Metafilter charges money and there are others that do as well. reply darcys22 12 hours agoparentprevThe issue is that without funding a projects velocity is low and that can frustrate the community. Everyone says they are on board with supporting the little guys, until they hit bugs and start complaining. reply mikro2nd 3 hours agorootparentSometimes -- those times when you're breaking entirely new ground with a thing, when you're starting with just a vague vision of where the thing might go -- slow is better. Slow gives you time to understand the effects of what you've already done and the possibilities that affords. I guess it depends on whether you're looking to achieve something unique and truly new, or just \"get rich fast\". reply wtbdrgb 11 hours agoparentprevand how much do you know about the internal workings of that community? how much do you know about it's \"future\"? how transparent is it about how much time top level management and leadership are investing and how they are compensated for it? how much do you know about the financial sponsors of the members of your community? reply ChrisMarshallNY 11 hours agorootparentActually, a whole lot. But that's a story for a different venue... reply Andrex 12 hours agoprev> I felt sad for the guy. Itâ€™s awful going through life never believing in anything. Being an idealist is fine, but being a dick is not. This article took on some personal schadenfreude after I read this line. reply tytso 12 hours agoparentThere was definitely a certain amount of \"I told you so\" vibes, but I don't blame the author. It appears that he was attacked by a lot of Ello founders and fans for raising some cautionary notes. And as it turns out, he was right and they were wrong. We would all like to have a model where users don't get charged money, and yet are not the product. But I haven't seen a model that works to date. In some cases, I don't mind my personal date getting sold; in other cases I pay money because the service is valuable. But I certainly make backups since I don't assume that even when I pay $$$, that the company might not go poof in the night.... reply SamBam 12 hours agorootparentI believe GP was referring to the Ello founder Budnitz, who said that line, as the \"dick.\" I agree. He was responding to perfectly justified -- and accurate -- criticism by saying how sad it is to be a person with such views of the world. reply Andrex 11 hours agorootparentYes. The author of the article knows how to write enjoyably. The CEO he was quoting is the subject of my schadenfreude. reply bruce511 6 hours agorootparentprev>> But I haven't seen a model that works to date Sure you have. Amazon grew without giving stuff away for free. Customers paid (just below market rate) from day 1. This demonstrated the -convenience- of ecommerce. It had revenues from the first sale. Yes, it spent mountains of VC money on marketing and development, but -not- on just buying stuff for you so you think it'll be free forever. Uber is the same, although it's less clear that users will pay gor what a ride really costs. (And their margin makes it attractive for competition) In both cases though there us revenue from customers from day 1. You can wind prices up. It's really hard to \"go from free to paid\". reply rurp 12 hours agoparentprevHah, same here. That line jumped out to me as a big toxic red flag. The quotes further down from users who suddenly lost all of their content were sad to read. It sucks how often regular people get burned for taking tech companies at their word. reply jnsie 11 hours agoparentprevIt's funny, the author went out of their way to give the company the benefit of the doubt...but they come across extremely arrogant and sometimes vitriolic. I wouldn't have been so positive reply cole-k 14 hours agoprevEven the supposedly indie anti-social social media outright violated their own manifesto. Is it any surprise that we're skeptical of the big promises of a bright future that corporations make all the time? I'm curious to know if anyone has evidence of a post similar to this but for a company with a (so far) happy ending. reply gwern 13 hours agoparentI'm interested about the public benefit corporation part here. Did the PBC status wind up changing anything at all here? How does a PBC sell itself or get acquired? How is a PBC supposed to terminate or wind down? If they violate their charter as Ello may have, who exactly enforces it or file a lawsuit, and what is their compensation? reply steveklabnik 12 hours agorootparentNobody should trust my opinion, I am not an attorney, let alone one specialized in this area. In my understanding, a PBC is effectively the same as a for-profit company with regards to these sorts of things. Unlike a non-profit, a PBC has stock, which it can sell, so that's how it would get acquired. I believe that there were even some PBC SPACs back when that was fashionable. > If they violate their charter as Ello may have, who exactly enforces it or file a lawsuit, and what is their compensation? The only real thing a PBC does is change \"shall maximize shareholder value\" to \"shall be managed in a manner that balances the stockholdersâ€™ pecuniary interests, the best interests of those materially affected by the corporationâ€™s conduct, and the public benefit or public benefits identified in its certificate of incorporation.\" See here for Delaware: https://delcode.delaware.gov/title8/c001/sc15/ So it would look like any other shareholder grievance against management in form. reply singleshot_ 11 hours agorootparentWhere in that document are you seeing that non P.B.C. corporations are required to maximize shareholder value? reply steveklabnik 11 hours agorootparentThis document only talks about PBCs, so it wouldnâ€™t be in this document. I am using that phrase because thatâ€™s how people refer to fiduciary duty (and similar things) when speaking generally. Obviously there is a lot of complexity in the rules around corporate governance. reply singleshot_ 10 hours agorootparentPeople do talk about the fiduciary duty to maximize shareholder value when speaking generally. They are wrong. There are only two fiduciary duties in this context: the duty of loyalty and the duty of care. A director of a corporation owes no fiduciary duty to maximize shareholder value. reply steveklabnik 8 hours agorootparentSure. I find it easier to use the same words everyone else uses in informal contexts even though there is obvious complexity and is not fully accurate. reply otteromkram 11 hours agorootparentprevMore PBC vs non-profit info[0]: > Benefit corporations are neither nonprofits nor hybrid nonprofits. Benefit corporations are for-profit corporations that need to consider stakeholders, morals, or missions in addition to making a profit for their shareholders. Nonprofits can't be benefit corporations, but they may create one. Due to the public benefit purpose provisions, expanded fiduciary duties of administrators, and extra shareholder rights created within the model benefit corporation laws, this structure may be helpful to operate and scale the earned-income activities of a nonprofit. [0] https://www.upcounsel.com/public-benefit-corporation reply komadori 12 hours agorootparentprevI suppose if the PBC was in debt then it could sell its assets, such as the Ello site, to pay its creditors and then dissolve. reply renewiltord 12 hours agorootparentprevWhen ICANN was in danger of violating charter, CA AG was the one who enforced on them. reply creer 12 hours agoparentprevIn a slightly broader manner, free software forking has been working out reasonably well: When the original branch goes off the rails, others can take over from a previous \"known manageable\" point. Forking leads to fractioning the user base but kinda, that's the point. reply spencerflem 13 hours agoparentprevI would have said bandcamp, until recently Itch.io continues to be great, for now reply DeathArrow 2 hours agoprevSo they had 7 people to pay, and also pay for hosting, rent, equipment and utilities. That means at least 1 million per year. How were they going to do it without outside funding if the creators subscribing weren't paying at least that amount? Ask for donations on Patreon? reply reso 11 hours agoprevI'm not sure why this post focuses so much on the angel investment. There are probably 10 reasons why Ello failed, starting with the fact that bootstrapping social network userbases is hard, and ending with users won't pay for social networks. None of these are directly related to the fact they built the site with investor money and not volunteer hours. reply urbandw311er 11 hours agoparentI think itâ€™s fair critique for the post to focus on the VC (not angel) investment â€” the expectations of VCs and pressure to deliver a profit could easily have been a significant factor in the decision made by the CEO to focus on substantial revenue growth. reply reso 6 hours agorootparentBut did they ever even cover their costs? If a business is stable for its current size, and then VCs push you to grow and that kills the company, then yes, that company was killed by VC pressures. However, AFAIK, ello never made much money at all, which is the most proximate reason they failed. reply x0x0 10 hours agoparentprevThey are imo directly related. Seven people working on ello means it's hard to understand, even on ramen salaries, how that costs less than $1m a year once you fully burden those salaries, buy office space, buy hosting, etc. So they've set themselves up from the beginning to spend more money than they make, and everything downstream flowed from that choice. If they had to be cash-flow breakeven from the get, they would have to have charged users. ie built a completely different product, with a different audience. reply d0gsg0w00f 11 hours agoprevHas anyone ever considered that social networking is just a bad business model? It's something that everyone wants to use, expensive to run but nobody wants to pay for. reply Kye 10 hours agoparentMastodon and ActivityPub prove another funding model can work even up to millions of active users. There are plenty of criticisms people have for them, but they're beside the point: it works. reply jrm4 9 hours agorootparentRight. This thread should be talking about Mastodon FAR earlier. I do not care AT ALL that VCs can't figure out how to make money from social media directly; if anything, I expect that. It shows that there's nothing particularly intelligent (and maybe perhaps even useful) about VC money. There are other models. Lots of them. We've seen a ton of them work to various degrees. Now, Mastodon is probably the right model for social media. I wish folks here could get their collective heads out of VC-money-land and realize this (presuming one thinks that there is utility in social media, which I do.) And much like the internet itself, there's even money here as well. Ask Eli Lilly. If they had signed on to something like Mastodon, where they could be their OWN source of truth, perhaps they wouldn't have had their \"Insulin is free\" moment. reply warkdarrior 9 hours agorootparentprevWho is funding Mastodon servers? reply Kye 9 hours agorootparentThe people who use them. Some are funded in part or whole by the person running it, but most still have a Patreon or something like it. reply rabuse 9 hours agoparentprevExcept that a lot of these companies have multi-billion dollar valuations currently... reply paulddraper 9 hours agoparentprev> social networking is just a bad business model I think Meta is doing pretty well... reply DeathArrow 2 hours agoprev>Would things have been different if they hadnâ€™t taken funding? Itâ€™s impossible to say. In all likelihood, it never would have been built in the first place. >But if it had, I doubt it would have ended like this. If it had I doubt it would have lasted as much. reply DeathArrow 2 hours agoprevWhat amazes me, is why would anyone sane pay to buy such a business? Why did Talenthouse buy Elo, and more important why did some investors buy Talenthouse? Have no one saw any sign of a very bad investment? reply ErikAugust 14 hours agoprev\"But a little digging shows a much more predictable source: they took a $435,000 round of seed funding in January from FreshTracks Capital, a Vermont-based VC firm that announced the deal in March.\" People forget (or mostly never knew) that Ello was a Vermont thing. I once spitballed with a certain VC at FreshTracks Capital about an idea I had, which lead to him running off with it and burning millions of dollars making it into BRIDJ, which shut down a few years ago. reply myfriendnewton 14 hours agoparent> People forget (or mostly never knew) that Ello was a Vermont thing. True, but a little misleading. The majority of the co-founders of Ello, plus nearly all of its staff, were based in Colorado. Source: I worked for Ello. reply dopeboy 13 hours agorootparentWell now I have to ask - what was it like inside the cauldron? Any learnings you took into your next step? reply myfriendnewton 11 hours agorootparentIt was my favorite job I've ever had. It was intense in the best way. I didn't have much contact with Budnitz, but the other 6 founders showed such a strong passion for the community, it was impossible for me to not to come to work excited. I'd say most of the negative stress I felt was from knowing that the user base was growing faster than we could fill in feature gaps that would keep folks engaged. I felt like we couldn't quite catch up, and by the time the money started running out and interest started to wane, it was too late. A few learnings: - 7 founders is a lot. I don't want that to sound like a criticism, it just means the company is going to feel a bit different vs a more classic 2 or 3 founder setup. - Positive feedback loops within a tight team of highly skilled people has a huge impact on getting more stuff done. That's how I would characterize the engineering team, and it was one of the highest-performing teams I've ever been a part of. - Don't build a startup on a custom, in-house UI framework ;) reply Rodeoclash 12 hours agoprevI wonder if it's possible to take the Wikipedia model (open source, non profit entity) and use that to build a social network. reply vdaea 12 hours agoparentWikipedia is special in that 1) it's very cacheable so the infrastructure costs are low and 2) it's not too expensive in terms of development since I assume people don't expect many features. reply paulddraper 11 hours agorootparentIt also has a better charity story, because \"summarizing the knowledge of mankind\" seems a tag more lofty than a social network. (Even if that's not the case...) reply ThinkingGuy 11 hours agoparentprevLike WT Social? https://en.wikipedia.org/wiki/WT_Social https://wt.social/ reply novagameco 12 hours agoparentprevI always thought it would be cool if every NPR/PBS station also ran Fediverse nodes of mastodon or whatever the Fediverse version of Facebook is. Would provide a public-funded option with more transparency reply rglullis 12 hours agorootparentThe BBC started running their own instance as an experiment, and it seems that they will not keep it running: https://mstdn.social/@isleofmandan/111775751771437531 reply Rodeoclash 12 hours agorootparentprevYeah, I like the federated idea, but I think it had its chance when Elon took over Twitter and they never managed to capture the exodus of users in any significant way. The barrier to entry was just too high (but they have taken great steps to reduce the complexity). reply novagameco 11 hours agorootparentWell my experience with Mastodon has been that it's almost entirely tech people who are joining mastodon for the technical novelty. If every NPR/PBS station launched a social network concurrently, then people would quickly find other people on the platform to connect with reply munchler 12 hours agorootparentprevDeleted reply r3trohack3r 13 hours agoprevI remember when tech twitter (or at least Node.js twitter) tried to migrate to Ello for like a week. A pretty good portion of my social network moved, myself included. But it fizzled out really quickly and we all ended up back on Twitter. Every once in a while I'd still get a notification from Ello that someone had followed me. It was always a porn bot, but the email notification was still nostalgic. A part of me is sad the site died. reply unsupp0rted 13 hours agoparentI remember when something-something twitter tried to migrate to Threads for like a week. And to Mastodon before that. Remember when tech Reddit tried to migrate to Lemmy? A hardcore handful of people migrate await from the Death Star and stay migrated (maybe a couple hundred medium accounts, and 1 or 2 bigger ones), but everybody else trickles back onto the Death Star eventually. The only thing that works to get people permanently migrated away is complete enshitification of the existing platform (i.e. Digg effect). Partial enshitification isn't enough. reply senkora 12 hours agorootparentMastodon and Lemmy do feel different to me, because of the decentralization. They are providing a foundation that gets built upon with every migration wave, and I think itâ€™s plausible that they will eventually break into the mainstream. Put another way, the fediverse is the first alternative that doesnâ€™t need to â€œsucceedâ€ in order for development to continue. Itâ€™s a bootstrapped model. And so it can grow quietly, work out the usability kinks over time, and be ready to absorb users whenever they get fed up with the centralized platforms. reply thejohnconway 43 minutes agorootparentprevSome of those definitely stayed on Mastodon. Mastodon had a semi-successful transition. Small but stable in the medium term. reply Earw0rm 12 hours agorootparentprevTwxttxr is getting pretty close now - maybe in some ways surpassing Digg in awfulness. Specifically the massive level of pornbot traffic, and algorithm changes that seem to be intentionally surfacing posts to adversarial users who will then go on the attack. reply unsupp0rted 12 hours agorootparentThe porn bots are pervasive and easily identifiable programmatically. That they persist must mean that X wants them to persist. reply jrnichols 5 hours agorootparentprevam I the only one that has not seen porn bots or had replies from them on Twitter? I see this mentioned as a huge problem, but are users in general actually seeing this? reply kristopolous 15 hours agoprevSocial networks and marketplaces are the hardest things to get going reply myfriendnewton 14 hours agoparentThat's one of the things that makes Ello's story a bit sad. It started out as a community of people that had this natural gravity, and the early community was admirably dedicated to the experiment. reply edhelas 14 hours agoparentprev*centralized and siloed social-networks Federated, standard and decentralized network just live by themselves :) reply forbiddenvoid 12 hours agorootparentThat doesn't make sense. Federated social networks have the same hard problem as centralized ones: social networks require people. The part that's hard is the people, not the technology. Centralization and federation have nothing to do with it. reply Workaccount2 13 hours agoprevJust a reminder: If you are not paying for the product, you are the product. The internet culture birthed from the early days of the internet \"Everything is free\", seems to have captured a whole generation who simply have no concept of cost and value. Vid.me is another start-up that comes to mind: Youtube sucks, has too many ads, and sells your data. We won't have ads, won't sell your data, and will host all your content. It made it four years before investor cash dried up and they said goodbye. reply Earw0rm 12 hours agoparentIt's hard to relate it to scale, is why. A sandwich costs $5 everywhere, and a car costs $30k everywhere, because that's just what those things cost to make. It's relatively difficult to look at a web service and determine whether its running costs are normal guy hobby money, rich guy hobby money, or no seriously this won't last six months without VC money. Decentralised and P2P systems run themselves, but it's hard for them to maintain a centre of gravity without offering something specific, and given that the network itself can't produce value out of thin air, it's probably not coincidental that the ones best able to maintain gravity are offering stuff stolen from elsewhere. reply woah 12 hours agorootparentDecentralized systems still need ongoing development and maintenance. reply dredmorbius 12 hours agoparentprevThere are numerous cases in which paying customers are also the product, most notably any captive-market advertising situation: transit, air travel, hospitality, cable and streaming services, telecoms (wired or wireless), and more. The truth is that a profit-maximising business will seek revenue opportunities where it can, and if that means selling both services, on a single-instance or subscription basis, and advertising, it will do both. Advertising-only or advertising-dominated businesses have a strong tendency to degrade faster and far more prolifically than those with mixed-model funding (I still find The Economist's three-legged revenues stool fascinating: subscriptions, advertising, and Economist Intelligence Unit bespoke consulting and research services, each roughly 1/3 of total revenues). Paying alone, however, is a far-from-sufficient condition. reply creer 12 hours agoparentprev> If you are not paying for the product, you are the product. That's a fun quip (and often correct) but the world needs a way to run this kind of project. Community? free? transparent? etc, etc. And I think this issue is not just about \"free systems\", culture changes and day to day corruption creeps and destroys everything. Even die-hard for-profit institutions (where entire branches might go rogue on their own objectives.) reply B56b 12 hours agoparentprevThat's exactly it. I'm not sure what about software in particular makes people think that it can exist without funding. People have no problem paying for a physical product, but virtual products are hard to justify for some reason. reply Thrymr 11 hours agorootparentA large part is that the marginal cost per copy approaches zero. It was hard enough to charge for software when it came in a box on a store shelf, now it has to be wrapped in a service. reply yawnxyz 12 hours agoparentprevSometimes youâ€™re still the product if you pay for the product. (YouTube, Uber, Airbnb, etcâ€¦) reply darnfish 13 hours agoprevAnyone wanna place a bet on how likely that an order from here would be delivered? https://ello.threadless.com/designs/white-ello-shirt/mens/t-... reply waxpancake 7 hours agoparentI ordered one yesterday as I wrapping up the post, and it was already shipped early this morning. reply slater 13 hours agoparentprevConsidering that the order would be fulfilled by Threadless (an Actually Goodâ„¢ company) and not by Ello, why do you think you wouldn't get the tee? reply ajhurliman 13 hours agoparentprevI've got 5 on it, DM for Venmo when you get your shirt or 10 weeks have elapsed since purchase. reply riffic 11 hours agoprevdefunct social networking services, a list from wikipedia: https://en.wikipedia.org/wiki/List_of_defunct_social_network... reply strangattractor 8 hours agoprevReplace \"Ello\" with \"OpenAI\" except OpenAI is not being silent about the changes. reply jl6 11 hours agoprevLooks like Archive Team didnâ€™t manage to get anything before it disappeared :( reply otteromkram 11 hours agoprevI don't see why Ello didn't just turn into a Pinterest + Etsy + DeviantArt hybrid. Let artists show off work, let them seem their art/products, take a percentage of the sale as profit. Maybe that's a bad business model for a social-media-first platform. reply paulddraper 9 hours agoparentYeah, I don't get it. Be a marketplace, and charge commission. reply jchw 13 hours agoprevI know that nobody is purporting to have the answer, and I am definitely not trying to suggest that there's anything wrong with the conclusions drawn here--quite the contrary, actually. But, if VC funding is clearly a bad way to go about things, then what is the best way to structure and fund an organization built around a network or service that is primarily in the game of serving user-generated content and providing social networking and chatting services? VC funding has a lot of problems. Funding via advertising is similarly fraught with peril, maybe worse, especially the most lucrative stuff. You can fund things by selling premium content or features, but this too is rather tenuous: if you are say, SoundCloud, one of your primary customers is inevitably going to be artists, who themselves are by and large not rich. Not to mention, no matter who you focus your monetization on, $1 is infinitely more than $0, and monetizing useful features or access to content will inevitably lower the overall value of your platform. This is presumably part of why advertising is so enticing: end users don't have to \"pay\" anything. Sure, advertising isn't literally free, but users do not have to set up a payment method and take money from their account and send it to yours, which is a massive difference, and massively increases accessibility. Then there's stuff like crowdfunding. Platforms that let you do one-off funding campaigns like Kickstarter or Gofundme, or platforms that let you do monthly subscriptions in exchange for \"rewards\" like Patreon or FANBOX. There even is a platform that is partly funded by monthly subscription payments (Misskey.io) and although I'm sure it is a relatively small part of the funding (at least I would certainly assume so) it still seems to have been successful nonetheless. And that's just funding. What about structure? Becoming a non-profit or public benefit corporation is seemingly not any kind of sure-fire way to avoid trouble, as can be seen here. While I don't know exactly how the legalese works around a lot of these topics, it feels like these measures simply don't do enough to prevent corruption or at the very least, undesired future changes in direction. You want a company to have autonomy to carry out its vision and try to survive in the process, but you don't want it to compromise its core values in the process. Is there anything you can do legally and/or socially to provide better assurances? This is very frustrating because I think a lot of us see the sad state of the Internet and want to do something, but it's hard to work towards it because you can also see a graveyard of good intentions gone horribly awry. There's all kinds of attempts to work around it, but as a wise man once said, \"Mo Money Mo Problems\". It seems that the temptation to exploit things always manages to find a way around your safeguards to prevent things from being exploited. Just to beat a dead horse even more, remember the last time you were excited for a Google product announcement, like say, GMail? I'm not saying they were ever a charity or intending to be... but it's hard to not see the painful way in which values that were once hard-fought slowly fade away. Somehow, eventually, everything becomes rent-seeking, a game to see how much money you can get back from an investment. One would hope there is a way out that doesn't involve a very painful upheaval of society, but over time it's getting harder and harder to believe it. reply laurex 12 hours agoparentTrue. Iâ€™m working on a project to answer some of these questions and consider innovations that might have an alternative outcome. We hope to make it a collaborative project with wiki-like tendencies. To me, figuring out how to create technical social infrastructure that does not inherently have anti-social incentives is one of the most important problems of this moment. reply creer 12 hours agoparentprevDay to day corruption is a problem. And if we had a solution, it would be known (the concept of bug bounties goes in the right direction, perhaps). I think this is a fundamental problem and research opportunity with the legal forms for institutions and staff incentives. Even \"winding down\" doesn't necessarily need to be a problem. It's all in the \"how\" it's done. reply bdcravens 12 hours agoprevThat's a name I haven't thought of for several years. I wonder if Fediverse, Blue Sky, etc will catch, or if it'll end up in the same boat. Threads too (yes it's backed by Meta, but G+ had Google behind it ...) reply forbiddenvoid 12 hours agoparentThere's a couple of key differences between Google backing Google+ and Meta backing Threads. 1. Meta's entire business is social apps, and Google's is not. There are strategic differences in approach as a result. 2. Google+ was an attempt to disrupt Facebook's rise at the height of Facebook's popularity. People _liked_ FB then - so trying to get them to switch to another product was harder. Threads shipped during a time of volatility with Xitter and is poised to capture more of that audience as Xitter continues to decay. In terms of how things will change in the space over time, Threads choice to support ActivityPub will probably mean good things for the Fediverse in general, at least in the short term (3E notwithstanding), and could ultimately serve to be the arbiter that kills BlueSky and the AT Protocol. reply Zigurd 10 hours agorootparentG+ also tried (was told to?) show relevance to other Google products by becoming a universal and mandated discussion thread mechanism. It wasn't ready. Got the totally expected blowback. In contrast Meta isn't trying to Threadify everything. The addition of ActivityPub is an experiment that should be run in Threads. reply jamiek88 6 hours agorootparentAnother thing is people weren't just meh about G+ but because of the 'you now must use real names across our properties, yes, including youtube' message people were actively hostile to it. reply x0x0 10 hours agorootparentprevAdditionally, Google never seemed to be able to answer why someone should use Google+ in lieu of Facebook except that it would be very nice for Google if people would. Whereas threads has the obvious benefit of attempting to grow while Twitter is self destructing. reply mdasen 12 hours agoparentprevThe reason I feel confident in the Fediverse's longevity is that it's independently hosted. If BlueSky ran out of money tomorrow and shut down its servers, BlueSky is gone. If mastodon.social ran out of money and shut down its servers, the Fediverse would continue. There would be pain if mastodon.social failed with zero notice. People would lose access to their accounts and would need to find a new server where they'd be starting over. Some may have backed up their contacts, but most wouldn't. If mastodon.social gave a couple months notice, people could migrate to other servers. given that mastodon.social is the largest server, there would be some growing pains as other servers worked to accommodate new users, but it's possible for the Fediverse to continue. Note, I'm not saying that the Fediverse will be incredibly popular. I'm simply noting that there's an amount of resilience. Once Ello's owners ran out of interest or money, that was the end of Ello. Even if others had a huge interest in seeing it continue, there was nothing they could do. Even if the Fediverse doesn't \"catch\" by your definition of catching on, it has caught on for enough people who have moved there and will remain there. That's why I feel happier in the Fediverse. It feels like something the community controls. Sure, I don't run my own server, but I possibly could in the future and there are enough people running servers that I don't feel beholden to any one entity. It just feels like something that can stick around - even if the cool kids aren't interested. Enough of us like it and we'll keep it going even if some of us become disinterested in it. reply riffic 11 hours agorootparentthe genie that is the Fediverse (based on interoperable and open web protocols) is impossible to place back into its bottle. reply DeathArrow 1 hour agoprevSo Marx was right! Capital is bad. All enterprises should be owned and ran by the state. reply zzzeek 12 hours agoprevthis post is a bit of a \"nyah nyah I told you so\", but since whoever was running Ello did not give any heads up to users a way to get at their content, they just allowed the thing to buzz into the ground and they shut off all communication, they deserve it. reply dredmorbius 10 hours agoprevI'd joined Ello early[1] on and watched its journey with interest, frustration, and ultimately sadness. That included an on-site visit in October 2015, which was genuinely enjoyable. I'd largely written off the site around 2018 when it was sold and information on either the status of the social benefit corporation (SBC) or new ownership was exceedingly scarce. Andy Baio's account corresponds strongly with my own. The community was small (I'd estimated total accounts at perhaps 10--15 million, and actives at roughly 1% of that, generally confirmed during my visit), but vibrant in its own way, and as with numerous other social networks, I miss numerous connections I'd made there, though a small handful have resumed at the Fediverse. There really were some notable gems among the group I connected with, including Paul Mason (journalist, briefly), poet Trenton Lee Tiemeyer, authors Ksenia Anske and Bruce Sterling, SVG guru David Dailey, and others. Most disquieting was how Ello died with neither notice to its members or commentary elsewhere. TFA here is among the very few accounts I've seen of its demise. (I've written a few times about it at the Fediverse myself.) The other concern, going far beyond Ello, is how little protection or guarantee either its manifesto or SBC status ended up providing. Going forward, I'm going to give similar attestations vanishingly slight weight. Having participated in online communities since the late 1980s (Usenet, mailing lists, Slashdot, Google+, Diaspora*, Reddit, Ello, the quite short-lived Imzy, amongst others), I'm reminded of the song \"dumb ways to die\": there are many ways for a social network to die, most of them depressingly uncreative. The flip side is that it's also difficult for a social network to survive, let alone thrive, and survival. Commercial pressures from every thing I've seen worsen this, though even noncommercial / non-ad-supported sites may see failure modes. Of the best communities I've encountered: - Early Usenet, when access was strongly predicated on academic affiliation. - 1990s-era mailing lists, most especially those focused around Unix / Linux and Free Software topics. (Broader-appeal mailing lists ... tended to function poorly.) - Google+, in patches. The fact that the social network wasn't ad-dependent, and had strong representation from the tech community were strengths, and some of the best engaging online conversations I've had were from there. Diaspora*, though vastly smaller, saw a substantial portion of my G+ community engage there and had similar dynamics which also made for some good discussions, though not quite as often. - The Fediverse. Not quite as rewarding as G+, but I strongly suspect it will prove far more enduring. - Hacker News. As with G+, not directly intended as a revenue-generating platform. Not as good as it could be, but far better many other options, and astonishingly consistent over a very long lifetime (approaching 20 years), which would beat out Usenet by quite a margin.[2] I'd chalk up HN's durability to a few factors: unsexy tech and appearance, stellar moderation, solid design principles, and a viable founding cohort and active community. There are of course criticisms of the site and I've made a few myself, but relative to much the rest of the Net, still running strong. ________________________________ Notes: 1. The Internet Archive has some captures:2. Usenet's birth date was ~1979. By 1999 it was well past its sell-by date, though not completely dead. reply hn_throwaway_99 14 hours agoprevI thought this was a fantastic post. I think it really dovetailed with what I've been thinking a lot about recently regarding my disillusionment with tech (or, rather, with big tech companies). I think everyone should understand (and, honestly, repeat daily) that in our modern capitalist system where never-ending growth is an expected requirement of any company that has ever taken outside funding, it is simply an impossibility for a company to have any kind of durable values that conflict with that growth-at-all-costs requirement. It's as much of an impossibility as the sun rising in the west, and we should stop any pretense that it's not. Enshittification is inevitable. Nearly every tech company starts out similarly: an absolute laser focus on users and their needs, because that is how you first grow. At some point, though, all of that fruit is picked, and you then start going into features that are \"user neutral\" but that make money, until finally you chip away at features that look like they can be user neutral in the short term (\"We A/B tested and nobody minded one more ad!\"), but the long term effect is that you've completely destroyed your founding ethos. For example, it's easy to pick on Google these days because it's, well, so easy. Their total about face from a company that was nearly universally loved by engineers to one that, if not loathed, is at best seen as the \"next IBM\" is so obvious. E.g. Google got huge originally with a world-first search engine by not \"selling out\", by not masquerading ads as organic search results. Now when I search for any remotely commercial term the entire first page is ads that are nearly indistinguishable from organic results. It's not just Google, though. Apple loves to crow about user privacy, but it's hard to square this \"value\" with their insistence that anyone on iOS who uses iMessage to talk to anyone on Android gets 0 encryption (oh, and if even a single Android user is in a group chat, nobody gets encryption). I don't think that makes any company \"evil\", but it does make it somewhat sociopathic in the sense that there can ever only be a single goal: growth at all costs. The sooner we all recognize it means we can treat all companies with an appropriate level of caution. One final note related to this, is that this is one reason I'm not really a fan of PBCs as mentioned in the article. PBCs are a smoke-screen. As the saying goes, \"Follow the money\". When push-comes-to-shove you'll also see PBCs compromise their \"values\" the second growth starts to be at risk. reply ajhurliman 13 hours agoparentYes, this is a tech thing in particular. You don't see VC being raised for a plumbing company, they'll get an SBA loan or bootstrap. They don't need to grow 10x every year, if the owners can pay their bills and send their kids to college they're happy. And plumbing is such a constitutionally important thing: having hot, running water and not having feces in your house is so much important than seeing what that guy from high school is up to. I think the issue lays with how high-variance tech is due to the scale: either it is marginally profitable at a massive scale and is worth billions of dollars, or you have something that is unprofitable at any scale and is worthless. It's like there's all of the sudden (in the last 15 years) become an appetite for throwing fortunes onto a roulette table (which may be giving better odds than a lot of VCs). reply mandevil 12 hours agorootparentTwo things here. One is that the marginal cost of software(1) drives this pattern of winners and losers. The first user of any software costs an enormous amount of money to actually write the software and deliver it to customers. The 100th user costs basically nothing once you have 99 others. And the millionth user (or billionth) user costs basically nothing as well(2). That in turn means that having a billion users is a lot more profitable than having a million users, which means that if you have a billion users you can afford to do things that the million user system can't- e.g. free webmail and a really good free internet browser, just to name two things picked completely at random and not having any particular company in mind. The other point is explaining your comment about the \"last 15 years\": tech's dominance (really, growth's dominance) is really an artifact of zero-lower-bounds interest rates from the 2008 financial crisis. If interest rates are zero (for discounted future cash flow computations) then I am indifferent about a dollar today versus a dollar in 2075. So someone who can argue that they have a 5% chance of being worth a trillion dollars in 2075 is worth a lot (0.05 * 1T=50 billion) when interest rates are zero, but if interest rates are high (or even, honestly, normal- like 2-3%) then that money is discounted heavily and the growth story doesn't matter as much because dollars today are worth a lot more than dollars in 2075. So if interest rates are zero, future growth will dominate the stock market (which was why 'tech' did well) but when interest rates are more normal, different companies can dominate the stock market (where the fundamental valuation of a company is, roughly, the expected value of future cash-flows discounted to the present). 1: Delivered by the internet- physical media distorts this a bit and behaves more like normal retail goods. 2: Exceptions for certain points in the growth curve where some key system falls over and needs to be rapidly replaced, e.g. storage or compute or whatever, but outside of those it's very cheap growth. Plumber company growth is limited by the number of trained plumbers you can hire- you can only have 1 plumber make so many house calls in one day- but software just replicates at zero out to infinity (again modulo some key systems which can't handle the load). reply wly_cdgr 12 hours agoprevOh wow, I'd totally forgotten about Ello. They were never going mainstream with that yuppie aesthetic reply micromacrofoot 14 hours agoprevIt's a shame that it's completely lost, they had some interesting layout conventions and it was kind of fun to browse images even in the later days. The network never really caught on, but there was some good work being done there. reply sakesun 7 hours agoprevoodbye reply unsupp0rted 14 hours agoprev> After leaving Ello in 2016, Budnitz returned to his Kidrobot roots with the launch of Superplastic in 2017, a vinyl figure company that expanded into NFTs and the metaverse in 2022, raising a total of $68M in seven rounds of funding, led by Amazon. Superplastic appears to have abandoned its NFT projects last year as the market cratered, and Budnitz stepped down from his CEO role in September, replaced by the former president of blockchain gaming company Dapper Labs. They are now focused on â€œsynthetic celebritiesâ€ and AI influencers. reply ilrwbwrkhv 13 hours agoparentThis is the game. Raise money, steal it, let the company go to the dogs. reply StreetChief 12 hours agorootparent> CEO Harry Stonecipher, a cutthroat corporate operative who liked to say, â€œYou can make a lot of money going out of business.â€ - https://jacobin.com/2024/01/boeing-malfunction-ceo-pay-stock... reply TaylorAlexander 13 hours agorootparentprevI am often jealous of the people who make huge sums of money grifting investors, but the thing is I care too much about what I do and Iâ€™d be bad at pretending I donâ€™t. The flip side is I instead love what I do and Iâ€™m very proud of my work, which I donâ€™t think someone could really say if theyâ€™re shilling crap like plastic toys and NFTs. Or maybe they could say that, but I never could. Grifting is just not for me. reply EdwardDiego 12 hours agorootparentI used to work in public service (in chronological order, ranger, social security, LLC incorporation and radio spectrum licensing and management) before jumping into software with glee. And I have the exact same thought about providing software for government and other large organisations. The number of \"solutions\" my public service employers paid millions for, that didn't fucking work properly or reliably is mental. I'm really not sure how contracts keep getting signed by big organisations that don't impose massive penalties on providers for failure, but it they do. Or the sister org that finally had enough and wanted to switch providers, and had to go to court in order to be even be able to pay a large amount for the IP rights to the source code of their system, because they'd signed a contract that let the provider retain IP, and the provider really liked that sweet sweet taxpayer money for buggy bollocks. So naturally, when they contracted HP to maintain the system they ensured that the contract retained IP ownership for their org. Haha, no, I'm kidding, they let HP keep IP rights on changes HP made, and later on had to fight HP in the courts so they could pay HP for the source to switch providers again after getting sick of being charged $2K (USD) by HP to update the text of a single link on a website. And I keep thinking that I'd very much like to be in the market of earning millions by providing broken software to people making big decisions who aren't competent enough to jump to private sector, broken software is easy. But then the guilt of stealing taxpayer money kicks in (it's not legally stealing, but morally, it's stealing. As the saying kinda goes, any great criminal needs a great lawyer, a great accountant, and a corporation), as well as the guilt of professional ethics. (What's the old joke about software ethics? An ethical programmer would never write a function called destroyBaghdad, they'd write a function called destroyCity and pass Baghdad as a parameter.) But look at Birmingham Council in the UK, bankrupted by shit software and Oracle's fearsome legal team. The entire fucking disgrace that is Horizon (although being fair to Fujitsu, nearly all of the evil was on their customer's side, it was only aided and abetted by Fujitsu employees lying in court). In my country, IBM sued our government (and won) because IBM wanted to be paid even more for not delivering a massively expensive and broken project to the Police (INCIS), more recently our Education dept spent $180 million on a payroll system called Novopay (they also paid the provider Talent2 to administer payroll with it) that was terribly broken and underpaid some teachers (and perhaps more egregiously, slightly overpaid some teachers, then the provider would eventually realise and demand the teacher repay the overpayment be returned in full in a short timeframe or debt collectors would be brought in, and threats of civil litigation or criminal complaints were used to pressure them) to the extent that teachers had to go on strike to get the government to take it seriously. Eventually the government took back the admin side of it, and then gave Talent2 another $45 million to get the system working, and are still paying them to maintain it today. The idea of being in a market where delivering badly broken software leads to you getting paid another 25% of the upfront cost to get it actually working, and you don't get fired, is wild. I suppose there's a reason that Oracle and similar are described as law firms that incidentally write software, but damn, they make crypto grifters look like complete amateurs. And I'll begrudgingly admit that Oracle et al are selling a product with actual utility at least, as opposed to NFTs which I'd call digital tulip bulbs, but that is mean to tulip bulbs because they can at least be used to grow flowers. I've seen 0 use cases for NFTs / ICOs that aren't gambling/unhinged speculation (usually with some fraud involved to make Number Go up to suck in the rubes), or just good old fashioned direct to the consumer fraud dressed up in complicated jargon. reply SpaceNoodled 14 hours agoparentprevGrifting is more lucrative than ever! reply hn_throwaway_99 14 hours agorootparentI thought this recent article was so insightful: https://news.ycombinator.com/item?id=39014737 reply NetOpWibby 14 hours agoprevThis post is a long-ass â€œtold you soâ€ and honestly, Iâ€™m here for it. I too had an Ello account and thoroughly enjoyed its minimalist nature. VC money really seems like the beginning of the end. reply indymike 7 hours agoparent> VC money really seems like the beginning of the end. For a lot of businesses, raising VC money is a mistake because rapid growth just isn't the right strategy. VC is expensive - you give up a lot of equity every round and are betting that your ever shrinking slice will be bigger because the whole pie grew faster. That is a very tough target to hit. reply NetOpWibby 7 hours agorootparentYouâ€™d think everyone would understand this by now. reply reiichiroh 3 hours agorootparentJust one more web boom please, say 4.0 with AI. reply paulddraper 11 hours agoprev> I figured Iâ€™d publish a short list of things Ello will never do: > ... > 2. Tolerate hate. Ello has many tools, some visible and others not, that help keep this network positive. Geez, it's hard to take anything said as authentic with a statement like that. How can you talk about things without \"hate\"? \"I hate shoveling snow.\" \"I hate terrorists.\" \"I hate this political candidate.\" \"I hate Taylor Swift music.\" reply wideopenjake 11 hours agoparentI was head of technology for another \"make a better world\" social network, and we approached fostering positivity as a practice of encouraging constructive interaction and discouraging _destructive_ interaction. In other words, being directly abusive toward others was obviously destructive and discouraged, but disagreement, even when quite strong, was great, as long as everyone involved maintained a level of basic respect when interacting with each other. There's also a big difference between vehement dislike of a distant thing, concept or person, especially if one can express their reasons well, and using slurs or advocating violence or harm. I imagine here they used 'hate' to stand in for 'hate speech', but not being in their minds - I really don't know. reply paulddraper 10 hours agorootparentAdvocating violence is straight up illegal (in the US). Slurs is a very specific behavior. --- So...that's a very permissive approach FWIW. reply wideopenjake 8 hours agorootparentWe did, early on, get flooded by people who migrated en masse from another social network who - for lack of a better phrase - equated 'freedom of speech' with a right to post 'shock-and-awe' content just to get a rise out of others. They'd been run out of the other one and decided to try to take over ours. Those of us running the site had a _lot_ of long philosophical discussions about what to do, but we ultimately realized that posting disturbing content with intent only to provoke wasn't constructive, and we had the right to define what type of community we wanted to foster. So we booted the shock-jockeys out, and then went to an application-only process that lasted from 10,000 until about 100,000 users (that's a lot of hand-reviewed applications!) - and you know... I could still sleep at night after that, because it wasn't about stopping any specific cause or idea or viewpoint. (Indeed, a few came back, reapplied, and rejoined as constructive members of the community after that) IMHO, there's a place for provocation, but only if there's a point to it - a message to be communicated. Random photos of animal heads in a jar with no commentary or explanation? Not so much. I guess I thought of us as rather selective due to the application process, but as I think back, the application process actually allowed us to accept a much broader array of viewpoints, because our goal was always aimed at intentionality and constructive interaction. reply edm0nd 11 hours agoparentprevIt's universally known that that means things like racist imagery/text content, not content like \"I hate cake\" or Tswift. reply paulddraper 9 hours agorootparentIt's universally know that this means whatever the speaker wants it to mean, whenever the speaker wants to mean it. reply jeffbee 11 hours agoparentprevHow about \"I hate reductive hackernewses who fail to engage constructively with the discourse and instead turn to gotcha language that 9-year-olds think is terribly clever\"? reply zemvpferreira 11 hours agorootparentHe's right though. \"Not tolerating hate\" is a paperthin principle, that would stand up to as much scrutiny as everything else Ello stood for, in hindsight. re, it was all bullshit and the warning signs should be called out as such so we know next time someone tries to bullshit us. reply paulddraper 11 hours agorootparentprevSure, great example! reply thimkerbell 12 hours agoprevHN is just doomy-doomy-doomy today. Sad. reply muppetman 13 hours agoprev [â€“] I'm amazed by the number of people who trust websites like this with their memories/diaries etc. I mean, I understand why, there's an expectation when you start with these sites they'll be around forever - most people don't have the time, the knowledge or the desire to \"do it themselves\" - When livejournal was all the rage I decided to do it myself with Postnuke, then (and still!) Drupal. Going on 24 years now. That said, LiveJournal is still going, but owned by a Russian company I think, and it could turn off tomorrow. I guess the flipside is, if I die tomorrow and then there's a PHP error on my website, no one's ever going to know how to fix it. So my memories and diary entries die as well. My \"fix\" for that is to export the ~2400 diary entires every few months into one massive PDF file. Edit: I understand why this is being downvoted, I just want to clarify that I didn't mean the opening sentence to read as if people who trust 3rd party websites to their hosting were silly/dumb, though I realise now that's how it scans. What I should have said was \"It's very unfortunate and a sad state of the current Internet that people trust websites like this...\" reply creer 13 hours agoparent [â€“] That is the main takeaway from all these. The lesson is not that venture capital ruined it. But that eventually, at some point, either the founder or circumstances change the thing. The one permanent here is that it's bit on a digital network. By definition not permanent. And so people run into this again and again and still don't believe that XYZ might be next. But it is, XYZ is their business platform, their social media network, their journals, their photo hoster, their \"lifetime membership\", etc. I ran into this all the time with clients. They would worry about what happens to their consultant, but never to their infrastructure. So for businesses: have a plan B, and have usable archives / backups. And for individuals, have a plan B, and have usable archives / backups. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ello, a social network that aimed to be an ad-free alternative to Facebook, has suddenly shut down, leaving users disappointed.",
      "Despite its initial commitment to privacy and user data protection, Ello faced challenges in maintaining its values while seeking funding for growth and monetization.",
      "Changes in ownership and management, along with financial difficulties, ultimately led to the abrupt closure of the platform without giving users a chance to preserve their content."
    ],
    "commentSummary": [
      "The article and comment thread cover various topics related to social networking platforms, including funding models, monetization challenges, and the impact of venture capital.",
      "Examples of both successful (Ello, Mastodon) and failed (Bluesky) platforms are discussed, providing real-world context.",
      "The discussions delve into the importance of user growth, founder control, and maintaining principles in business ventures, while exploring the risks and challenges of different funding and monetization methods. The negative influence of outside investors and the difficulties of building successful social networks are also acknowledged. Overall, the conversations shed light on the complexities and uncertainties surrounding the sustainability and financial models of social media platforms."
    ],
    "points": 413,
    "commentCount": 210,
    "retryCount": 0,
    "time": 1705595759
  },
  {
    "id": 39048317,
    "title": "Notify team successfully migrates PostgreSQL database with only 11 seconds downtime",
    "originLink": "https://gds.blog.gov.uk/2024/01/17/how-we-migrated-our-postgresql-database-with-11-seconds-downtime/",
    "originBody": "https://gds.blog.gov.uk/2024/01/17/how-we-migrated-our-postgresql-database-with-11-seconds-downtime/ How we migrated our PostgreSQL database with 11 seconds downtime Posted by: David McDonald, Posted on: 17 January 2024 - Categories: GOV.UK Notify, Posts for Tech Specialists GOV.UK Notify is hosted on the GOV.UK Platform as a Service (PaaS). The PaaS is being retired, so we are migrating all of our infrastructure into our own Amazon Web Services (AWS) account. This blog post explains how we migrated our PostgreSQL database with minimal downtime. Migrating our database The PaaS provides a database for us and we use it to store all of our data - from data about each notification we send to the content of the hundreds of thousands of templates service teams use to send those notifications. This is an AWS RDS PostgreSQL database and it lives in the PaaSâ€™ AWS account. Our apps that run in the PaaS talk to this database. We are going to call this database our â€˜source databaseâ€™. We needed to set up a new database in our own AWS account, and get all of our apps to talk to the new database. We are going to call this new database our â€˜target databaseâ€™. Creating a new PostgreSQL database in our own AWS account is not too difficult. The hard part is transferring all of our data and getting our apps to use this new database, whilst incurring minimal downtime. A bit more about our source database Our source database is about 400GB in size. It has about 1.3 billion rows, 85 tables, 185 indexes and 120 foreign keys. It is PostgreSQL version 11. On a usual weekday, we do somewhere in the region of 1,000 inserts or updates per second (sometimes much lower, sometimes much higher), plus a similar number of reads. GOV.UK Notify sends millions of important and timely notifications each day, from flood alerts to updating users about their passport applications . Every notification we send requires talking to our database. Therefore itâ€™s important that we minimise any downtime. AWS Database Migration Service The PaaS team offered us the ability to migrate databases using AWS Database Migration Service (DMS). DMS is responsible for transferring data from our source database to our target database. It can be run in either the source or target AWS account. DMS works by: Copying across all of the data, table by table, up to a specific point in time. This is known as the â€˜full loadâ€™ task. Entering replication mode, where it ensures that all new transactions on the source database are replayed onto the target database, so that the 2 databases are in sync. We would then be responsible for getting our apps to stop talking to the source database and start talking to the target database. Database migration process The database migration process was completed in several stages. Setting up the DMS instance In our case, the DMS instance was created in the source AWS account. We chose the source account because the PaaS team had already set up instances of DMS in their account and so were able to do this quickly and easily. The DMS instance also needed to be given PostgreSQL credentials to talk to both the source and target database. The DMS instance and the target database live in different virtual private clouds (VPCs). With the help of the PaaS team, we set up VPC peering so that traffic from the DMS instance in the PaaSâ€™s VPC could be routed directly to our VPC without the traffic going over the public internet. Setting up our target database We created our target RDS instance in our own AWS account. PostgresSQL version 11 was about to become unsupported, so we took this opportunity to upgrade our PostgreSQL version by making our new database PostgreSQL 15. We then took a dump of the database schema for our source database using `pg_dump`. This gave us a file with the SQL commands to recreate our database schema. From our database schema, we took the declarations for our tables and applied these to our target database. We didnâ€™t apply our foreign keys at this point because DMSâ€™ full load process doesnâ€™t try to copy across the data in an order that matches your foreign key constraints. We didnâ€™t create our primary keys or indexes at this point because this would massively slow down our full load task. Each individual insert would take longer; it would need to update our indexes and this would add up to a significant amount of time when inserting billions of rows. It was much quicker to first copy all of our data across and then add the indexes afterwards. Full load Once we had a target database with the tables created, we then started the DMS full load task. This copies across all the data that existed when we pressed the â€˜start full loadâ€™ button. It doesnâ€™t copy across any new data or updates that come in after this point. It took about 6 hours for the full load task to finish. After the full load task completed, we applied the remainder of our source database schema file which adds our indexes and key constraints. Adding these took about 3 hours. Replication Once our full load task completed, the data in our target database matched the data from the source database at the point when we started the full load task. But many new inserts, updates and deletions had happened on our source database since then. And many more changes would keep coming in too. To copy these new changes across, we then started the DMS ongoing replication (also known as change data capture) task. This reads all the transactions from our source database transaction log that were created after the full load task began and sends them to our target database. This ensures that our target database is in sync with our source database with, at most, a small amount of lag. It only took a couple of hours for the replication process to catch up. At that point, we monitored the latency in the DMS replication process to make sure it could handle the number of changes happening to the source database and continued to stay in sync. We ran the DMS replication process for about 10 days in the background, keeping everything in sync whilst we awaited the time for our apps to stop talking to the source database and start talking to the target database. We had announced this time to our users in advance and so had a set time already for the migration of traffic. Preparing to migrate traffic Several months ago we planned how we would stop our apps talking to our source database and get them using our target database.This was the process we used: Stop all traffic from our apps to our source database. At this point we would enter a period of downtime where Notify was unavailable. Ensure our replication had caught up so that all updates to our source database had been reflected on our target database. Allow our apps to start talking to our target database. This would end our downtime. It was important not to have some of our apps talking to our source database and the rest talking to our target database at the same time. If this happened any changes on our target database would not be reflected on our source database which would mean users would get inconsistent data. We wrote a Python script for this process so it could be explicit, easily repeatable and much quicker than being done manually. The quicker it could be done, the less downtime for users of Notify. Our target was less than 5 minutes of downtime. We ended up using this script at least 40 times during our various tests and practices beforehand. We picked a Saturday evening for the migration. This is because it is one of our quietest times without us having to be awake in the middle of the night when we wonâ€™t be as alert. Stopping traffic to our source database Our script would stop all traffic to our source database by calling `pg_terminate_backend` on all the connections from our apps. This took less than a second. We also changed the password for the PostgreSQL user used by our apps, meaning that if the apps attempted to reconnect to our source database they would get an authentication error. Checking replication had caught up DMS inserts some useful tables into our target database on the status of the replication which are updated every minute. These tables allow us to see how much lag there is between our target database and the source database. Our migration script would check these tables to make sure our target database was entirely caught up. To be extra safe, after our apps had stopped talking to our source database, our migration script would write a single record to our source database and then wait to see that it safely arrived in our target database. This gave us extra certainty that all changes had been replicated. Making a smooth swap of traffic For our apps to connect to our database, they need to know the location of the database and also a username and password for a relevant PostgreSQL user. These are provided to our apps in an environment variable of the following format: SQLALCHEMY_DATABASE_URI = postgresql://original-username:original-password@random-identifier.eu-west-1.rds.amazonaws.com:5432 If we want our apps to connect to a different database, we need to update the username, password and location in the URI and redeploy our apps so this change takes effect. Redeploying our apps takes about 5 minutes. If we redeployed our apps as part of our migration script then this would mean an extra 5 minutes of downtime. To minimise downtime we made two changes in advance of our migration so that we could use a quick Domain Name System (DNS) change instead of redeploying our apps. The first change was to create a user on both our source and target database that had the same username and password. This means that we donâ€™t need to change the username or password provided to the apps during the migration. The second change was to create a DNS record in AWS Route53 for `database.notifications.service.gov.uk` with a 1 second TTL (time to live). It had two records with weightings: 100% of DNS results were weighted to the source database location 0% of DNS results were weighted to the target database location We set our URI used by our apps to use our new username and password, and to use the new domain name for the location of our database. SQLALCHEMY_DATABASE_URI = postgresql://shared-username:shared-password@database.notifications.service.gov.uk:5432 Now, when we wanted to swap the database that our apps would be pointing at, our migration script just needed to update the DNS weighting in AWS to 100% of results being sent to the target database location and wait 1 second for the TTL to expire. Then, when our apps next try to query our database they will be querying our target database. What happened on the day When we gathered on the evening of Saturday 4 November, we had set up our target database, the full load process had run and new transactions were being copied across. We checked and only had a couple of seconds lag between our target database and the source database. We then successfully ran our migration script so that our apps would stop talking to our source database and start talking to our new target database. During the migration there was a short period of downtime, roughly 11 seconds. This was much less than our 5 minute target so we were very pleased and so were our users. What we learnt We chose to use DMS because it was well supported by the GOV.UK PaaS and we could also get support from AWS. If we were doing a PostgreSQL to PostgreSQL database migration in the future, we would invest more time in trying alternative tools such as pglogical. DMS potentially added more complexity, and an unfamiliar replication process than what we may have found with other tools. This backs up what AWS say themselves on PostgreSQL to PostgreSQL migrations. Whatâ€™s next for GOV.UK Notifyâ€™s migration to AWS Now weâ€™ve migrated our database, our next step is to migrate our apps. Sneak peek - we are moving them to AWS Elastic Container Service (ECS). We will blog about how this goes in the coming months. If youâ€™re interested in hearing about how a different team in government also migrated their database from the PaaS, then take a look at a recent blog post from the Department for Levelling Up, Housing and Communities. Tags: GOV.UK Notify, Migration",
    "commentLink": "https://news.ycombinator.com/item?id=39048317",
    "commentBody": "We migrated our PostgreSQL database with 11 seconds downtime (gds.blog.gov.uk)386 points by sh_tomer 12 hours agohidepastfavorite149 comments Ozzie_osman 9 hours agoWe did a similar migration (somewhat larger database) with ~20 seconds of downtime and much less work... using the magic of AWS RDS Blue-Green Deployments [1]. Surprised they aren't mentioned in the thread yet. Basically, you spin up a new Blue Green deployment with any desired changes (in our case, we were upgrading Postgres major from 13 to 15). While your blue configuration continues to serve traffic, AWS uses logical replication to keep the \"green\" deployment in-sync. You can keep modifying (or testing) the \"green\" deployment (eg you could load test it if you wanted to), as long as you don't do any writes to it (writes still have to go to your live, blue configuration, and are replicated to green). When you're ready, you run the \"switch\" command, and AWS does a few things for you: run checks to ensure blue/green are in sync, stops writes and connections, waits a few seconds to ensure replication is caught up, renames your database, then allows connections/writes again. We had less than 20 seconds of downtime, by our count. And, we had a primary and several read replicas and AWS successfully switched the full configuration over with no hiccups. You don't even need to switch your configuration because AWS swaps the database URLs for you. Green becomes blue, blue becomes old blue, and when you're ready, you delete \"old blue\". Highly recommend! They do have some restrictions (for instance, not sure if it would work if you're switching accounts, etc). 1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/blue-... reply sgarland 9 hours agoparent+1 for B/G. That said, I imagine they couldnâ€™t use it due to the cross-account shift. Iâ€™ve used it for both MySQL (with much higher QPS than TFA, by two orders of magnitude) and Postgres, and they both went flawlessly. Read the docs, especially the limitations. Re-read them. Do a test run in the dev environment, under load. Do it again in staging. Or just YOLO into prod â€˜cause itâ€™ll probably be fine, I guess. reply Ozzie_osman 9 hours agorootparentWe definitely did a dry run with a parity configuration a couple nights before. It gave us a lot more confidence. reply cljacoby 7 hours agoparentprevI also used RDS Blue/Green deployment to apply a MySQL major engine version upgrade from 5.7 to 8.0. With respect to downtime it worked fantastically, I think we measured 13 seconds of observable downtime from the API. However we did learn the hard way that RDS Blue/Green cannot be used to apply arbitrary changes. In our case, we discovered RDS Blue/Green can only be used to move up engine versions, not down. We discovered on MySQL 8.0 one of our stored procedures had very occasional failures, and considered the option of using RDS Blue/Green again to move back down to 5.7. Turns out that's not an option. reply 0xbadcafebee 3 hours agorootparentDatabase changes are typically one-way. If your new change includes creating or modifying a table, such that there are new additional columns, and you populate those with data, then downgrading would destroy the changed columns and the data in them. Hence you can't downgrade once you upgrade or you'd potentially be breaking things. To downgrade safely you'd need to backup or snapshot the old database, and then restore your database back to the backup/snapshot, but that's not blue/green. reply fulafel 2 hours agorootparentDB schema migration script frameworks (at least in Python, Ruby & Java lands) do typically support both upgrade and downgrade directions. People skip implementing and testing the downgrade side if the development model doesn't need it but the problem of what happens to the data is controlled by what you put in the \"down\" migration script. I'd guess if you can't throw the data away, you won't do a down migration, you'll do an up migration that changes the db to save that data in your preferred way before undoing or reworking the previous schema change. reply yellowsir 1 hour agorootparentbut now you have 2 up paths. and migrations are critical, i would avoid it where possible! reply Mavvie 6 hours agorootparentprevI wonder if that could be because MySQL 8's replication is backwards compatible but MySQL 5.7's isn't forwards compatible. If so, it makes sense that you're only able to move forward. reply troublebucket 8 hours agoparentprevHas anyone encrypted the storage on a previously unencrypted RDS using Blue/Green? reply wisosim 6 hours agorootparentWe did the exact thing not too long ago, but we couldn't do it using blue/green. We were able to minimize downtime quite a bit, but it was on the order of minutes, not seconds. I wrote a little bit about the process here. I spent a lot of time prepping and running the migration, so happy to share any details if it's helpful. https://phizzle.space/dbadmin/aws/postgres/2023/12/30/rds-en... reply d1str0 8 hours agorootparentprevGood question. This was a pain point for my small team (me, myself, and I) a little while back. We had an unencrypted db deployed with CDK, and then tried to get it encrypted without losing data. reply bgschulman31 8 hours agorootparentprevWe recently did this on my team over Christmas this year. We opted not to use Blue/Green for this but instead spun up an encrypted snapshot and began replication from the old database to the new database using MySQLâ€™s tools. Once traffic on our platform was sufficiently low, we cut connections to the database, waited for for replica lag to reach 0 and relaunch the servers with the new databases host info. Our downtime was around a minute. reply yeswecatan 5 hours agoparentprevHow did you go about stopping and restarting applications which reach out to the database? We have a number of tasks running in ECS which can take a minute to spin down and a few minutes to spin back up. reply todd3834 2 hours agorootparentYou arenâ€™t supposed to have to change anything in the application code. The same database URL should work. reply ThePowerOfFuet 3 hours agorootparentprevPresumably you don't stop them, and they throw errors during the cutover. reply londons_explore 10 hours agoprevThere are various ways to 'pause' incoming postgres queries, for example using pgbouncer, - ie. don't fail them, simply delay them until the replication has caught up and then let them continue on the new database. If anything goes wrong and replication doesn't catch up, you can unpause and let those queries happen on the old database. Therefore, your 11 seconds of downtime becomes 0 to 11 seconds of added page load time. But more importantly, of the thousands of users of the database who have never seen a query fail before and might have buggy error handling codepaths or have a single failed query ruin a whole batch job, this approach leads to a lot less collateral damage. reply alerter 36 minutes agoprevInteresting, though I have no idea why the government is using AWS in the first place. This isn't a startup hacking away trying to find PMF, or dealing with unpredictable marketing-driven traffic spikes. We know we need these services running long term, and can make solid predictions about usage patterns. We could build a public sector cloud and/or adopt a sensible on-prem approach. This requires funding, coordination and technical leadership, but would save the taxpayer an enormous amount over the long term. Public sector IT is a disaster in general ofc, but I know there are good engineers working there. reply jamietanna 15 minutes agoparentThe UK government as a whole operates across the big names in the public cloud as well as some on-Prem/colo. I'd very much recommend watching https://youtube.com/watch?v=mpY1lxkikqM&pp=ygUOUmljaGFyZCB0b... from September about Gov.UK's various iterations and some of the migrations across cloud that they've had to do. One thing about (at least UK government) is that procurement requirements means that they go to market for quotes around usage every few years. If ie Oracle Cloud was 1/10th the price, it would likely mean they'd win the deal, and so would have to migrate to Oracle for the duration of the contract, and then potentially do the same to another cloud if that was cheaper reply StupidOne 20 minutes agoparentprevI'm sure a lot of countries in EU did this. First hand I know, they did this in Croatia as I was one of the developer who had to use it to deploy on it. The worst thing I have ever seen in my life. And I worked on a lot legacy apps written in VB.NET, Web forms, old Sharepoint, Basic and even when the whole app was one big mess of store procedures. AWS, Azure, GC are at least written with thought about end users (us, developers) while government cloud was architectured, designed and built by the lowest bidder whose first goal was to cut and cut and cut his costs whenever possible. reply rjzzleep 28 minutes agoparentprevI don't know about the UK, but AWS has has GovCloud in the US for a long time, and to be honest compared to a lot of infrastructure I have seen there it's a blessing. On the flipside, I've met some really amazing infrastructure and ops people in a German gov healthcare institution running the in-house DC, where the problem was neither the tech, nor the people, but 100% the management and their processes, and their desire to be the bottleneck for every single interaction between infrastructure and engineering teams. reply MrBuddyCasino 30 minutes agoparentprevIf you think the public sector could improve its operational efficiency by building, operating and using their own cloud, I've go a bridge to sell you. reply pedrokost 2 hours agoprevWe recently completed the migration of a self-hosted 3 TB PostgreSQL database from version 12 to 16, transitioning from Ubuntu 18 to Ubuntu 22. Concurrently, we had to upgrade various extensions, most notably Timescale, for which a compatible version did not exist across all scenarios. We performed the upgrade by updating a replica in the following sequence: - Start: PG12, Ubuntu 18, TS2.9 - Step 1: Set up a read-only replica with PG12 on Ubuntu 22, maintaining TS2.9. - Step 1.5: Enter maintenance mode and halt all services. - Step 2: Detach the the read-only replica, upgrading from PG12 to PG15 on Ubuntu 22 with TS2.9. - Step 3: Upgrade from PG15 with TS2.9 to TS2.13 on Ubuntu 22. - Step 4: Upgrade from PG15 to PG16 on Ubuntu 22 with TS2.13. - Step 4.5 : Reconnect services to the new database server, resume all services, and exit maintenance mode. All the database upgrade steps were well-tested and automated using Ansible. Nonetheless, we did encounter an issue that had not arisen during testing. This extended our downtime to approximately half an hour, which, for our use case, was perfectly acceptable. Employing logical replication could have mitigated the last-minute surprise. So we will consider this approach for our next upgrade cycle. reply mbb70 11 hours agoprevInteresting to compare this to https://knock.app/blog/zero-downtime-postgres-upgrades discussed here https://news.ycombinator.com/item?id=38616181 A lot of the discussion boiled down to 'this is a lot of complexity to avoid a few minutes of downtime'. I guess this is the proof, just use AWS Data Migration Service, swap the DNS entries to go live and live with 11 seconds of downtime. reply ris 11 hours agoparentThere is no \"just\" about it. The absolute key takeaway is in \"what we learned\": > We chose to use DMS because it was well supported by the GOV.UK PaaS and we could also get support from AWS. If we were doing a PostgreSQL to PostgreSQL database migration in the future, we would invest more time in trying alternative tools such as pglogical. DMS potentially added more complexity, and an unfamiliar replication process than what we may have found with other tools. This backs up what AWS say themselves on PostgreSQL to PostgreSQL migrations. The message here is not \"just use DMS\". reply T-Winsnes 8 hours agorootparentEven AWS in their own docs says to use the native tools when migrating from postgres to postgres[1]. They don't go into the details to much and points to pg_dump rather than pg_logical, but interesting to see that they don't recommend using DMS for it [1] https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source... reply btown 10 hours agoparentprevHas anyone used https://cloud.google.com/database-migration/docs/postgres/qu... to do something like this? Does it work similarly to AWS DMS? reply postpawl 10 hours agoparentprevThere are a lot of gotchas with using DMS (which seems to use pglogical under the hood). Since itâ€™s not hardware-level replication, you can run into issues with large rows/columns/tables and it doesnâ€™t really handle foreign keys. It may not handle some special data types at all. You also need to update the sequences after the migration or youâ€™ll get errors about duplicate primary keys. You can also have issues if you donâ€™t have proper primary keys, because it doesnâ€™t always copy the entire row at once. If the databases are within the same AWS account, itâ€™s likely easier to use hardware-level replication with global database or snapshots to do migrations if youâ€™re ok with 4-5 mins of downtime. reply Twisell 3 hours agorootparentThere are many options available with PostgreSQL you could also do a physical full backup + WAL level replication to keep key AND a get low downtime. What might have oriented theirs choice is that they wanted to upgrade from major version 11 to 15 during the migration process. This is only available using logical replication. Otherwise you'd have to chain upgrade process of each major version (and possibly OS because 11 is EOL on some arch) and this is nor trivial nor quick. reply londons_explore 10 hours agoprevNote that the enemy of low/zero downtime migrations like this is long running queries. Ie. a single update query which takes 30 mins. You either have to kill and roll back that query, or suffer 30 mins of unavailability. As far as I know, there is no way to migrate a currently in progress query. reply necovek 6 hours agoparentFor a software engineering project, you probably want to limit your transactions to much less than that (set statement_timeout is your friend). If you've got extremely long transactions, you can probably avoid doing the switch-over when they run (hopefully they are not a random occurrence but a result of a scheduled job or similar). In combination with transaction time limit and fail-over configuration (where you fail the old primary), you can control the slowdown (instead of downtime, eg. with pgbouncer) very precisely. I would be more concerned with the DNS TTL being respected in the entire stack (and external caching DNS servers you rely on), tbh. But it is usually not critical to avoid a dozen seconds of downtime for an app, so whatever is simpler for you should be your go to solution. reply callalex 2 hours agoparentprevWell youâ€™ve certainly introduced a teaching moment to me! What are the nature of writes you deal with that last 30+ minutes? What kind of data/what kind of people are involved with such DB writes where you need to rely on the DB engine to work so hard instead of something more split up by queues at a higher layer? reply londons_explore 1 hour agorootparentIt's usually badly engineered things. However, just because it's badly engineered doesn't mean it's fine for it to break :-P Things like a super complex n^3 complexity query to find all users who were 3 hops away from a known fraudster, where a 'hop' means 'shared any piece of account data in common' reply londons_explore 1 hour agorootparentprevPostgres queries are streaming. Ie. If the query result has 1 billion rows, but the client only has enough ram for 1 million rows, then the query will be slowed down until the client is ready to accept more rows. If the client is slowly processing through the result set, then the query can take many minutes/hours. reply Amezarak 9 hours agoparentprevIt's hard for me personally to imagine a 30-minute update query that is not written extremely inefficiently, or else a one-time huge data migration. There are a lot of the former in the wild to be sure. I've had a lot of run turning minutes-hours into milliseconds. :) reply londons_explore 8 hours agorootparentData scientists... And when you look at the query, it'll be 800 lines of SQL... reply hobs 4 hours agorootparentHeh, that's not so bad - 2 jobs ago I had to fix a KPI generation process that was 70k lines of dynamic sql, that unwrapped to up to 1m LOC :) reply efxhoy 9 hours agoprevLovely! We just migrated from postgres 14 to 16 for 3 postgres clusters (servers) on RDS containing about 2TB of data across 8 databases. We were down from 00:00 to 04:00. Steps we took: * enabled our fallback \"maintenance mode\" site. It's a super lightweight version of our site running on CF workers. * scaled down all apps using the db to 0 in terraform * hit the upgrade button in the aws web ui, which runs pg_upgrade. 14->15 * waited for it to finish * hit the upgrade button again. 15->16 * waited for the dbs to start accepting connections (they do before they're marked as ready, I think aws does more stuff than pg_upgrade) * Started `VACUUM ANALYZE; REINDEX DATABASE CONCURRENTLY`. The idea is to avoid performance issues between versions and make use of performance improvements from new versions. * Started spinning up the apps again * Waited until all apps had a handful of containers running * Started accepting traffic (disabled maintenance site) * Went to bed The REINDEX CONCURRENTLY happily chugged along for the biggest db for another 18 hours without blocking anything. Next time we're doing aws blue/green deploys to avoid downtime. We didn't this time since we weren't on 14.9 yet (the minimum minor version of 14 supported by blue green). If I was doing this myself I wouldn't pay the AWS tax, instead do blue/green myself with logical replication and a load balancer. reply ComputerGuru 9 hours agoprev> The second change was to create a DNS record in AWS Route53 for `database.notifications.service.gov.uk` with a 1 second TTL (time to live) [..] our migration script just needed to update the DNS weighting in AWS to 100% of results being sent to the target database location and wait 1 second for the TTL to expire. Then, when our apps next try to query our database they will be querying our target database. Wait. Their (or Python's default?) db orm blocks while it performs a DNS lookup for each and every query!? It doesn't cache resolved addresses for any length of time? No connections are pooled and reused? reply necovek 6 hours agoparentIt would probably be the OS' `getaddrinfo` or `gethostname` that does this: Python rarely reimplements system level calls, which means it relies on the system's configuration. If TTL of 1s was respected, they would be cached for 1s, but it's not uncommon for DNS query libraries and especially caching DNS servers to not fully respect TTL anyway: tbh, that might explain some of the downtime they've seen. reply ComputerGuru 5 hours agorootparentI didn't mean it was directly implementing the networking call to the dns server -- just that it wasn't directly caching the result. getaddrinfo(3) and getnameinfo(3) (guessing that's what you meant) don't implement caching, at least not explicitly in the spec and not normally in practice. On Windows, DNS results are cached by the OS but on Linux that would be distro-dependent behavior and usually requires setting up a local caching dns server (Ubuntu uses unbound out-of-the-box, iirc. Other choices include ncsd and dnsmasq). Even if they implemented caching at the syscall level, this still assumes no connection stays open for more than 1s or is reused except per query. It seems like a big assumption (at least I hope it is, because I certainly wouldn't want my app to initialize a new db connection, let alone perform a DNS lookup, for every query). reply juggertao 3 hours agorootparentThey mentioned they had a script which terminated all connections to the old database then changed the password. But on the app side you typically don't cache DNS, that creates other problems like stale DNS. reply igammarays 10 hours agoprevNow all we need is for Amazon to come out with a \"government-as-a-service\" product for your budding nation state. reply hinkley 9 hours agoparentIn partnership with pinkerton.com reply ris 10 hours agoparentprevFWIW GOV.UK Notify is part of a suite of services offered by GDS to UK public sector bodies (along with GOV.UK Pay and GOV.UK PaaS) that was originally known as \"Government As A Platform\". reply ryandv 3 hours agoprevI've also used DMS to migrate smaller datasets (~200GB) from AWS RDS MySQL 5.7 to RDS PostgreSQL 11. 10 seconds of downtime here was actually incurred not due to the migration itself, but to enable MySQL binary logging on the RDS instance, which requires a restart, and which AWS DMS uses to replicate changes from the replication source (MySQL) to the target (PostgreSQL). Traffic was steered to the new PostgreSQL instance not with DNS/Route 53 weighted records, but an application-level percentage enroller (based on user ID). Our particular set-up did in fact have apps talking to both databases simultaneously, each with a percentage share of traffic, and so we did not need to incur additional downtime to cut off traffic to the original source database - though now you do have to worry about eventual consistency. I wouldn't recommend using their Schema Conversion Tool. We instead migrated the data as 1-to-1 as possible into the PostgreSQL target table, and then used plpgsql triggers on the replication target table to clean/validate the data and write it to another table with our desired (and more strongly typed - no more storing JSON as TEXT) schema. There were also some issues with the replication task seeming to stall and stop during the change data capture (CDC) phase. As mentioned support is kind of spotty in this area, though we learned it may have to do with sizing the DMS replication instance correctly. reply sharadov 5 hours agoprevDMS is a terrible migration tool, I spent almost a month fighting with various migration issues before I gave up. It would not migrate text and json types. Even AWS support could not offer a solution. We got in early testing AWS Blue/Green and that has made close to zero downtime upgrades a reality. reply slyall 4 hours agoparentIf you think DMS is a bad migration tool then try using it for ongoing replication to an external destination. Completely broken. reply denysvitali 2 hours agoprevThey could have probably used pgpool [1] to avoid relying on the DNS (you never know in the chain who's not respecting the TTL). With this, you can choose which queries are ending up where - and migrating the DB endpoint can be done once, centrally [1]: https://www.pgpool.net/docs/latest/en/html/ reply speculator 2 hours agoprevnice writeup. easy to read, easy to understand reply ClassicOrgin 9 hours agoprevMinor detail but did anyone else notice they are using eu-west-1? Kind of weird for the UK to be hosting there sites in another country (Ireland). I'm sure this isn't super sensitive data but still. reply callalex 2 hours agoparentIt made a lot more sense beforeâ€¦you knowâ€¦the thing that made no sense. reply esskay 9 hours agoparentprevThey've been on AWS since before eu-west-2 was added, it's still not at the scale of eu-west-1. Capacity issues are still a thing (but getting much better), and only recently have they become pretty much feature parallel. reply kitd 1 hour agoparentprevI think one of the bits of carry-over legislation in the Withdrawal Agreement after Brexit was the UK continuing to comply with GDPR. So using an Irish DC is still ok. reply lozenge 9 hours agoparentprevThe London AWS region was missing a lot of features for a long time. It's easier to just go with a big region. reply justinclift 8 hours agorootparent\"Lets go with the easier approach\" is a bit worrying when it means potentially breaking security assumptions / legal assurances. Though I guess it could be explained away by having something in the website's \"Terms and Conditions for use\". ;) reply juggertao 3 hours agorootparentIt's a gov website. What are they going to do, sue themselves? reply another2another 2 minutes agorootparentHave a public enquiry, with lots of tea. saisrirampur 8 hours agoprevVery clear and concise blog! Loved reading it. I'd be very curious to see how Amazon DMS performs at scale. Scale includes either of these situations: a) Larger dataset - 2+TB b) Higher throughputs - WAL Spikes (at least 2-3K TPS) c) Reliably and efficiently replicating TOAST Columns (ex: large JSONBs). d) Advance data-types - BLOB, CLOB, HSTORE, ARRAYs etc. In my previous role with the Azure Postgres team, we observed that Azure DMS worked pretty seamlessly in migrations that did not involve the above situations. Once either of the above came in, the replication experience was hairy. Interestingly, in my current gig at PeerDB, many use-cases we are seeing have either of the above situations. We have been doing quite a surgical optimizations to handle those situations and they keep coming! That is the beauty of Postgres, enabling a myriad of workloads, each of the unique in their own way! :) reply DeathArrow 3 hours agoprevSeems bad that government services depend on clod providers. reply callalex 2 hours agoparentWhy? Do you deny the benefits of shared hosting in its entirety? reply DeathArrow 1 hour agorootparentNo. But I wish government agencies depend less on other entities. A government agency isn't in a business to make money. They should be concerned less with economic efficacy and more with accomplishing their goals. They have a fiduciary duty towards the citizens. reply aidos 10 hours agoprevI love that where the rubber meets the road it doesnâ€™t matter if youâ€™re a government organisation or a web agency, itâ€™s still just plain old Postgres, python, sqlalchemy and dns with a low ttl. reply NegativeK 9 hours agoparentTo be fair, there's plenty of government orgs at the bottom and web agencies at the top. reply oulu2006 6 hours agoprevWe didn't even use red/green deployment; just had a multi-AZ deployment and migrated from 11.x -> 15.2 with about 30 seconds of downtime. No dramas really, didn't even need logical replication. reply globular-toast 1 hour agoprevIs that a picture of them doing it? What is this weird fantasy that programming looks like this? It's always the same: a couple of people, always of diverse backgrounds, physically interacting, usually pointing and laughing at something, with perhaps another group, representing different demographics, looking on with a mixture of curiosity and awe. Do an image search for programming to see more examples of this. I guarantee this work was the result of guys sitting at desks, possibly in the dark, thinking. Are we collectively embarrassed that this is what programming looks like? Or are these just fantasies of management types who have never written a line in their lives? reply draaglom 28 minutes agoparentThe primary goal of most large organisations' dev blog is to attract potential candidates to the top of the recruitment funnel. This picture appears to be (presumably) the actual team doing a team building activity. This is both a reasonable choice given the inferred instrumental goals of the blog, and a honest reflection of (one part of) the team life, assuming it's a photo of the real team. reply johneth 35 minutes agoparentprevGive it a rest, mate. reply globular-toast 27 minutes agorootparentNah, this is the thing that leads to open offices etc. I want people to understand what programming actually looks like and these silly pictures need to go. reply zImPatrick 3 hours agoprevI really love how verbose and up to date the UK with tech reply gbraad 9 hours agoprevThey don't just sent the notifications but store them? Sounds like it might contain PPI as it records passport extension data, etc. Might be minimal, though over 1 billion rows (400GB) sounds massive trove to keep around. reply karol 10 hours agoprevHope the picture is illustrative only. reply vfclists 8 hours agoprevThis doesn't seem to bode well for Oracle, but lobbying trumps the day. reply Topgamer7 10 hours agoprevWe tried to work with DMS to migrate mysql to postgres, and it was a nightmare. Support was useless, and would often just not get back to us without prodding. Then them giving us canned responses unrelated to our queries. The whole thing is nigh on un-debuggable. Stay away. reply mey 10 hours agoparentI worked on migrating our MySQL system to PostgreSQL using pgloader ( https://pgloader.io/ ). There were some hiccups, things that needed clarification in documentation, and some additional processes that needed to be done outside of the system to get everything we need in place, it was a amazing help. Not sure the project would've been possible without it. Data mapping from PostgreSQL to PostgreSQL as in the article isn't nearly as bad as going between systems. We took a full extended outage and didn't preload any data. There were many dry runs before hand and validation before hand, but the system wasn't so mission critical that we couldn't afford to shutoff the system for a couple of hours. reply Topgamer7 9 hours agorootparentWe also ended up using pgloader. Its not without its friction either. For example the concurrency/number of rows setting seems broken out the gate, and its like playing darts with a blindfold on to get it to run without running out of memory. But being able to read the source, github actions, and overall at least I could debug my problems, or find others who had the same issue. Would recommend pgloader. reply tibbon 9 hours agoparentprevWe also tried to use DMS for a few things (Rackspace to AWS migration, replication out to data lakes, etc) and it has been consistently undersupported, buggy and ate months of time before we went to other solutions. While a lot of AWS support has been good; not for DMS. It feels entirely half baked . reply extesy 9 hours agoparentprevI can confirm that. Both DMS reliability and support quality were terrible. reply troublebucket 8 hours agoparentprev+1 DMS is very half baked. Silent, unbuggable errors. Tons of unsupported LOB and CLOB data types. Built-in Postgres logical replication is way easier. reply rjh29 10 hours agoparentprevTried it for mysql and it was flat out broken and silently corrupted data. reply Topgamer7 9 hours agorootparentFor us it seemed to be trying to load data from the wrong table on mysql, into the wrong table on postgres. reply NomDePlum 10 hours agoparentprevSurprised by that. I've used AWS DMS quite a lot to do both on-prem to AWS and AWS (MySQL) to AWS Postgres migrations and long term ongoing replication. Whilst there is some complexity/gotchas there it's always been more than up to the task. Takes a little bit of validation/testing to understand but it's very well documented too. What sort of issues did you hit? In all honesty I'm not sure I've been more impressed by another AWS service. reply Topgamer7 9 hours agorootparentIt seemed to try to load data into the wrong table on postgres. That was the one that immediately comes to mind. Honestly poor support is what really killed it for us. But we had other technical problems with it. We burned 3 weeks just trying to get support to provide a sensible response. I never got the sense anyone replying to us knew any more than the surface level about the infrastructure of how DMS worked. reply NomDePlum 2 hours agorootparentWe kept our table mappings pretty much mirrors of the source tables. Any data transformation we managed on the target cluster, not through AWS DMS. I've used it fairly frequently over a number of years so maybe the issues we hit on the learning curve have dimmed. We also deliberately kept things as simple as possible at first and focused on DMS's ability to move the data from source to target and really only tweaked settings that increased security or reliability. We stayed well away from any of the data transformation or more complex functionality. reply tibbon 9 hours agorootparentprevOne issue we hit were any schema changes totally messed it up. I don't have my notes in front of me, but we were constantly hitting data that wouldn't migrate, or that things suddenly broke whenever things changed. reply NomDePlum 2 hours agorootparentInteresting we managed several schema changes when using AWS DMS for replicating data over a long period between MySQL and Postgres clusters. We treated these carefully and tested as we made them but never had any real issues with them. From memory DMS could cope with adding columns pretty transparently. One setting we invested in configuring and understanding was to allow DMS to attempt to recover from replication failures. This allowed it to error on DDL changes and attempt to recover. This usually involved restarting the task, but it would do this transparently as part of the recovery. reply Spivak 10 hours agoparentprevThis was my experience as well. We thought it was a nice managed way to move pg to pg with minimal setup but we ran into so many issues we just did logical replication with bespoke fixes for things it didn't handle well. reply Edwinr95 11 hours agoprev [â€“] I'm quite negatively surprised that a government service is moving from their own platform to AWS for such an important service. reply conception 11 hours agoparentAWS has a lot of pre-audited compliance built into their services. Being able to inherit their certification for services can save an organization a lot of time and effort. reply lnxg33k1 11 hours agorootparentIts not an organisation, its a blucking government, it handles citizen data, and its sending them to a company of foreign country, because it canâ€™t hire some system administrators? A GOVERNMENT? What are they doing? Still looking for their product market fit and canâ€™t afford the headcount? Is it a joke? EDIT If they are looking for money id like to participate a bit in the seed round reply solatic 2 hours agorootparent> because it canâ€™t hire some system administrators? Spoken like someone who has never worked in the public sector. Hiring can easily take 6+ months or more due to an ever-increasing list of requirements that government HR is required to fulfill, not least of which is passing a security clearance which takes even more time. The best people on the market rarely have the patience for this. Once your employees do get hired - on-boarding can take another few/several/more months, getting various permissions, technical documentation, etc. Everything is out-of-date because making changes requires committee consensus, in a culture that is risk-averse, because nobody notices when you out-perform (after all, the requirements were also set by a committee that doesn't know who you are) but something going wrong is grounds for termination. Public sector work over-relies on hiring contractors precisely to shift blame for failure to the contractors. Managed database services are excellent tools to shift this kind of catastrophic risk of data loss to a contractor/vendor (who is managing the database). Governments not owning their data isn't due to technical or budgetary limitations - it's strictly cultural. reply NomDePlum 2 hours agorootparentFully agree with this. I'd also add that a lot of IT is buy not build, in general. That includes support. Particularly true for the public sector and has been in place well before AWS existed. Outsourcing the complexity to run and maintain a secure reliable database cluster really is making good use of the managed service model. reply Dylan16807 2 hours agorootparentprev> Hiring can easily take 6+ months or more Do you think this move didn't take even longer to plan? > to shift blame That reason is much more plausible. reply dijit 10 hours agorootparentprevSysadmins are cheaper than many people seem to think. I had a person I trust a lot telling me that \"if we go with a bare metal provider like GCore we'd have to hire someone\", his reason for bringing that up was that the cost difference would be justified by not having to hire someone,. However a GCore â‚¬400,000k/y bill becomes a â‚¬6,000,000~ if you were to use a public cloud, even with the scaling up and down when not in use (we are an extreme case of needing a lot of dumb unreliable compute thats geographically distributed). I can hire a lot of sysadmins for that money, but I probably don't even need one because public clouds also need devops staff to manage the complexity anyway. reply rcxdude 2 minutes agorootparentyeah, every company I know of that uses cloud has a team responsible for managing it anyway, and they don't seem much smaller than the team needed to manage on-prem. I don't really think this 'savings' exists in most cases. DylanDmitri 9 hours agorootparentprevThe risk is hiring a team of ineffective sysadmins, especially if your organization canâ€™t assess sysadmin competence. reply dijit 9 hours agorootparentThat would indeed be a risk, but the circular logic of this means no new company could ever have any competence outside of its founders. Which feels shortsighted. Anyway, I am a former sysadmin. I am confident that I can identify competence in the requisite areas. reply criley2 9 hours agorootparentGovernments tend to be far less competent at determining technical competence. Due to a wide variety of factors, governments tend to be completely uncompetitive in salary for technical positions meaning they're already hiring from the lower end of the pool (not including a few altruistic folks willing to forgo their market value). At a company if a department isn't working out you just restructure and move on, but in the government, that team is going to retire in your org and collect pension from you, and there's very little you can do about that. reply belter 10 hours agorootparentprevIf you are worried about that, start with your government use of Microsoft Office and Windows who both send MB of data per minute to a US based company. reply kunwon1 11 hours agorootparentprevAWS has a G-Cloud for UK just like they have one for US, no? reply NomDePlum 2 hours agorootparentNo. It is only relatively recently (~5/6 years) AWS have had any data centres in the UK. That blocked use of AWS for a lot of UK departments due to data sovereignty concerns. reply snoman 10 hours agorootparentprevAWS has government specific regions (called GovCloud). Many services or features make it to GovCloud later than other regions because of the certification requirements. reply travem 10 hours agorootparentprevAWS has US based GovCloud regions: AWS GovCloud (US-East) and AWS GovCloud (US-West). It does not have a UK specific GovCloud region that I am aware of. reply bboygravity 10 hours agorootparentprevWhy can't the UK government build there own cloud? It's just completely insane to me that they would make the gov internet infrastructure completely (geopolitically) dependent on another country AND just literally give all their (citizens') data away AND pay for that \"privilege\"?! I mean if the government can't host the government's websites using tech from the government's country, maybe it would be better to just forget about the whole cyberweb thing altogether? Just turn it off? reply kakoni 3 minutes agorootparentYou know that UK's National Health Service did a deal with Palantir for \"federated data platform\"? ris 10 hours agorootparentprevI don't think you have any idea just how much it costs to run infrastructure at the reliability levels provided by AWS, and just how much investment it would require to get the ball rolling on this. A lot of people have a very unrealistic picture of what government budgets are like. reply blibble 10 hours agorootparent> I don't think you have any idea just how much it costs to run infrastructure at the reliability levels provided by AWS my $12/year VPS does better than us-east-1 reply hdlothia 9 hours agorootparentWhere do you get a 12 dollar a year vps. Hetzner charges me 4 bucks a month and it feels like a steal reply blibble 8 hours agorootparenthttps://lowendtalk.com/ quality varies reply 0xbadcafebee 3 hours agorootparentprevWhy can't the UK government build their own cars? Their own boots? Their own pens, paper? How wasteful and pathetic that they wouldn't make all those things themselves. If it's possible to do it yourself, by golly, you should do it yourself, and there's absolutely no reason in the entire world to purchase those things from someone else instead. reply robertlagrant 10 hours agorootparentprevThey'd still be outsourcing to a firm to do this. They wouldn't hire a load of people to do it in-house. See also Fujitsu in the recently-popular Horizon scandal, or the NHS for IT debacle[0]. [0] https://en.wikipedia.org/wiki/NHS_Connecting_for_Health reply shagmin 5 hours agorootparentprevI've always wondered how beholden the world is to Microsoft. I was once surprised to learn the US military (and probably virtually all others) don't have their own OS to avoid being tied to a particular company. reply vdaea 10 hours agorootparentprevWhy should they build their own cloud, seeing that costs more money? reply willsmith72 10 hours agorootparentprevyou want every government to build their own cloud? what in the world? the whole world is interlinked, should they also manufacture their own government laptops in the UK? reply foofie 10 hours agorootparentprev> (...) its a blucking government, it handles citizen data, and its sending them to a company of foreign country, because it canâ€™t hire some system administrators? A GOVERNMENT? What are they doing? This is a very good question, and bears repeating. It's not a massive database as well. 400GB with 1k inserts/second. reply everfrustrated 9 hours agorootparentprevThe UK replies entirely on the mercy of USA for its nuclear deterrent (Trident) For the UK at least, that ship has _long_ since sailed.... reply blibble 9 hours agorootparenttrident has UK built warheads and is operationally independent of the US reply sph 11 hours agorootparentprevHow would you feel if the US government ran on servers from a European company, which also works very hard to avoid paying taxes in US soil? All those reasons to go AWS hold for a private company, not for a government service of a first world country and G7 member. AWS has a lot of compliant services, but it's not like they're doing rocket science one of the top 5 richest countries in the world cannot afford to develop or contract within its borders. The simple reason is that the UK has been on a long trend of selling out to the highest bidder, whether they are US tax avoiding companies, chinese or managed by Russian oligarchs. We have chosen AWS for the same reason Post Office chose Fujitsu. reply freedomben 10 hours agorootparentI would be surprised if they aren't deploying to the London data center, so I would think it is within the UK reply dijit 10 hours agorootparentThere's no govcloud in the UK; unless there are specific terms then the terms-of-service state that you are licensing either the irish entity or the american entity to have access and dominion of your data. I had to spend a lot of time writing my privacy policy (perks of being CTO... yay), and part of that privacy policy was an admission that we transfer ownership of data to a US company (by using public cloud) despite using european datacenters. This is because our agreement is with a US entity. reply esskay 9 hours agorootparentpreveu-west-2 is a bit misleading, most of its nowhere near London, they've got DC's right up into the midlands. One of their newer ones for example is out in Didcot Oxfordshire, they've also got a few up towards Peterborough. All classed as 'London' despite being a fair distance away from it. reply arpinum 10 hours agorootparentprevThe blogpost shows a connection string to eu-west-1 in Ireland reply jazzyjackson 11 hours agoparentprevI don't know what it's like in UK but it may be the case that government has a hard time a{ttract,fford}ing talent to administer everything in house. Not that AWS is great for cost saving but if its between paying 50k/year for cloud services and not being able to find an engineer who will competently do the job for less than 50k, then the cloud is your only move really. reply prmoustache 3 hours agorootparentOnce your past the emerging startup status, running on the cloud involve as much engineers and complexity as running on prem if you want to follow best practices. The \"let's be managed and only hire developers\" is a huge myth. All large organizations involve tons of \"cloud engineers\" or \"devops\" depending on how they want to call them and are just sysadmins with a different name and a bigger paycheck. Having actual datacenters doesn't add a ton of complexity and datacenters themselves are often managed by people who don't even have an engineer paycheck. The main difference between being on prem vs cloud is you have to plan (how many servers/storage/network equipment you have to buy and replace on the following year) and pay for stuff (like space, racks) more in advance + take into accounts delays in delivery. This is where cloud makes the job much faster for companies but given the slow pace at which gov stuff happen usually I don't think this is a problem for them. reply solatic 2 hours agorootparentprev> and not being able to find an engineer Remember it's not just about being able to find one single engineer - then they become key-person risk. You need multiple engineers to be able to handle the loss of that engineer, either temporarily (vacation) or permanently (suddenly hit by a bus). Then you end up having a team of DBAs. Then you have functional rather than feature teams. Then you need multiple managers to align to get anything done, and have internal politics. Being able to consume databases as a product has non-trivial value. reply swozey 10 hours agorootparentprevThey require various clearances (digging into your life and past relationships to a miserable degree), don't allow someone to have ever smoked pot and pay half or less of what you can make in the pvt sector here (usa). Everyone I know working FedRAMP jobs is prior military/g-level. reply robertlagrant 10 hours agorootparentThey wouldn't need that. And having been SC cleared in the UK, and known a few DV-cleared ones, at least in the UK they don't care if you've smoked pot. They just care that if you have, that you don't mind your family knowing one day. They don't want people who can be blackmailed. reply swozey 10 hours agorootparentHere it's like this: Don't ever lie to them, \"no matter what it is they'll find out.\" So, some people don't lie, say they smoked pot in high school and none of them make it to the next step. I had a twitter convo last year or pre-x whenever with the CTO of some org I can't remember (I don't think centcom, something much smaller) and he mentioned that they've lightened up quite a bit, or at least his program which was a softwar engineering group was more lenient. He was looking for engineers on via twitter on his official account. So maybe that's loosening up here thankfully. reply justsomehnguy 10 hours agorootparentprev> who will competently do the job for less than 50k, then the cloud is your only move really Well, there is the other way, but, as we know, never ever that would happen. reply kingkongjaffa 11 hours agoparentprev> This is an AWS RDS PostgreSQL database and it lives in the PaaSâ€™ AWS account. Our apps that run in the PaaS talk to this database. We are going to call this database our â€˜source databaseâ€™. It already was. Read the article. reply pmcp 10 hours agoparentprevAs somebody who worked for the European Commission, and a european national government, I agree with your sentiment, but the harsh reality is that government divisions in generally work on a shoe string budget, when it comes to decisions like these. I wouldnâ€™t be surprised if this was a â€œbest effort given the circumstancesâ€ move. reply NomDePlum 9 hours agoparentprevWhy? I've worked on a number of UK government projects, including some with particularly sensitive security and data requirements. Having some knowledge of their on-prem data centres and UK Cloud offering they have also used moving to AWS has so many operational, security and resilience benefits that aren't available elsewhere. It's not a free-lunch by any means and needs thought and governance certainly but the procurement simplification benefits alone make going to the public cloud a no brainer for a lot of government services. It is worth knowing that even the on-prem data centres are usually operated by 3rd parties such as HP, BT and IBM. There was an initiative to have \"Crown-managed\" data-centers but it's not particularly scalable. reply overstay8930 9 hours agoparentprevIf you saw how non-tech companies run datacenters, well let's just say they're not exactly working with NATO like the big 3 cloud providers do when designing their DCs and backbone. Honestly you should be frightened when you see someone NOT using a cloud provider, because it is hard work to properly run and secure a datacenter. Even Equinix fucks up HARD regularly and they are considered the gold standard (shout out to those I saw at 350 E Cermak over the weekend). reply ris 11 hours agoparentprevGOV.UK PaaS also runs on AWS (for as long as it remains to exist) reply 0xbadcafebee 11 hours agoparentprevThat sentence was a little confusing. You're not happy that the government is hiring experts to run an important service? reply dtnewman 10 hours agorootparentYes. RDS is a very reasonable choice if you are a tech company, let alone a govt org. The alternative isnâ€™t â€œletâ€™s host this ourselvesâ€ it is â€œletâ€™s host this with Oracle at a much higher costâ€. reply tobias_irmer 2 hours agorootparentIt isn't? AWS is crazy expensive and you don't have as much control over things as you may occasionally need. The best decision we took in the past few years with regards to infrastructure was moving away from AWS and doing everything ourselves. On RDS we had inexplicable spikes in cost, deteriorating support and no real support for any of our issues. When we tried using DMS, it just didn't work as expected, even after spending two days on the phone with their support. reply 15457345234 6 hours agorootparentprevThe alternative - at government scale - is absolutely 'let's host this ourselves' and that's what they should be doing, to ensure that institutional expertise remains. They should also own and operate their own datacentres which should be physically secure, not shared with commercial ventures and guarded by the armed forces, not civilian security. reply 0xbadcafebee 3 hours agorootparentWhy doesn't the government manufacture their own cars? They're going to lose institutional expertise in building cars! They should also own and operate their own manufacturing facilities which should be physically secure, not shared with some 'civilian commercial venture'. By golly, the government can't do business if it isn't a datacenter operations company, a software vendor, and a car manufacturer. reply 15457345234 1 hour agorootparent> By golly, the government can't do business if it isn't a datacenter operations company, a software vendor, and a car manufacturer. I mean, precisely, which is why some countries are rapidly turning into failed states. Too much buck-passing and outsourcing. reply 15457345234 6 hours agorootparentprev> is hiring experts 'moving to AWS' (or any cloud provider) is not 'hiring experts' it's just outsourcing the risk to an entity that you, in the event of a genuine crisis, have no leverage over beyond 'we're going to stop paying you (once we migrate away from you which will take ten years)' reply 0xbadcafebee 3 hours agorootparentAWS are not experts at providing computing services? Holy cow. This is news to me! I thought they were the most popular and highly regarded computing infrastructure and PaaS company in the world, managing both hardware and software and providing subject matter experts to work with customers on architecture and implementation, along with official partners and a marketplace of turn-key products. Boy, am I embarrassed! I need to start building my own datacenter right away, all my shit is on AWS!!! reply ivix 10 hours agoparentprevI'm surprised that you're surprised. Why on earth would government not be migrating to the cloud? reply _joel 10 hours agoparentprevThere's an absolute ton of stuff on AWS. There used to be gCloud that allowed for smaller clouds to tender for government contracts bit there was a big pull to AWS, at least from my experience with it. reply pixelesque 10 hours agoparentprevAs other comments point out, their own platform was (at least in terms of DB) already running on AWS, just using a different account. reply foofie 10 hours agorootparent> As other comments point out, their own platform was (at least in terms of DB) already running on AWS, just using a different account. That changes nothing. It just means this unjustifiable nonsense is going on for a while. reply cpursley 11 hours agoparentprevAnd an American one, at that (weâ€™re talking government services here, not some SaaS). Are there really no native UK cloud providers? reply cameronh90 11 hours agorootparentNot any remotely comparable. The small â€œcloudâ€ providers we do have were just reselling vSphere last time I looked into it. reply otteromkram 11 hours agoparentprevI'd argue that AWS is much better suited than self-hosting because it's such an important service. Downtime becomes negligible and global reach vastly increases with comparably little cost. reply okasaki 11 hours agoparentprev [â€“] All UK businesses run on Oracle and Microsoft, so I'm not sure why you're surprised. They have us by the balls. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The GOV.UK Notify team successfully migrated their PostgreSQL database with minimal downtime using AWS Database Migration Service (DMS).",
      "The migration process involved setting up the DMS instance, creating the target database, performing a full data load, and implementing ongoing replication.",
      "The migration resulted in only 11 seconds of downtime, exceeding their target of less than 5 minutes. The team plans to migrate their apps to AWS Elastic Container Service (ECS) in the future."
    ],
    "commentSummary": [
      "The discussion covers topics such as AWS RDS Blue-Green Deployments and limitations of database downgrades for database migration.",
      "Challenges with database migration frameworks and issues with AWS Data Migration Service (DMS) are also discussed.",
      "The discussion also touches on government cloud services, data security and sovereignty concerns, and the pros and cons of outsourcing IT services to foreign companies, particularly in the public sector."
    ],
    "points": 386,
    "commentCount": 149,
    "retryCount": 0,
    "time": 1705614665
  },
  {
    "id": 39042626,
    "title": "Hans Reiser Apologizes for Delay and Discusses ReiserFS Deprecation in Linux Kernel",
    "originLink": "https://ftp.mfek.org/Reiser/Letters/â„–2%20Hansâ†’Fred/reiser_response.html",
    "originBody": "Â§ 1 Cover letter To: Fredrick R, Brennan 597 North Raleigh Avenue Atlantic City, New Jersey 08401-1081 D ear Mr. Frederick [sic] R. Brennan, I thank you so much for writing me. I apologize for the delay, and for it being so long. The length is the reason for the delay in my response. I hope that OCR technologies are effective at saving you from having to type this in. Could you carefully proof the OCR results? I apologize for the burden it will be. I hope you understand the length as my taking your request seriously, and are pleased rather than dismayed. It was alot of work to write it. If you sign up for text messaging at gettingout.com, you can get faster responses from me. Sending a phone number will also work. Please use your judgment in where to send thisâ€”any place that would be interested is fine. LKML and Slashdot.org seem like reasonable places to send it (as of 2006). Your advice is desired. Please let me know if you or anyone else has questions. If after sending this somewhere you still have time, could you send me info on Reiser5, or any interesting papers on other Filesystems, compression (especially Deep Learning based compression), etc.1 Gratefully, Hans Reiser 11/26/23 From: Hans Reiser (architect of ReiserFS V3 + Reiser4) 26 November 2023 Â§ 2 Introduction I was asked by a kind Fredrick Brennan for my comments that I might offer on the discussion of removing ReiserFS V3 from the kernel. I donâ€™t post directly because I am in prison for killing my wife Nina in 2006. I am very sorry for my crimeâ€“a proper apology would be off topic for this forum, but available to any who ask. A detailed apology for how I interacted with the Linux kernel community, and some history of V3 and V4, are included, along with descriptions of what the technical issues were. I have been attending prison workshops, and working hard on improving my social skills to aid my becoming less of a danger to society. The man I am now would do things very differently from how I did things then. Perhaps some might accept my apology; others might learn from my mistakes if I describe them well; some might find the design issues interesting. I will leave it to the users to decide whether ReiserFS V3 is still useful. Users should understand that it is a burden for those who maintain VFS and the like to have to test their changes on an additional filesystem, especially given Linux filesystems are hard code at the VFS layer. ReiserFS 4 provides a more maintainable basis for the future for those users who like the features of V3. If V3 isnâ€™t used it should go, I trust the users and the kernel maintainers to discuss whether it is used, and to make the right decision together. Â§ 3 Main text V 3 had a moment in time when it was useful, and I am happy that we were able to contribute to the success of GNU/Linux for a few crucial years during which it was growing rapidly in usage. Chris[page 2 follows] Masonâ€™s contribution of journaling was the most practically useful feature of V3, and I thank him for it. I am sad that SUSE didnâ€™t make it in the market place, I found it to be a well-crafted distro, and it was a privilege to be able to contribute to it. I am grateful for their sponsorship and support. Reiser FS V3 was our first filesystem, and in doing it we made mistakes, because we didnâ€™t know what we were doing. I have to tell you that when I did the first benchmarks the performance was terrible, and I didnâ€™t know why. By terrible I mean that no sane person would use it for anything, there were years of dark depression before it was debugged enough to run at all, and then, 5% here and 5% there, I dragged it into being a little faster than the competition, and saving some space for traditional filesystem sizes, and more space for small files. Changing the allocation of blocks to filesâ€”simple code fortunatelyâ€”yielded most of the performance gains. In V3 performance tweaking, Ext2, the existing GNU/Linux filesystem, was actually a very high performance filesystemâ€”probably the best in the world.1 The man I was then presented papers with benchmarks showing that ReiserFS was faster than ext2. The man I am now would start his papers [page 3 follows] crediting them for being faster than the filesystems of other operating systems, and thanking them for the years we used their filesystem to write ours. Not doing that was my first serious social mistake in the Linux community, and it was completely unnecessary. Vladimir Saveliev, who had pity on me and came back after everyone else had quit, was the man who made the code work well enough that anyone would want to use it for more than a benchmark. After he came back, I left the debugging to him. He is one of the most good, mild-mannered, and hard working men that exists, anyone who has ever worked with him will agree with that. He didnâ€™t say much about it, but he believed in the Free Software Movement. Through force of will, and hard work, he made himself into a programmer of extraordinary skill, the effects of which you can see manifested in our Reiser4 code. He went from being the must junior of the programmers at the start of V3 to being the lead programmer, earning it through hard work all the way, Assuming that the decision is to remove V3 from the kernel, I have just one request: that for one last release the README be edited to add Mikhail Gilula, Konstantin Shvachko, and Anatoly Pinchuk to the credits, and to delete anything in there I might have said about why they were not credited. It is time to let go.[page 4 follows] In prison I have been working quite hard on developing my social skills, especially my conflict resolution and conflict avoidance skills. There is a lot of conflict in prison, as you can imagine, and it is quite a good place to learn those skills. Nothing like lots of practice, and the groups they let us take if we want to have a quite well developed curriculum, Repetition helps, at least for me. It has changed me. I had a tendency to see people in extremes. That I am working on by being mindful of it, and by being around people who it would be easy to see in extremes, Many of them have become very good persons [sic] since their crimes. I look back, with the advantage of the passing of years helping to improve my vision, and I see that while I intended to be helpful to researchers in Russia living on less than a hundred dollars a month, I could not be as helpful as a job working in America earning a Western salary. I put everything I had into the project, working 40+ hours a week at a day job, most employers not happy that I wanted to work only 40 hours if I could, and then I spent 15-20 hours a week arguing over algorithms, architecture, code, etc., by email. I learned to cut out everything in my life besides the[page 5 follows] project because otherwise my dream just would not make it. I had more dream than experience. With Mikhail there running things in Russia it went pretty well because we had an ability to understand each other, I believe Mikhail Gilvla was the brightest mind in his generation of computer scientists, and his talent was wasted. First it was wasted by Russiaâ€™s economy making his success impossible, and then in America it was wasted by most of the database field not being able to understand that he was right in wanting to rewrite the basics of their field in the ways be wanted to because he was just so much brighter than they were. I donâ€™t think they could even understand why it mattered, what he wanted to do. We both believed that relational algebra was a special case of something more general, something that was needed for â€œsemi-structured data\". He called his approach â€œset-theoretic\", and implemented it in the form of a database. I had my own syntax that expanded the filesystem namespace, instead. We came up with our ideas independently, before we met.[page 6 follows] I had the idea that the place to implement it was in a filesystem, and that the motivation for implementing it there was to evolve it into a namespace that would allow unifying all of the namespaces of the operating system into one namespace. I thought this would be the most important refactoring of code ever, and would increase the expressive power of everything in those namespaces. I drew analogies between the effect of roads and waterways on the development of civilization according to Adam Smith, and the effects of free trade on specialization thus wealth according to Adam Smith again, and the effects of unifying the namespaces on the expressive power of the operating system. That was my dream. I was not the only one with this dream. The term â€œnamespace\" is pretty much only used by people who share in that dream enough to use a term that implies an equivalency between databases, filesystems, DNS, etc. Rob Pike and Plan 9 are examples of work to increase the Filesystem namespace, My particular flavor of the dream was that I had a syntax that could expand the filesystem hierarchical namespace to handle â€œsemi-structured data\". That means queries that are constructed from primitives that can be combined into the equivalent of searche engine queries (unstructured associations), database queries (unordered ordered pairs to search tables), or filesystems (fully[page 7 follows] ordered names to search hierarchies), or things that are richer than any of those special cases. Now that was my dream! Sigh, It probably wonâ€™t surprise you that I was a teenager when I came up with this dream, and its syntax for searching semi-structured data. I apologize to the users that I never got to that dream because of my crime and my going to prison, and they never got to see any semantic enhancements to Reiser 4. The most technically difficult task that was a prerequisite to someday implementing my syntax, a task that had to be implemented first to do things right, was to make the filesystem efficient for small files. I was very sensitive from the start to the power of net work effects to drown efforts to shift paradigms, to introduce better ways to do things. Network effects were abstract, so I understood them better than the importance of believing that I can make friends and allies of people who start out hostile because I had not made them feel included. Awareness of network effects was why I decided that the path to unifying the namespaces of the operating system started with enhancing filesystem semantics which started with creating a storage layer that could emulate a filesystem faster than any existing filesystem but could also be[page 8 follows] effective for storing small objects like databases are. Yes, it was arrogant to attempt that, but it seemed like it should be possible to do it. I had no idea how long it would take to get it right. Mikhail advised me to use balanced trees instead of extensible hashing (what dcache uses). I would come to understand that locality of reference is the sina qua non of performance, and that balanced trees are the best of all tools for implementing clever ways of maximizing locality of reference, Mikhail had tried extensible hashing, and learned the hard way that trying to fix its problems leads to using balanced trees. Locality of reference doesnâ€™t just affect hard drive performance, it affects compressed data performance (that means SPRAM performance), and even affects CPU cache performance (and thus DRAM stored data performance). He told me he was saving me 2 years by telling me to use balanced trees, and thatâ€™s true, and I thank him for that, I never told Mikhail that Oracle had tried implementing a filesystem using balanced trees, and its performance was terrible leading to most insiders in the industry concluding that balanced trees performed poorly for filesystem File size patterns. I didnâ€™t tell Mikhail; I didnâ€™t tell any of the programmers; I didnâ€™t tell anyone involved in the project. I couldnâ€™t see why they should be slower so I disregarded it, Vladimir would[page 9â€“1 follows] have good cause to be angry with me if he reads this. I think part of their performance problems were how they did their journaling. Iâ€™ve observed that most balanced tree implementations are too synchronous, and most filesystems arenâ€™t very synchronous for performance reasons. fsync() is like using a sledge hammer to turn a screw with repeated sideways blows on the hoad of the screw. What is needed to have high data integrity guarantees with no unnecessary performance losses is a new API that allows intelligence in doing it by allowing the different layers to share their greater intelligence with the other layers. We need to allow the user to share their intelligence with the application, the application to share its intelligence with the filesystem, the filesystem and process scheduler to share their intelligence with the I/O scheduler, the I/O scheduler to share its intelligence with the I/O scheduler and other aspects of the hard drive, and then share intelligence back up the other direction of that stack, and then also tie in the memory manager in there too. 2 It requires not just ordering of I/Oâ€™s, but specifying groupings of I/Oâ€™s that should commit or not commit as a group, to communicate that intelligence, and not be more synchronous than necessary. Other features relating to priorities, fairness, guaranteeing I/O rates, etc, would also be desirable. If more details are wanted by anyone, ask, please, This is an area where Reiser 4 should do more[page 9-2 follows] than we had time to do. I wish I had had the money to retain Joshua MacDonald when Orade hired him away from me, and learn more from him about logical journaling ideas he had then, I hope he is doing wellâ€”he was simply a brilliant young man, Iâ€™ll just say that block aligning journaling isnâ€™t necessarily optimal for all needs that userspace has, and refer the reader to him for more. What I didnâ€™t know when we were arguing over the V3 design is that the FFS bench marks are misleading, and fail to highlight something that also hurts database performance, FFS is the BSD filesystem, and it was regarded as the best of its day. It used 4k blocks except for the tail end of files for which it used 1k blocks, and it would combine those 1k blocks from different files into the same 4k, thereby allowing them to increase block size but still conserve space. Sounds clearly correct, yes? Alas, the performance cost of pulling the tails of files out of line with the rest of the file to combine it with the tails of other files is a seek plus a rotational delay (20 ms), Thatâ€™s hugely expensive compared to the tail size divided by the transfer rate, Seeks dominate filesystem performance unless the layout is perfect. You can see the importance of avoiding adding any seeks by having the tail of a[page 10 follows] file located inline with the rest of the file, Databases with their \"BLOBS\", ReiserFS V3, and FFS all combine tails in a way that adds seeks and hurts performance substantially. For Databases and Reiserts V3 itâ€™s even worse though, because BLOBS make it not really a balanced tree, and the ability to effectively cache all the internal nodes of the tree is lost. Google â€œReiser 4 twigsâ€, and hopefully that will find a longer discussion of that for interested readers, including how to fix it, That performance failing drove me crazyâ€”I felt the design was just wrong, and I resolved to redo everything from scratch with Reiser 4, The plugins, and the modularity of the code they created, are the most important feature of Reiser 4, It is far easier to add features to Reiser 4 than to add them to other filesystems, because you just add new plugins. The hard stuff is done, and new features are a downhill ride. Well, except that I am in prison, and so I must leave all that to others. There is a problem that filesystems have, and that is that format changes are unwanted by many for good reasons, That is the primary reason that filesystems stagnate, Well, that, and stagnating is easyâ€¦[page 11 follows] I just had to fix all these flaws, fix them and make a filesystem that was done right. Itâ€™s hard to explain why I had to do it, but I just couldnâ€™t rest as long as the design was wrong and I knew it was wrong. SUSE didnâ€™t want a format change, they wanted incremental improvements to V3. Thatâ€™s the way it is for a lot of filesystem architects. Incrementally changing things they know are deeply wrong to their cores, but stuck in that misery of doing so. I said no to that, which I wonâ€™t apologize for and donâ€™t regret, because I have a soul, and I had a dream. What I do apologize for is how utterly inarticulate and unsociable I was in explaining that to SUSE. What I essentially said to SUSE was that the code was unmaintainable terrible code that needed to be rewritten from scratch, trust me, it needed to be done, we didnâ€™t know what we were doing then and now we have learned what we should have known, but we will fix every bug in V3 that is found. I could have said that I hear them, and I hear them well, so well that Reiser 4 has node format plugins that solve the format change problem. I could have told them of our plans for a repacker for Reiser 4, so that partitions could be shrunk, and layout perfectly optimized, and â€¦spent a day visiting them and making Reiser 4 our dream not my dream. Instead I[page 12 follows] communicated that I couldnâ€™t pursue my dream without a format change. Both SUSE and I wanted what was best for Linux and SUSE, so the reason for my failure was that I had failed to socially connect by reaching past the initial hostility to the format change to I make my (and DARPAâ€™s) dream into our3 dream. I would repeat this failure style with the Linux kernel community when Reiser 4 was submitted for inclusion, only worse. Let me go back in time though to the early days of V3. Not long after the computers were purchased, and then the project really got going, Mikhail got a job in America, Mikhail was the reason I had hired this group. Now I no longer had somebody running things on site that I was intellectually compatible with, and frictions developed. I had not chosen them, and they had not chosen me, nor had they chosen my dream or the Free Software Movement. Alas, I was inexperienced, and they didnâ€™t respect. that, which is understandable, yes? I had a feel for abstractions that was stronger than my feel for people, and a casual delight for tossing socially established algorithms that made them even less comfortable than my wearing a cowboy hat instead of a tie, None of this was a problem with Mikhails but Mikhail had left. It was to be expected that there would be problems, but I was too young and hopeful to see that. There was a cost to going from system administrator to architect without first spending a few years as a coder.[page 13 follows] An example of this was their use of BLOBS in V3. I didnâ€™t know that putting unformatted nodes on a level of the tree below the putative leaves of the tree was the standard way of doing things in the database world. When I saw it in the code I objected to it. I was asked to just let them try it their way, and if it didnâ€™t work it could be removed , I was too inexperienced as a software project manager to know that that was an argument to only entertain after the first version of a product has shipped, because whatever gets written before product shipment is not likely to get rewritten until after product shipment, especially if you know the design is wrong. Thatâ€™s especially true if you know the design is wrong. What I didnâ€™t know was just how wrong the design was, The performance cost was higher than I feared it would be, I should also say that the coding cost of doing it right was higher than I thought it would be, To the young architects out there, let me say that if you know something is wrong, donâ€™t lot it happen just to be agreeable or to accept the consensus, Yes, listen to all the arguments, but if you donâ€™t have a better feel for algorithms, you should not be in the job of architect. Believe in yourself, I paid the price for not knowing when to be firm, when the benchmarks came in, and then again when fixing it required a format change that lost me SUSE. 4 [page 14 follows] Then Mikhailâ€™s employer hired the rest of them, and left me with a pile of poorly commented code that was not able to run. It would have been wiser for me to write it again from scratch, but that would have meant admitting that all I had invested into the project was a total loss.5 Now, with the distance of time, I can see that their leaving was simply the reasonable thing from their point of view, There were some unkindnesses in how they left, but thatâ€™s to be expected, says the distance of time, Then I felt so betrayed. Now I wish to let go of that. They were just ordinary people caught in economic forces, and not enjoying working for the guy with more dream than experience. They too were inexperienced: none of us had worked on a filesystem before. We were all young, and impatient. I never did get to where we made enough money that I could pay people well, and I am truly sorry for that. If I had not committed my crime, that day when Reiser 4 was a worthy use of the extraordinary talent of the programmers working on it probably would have come. I was callous and indifferent to their needs and dreams when I committed my crime, and victimized them financially and ruined their dreams that I had talked them into. One of my great regrets is that I let go of Mikhail as a friend. I hope be is alive, and doing well.[page 15 follows] I read about a DARPA request for proposals for open source software on a Friday on Slashdot, and it had a Monday submission deadline. I went into a writing Frenzy, and proposed what became Reiser 4, DARPA was very good to us, very and I learned a lot about accounting and security both from them. Iâ€™d like to apologize to DARPA for two things: All we were able to complete was the infrastructure that would enable the security features I proposed, and that was despite my putting several times the money they gave us into the project from every where I could get it, including using 29% interest credit card cash advances to make payroll near the end. 6 Now that Reiser 4 is stable, the plugin infrastructure would make it so easy to add extra features, we could probably have done the encryption plug in and stat data inheritance in just 6 months.7 At the time I made the Reiser4 proposal it looked like democracy had won in Russia, I believe we were a point of light in USâ€“Russian relations, The problem was that what was needed was a thousand points of light, and we were one of a very few.[page 16 follows] Russian Intelligence/Law Enforcement, after doing a very thorough job of making sure we werenâ€™t a CIA cover operation,8 was very nice to us, and quite supportive of us and the Free Software Movement, It might not have been a coincidence that we had no Mafia problems, The time that I got scammed for $300, they got my money back in 45 minutes. I know that one is not supposed to say good things about them, but my own personal experience is that they were very effective, kind, and even wisely guiding. In important ways, Russian culture teaches a better understanding of people. As a for instance, one of them told me that my wife was in a lot of pain. Now I can see clearly that that was exactly correct, and perfectly illuminated the path I should have taken. Alas, I lacked the wisdom to understand the words with just one repetition. *9 In prison I have learned that alienation, which I intend to use to protect myself, is often a cage I bulld around myself instead. A fear of being naÃ¯ve can often be as dangerous in its reality distortions as being naÃ¯ve,[page 17 follows] Now is not the time to try to be a light in US-Russian relations. I hope that there will again be such a time, and an end to all the death and dying. I hope the time will come again for reaching past the alienation, and finding friendship[page 18 follows] and love, between Russia and Ukraine and the U.S, and between my children and I. Call me a fool, or simply someone who thinks the pain is too much for us all, I leave that to you. Back to Reiser4: We10 built a beautiful filesystem that embedied everything we had figured out we should have done the first time, called Reiser 4, and it smoked, Whatâ€™s more, it had this plugin architecture that I had proposed to DARPA in that writing frenzy, but that Nikita Danilov had made even better than what I had proposed (he made the balancing operations plugins too, and I am so glad that he was smarter than me and showed that the performance costs were acceptable). With most filesystems, adding a feature is 80% altering the existing code and 20% writing the new feature, and then you will be likely adding a Format change that someone not even working in the filesystem group will say no to. With Reiser 4 we made every aspect of it that we could imagine doing so for into a plugin. If you want to add a new feature, you just spend your time writing the new plugins for it, and 90% of the time that is all you will have to write, or failing that, it will be 80% of what you will have to write, You get to spand your time on your clever idea instead of on why it was so much harder than it should have been to write it. I think youâ€™ll find it is more than 3 times faster to add it to Reiser 4 than to any[page 19 follows] other filesystem, with all the features required of a filesystem for compatibility (an enormous burden to writeâ€”if you have a clever filesystem idea save yourself that burden and add a plugin to Reiser 4 insteadâ€”you can be one programmer doing a 6 month plugin instead of having to fund a team for 5 years to do a filesystem) completed, it was going to be all downhill from there. We would have been theones implementing a substantive new feature per programmer per 6 months, The code that Alexander Zarochentcev, Nikita Danilov, and Vladimir Saveliev wrote (all three of them contributing equally, working together like the three musketeers) was beautiful code, and then the junior programmer Edward Shishkin came along as the fourth musketeer and his compression plugin doubled performance again for compressible files. I cannot remember ever finding anything I could improve in Alexander Zarochentcevâ€™s code: it was always perfectly written: â€œread it and learn how things should be writtenâ€ kind of code. I am not known for being unable to find things to criticize, or praising easily. Somehow with the smallest budget for paying them in the filesystem world, I lucked onto the best programming team in the filesystem world. The filesystem was worthy of their talentsâ€”I wish that I as a person had been worthy of them.[page 20 follows] The problem was that it didnâ€™t use the code that had been written by others in the kernel community, and people donâ€™t really like their code not being used. People want to feel included. I responded to their social need by, well, screwing the pooch in response (benchmarks and disputing their expertise). Imagine if I had responded by saying that I needed their help in imagining new file plugins instead? You know how people are much more likely to read an email if it is one screen long, rather than the length of this :-/ ? It is similar with contributing code to the kernel. It is much more social and relationship developing to contribute a screenful or two of code once every week or two over the course of years. We were dropping 90,000 lines of code on them all at once, having worked on it in total social isolation for 5 years in Moscow, Socially it was all bad. Small increments are the more social way to go. Incremental improvements to V3 would have met no opposition. We could have lived a life of being a little bit better than ext3, and been respected in the field as we waited for someone young to obsolete us, Alas,11 it had to be written from scratch to be written right, to be written the best I knew how to to design it, to fix what the benchmarks had 12 revealed to an empiricist. My leadership and project management failures needed to be atoned for. The maintainability of a plugin based filesystem was perhaps more important than the[page 21 follows] benchmarks, I had added comments, and we had added bug Fixes, but I am so glad I kept none of it for V4. If I had had then the conflict resolution skills I have learned in prison Cognitive Behavioral Intervention classes I might would have been able to overcome all that. Then, my attitude was, itâ€™s the fastest filesystem in the world, why arenâ€™t you happy and helpful?! Look at these benchmarks! These plugins! Why do I have to deal with these people who didnâ€™t write as fast of a filesystem ? Let them write theirs, and us write ours - VFS should allow that ! My attitude should have been, ignore the hostility, thatâ€™s to be expected at first and overcome, I can overcome hostility, and the way to do that is simple : 1) make people Feel appreciated and cared about, 2) make people Feel included, 3) make people want to do things with those plugins themselves by asking them for their ideas on what plugins they could imagine. Now I Know that it is possible to overcome such problems if I actively apply my mind to Finding an emotional or social path to making people Feel good. The most important part of that is to believe that I can do that successfully. I used to lack the ability to imagine that I could succeed at overcoming hostility, but by doing the exercises in my Cognitive Behavioral Intervention classes in prison situations, I have started to see that I can,[page 22 follows] started to believe that I can, If you believe you can do it, you usually can, when it comps to making things go well with others, If you focus on Finding a way past a problem, instead of on your Feelings of having been wronged, you can usually get past a relationship hiccop. If you Fail, youâ€™ve lost little to nothing in making the attempt, so why Fear to make the attempt? Contrary to what young men so often Fear, if you Fail in such an attempt you donâ€™t lose Face - you gain respect From others watching you try - especially the older ones. If you make a habit of always trying, you will inevitably get good at it, *13 One of my dreams is to someday convince the State Legislature to teach the curriculum they teach us prisoners, in elementary school, that people like me can learn it better without having to go to prison to learn it, Iâ€™m try my to convince some people to pitch it to legislatorsâ€”if any one would like to help with that please let me know. It will help with more than just avoiding prisonâ€”it will help with all relationship conflicts, and who does not have thoseâ€¦? The prison parenting class should be taught in High School tooâ€¦[page 23 follows] An example of what I could have hand led differently was when Viro announced that there was a race condition in our code, but that he would not tell us where it was because if we could not audit our code for race conditions we should not be allowed into the kernel, Viro was this guy whose career focus was lacking, I didnâ€™t know any thing about auditing code for race conditions, and disappointingly Google didnâ€™t get me any where in looking for how does one audit for race conditions. My attitude at the time was that it sounded like necessary but tedious work, really tedious, that hopefully the guys who were doing the debugging would figure out while I tried to get the money for their next pay check. 14 I should have done more than communicate the problem, I should have asked â€œwhat is the audit for race conditions plan, and help me find literature on how to do it, and then letâ€™s divide up the relevant code and do it, all code to be audited by two different people\". Race conditions are very expensive to debug when they are rareâ€”auditing would have saved money. This was an area where we all needed to improve our methodology. 15 I Failed to communicate by Failing to ask if this was an area where my guys didnâ€™t know how to do it and were too shy to say so, and in this were just like me.[page 24 follows] What I should have done was ask Viro instead of Google, and invite him to come to Moscow, stay in my spare room, sample the worldâ€™s wildest nightlife (Moscow), and give our team a seminar on auditing for race conditions and supervise us as we each took a part of the code and did the audit per his instructions, We had as much motivation to eliminate race conditions, no, much more because it was our code and business, as Viro, There was no good reason for us to not be allies in this. There was only a bad reason I was responding to the initial hostility rather than reaching past it to make an ally of someone who had a lot of potential to be very helpful to us. Now of course he might well have refused the invitation, said he was too busy, told us to get better at using Google, etc., but even if he refused the invitation he would probably have felt mollified somewhat. If he took us up on the invitation all of us could have made valuable Friendships likely to have been useful for the rest of our lives, as we fed him shi [sic] (Ñ‰Ð¸, Russian soup, one of the best aspects of Russian cuisine is their soups) and pelmenie (elmeni, Georgian spicy pot stickers), and took him to dance the night away when the race conditions were gone. I could have similarly approached other Key persons in the Kernel community who expressed unhappiness at our contribution offering, if only I had had then the social confidence, and belief that it is possible to overcome initial touches of alienation, that I have now developed.[page 25 follows] Instead I responded to hostility with my own hostility. In prison, on MLK day, I learned of MLKâ€™s words: â€œO nly love can fight hate.â€ I have come to appreciate, and fully understand those words, I wish I had understood them then. There were a bunch of such situations that I handled in ways that did not make people Feel appreciated or included, and I want to take this opportunity to apologize For those. I especially want to apologize to the other members of our team who invested so much of their lives into our dream only to be failed by me, and by my alienating others in the Linux kernel community. The Linux kernel is not about benchmarks, it is about a community of people who enjoy working together in the Christmas Spirit to give to the users all year long. Now that I have changed who I am I can better see that. I donâ€™t know what is in Reiser 5â€”I havenâ€™t been told, and I cannot go on the Internet. Edward Shishkin is a very bright man though, and one of my regrets is that I didnâ€™t spend more time with him, I am confident he has done some thing nice in Reiser 5. Who knows, maybe he has done some nice plugins that I would never have imagined. The compression plugin Edward coded was the one thing yielding the biggest performance boost of all the things we did in Reiser 4. Chances are high that I wonâ€™t be[page 26 follows] released anytime soon. I encourage people to allow those who worked so hard to build a beautiful filesystem for the users to escape the effects of my reputation. I invite you to empathize with what this has been like for them for a minute. Let their dreams escape from the harm I have done, if that feels right to you. Â§ 4 Conclusion I wish I had learned the things I have been learning in prison about talking through problems, and believing I can talk through problems and doing it, before I had married or joined the LKML. I hope that day when they teach these things in Elementary School comes. I thank Richard Stallman for his inspiration, software, and great sacrifices, It has been an honor to be of even passing value to the users of Linux. I wish all of you well. Hans 11/26/23 P.S. Letters are welcome, Please send them to: Hans Reiser chcf g31008 p.o. box 213040 Stockton, ca, 95213 u.s.a. You can also send texts. or video chat or phone about, if you go to gettingout.com, or phone chat if you send a phone number, for me to call and accept the phone call.",
    "commentLink": "https://news.ycombinator.com/item?id=39042626",
    "commentBody": "Hans Reiser on ReiserFS deprecation in the Linux kernel (mfek.org)364 points by wut42 18 hours agohidepastfavorite336 comments not2b 17 hours agoI worked with Hans Reiser in the late 90s. He was a contractor with the company that I was working for, and he was doing that (working on logic synthesis for FPGAs) by day and trying to start his company at night. He was very passionate about his technical ideas, though in those days he had difficulty explaining them, so I went back and forth about whether he was a genius or a crank (I decided that he was some combination of the two). I have a music CD somewhere around that he gave me, new age-y music his mother composed (not sure whether I still have it or not). I didn't want to believe that he was a murderer, but it soon became clear that he was lying. reply jeffrallen 15 hours agoparentI met him at the same place at the same time and had the same reaction to him. Are you me? reply bombcar 15 hours agorootparentIf it makes you both feel better, I had a similar reaction completely removed except as a user of RieserFS. reply not2b 14 hours agorootparentprevI don't think I'm you. :-) reply horsh1 11 hours agorootparent... yet. reply lilbaby 8 hours agorootparentnon-duality on HN. well I never reply mariusor 18 hours agoprevI don't know if ending another human's life leaves any possibility of redemption for a person, but reading this I still empathize with the sense of loss and powerlessness that emanate from this letter. reply iaw 17 hours agoparentI suspect many are aware of this but for those uninformed: Reiser committed premeditated murder of his (ex?)wife Nina around 2006 and hid her body so well they could not find her. He made his children think either that their mother abandoned them. He had thought without a body he could not be charged and convicted. I believe he waited until it was apparent he would lose the trial and then plead down so that they could recover her body. I want to believe redemption is possible, especially given how eloquent he is, but his demonstration of calculation over emotion in her murder makes me strongly question his change. reply dale_glass 17 hours agorootparentHe was far less of a mastermind than he fancied himself at the time. If I recall, he bought a book on murder investigations and a socket set after his wife's disappearance (which was easily tracked back to him), removed car seats (blood) from his car, and willingly testified in court that it was his manly dream to sleep in the car, or something along these lines. He could have likely gotten away with it if he kept his mouth shut. Luckily he had the arrogance of believing he had actually come up with a convincing story. reply starkparker 17 hours agorootparentFor those interested in the trial, the SF Chronicle's Henry K. Lee ran a very detailed blog on it: https://web.archive.org/web/20080501184401/http://www.sfgate... reply RajT88 16 hours agorootparentI go back periodically and read the Wired article about it. It is totally bananas: https://archive.is/BcMRF The wildest part was the friend who had an affair with his wife who blurted out unprompted on the stand that he had killed 7 people. They let that guy go! reply jacquesm 15 hours agorootparentThe 'weird nerds' defending Reiser brought this up time and again during the trial. But Reiser showed them all up by leading the authorities to where he had buried the body afterwards so I guess that that particular angle is now settled. reply RajT88 15 hours agorootparentYeah, some follow-up reporting found that the guy was lying for some weird reason. He said as much. I forget the reason. reply bombcar 15 hours agorootparentApparently it's a moderately common enough phenomena that cops intentionally keep aspects of a murder scene out of news and reports, so that they can check if someone knows them or not. People are sick enough for fame that they'll murder, and being sick enough for fame to confess to someone else's murder isn't nearly as bad. reply pvg 16 hours agorootparentprevHe could have likely gotten away with it He had a plea deal offer for not much more than time served so he even had a definite option to a form of getting away with it. reply XEKEP 9 hours agorootparentI briefly worked with Hans around 2005. My impression at the time was that he declined the manslaughter plea because he thought he was smarter than everyone around him. reply scotty79 16 hours agorootparentprevWhy didn't he take it? It's pretty much the best what murderer on trial can hope for. ... then again, if he was reasonable he'd probably never commit murder. reply pvg 16 hours agorootparentYou can get the details from the contemporary coverage linked in the sibling comments but it seemed like he felt he'd go to trial and be acquitted. If I had to guess, having to admit he'd been lying to everyone through the whole process was probably also a factor - the deal was something like plead to a manslaughter charge and reveal the location of the victim's body. reply jacquesm 16 hours agorootparentprevI figure it was because he thought he was so intelligent that he could run circles around the court. reply jonathankoren 17 hours agorootparentprevI will always remember the Slashdot comment that said that removing the passenger seat of your car so you could sleep in your car was a reasonable thing to do, and everyone saying it was suspicious was a hater. (Bro. A car floor isnâ€™t even flat.) I think it was my first experience with absolute egregious fanboism. reply wetmore 15 hours agorootparentIt is reasonable, although niche enough to be a bad defense. Here is a popular Instagram account where someone does exactly what you are saying is unreasonable: https://www.instagram.com/salvagetoscenic reply johnchristopher 14 hours agorootparent> Here is a popular Instagram account where someone does exactly what you are saying is unreasonable: https://www.instagram.com/salvagetoscenic Except they don't. First post shows them asking themselves if there's a more comfortable way, second post shows them installing a flat surface. https://www.instagram.com/salvagetoscenic/reel/CyGu0vUuXsz/ https://www.instagram.com/salvagetoscenic/reel/CyWqTSSJV7U/ reply carcampy 13 hours agorootparentExcept they do. They donâ€™t reinstall the seat. And hence removing the seat for the purpose of camping was indeed a reasonable thing to do. reply johnchristopher 12 hours agorootparent> I will always remember the Slashdot comment that said that removing the passenger seat of your car so you could sleep in your car was a reasonable thing to do, and everyone saying it was suspicious was a hater. (Bro. A car floor isnâ€™t even flat.) > (Bro. A car floor isnâ€™t even flat.) > (Bro. A car floor isnâ€™t even flat.) Do you dig it ? A car floor is not fucking flat. That's why it's suspicious to remove the passenger seat without installing a flat surface over it. That's why the instagram poster did install a flat surface. Because they didn't want to sleep on the car floor. Because it's not flat. It's not comfortable. And because it's not comfortable it's not reasonable. > As investigators follow Hans, they discover the missing CRX, but something is missing, says prosecutor Paul Hora. \"He removed the front passenger seat. Then he completely disassembled, removed the rear cargo area of the car, threw away the carpeting that covered the spare tire and the cover that covered the spare tire.\" > When it was Hora's turn, he asked Hans why he had removed the front passenger seat from his car. \"He said he removed the passenger seat in order to make a Honda CRX a more comfortable place to sleep,\" Hora recalls. \"His explanations were ridiculous. I mean, they were lies. A Honda CRX is an awfully small car that wouldn't be comfortable no matter what you did to sleep in it.\" https://www.cbsnews.com/news/betrayal-29-12-2008/ > On October 11, 2006, law enforcement officials said that blood spatter had been found in Hans Reiser's house and car. Forensic testing (including DNA analysis) could neither confirm nor rule out Nina Reiser as the source of the blood. Officials had not located the missing passenger seat of his car. They also indicated that they had found in the car two books on homicide investigation purchased by Reiser on September 8 â€” five days after Nina Reiser's disappearance: Homicide: A Year on the Killing Streets by David Simon, and Masterpieces of Murder by Jonathan Goldman.[28] Daniel Horowitz, a high-profile defense attorney, joined the defense team[6] but dropped the case on November 28, citing Reiser's inability to pay for his services.[29] https://en.wikipedia.org/wiki/Hans_Reiser#Murder_investigati... It has never been mentioned that the car was modified to accommodate for sleeping on the floor in a comfortable and reasonable way. The passenger seat, carpeting were removed but that doesn't make the floor flat. JFC. reply shepherdjerred 3 hours agorootparentOne could imagine being in the process of installing a flat surface after removing the car seat. reply jonathankoren 2 hours agorootparentOf course! Who doesnâ€™t decide that they would rather sleep in a car the moment their significant other goes missing? Itâ€™s just to get away from the press and the house where you had all those memories! And of course youâ€™ll start researching crime scene analysis and cleaning methods right after she goes missing as well, because you know youâ€™re the number one suspect, and you just want to help find the guy that did this. The real killer is out there! And Hans and O.J. are on the case! Seriously though. If this isnâ€™t suspicious behavior, what would characterize as obviously suspicious behavior from a suspected murder? reply jonathankoren 12 hours agorootparentprevIt warms my heart that almost 20 years later, the same thread is playing out again. >All this has happened before, >and it will happen again. reply johnchristopher 11 hours agorootparentI don't understand how slashdot can still troll me, I never even made an account on that site. I'll let this go, the hour is getting late. reply doubloon 10 hours agorootparentI will always remember this HN thread. reply carcampy 7 hours agorootparentprevYouâ€™re out of control bro. reply tabataga 47 minutes agorootparentprevThe fanboys spilled over to HN as well: https://news.ycombinator.com/item?id=176098 They were even at it after Reiser led police to his wife's body: https://news.ycombinator.com/item?id=240814 Best comment on that thread, calling out their ridiculous takes: > I gotta say it: the guy was a f-cking murderer and yet you guys are arguing about whether he got a fair trial, even after he led the cops to the strangled, decomposing corpse. And then complaining about the sheer brass neck of a journo who fails to show appropriate respect to this f-cking murderer. What, just because he hacked on Linux once upon a time? Jeez, you really couldn't make this stuff up. reply xtracto 7 hours agorootparentprevThat /. thread was amazing. So many people trying to justify behavior that cleanly pointed to murder. Not every action by itself, but the combination of all of them: buying crime books, removing the seat, cleaning his car and there were more actions. But the slashdot technical community defended him until the moment he confessed. It was really cringey. reply webnrrd2k 13 hours agorootparentprevIt's certainly not common, but I had a friend in highschool that took out the front passenger seat of his VW bug, to make it easier to get surfboards into the car. He normally just had a folding chair for passengers. reply bdamm 16 hours agorootparentprevIt was probably him. reply RobotToaster 17 hours agorootparentprevMakes you wonder how many people do actually get away with it. reply bena 15 hours agorootparentIt really depends on what you're looking to get away with. If you're looking to get away with orchestrating the murder of someone you know, it can be difficult. However, if you're just looking to get away with murdering someone in general, that's surprisingly easy. Just go a town or two over and knife a random someone in a random parking lot. Police success rates are comically low. reply bombcar 15 hours agorootparentPolice success rates on completely random murders are insanely low partially because they're insanely rare. Complete success is something like 50% overall, but in general in many of those cases that \"aren't solved\" they know who did it, they also know they can't prove it. reply bena 14 hours agorootparentConsidering the number of people in prison who get exonerated, I'm glad that the ones \"they know\" did it aren't actually in jail. Because that seems like random chance that they're actually right. But it's also why I qualified my statements. That if you're looking to kill a particular person, that's way harder than \"getting away with murder\" in general. Police only have so many tools at their disposal. And if there is no link between victim and perpetrator, the job becomes way harder. reply EasyMark 7 hours agorootparentThis is why I'm against the death penalty. I don't think that executing 95(97?) actual murderers is worth the chance of killing 5(3?) completely innocent people. That's not justice, that's just good odds, and it shouldn't apply to human life. Lock them up for life. Give an option for execution if they want to take that way out. reply Arch-TK 15 hours agorootparentprevSource on premeditated? Everything I saw made it look like it was spontaneous (and then he put a lot of work and some poor planning into trying to hide it). I could obviously be wrong, I didn't really spend that much time on it. (Note: I know he was initially found guilty of first degree murder but it appears that first degree murder doesn't necessarily require premeditation.) reply bena 15 hours agorootparentYeah, I don't think the murder itself was premeditated, but he did treat the event with a sort of self-serving callousness that gave the perception that he did not care about Nina's life beyond how it affected his. reply EasyMark 7 hours agorootparentthat's not what premeditated murder is though. That's trying to cover up the murder which is also a crime, but a far cry from premeditated murder which is one of the most heinous crimes recognized by the legal system. reply naikrovek 17 hours agorootparentprevHigh levels of calculation in times when high levels of calculation are required to keep you out of prison are not a sign of anything. Humans are amazing at compartmentalizing things like this away, even while they are happening. It is impossible to know from this single datapoint if he is remorseful or not, but it is not at all outside of the realm of possibility. As a child I merely punched my brother and I tried to kill myself afterwards because of the guilt. In the moment I could not have been more prescient about what I was about to do and what I was doing. I recalled how I had observed him fighting others, how he threw punches, how he swung his arm based on how angry he was, and I planned an arc that took advantage of his habits and clocked him. Knocked him out in one punch. The instant he hit the floor I felt remorse like I had never felt before. Who the hell am I to take an action like that?! Anyway, how someone feels while doing something like that does not necessarily reflect how they feel at any other time in their lives. It also may reflect how they are at all times, or anywhere in between. There is no foolproof way to know. reply JadeNB 17 hours agorootparentprev> I want to believe redemption is possible, especially given how eloquent he is, but his demonstration of calculation over emotion in her murder makes me strongly question his change. I think it would be ridiculous for me to presume that I can possibly have any view into whether or not someone has sincerely changed, but why should the fact that someone was calculating once affect whether they have changed? I could see doubting the apparent demonstration of change, because they might have calculated the appropriate words to say, but I don't see any reason that a calculating person is less able sincerely to change than any other. reply iaw 17 hours agorootparentI consider it a Bayesian approach to understanding potential internal drivers. Someone who is not cold and calculating likely has less capacity to completely present the appearance of redemption whereas someone who is calculating has that capacity. So, someone who is demonstrated to be calculating has higher odds of faking a behavior if it is beneficial to them (e.g. leaving prison). It's for him to know, but I don't think it's ridiculous for me to question. reply jacquesm 16 hours agorootparentI'm with you on that one. I read the whole thing closely and my conclusion is that some of what's there is playing to an invisible audience. And some of the rest of what's there feels like 'the real Hans' shining through because he hasn't really changed, but is actively trying to change how he is perceived. I could try to enumerate those bits but it doesn't matter all that much, it's just the feeling that I get from reading the text. reply okwhateverdude 16 hours agorootparentSame. Pretty much any instance where he mentions prison groups or classes, it is very specific and emphasizes strongly that they have changed him. And he knows his mail will be read by the prison staff anyhow. The only benefit of the doubt I have here is maybe the groups/classes promote discussing topics like this precisely because they know a parole board gives them consideration. In which case, he'd be an idiot to not play along if he's angling for parole. (And if that is the case, it wouldn't surprise me if the prison system is being duplicitous in telling prisoners that so they can be demoralized when denied, ie. \"I followed the rules and did what you tell me, but you still won't let me go?\") reply fl7305 15 hours agorootparentprev> my conclusion is that some of what's there is playing to an invisible audience My impression was that he got an assignment in class to write a letter where he reflects on bad interactions in the past, apologize, and try to put them behind him. I also got the impression that he really wants people to write/call him and discuss computer stuff, so this might be part of the motivation for writing it. But I don't know him, so who knows what's going on in his head? reply bombcar 14 hours agorootparentI've not done it, so I don't know, but I suspect you can never fully get to \"I completely regret what I did because it was wrong\" without having somewhat of \"I completely regret what I did because I got caught\". I do think we wants to discuss computer stuff; he seemed entirely unaware of SSDs and how that has (and should) change filesystems, and still thinks Slashdot is a place to post things. reply JadeNB 16 hours agorootparentprev> It's for him to know, but I don't think it's ridiculous for me to question. My reference to ridiculous was to the ridiculousness of my thinking that I have any insight into Reiser's characterâ€”a disclaimer at the beginning that I was not presuming to offer any. I was in no way meaning to call you or your statement ridiculous. > I consider it a Bayesian approach to understanding potential internal drivers. Someone who is not cold and calculating likely has less capacity to completely present the appearance of redemption whereas someone who is calculating has that capacity. Yes, that was exactly what I was meaning to say. Someone being known to be calculating should create a higher evidentiary barâ€”they need to do more to convince me that they have changed. But I don't think that it offers any evidence against their having changed. And maybe this is what you were saying: > I want to believe redemption is possible, especially given how eloquent he is, but his demonstration of calculation over emotion in her murder makes me strongly question his change. I read this as \"the fact that he is calculating makes it less likely that he has changed.\" But maybe you just meant \"the fact that he is calculating means that I require stronger evidence that he has changed\"? reply iaw 10 hours agorootparentThank you for the well-reasoned reply, I misunderstood the thrust of your commentary. > I read this as \"the fact that he is calculating makes it less likely that he has changed.\" But maybe you just meant \"the fact that he is calculating means that I require stronger evidence that he has changed\"? That's a fair point. I need to reflect more on that. It is not my place to proclaim absolutely likelihood, you're correct. I think the latter statement is closer to the thrust that I'm getting at. My burden of proof for redemption is higher than a less calculating criminal/crime. reply jacquesm 15 hours agorootparentprevGreat comment. For me that fact means that I don't just read it with 'a higher bar' but with the possibility that what I'm looking at is created with the express purpose of deceiving me so some of it reverses in meaning. reply prirun 14 hours agorootparentHans is probably high on the psychopath scale, and if you do any reading about psychopaths, the main takeaway is that you can never believe what they are saying. From Google: What is a psychopathic person? Psychopathy is a severe personality disorder characterized by interpersonal deceptiveness and calloused, remorseless use of others, as well as behavioral recklessness, impulsivity, and overt antisocial behavior (e.g., aggression, violence). From: Encyclopedia of Mental Health (Third Edition), 2023. reply bombcar 14 hours agorootparentprevA \"higher bar\" is basically \"evidence against\" because you're saying you need more evidence for. Then again, everything I've read leads me to believe he's impulsive at times (even says so in the letter!) and the calculating part was afterwards not before or during (if it was, he was notoriously bad at it). reply PH95VuimJjqBqy 14 hours agorootparentprevthe assumption here is that your judgement of calculating is accurate. reply bachmeier 17 hours agoparentprev\"Ending another human's life\" covers a wide range of cases. My recollection of this event, which is now long in the past, is that he was cold, calculating, did not value human life, and was quite comfortable with his kids moving on without their mother. He didn't just do something to her. He permanently damaged his kids, her family, and all of her friends. He made his decision knowing all of this. Redemption? Possible I suppose, but don't make the mistake of looking at this from your perspective, because he's not like the rest of us. reply bejk22 16 hours agorootparent> because he's not like the rest of us. He's human and killing other humans is something a humans can do, given the right circumstances. reply jacquesm 16 hours agorootparentYes, but normally you have a fairly high bar to cross before you would resort to such an act, and it would be in the context of self defense or something equivalent. To kill your wife in a premeditated manner is not something most humans can do, even given the 'right' circumstances, most people would resolve a conflict at that level in a different way. reply mardifoufs 16 hours agorootparentYeah I don't get how some frame this as a mistake that just happens or how it shouldn't define the person. When, no it doesn't happen!! And yes it absolutely should define how we perceive them? Maybe I just live a sheltered life but murdering your wife is probably a sign of.. something bad in you as a person? And it's super super uncommon and extreme. reply PH95VuimJjqBqy 14 hours agorootparentprevyou don't know his emotional state, he could have very well passed that high bar internally. From my recollection, his wife was sleeping with another man, or there was some conflict between the two that was related to another man who I _think_ was supposed to be a friend to them both. it's been a while, but the point remains, he very well could have been in a state that allowed him to \"pass that bar\". reply jacquesm 14 hours agorootparentReiser himself is on the record as stating that he killed her because he was protecting his children. Whether that passes that bar or not I'll leave up to you but for me it rules out that this was a 'heat of the moment' thing. In my opinion he knew full well what he was doing, he understood that his kids would move to Russia and be raised there (she got sole custody) and this was his way of putting a stop to that. reply PH95VuimJjqBqy 13 hours agorootparentI didn't say heat of the moment, I said emotional state. If someone plots the death of a person who sexually abused their child no one would claim that it being premeditated implies they were not in a heightened emotional state. reply jacquesm 11 hours agorootparentThat's fair but it would still count as premeditated in a legal sense, but there would be circumstances that would likely weigh in as to the severity. reply PH95VuimJjqBqy 10 hours agorootparentregardless of legal definitions, I posted responding to what seemed like a belief that the only way to \"cross a high bar\" is to do so in the moment. I've given a clear example where that's not the case. reply Gibbon1 12 hours agorootparentprevGF mentioned having an ex-bf who before they dated had accidentally run someone over and killed them. She said he had this ever present air of guilt about him. Like nothing he could do would make up for that. Then you got Reiser who likely just cares that he got caught and his life is now fucked. Not everyone is the same. But way more people are psychologically like my GF's ex. reply scotty79 16 hours agorootparentprev> He's human and killing other humans is something a humans can do, given the right circumstances. Absolutely not. Average human needs to be ordered to kill and lied to and desensitized throughly to be able to do it. People who can kill out of their own initiative are not like the rest of us. Most cases of killings happen only because humans are so fragile in context of our technology. Intentional killing is something very unique. reply agumonkey 15 hours agorootparentprevyou can't define human that broadly i guess what peop le want out of this word is a decent enough amount of compassion and altruism, something that would prevent that kind of harm to others (but i forgot if there was some heated arguments before he decided to step onto the murder path). unless passionate crime is what you had in mind reply bombcar 14 hours agorootparentprevTo be quite frank, redemption isn't really for us to decide. His family, her family, they have a say in it. We only have a say insofar as we're part of the society that determines the laws that form the judges who will decide when it's appropriate to let him back into society. reply robertlagrant 17 hours agorootparentprev> because he's not like the rest of us I don't think we can know this, and there's no point speculating. I would say that the letter doesn't read as someone who's imperfectly simulating regret. reply ryandvm 15 hours agorootparentOf course - this entire thread is nothing but speculation. That said, the premeditated murder of someone, let alone your wife and children's mother, is not something that the average person is capable of. It is entirely different than the crimes one may commit out of rage, fear, or passion (i.e. when your amygdala is driving). I don't believe in capital punishment or lesser forms of punitive justice, but I have a hard time believing that psychopaths can ever be meaningfully rehabilitated. They are just humans that shipped with a fucked up firmware and that's all there is to that. reply ako 12 hours agorootparentThe letter reads like Reiser thinks the firmware bug is fixable, and itâ€™s more a case of nurture over nature. Donâ€™t know if thatâ€™s true, but itâ€™s not unthinkable. reply silisili 17 hours agoparentprevI'm always wary of how manipulating some people can be. To be clear, I'm not declaring this letter or Reiser is that way necessarily, just how people have that capability. That said, to me, some of the specific phrases used felt that they were for a parole board rather than the broader audience, or charitably, both. But perhaps I've become too jaded. reply riversflow 16 hours agorootparent> too jaded I donâ€™t think you are. The number of times the person inferring Iâ€™m jaded is later found out to be a manipulator is very high. Calling people who are perceptive of lies, â€œjadedâ€, â€œnegativeâ€, â€œpessimisticâ€, etc is seemingly a common tactic employed by sociopaths to socially empower themselves while simultaneously weakening those that might call them out. reply rokkitmensch 8 hours agoparentprevGood thing the lizards who pass the US throne back and forth don't have souls that need redemption! reply Aloha 17 hours agoparentprevSpeaking in general terms, not to the specifics of Hans Reiser's crimes - I dont see why it wouldn't allow for redemption, people do stupid things and get blinded easily. reply masklinn 17 hours agorootparentThereâ€™s â€œStupid thingâ€. And then thereâ€™s murdering your ex, hiding her body over two days, lying to your children that sheâ€™d left for russia and theyâ€™d been abandoned, and only revealing the location of the body so you could plea down to second degree murder (a good 18 months later mind, weâ€™re not talking quick change of heart). Oh and then filing a civil suit against pretty much the entire legal system, including the trial judges and your attorney. And when sued for damage by your childrenâ€™s grandmother (on their behalf) assert that you killed your ex to protect your kids (which you had basically never been there for, which was the entire reason your wife left you). Iâ€™m not saying redemption is not possible, but Iâ€™d think some reflection and atonement would be the baseline, and Iâ€™m not aware of Hans Reiser having done any such work. reply dlandau 16 hours agorootparentThat he still wrote \"in prison for killing my wife Nina\" when she wasn't his wife anymore at the time indicates IMO that he still doesn't get it. reply 0x457 15 hours agorootparentLegally speaking, she was, since the divorce wasn't finalized. reply jacquesm 15 hours agorootparentI don't think that matters much. To all practical intents and purposes she was no longer 'his wife' and given that he killed her the fact that the divorce was never finalized shouldn't give him extra rights. reply 0x457 15 hours agorootparentHow is he supposed to refer to her? ex-wife is incorrect. By name doesn't provide enough context for people that don't know about him. The fact is - he killed his wife. > To all practical intents and purposes she was no longer 'his wife' It doesn't work like that, though. My soon-to-be-ex-wife is still listed as spouse on our health insurance because I can't remove her until the divorce is finalized. I still have to specify her in many legals documents as my wife. Even outside the legal field, many in my personal life consider her as my wife, go \"call me when it's finalized\". reply jacquesm 15 hours agorootparentThat's besides the point, the question is whether you still think of her and refer to her as 'your wife'. And then extrapolate to the - obviously hypothetical - situation in which you murdered your soon-to-be-ex-wife and still refer to her as 'my wife' many years later. It's bizarre that this needs to be spelled out. This isn't a legal issue, it's a bit of insight in how Reiser feels about the person he murdered. reply 0x457 14 hours agorootparentWell, in my mind, he is referring to the state at the point of murder. The fact that they were going through the divorce process isn't important here (to us bystanders, to the investigator it's a motive). I think this is just bs for his next parole hearing tho. reply bombcar 14 hours agorootparentprevI'd say that saying \"my wife\" makes it worse for him than saying \"my ex-wife\", maybe that's just me. Doubly so because she's, you know, dead. reply jacquesm 14 hours agorootparentThat's how I read it as well. reply foxyv 17 hours agorootparentprevRedemption requires that a person change and provide restitution. What Reiser did wasn't a stupid mistake, it was a calculated action that he took. His only mistake was getting caught. He didn't accidentally kill someone, or do so in the heat of a unique moment in his life. He decided that he could make his life easier by killing someone else and did so with no intention of facing the consequences of his actions. While I won't say redemption is impossible. He is going to have to serve his time and dedicate the rest of his life to helping others to even come close. reply hollerith 17 hours agorootparentSince the prosecutor's office offered him a sentence of 3 years if he'd lead investigators to where he buried the body, the burden is on you IMHO to support your assertion because obviously if the informed professionals in the prosecutor's office thought it was a pre-planned murder they wouldn't've been that lenient. (In the US, pre-planned murders are routinely punished by life in prison without parole; California might be a little more lenient than the rest of the country, but not that much more lenient.) reply masklinn 17 hours agorootparentWhat sentence of 3 years are you talking about? The judge offered (and prosecutors agreed to) a plea guilty of second-degree murder (down from the first degree murder he was convicted of) if he revealed the location of the body and gave closure to her Ninaâ€™s children and family. He got 15 to life, the maximum for second-degree murder, and his first request for parole was rejected so heâ€™s doing at least 20 for now. reply hollerith 17 hours agorootparentWhat you describe happened after the trial. The offer of 3 years happened before the trial: >An Alameda County Superior Court judge confirmed today Hans Reiser was presented a deal last year in which the convicted murderer would have only served three years in prison. During what was supposed to have been Reiserâ€™s sentencing hearing â€“ which has been delayed due to this weekâ€™s events â€“ Judge Larry Goodman, in an effort to clear up what he called inaccuracies in the media, said that Reiser was given the opportunity last September to plead guilty to voluntary manslaughter. While voluntary manslaughter can carry different prison terms, Goodman said he agreed to give Reiser three years â€“ the lowest possible term â€“ to spare Nina Reiserâ€™s family the turmoil of going through a trial and having the coupleâ€™s oldest son testify. Goodman pointed out in court if Reiser had accepted the deal, he would have been released in May 2008. However, Goodman said Reiser chose to â€œroll the dice,â€ and a jury convicted Reiser April 28 of first-degree murder in the killing of his wife. https://www.mercurynews.com/2008/07/09/reiser-rejected-volun... reply andai 15 hours agorootparentprevRemarkable. Would it really have been 3 years if he'd accepted? That seems far too low. On the other hand, the first degree homicide seems absurd given the evidence. Did they just give him that because he refused to cooperate, and not because it was actually an accurate verdict? reply bombcar 14 hours agorootparentEverything I've seen indicates that the \"court\" seemed to think it was a case of \"murder in red blood\" or whatever they call getting angry and killing your wife these days, with a dose of \"very intentional coverup afterwards\". Had he driven the car with her dead body directly to the police, he probably would have received the three year sentence or even less. reply jacquesm 14 hours agorootparentMore has come out since the trial (and mostly on account of Reiser himself making very hard to walk back claims on the record in another court case). reply bombcar 13 hours agorootparentNot saying they were right, but that's likely what they were feeling (and maybe even the family was pushing for - they clearly knew she was dead, and just wanted the children out of the whole thing). reply themerone 17 hours agorootparentprevDrunk driving is a stupid thing people do. Murder is an act of evil. reply auntienomen 17 hours agorootparentDrunk driving is worse than stupid. It's up there with shooting a gun into someone's house. reply TomK32 17 hours agorootparentprevI don't understand and can't accept why crimes committed while drunk get you a lesser punishment than a crime committed while sober. reply frenchyatwork 13 hours agorootparent> I don't understand and can't accept why crimes committed while drunk get you a lesser punishment than a crime committed while sober. Where I'm from, most people who kill other people while driving get off without any punishment at all. reply EasyMark 7 hours agorootparentprevand if either happened to kill someone, the person would likely receive a similar sentence for manslaughter. reply efitz 13 hours agorootparentprevBecause our justice system believes intent is an element of criminality, not just effect. reply TedDoesntTalk 16 hours agorootparentprev\"Impaired judgement\". I'm not supporting it, just stating that's the claim. reply hobs 16 hours agorootparentprevtl;dr https://www.law.cornell.edu/wex/mens_rea If you don't want to accept it, that's more on you, refusing to understand it is weird though. reply kwhitefoot 16 hours agorootparentRecklessly drinking when you know you are going to drive immediately afterwards means that there is mens rea. Perhaps not for murder but certainly for deliberately increasing the risk of harm to an innocent party. reply HideousKojima 16 hours agorootparentWhich is why killing someone while driving drunk is treated more harshly than killing someone because you got distracted by something on the side of the road. Another example of mens rea. reply shadowgovt 16 hours agorootparentprevSo, this is a reasonable thing to be confused and frustrated about. It's worth remembering that the underlying philosophy of justice, crime, and punishment isn't actually something a society agrees upon. Ask five different people a question about the law, the courts, or the prisons and you'll get five different answers. And the system we get out of that is a hodgepodge of extremely path dependent features based upon who was in control of what levers of power at the time a given law was passed or a given punishment decided to be cruel and unusual (or not). Broadly speaking, there are two independent axes the judicial system is trying to satisfy: - punitive punishment. There are some actions that cannot be undone and some catastrophes for which there is no \"making whole\" the victim. Our system factors in a certain amount of eye for an eye retribution in these cases that dates all the way back to Hammurabi. If you're looking for a justification based on societal structure and survival and not just \"vibes\" (and make no mistake, there's a huge amount of just vibes in the way law, crime, and punishment come about)... It is believed a general understanding amongst the people that committing irrevocable transgressions on their neighbors will cause society to inflict transgressions upon them keeps the society from degenerating into infliction of individual violence on each other in the common case. Does it work? Depends on who you ask. But that's the idea, at least from the Machiavellian \"stable society\" standpoint. In that context, it doesn't matter if Reiser completely overhauls his philosophy of life in jail; he took something that he cannot give back, he took something no one can give back, and a certain amount of punishment is necessary to inform everyone else this is not acceptable (\"thus always to the enemies of the country,\" etc). - rehabilitation and rebuilding of trust. We humans broadly speaking divide other humans into two categories: those who would never and those who would. Certain transgressions bump a person from the would-never into the would category, and that opens a fissure that can never be closed. The fissure can be diminished by the transgressor demonstrating that they understand why that's unacceptable and providing reasons for the public to believe they will never commit that transgression a second time. Under this theory, crime commission is contextual; if a person can demonstrate that they will never be in the context again that would cause them to commit the crime, a certain amount of trust can be reestablished. And here we get to the question of why drunk driving is treated less severely than, say, premeditated murder. As an individual, it's very hard to guard against premeditated murder. And people premeditating murder look like everybody else; It's hard to generate signifiers that would rebuild trust if somebody does such a thing. So the state has a large interest in discouraging it via \"the olde ways,\" because the state has a hard time detecting it coming or defending the victims. In contrast, crimes committed under the influence of mind-alterers we generally feel would be something the transgressor would not do if the influence were removed. It's a lot easier to reestablish the trust gap in theory if somebody who drives drunk swears they will never drink again. ... That having been said, in practice, I totally agree with you. I think the numbers on drunk driving recidivism are ridiculous and it is completely unacceptable to maintain the status quo trust model on this issue; drunk driving should be an immediate revocation of the ability to use a licensed vehicle for life without extraordinary circumstances (on the order of pardon from the governor) to allow someone to retest for a license. We treat pilot licenses thusly; we should treat vehicle licenses with similar scrutiny. ... Problem is, in the US at least, we've built a society so heavily dependent upon cars in most of the country that doing this in the general case would be a sentence worse than the location constraints we put on sex offenders, and there's an upper limit on the state's capacity to actually enforce a law. reply bombcar 14 hours agorootparentSomeone once said that society forms laws and such mainly to prevent vigilantism, and not really for much else. The remainder is post-facto argumentation about how it was \"ok\" to do so. reply shzhdbi09gv8ioi 17 hours agorootparentprevOnly if you believe in evil. I'm not christian so I don't see the world like that. He killed his s/o, like what 15 years ago now? People change and deserves a second chance. reply masklinn 17 hours agorootparentHas Hans Reiser changed and does he deserve a second chance? His first parole board certainly didnâ€™t think so and decided to keep him in for 5 more years. reply seti0Cha 14 hours agorootparentprevChristians believe in evil AND believe in redemption. If you are looking for people who believe that positive change is impossible, try genetic determinists. reply nulld3v 17 hours agorootparentprevWhat do you mean by \"I don't believe in evil\"? I think many people can agree that inherently \"evil\" people are very very rare. Usually people who commit an \"evil\" act have a reason or justification. It's portrayed in literally every movie with an antihero and spawned the \"villain origin story\" meme. But even if they have a reason/justification, that does not make the antihero or villain any less evil. reply readthenotes1 17 hours agorootparentprevReligion-free definition of evil: inclined to increase someone else's suffering without regard (that is, without caring enough to try to reduce that increase). reply themerone 17 hours agorootparentprevEvil is not a religious concept. reply shzhdbi09gv8ioi 17 hours agorootparentDude. Good & evil is such a central concept in Christianity it is practically ingrained in your society if you live in a christian country even if you are secular. reply skissane 16 hours agorootparentThe English words for good and evil are pre-Christian in origin. So are their cognates in other European languages. Greek philosophers were debating â€œgood and evilâ€ centuries before Jesus of Nazareth was born. So there is nothing inherently Christian about those words, or the concepts they describe. reply lupusreal 16 hours agorootparentprevChristianity also features the premise of marriage, so does that mean no secular conception of marriage can exist? Most people think otherwise. Christianity doesn't own \"good and evil\", even though it features it, and nor are these premises even owned by religion generally. reply anthk 15 hours agorootparentprevGoodness and evilness predates Christianity by millenia. Read about Mesopotamian religions, or the Hindic ones. reply hnbad 42 minutes agorootparentprevEvil as a moral judgement isn't. Acts can be good or evil. In more secular terms we prefer to say \"harmful\" or \"unjust\" but the meaning is arguably the same. But the idea that \"evil\" is an attribute a person can possess is 100% a religious one. If you're not religious, there can be no evil person unless you think there is an \"evil\" gene or an \"evil\" psychosis - \"sociopath\" and \"psychopath\" are often used this way but usually in ways that have very little to do with diagnostic criteria and more with trying to sound more profound than just calling someone a bad person; in pseudoscience this also sometimes manifests as the idea that some people are more predisposed to crime, though usually nowadays this more often manifests as vague notions of \"racial culture\" than measuring skull shapes, but this too is just a more elaborate way to call groups of people inherently bad. As a religious concept, \"evil\" can be somewhat nebulous where people just take some wrong turns and \"evilness\" seeps into them making them irredeemable: many Christians (especially certain sects of American protestantism) believe \"sins\" (i.e. disobeying God's rules, not necessarily causing measurable harm to others in secular terms) work kind of like this where habitual sinning in one way can lead to sinning in other ways as sinfulness takes over the person's life (like an addiction spiraling out of control). It can also be a much more literal idea of outright demonic possession (e.g. the kind of thing you need an exorcist to help with) or demonic presence (e.g. evil people actually being lizard people masking themselves as fellow humans to hide among us). And yes, I'm labelling certain fringe conspiracy movements as religious as they operate on a similar framework and often have direct ties to religious traditions and concepts. Conversely, not only are \"evil people\" a religious concept but so are \"good people\". If good is something you do that means you need to continously demonstrate your \"goodness\" by doing good things. But if good is something you can be then any accusations of wrongdoing are highly suspect because a good person would do no such things. This is why most people don't take kindly to being told even in the most polite terms that something they did was kinda racist (or sexist, or misogynist, or...) because \"I'm not a racist\" (i.e. thinking of it as an innate attribute of their character rather than one of their actions and hence something they can and need to actively control) - mind you, liberals did not do a good job with this distinction either over the past decade because as it turns out even self-professed non-religious people often have religious upbringings that stick with them (i.e. self-applied labels like \"feminist\", \"anti-racist\", etc should only ever be read as statements of intent and dismissed if they do not manifest in their actions which they rarely do). reply beepbooptheory 13 hours agorootparentprev> The true Ãœbermensch would never give a second thought (or the light of day) to such a piddling subject as this, one who exhibits all the frailties and animal passions of the last man! \"Second chances\" and \"forgiveness\" are just as much symptoms of christian morality as good and evil themselves. Remember always that justice died with God. Our only arbiter is the creative life, is the aesthetic domain. Thus spoke Zarathustra.. reply hnbad 15 hours agorootparentprevIf you don't believe in evil (I don't) that not only means he isn't evil but that he also didn't murder his ex because he was evil. So there must still be something to him 15 years ago that made him plan to and murder his ex, hide the body, use elaborate lies to deny his actions and then only admit to it when offered a deal to disclose the location of the body to allow the victim's grieving family to bury her. That's a lot. The prison system is neither equipped nor designed to resocialize or rehabilitate people. He hasn't demonstrated any considerable change in his character or outlook on the value of human life that makes me believe he changed for the better. He didn't make a mistake. He intentionally planned out the murder of his ex and how to hide the body and explain her disappearance and he did this to keep his children he neglected, which was the reason for her breaking up with him to begin with. And then he acted out that plan and stuck to it for months. Most people don't even commit to their gym memberships as long as he did to his cover story. People aren't evil. But people also don't improve by rotting in prison. You can argue that means we need something better than prison and I would, but you can't argue that means he should be treated as redeemed or released early. Dropping a feel-good out of context MLK quote to try and impress a future parole hearing is not a demonstration of character growth. Still referring to his victim as \"my wife\" when she had already broken up with him is not a demonstration of character growth. If he seeks redemption he needs to address those surviving his victim. If he wants to demonstrate rehabilitation he needs to do more than just get older and memorize meaningless platitudes. reply tussa 17 hours agorootparentprev> do stupid things Yes, we've all done stupid things we regret. But this is not it. This is way to bad to fit in the \"stupid things\" category. reply kstrauser 16 hours agorootparentIâ€™ve said and done stupid things that hurt people I cared about. Anyone whoâ€™s been a teenager and yelled â€œI hate you, Dad!â€ in a moment of hormonal overload has. Ainâ€™t killed anyone, though. reply eatbitseveryday 17 hours agoparentprev> ending another human's life leaves any possibility of redemption for a person You realize the volunteer soldiers that enter a battle to kill other humans also fall under this scope? Yet in many countries we celebrate their return and service, despite what they may have done. I agree these are not quite the same thing, in how a deed is carried out, but the end result is in fact the same. reply jacquesm 16 hours agorootparentIt's called the department of defense for a reason, even if in plenty of cases the military is used offensively. Volunteer soldiers that go abroad to try to annex another country at the behest of their local overlord are looked at differently then volunteer soldiers that defend their country from annexation. It's not that the 'end result is in fact the same', it's that circumstances matter. In some cases killing another person is acceptable, in most others it is not. That's why we have so many very specific terms to describe the different situations in which one person kills another, and which of those applies is a big factor in whether we see the killer as having acted justifiably or not. Reiser is on the extreme side of that scale in terms of not having acted justifiably, then he compounded that by his stance during the subsequent trial. reply edgyquant 16 hours agorootparentprevContext matters reply scotty79 16 hours agorootparentprev> You realize the volunteer soldiers that enter a battle to kill other humans also fall under this scope? Yes. And I strongly believe there's something wrong with their brains. Not so wrong as with the brains of murderers. But to let someone's words override your innate blocks against killing is some weaknes of the brain, easily exploitable with disastrous consequences for humanity. It makes wars feasible. reply jacquesm 16 hours agorootparentI strongly disagree with you on that one. I can totally see myself volunteering to come to the defense of a country against invaders, I can absolutely not see myself volunteering (or even being conscripted) into helping some country to invade another (or to enlarge their territory). I'm a conscientious objector against military service which at the time that I did so still carried a prison sentence and even if I ended up not going to prison (through some luck and a sympathetic police officer) I was more than willing to do so rather than to be used as a tool. So that takes care of the second part of that statement, the first has so far not been put to the test (and let's hope it stays that way). reply shepherdjerred 3 hours agorootparent+1 I would never serve for an offensive war, but for example I would have been proud to serve the Allies in WW2. reply nyolfen 15 hours agorootparentprevi think if you take a look at human history, the animal kingdom, etc, you will find that in fact it is you who has something strange going on in your brain reply scotty79 15 hours agorootparenthttps://www.theguardian.com/science/2016/sep/28/natural-born... Humans and other primates are more prone to this deficiency of the brain than other mammals. But even so, only 2% of humans were killed by other humans. And since many killers usually kill more than one person killers are a miscule minority even in such deficient species as humans. Even with all the cultural pressure that glorifies killing in the \"right circumstances\". Given that anyone who volunteers to be a killer has something wrong in him. Falls on the far end of some spectrum. reply fl7305 15 hours agorootparent> anyone who volunteers to be a killer has something wrong in him Consider the native american indian warriors who volunteered to defend their land against the invaders. Or jews in Poland who volunteered to defend against the Germans in WW2. Does your statement apply to them as well? reply scotty79 15 hours agorootparentOf course. Some of them. Not everone who joins the army is a volunteer killer. Some people just want to help. Treat wounds. Recover wounded. Scare the enemy away. Some tentatively accept that some people might die in the process. People tend to accept that in war people die. They are more like armed robbers who'd love to have their goals met without killing anyone but some are accepting that someone might die in the process. But fraction of people are killers. They participate in the process in order to kill. Those are the most deficient ones. They are present in every place where people die, on both sides. reply bombcar 14 hours agorootparentSome fraction signing up so they can gun someone down, sure, those people have bad motives and should be found and excluded. But being willing to say \"I'd kill to protect X if there is no other option\" is not that. Someone who becomes a surgeon so that he can kill a patient now and then and get away with it obviously has something wrong. Someone who becomes a surgeon and now and then causes a patient to die unintentionally (even if they intended to do the surgery, knowing it could result in death) is not the same. reply fl7305 14 hours agorootparentprevAre you a pacifist who thinks that it is never OK to take a life, no matter the circumstances? In that case I understand what you think, even if that is not my way of thinking. If you are not a pacifist, then I don't understand how you think a peaceful society should act when an aggressive neighbor tries to kill all of them? reply scotty79 12 hours agorootparentI think it's ok to take life if it's your own life or help someone to take their own if there are good reasons for it. I don't know how a peaceful society should act if neigbour tries to kill them. I think if that's the case, they made a lot of mistakes already, if they reached that point. Probably the only thing to do is gather your killers and send them to kill and tell everybody it's ok this time. And most likely just die regardless of what you decided to do. If this society somehow survives it's way ahead because they not only repelled foreign killers but culled their own. That's pretty much was the result of WW2. Europe was destined for prosperity after it no matter who won. Just because higher fraction of killers than normal people died. reply fl7305 11 hours agorootparent> I don't know how a peaceful society should act if neigbour tries to kill them. I think if that's the case, they made a lot of mistakes already, if they reached that point. There are literally thousands of examples throughout history of smaller ethnic groups that were completely wiped out by their bigger and more aggressive neighbors. Do you think these small groups were provoking their neighbors? Why? Did they all have a death wish? How do you appease someone who is determined to take over your territory while getting rid of your people? What does the compromise look like? > Europe was destined for prosperity after it no matter who won. Wow. If the Germans would have won, they would have cleansed large parts of Europe. Do you call that \"prosperity\"? Same thing with Stalin. If he had gotten a free rein across Europe, I don't imagine there would have been many Scandinavians left today, for instance. The few left would live somewhere in Siberia. reply scotty79 1 hour agorootparent> There are literally thousands of examples throughout history of smaller ethnic groups that were completely wiped out by their bigger and more aggressive neighbors. Exactly. Figting and killing didn't help them in any way. > Do you think these small groups were provoking their neighbors? Why? Did they all have a death wish? The wrong decision in that case was deciding to be separate from their neighbors despite the fact that they presented overwhelming force. They were multitude of ethnic groups who survived by getting assimilated into their stronger neighbors. You might argue that it's not a survival if culture disappears. But that's just words. Genes are what matters in any broader context. > If the Germans would have won, they would have cleansed large parts of Europe. Do you call that \"prosperity\"? They would possibly kill all the Jews which is unfortunate and a terrible loss. The rest of the populace would just become the part of their empire. And running an empire is a troublesome thing as countries like Britain found out. India used to be a British colony. And today more property is owned in London by the Indians than by native British people. Some regions of London are minority white. Nobody designed it like that. It is just a result of previous attempts at exploitation of their acquired empire. Same happened to France. Germans would eventually succumb to the same fate. Stalin is a different thing. Just because Russians are terrible at everything. I'm still sure they wouldn't manage to keep whole Europe under their shoe for long. And if they did that would mean they seriously stepped up their game, so prosperity of sorts. reply throwaway365980 17 hours agoparentprevnext [3 more] [flagged] gertop 17 hours agorootparentWhy do you think that her being a mail order bride makes it less bad? If anything it just shows that he wanted to buy another human that he could control and, when it turned out not to be the case, he decided to kill her. reply iaw 17 hours agorootparentprevI am not going to touch on your other points as you clearly have decided your mind. > why a mistake he committed in personal life would make his file system a taboo to touch. He is no longer here to fix bugs or improve the file system, it is not that it's Taboo to touch per se. The benefits of ReiserFS are no longer clear compared to alternatives, there's a cost to including ReiserFS (which Reiser acknowledges), no other FS is associated with the name of a premeditated murderer. reply sph 17 hours agoprevI think about Hans Reiser pretty often, incidentally, because there is a quote from him I read as a teenager that stuck with me. \"The utility of an operating system is proportional to the number of connections possible between its components, than it is to the number of those components.\" â€” Hans Reiser (from http://web.archive.org/web/20040126210110/http://unununium.o...) It's hard to reconcile good things a person might have said and done, with the bad. That sentence is a guiding principle of software design that I cannot often quote, without entering into a huge discussion on the pain Reiser has caused. This is the only time I feel I am able to share that quote, on a thread that hopefully tries to look past the right and wrong of his actions. Just as no one is truly good, no one is truly evil either. It is good for one's soul and humanity to acknowledge that a bad person might have done something good in their life. ReiserFS was pretty cool as well, sad to see it go, but no one uses it anymore. I hope they'll find redemption and peace. reply robertlagrant 17 hours agoparent> That sentence is a guiding principle of software design that I cannot often quote, without entering into a huge discussion on the pain Reiser has caused That's a shame. He did something awful, but that's nothing at all to do with the idea in the quotation. Ideas shouldn't be cursed because the wrong person said them; they should stand or fall on their own merits. reply pdntspa 16 hours agorootparentCertainly, I have an issue with this idea that everything a person does gets cancelled because the person gets cancelled. Particularly in this era of intense political polarization.... It is throwing the baby out with the bathwater. The world is full of examples of art and science from troubled individuals; much of our foundational understanding of certain areas of science is derived from the learned experiences of inhumane research conducted by nazis or WW2 japan. Yet one guy murders his wife and suddenly we are all rejecting a perfectly cromulent filesystem. reply anthk 15 hours agorootparentNo, ReiserFS was unreliable by itself. Run fsck on a ReiserFS filesystem with a ReiserFS loopback image/wm, then your whole partition it's trashed. reply starfallg 15 hours agorootparentprevReiserFS and BTRFS are the only 2 Linux filesystems that truly ate my data. Everything else I was able to substantially recover from. reply __david__ 14 hours agorootparentI had XFS eat some data once. I somehow got it into a state where it wouldn't mount and wouldn't fsck. Luckily for me it was \"just\" my backup disk, so after a week of fighting with it I just gave up and reformatted (as ext4) and didn't end up losing much. Was eye opening though. I'd rather have a slightly less featureful fs that I have a chance of recoveringâ€¦ reply hulitu 14 hours agorootparentI had the same issue with xfs. Seems to be fixed recently. reply pdntspa 14 hours agorootparentprevI've had really bad experiences with fat32 and xfat... back in the day it was pretty common to lose data due to hard drive or filesystem bullshit. In any case, I was a technology journo at the time this happened, and I covered this story, but I don't recall encountering a lot of technical discussion... it seemed to be mostly \"ew this guy murdered his wife\". Which is entirely deserved. (If a little unfair to the creative work) I wasn't much of a programmer yet so maybe I wasn't looking at the right discussions. reply wtracy 14 hours agorootparentprevReiserFS and BTRFS always seemed like the two big \"performance over reliability\" Linux file systems. reply bombcar 15 hours agorootparentprevFriends, Romans, countrymen, lend me your ears. I come to bury Caesar, not to praise him. The evil that men do lives after them; The good is oft interrÃ¨d with their bones. (What's interesting to me is that it's often black and white; dead people become either perfectly good or perfectly evil, depending on where you fall - only if they're \"not important\" are they allowed to be human and gray.) reply sph 16 hours agorootparentprevCertainly, I don't have a problem with the quote. I just don't want to face the inevitable \"Hans Reiser? Isn't that the one that...\" quagmire that pretty much everybody is going to step into. reply Pet_Ant 15 hours agorootparentI have a Bill Cosby quote that I attribute to Dr Huxtable. It is sufficient citation, old heads will know but don't react, and new heads will just nod and not get triggered. reply lupusreal 16 hours agorootparentprevJust attribute the quote to Voltaire or Franklin. reply DaiPlusPlus 16 hours agorootparent...there's an Abraham Lincoln quote somewhere about that. reply dekhn 17 hours agoparentprevIsn't that a restating of Metcalfe's law? https://en.wikipedia.org/wiki/Metcalfe%27s_law [EDIT: I have misunderstood Metcalfe's Law for over 20 years, assuming that \"connections\" meant edges in the following quote. Metcalfe intended to mean that the value of the network grows as the square of the number of nodes because \"connections\" here aren't edges, they're fully reachable pairs of nodes. Thanks, again, HN, for helping me through that] > The financial value or influence of a telecommunications network is proportional to the square of the number of connected users of the system (n2). Generally speaking, \"the value of a graph is proportional to the square of the number of edges\" rabbit hole: https://en.wikipedia.org/wiki/Locally_linear_graph reply atleta 16 hours agorootparent> Generally speaking, \"the value of a graph is proportional to the square of the number of edges\" No, what Metcalfe's law assumes is that the value of the graph is proportional to the number of edges (not their square). And from that assumption and the fact that the graph is fully connected follows that it's proportional to the square of the number of nodes. (Because you can have (n-1)*n/2 edges with n nodes in a fully connected graph. And hence, the Reiser quote above is similar but it emphasizes something else: it states what Metcalfe's law (I think) uses as a premise (or implicit claim) that the value is in the connections. Because it's not necessarily a fully connected graph. Edit: originally I've given (n-1)*2/2 as the number of edges instead of (n-1)*n/2. reply amomchilov 16 hours agorootparentPromotional to the number of _edges_. Edges are proportional to the square of the number of nodes, so the value of the network overall is proportional to the square of the nodes. Think of it this way, for every new user added to the network: * the new user is enriched proportional to the number of existing users * every existing user is enriched by the 1 new user This double-counting is what gives it the quadratic growth. reply atleta 15 hours agorootparentYep. That's what I was saying too. The first line of my comment quotes the GP and I was correcting that. reply dekhn 16 hours agorootparentprevSo, the wikipedia first line is wrong, you're saying? \"Metcalfe's law states that the financial value or influence of a telecommunications network is proportional to the square of the number of connected users of the system\" Later in the article it seems like the original stating is more consistent with what you said, but everything I've ever learned in network theory and practice shows that it scales as a power of number of edges, and the logarithm of the number of nodes. reply gnramires 16 hours agorootparentThe number of connected users is different from the number of user connections :) The first is the number of nodes, the second edges. reply dekhn 16 hours agorootparentUhh, are you sure? I believe \"connected users\" refers to edges. Otherwise it would be stated as \"users connected to the network\". It could explain my misunderstanding, and also seems consistent with the explanation later in the article, but it's also completely the opposite of what we observe on the internet; for example, the value of the web is definitely not in its in number of pages, but in the value and quality of the connections between the pages. reply zvr 16 hours agorootparentTwo users in the network: A and B; one connection: AB. Three users in the network: A, B, and C; three connections: AB, AC, BC. Four users in the network: A, B, C, and D; six connections AB, AC, AD, BC, BD, CD. Metcalfe's law says value increases as 1-3-6-... instead of 2-3-4. In graph terms, users are nodes, connections are edges, and in a fully-connected graph edges are in order of the square of nodes. reply dekhn 16 hours agorootparentYes, I see I had completely misread and misunderstood the original law. But ethernetworks aren't fully connected (they tend to have lots of local connections that then are connected to each other through routing). reply jacquesm 16 hours agorootparentI think the difference between logical and physical connections is what drives the confusion here. If two nodes can reach each other somehow then for Metcalfe's law they are connected, even if there is no direct connection between them. reply dekhn 15 hours agorootparentYes, I realized that shortly after reading the replies. Thanks for stating it explicitly. Once again, my brain's inability to parse english caused a multi-decade misunderstanding. Realistically, the only metric that I can think of that makes sense here isn't proportional to |V| or |E| but to the betweenness connectivity of the graph and the average distance between nodes. reply jacquesm 15 hours agorootparentYou actually have a very valid point: given that there is such a thing as the maximum ttl at some point that 'logically connected' network will become more and more sparse depending on how 'wide' the network really is. I wonder if there are already parts of the V4 net that are so far removed from each other that this is an issue. reply sph 17 hours agorootparentprevIt did sound something that could be applied to much more than the niche of OS design. The focus is to make the connections between things composable, rather than adding a lot of subsystems. Think UNIX or Lego bricks. Thanks for those links, I did not know Metcalfe's law, but it expresses a similar concept in a much more succinct way. reply krisoft 16 hours agoparentprev> That sentence is a guiding principle of software design that I cannot often quote Just rephrase it. It is not like you need to bring him up to discuss the idea, or as if this is the only form the idea can be expressed. In fact I would say the quote as it is is confusingly written. reply mtlmtlmtlmtl 16 hours agoparentprevFully agreed. We also have to remember that a lot of the historical figures we glorify through their great achievements were terrible people in many respects. And that often goes undiscussed. reply logifail 16 hours agorootparent> We also have to remember that a lot of the historical figures we glorify through their great achievements were terrible people in many respects. And that often goes undiscussed. ...or we focus on how terrible a person was, and insist on completely disregarding their great achievements. reply atleta 16 hours agoparentprevThe word \"more\" is missing from the first half of the sentence: \"more proportional\". reply coldtea 15 hours agoparentprev>This is the only time I feel I am able to share that quote, on a thread that hopefully tries to look past the right and wrong of his actions. Well, people would still use the theory of relativity if Einstein was proven to be a serial killer, so intelligent people who don't play it \"hollier than thou\" should be able to separate between some person's acts and their unrelated achievements or expressions. reply sph 14 hours agorootparentScientists would, while Twitter and average Joes will be discussing ad nauseam whether to rename the theory and delete the name Einstein from history books. Wasn't there a similar discussion about renaming the James Webb Space Telescope? He was not even a murderer. reply narag 15 hours agoparentprevIt's hard to reconcile good things a person might have said and done, with the bad. It's very easy to reconcile that a person that has done very bad things can say insightful things or be competent. Being bad doesn't mean being stupid. reply pimlottc 16 hours agoparentprevYou accidentally omitted a word, that should read: > The utility of an operating system is more proportional to the number of connections possible between its components than it is to the number of those components. reply hosh 15 hours agoparentprevThat principle has been stated and developed in other context. For example, there was an earlier HN post about composition of features (https://lea.verou.me/blog/2023/eigensolutions/?latest) Another example is in ecology. Resilient ecology has many possible interactions among members of the ecology (including humans). An \"invasive species\" isn't necessarily one that is not native to the ecology, but one that is able to exploit a resource while having a minimum interaction with the rest of the ecology. Dr. John Todd's ecovats are essentially self-contained ecologies that self-organized around a pollutant. They are created by taking samples from a number of ecological systems and putting them together into vats, and then running contaminated water through there. It's because the possible interactions are so high, that somewhere in there, was a path to breaking down the contaminant. In such a way, Dr. Todd was able to break DDT down in a matter of days through a system like that, and has worked on cleaning up superfund sites with this method. To go one step further than number of interactions, Christopher Alexander's ideas on pattern languages was more than just about interaction of components, but actually about the _grammar_ of design patterns. Such a grammar can be constructed in a way that all possible combination coming out of the grammar results in a cohesive design. This allows inhabitants of an architecture or an end-user to reconfigure anything (as long as it follows that grammar) to suit their current needs, and it would still come off as a cohesive design. To circle back to addressing the idea of evil and people who do bad things. I think you can find truth anywhere, and Han Reiser certainly touched on an insight (though it was not exclusive to him). I would further suggest this though: wouldn't this also mean that there is value in _relationships_ among people? In, not just the exchange of thoughts and knowledge, but the exchange of shared experience and feeling? I don't know what went through Reiser's head when he killed his wife, and I can believe that there are a kind of madness that can consume someone. I think perhaps, Reiser saw an insight in systems engineering ... but did not see how that same principle was also present in the day to day life as well. (Or maybe he did see it, and was consumed by a madness anyways) reply graemep 15 hours agoparentprevLots of people who do good work have done awful things. I love Oscar Wilde's plays, but he was a paedophile sex tourist. Eric Gill created beautiful stuff, including typefaces most of us probably use or read fairly often, and he sexual abused his children and his dog. reply coldtea 15 hours agorootparent\"Pedophile\" back then often just meant \"gay\". In French pedÃ© (pedophile) was the regular way to say \"homosexual\". Also the age of consent was lower back then, and untold numbers of \"normal respectable ethical people\" who back then would otherwise condemn Wilde as \"pedophile\" did marry girls at 14 or so. Before the 20th century basically after 13-14 kids were considered more like short adults than as a special category of teens. Wilde surely wasn't any kind of pervert going with prepubescent kids or anything like that. In fact, the guy he went to prison for being a lover to was 21. As for his \"sex tourism\", it was basically travelling in countries you could have gay sex with locals and the local authorities would turn a blind eye. reply graemep 10 hours agorootparentNo. He had sex with boys, and he had sex with boy prostitutes while traveling abroad. > In fact, the guy he went to prison for being a lover to was 21. Yes, he had sex with adult men too. Also with adult women too - he was married to one and they had kids. reply hulitu 14 hours agorootparentprevYeah, right. reply coldtea 13 hours agorootparentYeah: right. reply _a_a_a_ 15 hours agorootparentprev> Oscar Wilde's ... was a paedophile sex tourist I've never heard of him being into children, have you a link for this, thanks (also, 'sex tourist'?) reply martin8412 14 hours agorootparentApparently he went to North Africa and Italy. Plus he was what would be called a rapist today. Mind you, I don't know if this is a reliable source. https://thefederalist.com/2018/09/18/time-left-stop-idolizin... I'm not really a fan of applying modern standards in historical contexts. Times change, but even today the age of consent is 16 in the UK. Condemning him for being 30+ and having sex with 15-16 year old boys just doesn't make sense to me. It seems people try to apply American puritanical standards to a historical person from Europe, who lived in the 1800s Victorian era. If we were to apply modern standards, you should be condemning over 1B people around the planet for following the teachings of a 30yo+ guy who married a six year old girl. reply graemep 10 hours agorootparentEven if you accept that, the age difference and the hiring of poor boys as prostitutes makes a difference. Differences of an year or two in age of consent is one thing and some variation is one thing. The article you link to mentions a 14 year old. How far will you take \"it was acceptable in their culture\". Child brides in modern Yemen or many other places? Romans being into little boys? Legal does not mean socially acceptable either. 16 might keep you on the right side of the law here in the UK, but a 40 year old who is found to have had sex with a 16 year old is likely to be badly regarded. > If we were to apply modern standards, you should be condemning over 1B people around the planet for following the teachings of a 30yo+ guy who married a six year old girl. A lot of them claim he did not have sex with her until she was much older. I would condemnd them if they had sex with six year olds themselves. reply _a_a_a_ 10 hours agorootparentIt's complicated. > and the hiring of poor boys as prostitutes makes a difference I'd say absolutely yes, that is wrong, but at the time it was not considered so wrong. I understand the age of consent was introduced for girls to stop them being used as prostitutes, and some men at the time were against this legislation. The question is, who defines 'right'? > Child brides in modern Yemen or many other places Sadly in their eyes, this is considered acceptable, even good. In our eyes, and mine, it's unacceptable. How do we define 'right' in this context? If we are right then how do we make them understand they are wrong? Why they do it is simple; it is done in their culture so it is right. I see exactly the same kind of thing appearing here on HN where somebody condemns something they don't like (e.g., https://news.ycombinator.com/item?id=38981118) because \"you're wrong because you're not right\", essentially. > but a 40 year old who is found to have had sex with a 16 year old is likely to be badly regarded I'm not so sure. Such cases have existed, I remember on TV maybe 25 years ago a woman of 40 who married her husband of 16, it seemed to work and nobody seemed to upset about it. I personally knew of a couple, she was 19 and he was 60 and it was a good relationship while it lasted. I think people would take such age-unequal relationships on their own merits, and that is actually a good thing because otherwise it would just be intolerance. reply _a_a_a_ 13 hours agorootparentprevExtremely informative, thanks. Agree with you about the difficulty of interpreting morality over timespans and cultures. reply tonymet 17 hours agoparentprevYour observations are right but your conclusions are shoddy . We can and should separate ideas from the person . There are plenty of truly evil people though . No indictment of Hans I donâ€™t know his case . But of truly evil people there are countless numbers reply sph 16 hours agorootparentI disagree, but this is personal philosophy I do not feel comfortable going too deep with on an Internet forum. From my point of view, people that are born with evil streak are vanishingly rare, as much as being born with two heads. What happens later is simply a product of nurture, upbringing, context, and chemical imbalances. Pure black and pure white do not exist in nature. reply andai 16 hours agoparentprevI was impressed by this quote from TFA: > Through force of will, and hard work, he made himself into a programmer of extraordinary skill ... reply agumonkey 15 hours agoparentprevalso slightly reminiscent of perlis https://stackoverflow.com/questions/6016271/why-is-it-better... reply zubairq 16 hours agoparentprevGreat quote! Isnâ€™t the number of connections instead of number of components related in some way to metcalfs law? reply chubot 15 hours agoparentprevFWIW this is highly related to what I think of as the \"narrow waist\" architectural principle. You may like these articles I wrote: The Internet Was Designed With a Narrow Waist - https://www.oilshell.org/blog/2022/02/diagrams.html The Internet has huge utility because TCP/IP is a narrow waist. It has architectural connections to Ethernet/wireless/... on one end, and HTTP/BitTorrent/... on the other. For the most functionality, you want fewer code components, and more interoperability. You want O(M + N) pieces of code to give O(M * N) functionality. The narrow waist architecture does that -- it gives O(M * N) connections to O(M + N) amounts of code. You don't want to write O(M * N) code, though many people and systems are stuck there! This generally works the best when the connections are data-oriented and protocol-oriented, not oriented around source code. --- A Sketch of the Biggest Idea in Software Architecture - https://www.oilshell.org/blog/2022/03/backlog-arch.html I mention Metcalfe's law, which is related but distinct. Metcalfe's law is about O(N^2) network node connections (\"dynamically\"), while the (usually) O(M * N) narrow waist is about system architecture (\"statically\"). They both produce network effects! If the Internet already exists, then the easiest design to implement is to attach your new network to it (e.g. a network in space), not create a new, incompatible network. --- Incidentally, this seems like what's wrong with the Kubernetes ecosystem -- it has an combinatorial explosion of code due to lack of protocols and interoperability. It's not data-oriented, like Unix is. (An important point is that lots of people complain about Unix-style unstructured byte streams because it's suboptimal LOCALLY, while missing the global interoperability / scale / system economy issues -- they get stuck writing O(M * N) code to avoid parsing and serializing ) --- Newer article from last year - Oils Is Exterior-First (Code, Text, and Structured Data) - https://www.oilshell.org/blog/2023/06/ysh-design.html Software modularity within a process is much different than modularity between processes -- it's a bit more like networking. You need an exterior narrow waist. To pick an example, a consequence of that is that encodings like UTF-16 don't make sense in any channels where you don't have metadata, and there are a lot of those e.g. the URL comes BEFORE the Content-Type header in HTTP! reply sph 13 hours agorootparentYeah, I can see the similarity. Thanks for the links. Also, vaguely related, and a way to achieve this goal of making things composable, is the \"everything is an X\" pattern: https://lukeplant.me.uk/blog/posts/everything-is-an-x-patter... reply chubot 11 hours agorootparentYup, the \"Everything is an X\" link is in the appendix to the second post :) https://www.oilshell.org/blog/2022/03/backlog-arch.html#wiki... I call it the Perlis-Thompson Principle, after Perlis: It's better to have 100 functions on 1 data structure than 10 functions and 10 data structures. and Thompson: A program is generally exponentially complicated by the number of notions that it invents for itself. To reduce this complication to a minimum, you have to make the number of notions zero or one, which are two numbers that can be raised to any power without disturbing this concept. Since you cannot achieve much with zero notions, it is my belief that you should base systems on a single notion. https://www.oilshell.org/blog/2021/08/history-trivia.html reply HideousKojima 16 hours agoparentprevnext [2 more] [flagged] jacquesm 16 hours agorootparentTerry Davis was diagnosed with schizophrenia and never killed anybody. reply mpol 17 hours agoprevA few things that stuck out to me. SuSE supposedly failed. I don't know who told him that. He might have expected it to be a RedHat or Ubuntu by now, which it isn't. But failed is very black and white. I would argue, if they still exist as they do now, they are quite successful. He talks about Reiser V4. I think there is a Reiser V5 now? Or am I wrong? I cannot find that on Wikipedia. Anyway, the chances of it ending up in the Linux kernel seem close to zero. He sounds very humble. Also he talks about being more social and having got education and therapy in prison. Still it reads as if they are all working together in prison, in certain ways. The world out there might be more complex. I don't know if he is being naive in this regard. reply the_af 16 hours agoparentHe does mention Reiser5 in his letter: > I donâ€™t know what is in Reiser 5â€”I havenâ€™t been told, and I cannot go on the Internet. Edward Shishkin is a very bright man though, and one of my regrets is that I didnâ€™t spend more time with him, I am confident he has done some thing nice in Reiser 5. reply bombcar 14 hours agorootparenthttps://www.phoronix.com/news/Reiser5-Development is the last reference I find to Rieser5, but the link in it goes to what appears to just be Reiser4 maintained against moderately recent kernels. reply ajb 12 hours agoparentprevHe is also still talking about spinning rust (rotational delay). I forget the timeline, but maybe he went into prison before SSDs became ubiquitous? (I know they are still in servers) reply bjourne 16 hours agoprevReiserFS is the only Linux file system that has lost me data. Back in the day it had performance advantages when dealing with small files. But now I'd be very surprised if ext4 isn't superior to it in every conceivable way. reply ghaff 15 hours agoparentThere's an argument for copy-on-write filesystem options but it's pretty hard to argue there needs to be more than 2 or 3 \"traditional\" journaling filesystems like maybe ext4 and XFS. reply kstrauser 14 hours agorootparentHis letter contends that ReiserFS was intended to be more than just a filesystem, and that jibes with what he was saying about it at the time. I think that it was meant to be a queryable database that happened to be good at implementing traditional filesystem semantics, but also optimally useful through some other kind of API. reply jbverschoor 14 hours agorootparentOnly 5-10 years after BeFS. reply Eisenstein 13 hours agorootparentprevCan you explain what that means? What are 'traditional filesystem semantics' and how would it be useful through 'some other kind of API'? reply kstrauser 11 hours agorootparentWell, you know how to R/W data with a normal filesystem. You can chdir() to the location you want to be, look around there with readdir(), open() and read() or write() files in there, and all that. You could also have a SQL-like API where could \"select count(1) from all_files where path_root = '/usr' and owner_uid = 0 and world_readable = true\" that allowed you to query files, or maybe kernel calls that looked a lot like the Amazon S3 API (PutObject, ListObjects, ListBuckets, etc.) if that turns out to be more efficient for certain usecases. The normal POSIX filesystem calls are obviously enormously useful. I mean, they've been used to implement SQLite and PostgreSQL, so you can* implement those other kinds of APIs on top of it. I can also imagine it being the case where there might be a much more efficient way to implement specific workflows if you didn't care about all the conventions that POSIX brings along. reply bjourne 14 hours agorootparentprevI beg to differ. In 2024 we know that COW is bad regardless of whether we're talking about disk or memory. reply hinkley 17 hours agoprevI thought the usual solution when we disagree irreconcilably with a maintainer was to fork and rename? I always thought it a bit weird that we were naming parts of Linux after people. We already did that once and that kinda uses up your freebie. Seems like everyone quit Hans and nobody rallied the project back together. reply dale_glass 17 hours agoparentI don't think Reiser's name had anything to do with the removal. If I recall the situation was more or less as follows: Reiserfs3 was out there, and while it had plenty fans (good performance and efficient disk usage), it had a fair amount of corruption issues. Reiserfs4 was about to come out. Reiser insisted that Reiserfs3 was done and an obsolete relic, and reiserfs4 was the new hot thing. Reiser ran a consulting company of some kind. IMO this may have put a bit of a damper on contributions. He also had a contentious personality, with quite a lot of people disliking him, and him having trouble convincing people to merge reiserfs4. Right about that time the whole murder mess happened. So reiserfs3 was apparently abandoned, reiserfs4 was uncertain if it was going to get merged. Namesys, Reiser's company of course fell apart and the existing employees had to find something else to do. So that was probably about the worst timing possible. Reiserfs4 didn't get merged, Reiser was dealing with the trial/prison, and other filesystems started showing up as well. reply dspillett 17 hours agoparentprev> I thought the usual solution when we disagree irreconcilably with a maintainer was to fork and rename? Yes. But that requires someone, or a group, to take responsibility for that and support the fork. Maintaining a filesystem can be a complex undertaking. > Seems like everyone quit Hans and nobody rallied the project back together. I think it was more like he was the core of the project with others contributing. Once he was out of the picture no one else had sufficient passion and/or time for it to take on the mantle of project lead sufficiently (to push Reiser4 onward and eventually getting it merged into the mainline Kernel and maintaining Reiser3 in the meantime & further forward). While Reiser4 is still maintained, it has never been merged into the mainline kernel limiting its support in common Linux distributions. I don't know if that is because the current maintainers have tried to have it merged and failed for some reason, or if they have not pushed of its inclusion at all. What is deprecated and due to be removed is Reiser3, which is not actively maintained. There are some technical issues that would need addressing soon if it were to remain, and in any case an unmaintained filesystem is a dangerous thing to rely upon if you can avoid doing so. It isn't being removed because of who started it, it is being removed because it is not well enough supported for mainstream safety. Reiser3 won't be removed until some time in 2025, and unless you need the latest latest kernel at all times an active setup will keep working for a while after that (until the older kernel it uses falls into EOL), so you have plenty of time to migrate if you need to. If a lot of people were relying on Reiser3 there would be a lot more noise about this. People using Reiser4 are building their own modules (or patching a kernel tree and building it in) already and this will not affect them. reply IlliOnato 12 hours agorootparentIf I remember correctly (and I followed the discussions on LKML at the time, but it was a long time ago), Reiser4 was not merged because it had some \"cool\" features that could cause problems. For example (again, IIRC), it allowed directories to have hard links. Al Viro was adamantly against it, showing that this potentially creates some very serious problems. In particular, it allows for cycles in the directory graph (it's no more a tree), and Viro has shown that detecting or preventing such cycles may by prohibitively expensive, and undetected they would cause any program that does directory walking (like search) to loop infinitely. This was not the only problematic feature, just the one I remember more vividly (in part, because of Al Viro's caustic argument style :-) ). reply dspillett 1 hour agorootparentI didn't follow LKML directly, but from what I saw elsewhere that seems right. I remember there being technical arguments against Reiser4, and the discussions about them getting interesting (not combative, but very direct) in part because Hans wasn't one with a \"nicey nicey\" discussion style either! Though until Hans was out of the picture, those discussions were still on-going. reply bombcar 14 hours agorootparentprevRemember that XFS was added to the kernel in 2001, and was already well-supported by most (all?) distros by the time the Reiser3/4 issue was beginning. People who encountered issues with Reiser3 usually migrated away, and never looked back, Reiser4 was already DOA imo before all the other stuff happened. reply marcosdumay 16 hours agoparentprevInstead, people integrated the interesting ideas of reiserfs into ext2, and made ext3. This is also a perfectly fine way to handle disagreement. Also, people quit him way before that thing. He mostly supported the filesystem alone. reply 0x457 15 hours agoparentprevThere is just no need for such FS today. Everything is bloated, random access is much faster (SSDs, NVMe), storage is cheaper. It's the only FS that I lost data with. reply keeganpoppen 13 hours agoprevwow, he is an amazingly compelling and articulate writer. definitely gives me a bit of an eerie feeling, of course, because he seems like a very meticulous person and perpetrated a heinous crime in a most meticulous fashion... but... it is very hard to completely discount the idea that he has learned something from prison in a way that makes him redeemable, though i'm a bit of a softie-- him bending over backward to commend people on their work in a way he clearly didn't do at the time... that is very hard for a prideful person to do without at least some little bit of subtext... and i just didn't pick up on anything like that. the only subtext would essentially be that he is so clever that he knows the only way for him to get his roses is to genuflect. so i guess this whole thing is kind of a litmus test on how you view human nature... but it was an incredible read, at the very least. reply ajb 13 hours agoparentHe's serving 15 years to life, and has already served 15 years (next chance of parole in 2027). So he's at the point where its very important for him to look like he's a reformed character. That makes it particularly hard for us to judge, at this distance. If he'd remained cold and calculating, this is still exactly what we'd expect him to write. reply vvillena 16 hours agoprevI found this to be a great story about mismanagement. It appears Hans made a multitude of small mistakes that ended up crippling his filesystem project. It's extremely interesting to see such a thorough reflection on all the things that went wrong. reply sitzkrieg 15 hours agoparentyea im thankful he shared all the failures and redesigns etc reply kstrauser 17 hours agoprevThat was fascinating. It sounds like heâ€™s done some real introspection during his lockup, and I hope heâ€™s able to apply those learnings to future situations. I felt bad for him[0] while reading. He was a brilliant young person with a big dream, yet without the interpersonal skills to help him realize it. Iâ€™ve seen that so often. Maybe this will help me look past the next personâ€™s challenging communications, and think hereâ€™s someone who means well but doesnâ€™t know how to explain it. Reiser wants to learn how not to be an ass. I can try to learn how to recognize when someone being an ass is caught in the same traps he was. That, and how to be sure Iâ€™m not the one being the ass. Best of luck on the continuing personal growth, Hans. [0]Minus the obvious, of course. reply mardifoufs 16 hours agoparentI don't believe he did. He's just angling for his next parole date as he got denied this year. reply kstrauser 16 hours agorootparentThat's very possible. Some of his phrasing sounded like he hoped the parole board would be reading it: I accept responsibility for my crime, I'm using the skills I'm learning in prison, etc. etc. Still, if you asked me about my own sins, I might say similar things: I accept responsibility for acting like a jackass, I'm using the skills I've learned from mentors and through meditation and mindfulness, etc. etc. I'd be completely earnest about all that. I've behaved poorly in the past, decided I wanted to be a better person, and genuinely try to do that. If I want people to take me at my word and believe that I'm trying to be better, I have to take him at his word until proven wrong. (One of my sins was unnecessary cynicism. I have the luxury of it not mattering to me whether he's sincere or not, and I think it's a healthier mindset for me to accept stories like his at face value than to default to mistrusting everyone. I'm not naive, though. The people in his life need to weigh that a lot more carefully than I need to.) reply cperciva 15 hours agorootparentSome of his phrasing sounded like he hoped the parole board would be reading it: I accept responsibility for my crime, I'm using the skills I'm learning in prison, etc. etc. This is true; but it also struck me as being very similar to things I've heard from recovering addicts going through 12-step programs -- I'm an addict, I'm sorry for all the harm I caused through my addiction, I'm learning skills to help me overcome my addiction, etc. -- so my hunch is that it's there as a result of the anger management program he's going through in prison. reply kstrauser 14 hours agorootparentDefinitely, and I hope for his sake that's the actual explanation, and that it's sincere. That is, while we're talking about a specific person here, that person is someone I have zero connection with. I hope all the Hanses around the world are working on themselves with good intent. That's obviously untrue, but I can still wish it. reply bawolff 15 hours agorootparentprevWould there be anything he could say? reply mardifoufs 13 hours agorootparentHonestly? No not really. Not until he gets his parole I guess. The stakes are way too high for him to be honest. He might very well be, but the phrasing is just very \"list checking\" to me still. As someone else said, it's like the generic stuff you learn from therapy (at best, if we assume he's honest). reply ddtaylor 16 hours agorootparentprevHe was denied two years ago. reply jacquesm 16 hours agorootparentHe planned the murder of the mother of his kids, I'm pretty sure he can plan well in advance for a parole hearing. I wouldn't put anything past the likes of Hans Reiser or Peter Madsen. reply stickfigure 16 hours agorootparentWas there something I missed? I just reread his wikipedia page, and it seems to confirm the crime-of-passion narrative that I remember from 15 years ago. That said, I would not disagree with your character evaluation. reply jacquesm 15 hours agorootparentA crime of passion does not normally include studying up on body removal, ways to hide further evidence and not owning up to the crime for years because you - wrongly - believe that you can't be convicted if the body can't be found. This was premeditated murder, not a crime of passion. reply cachvico 15 hours agorootparentPremeditation means planning it beforehand. The books were purchased after the deed was done. A crime of passion can be covered up without making it premeditated. reply jacquesm 15 hours agorootparentI'm not going to split legal hairs here",
    "originSummary": [
      "Hans Reiser, the creator of ReiserFS V3 and Reiser4, apologizes for the delay in his response to a letter and proposes using OCR technologies to improve response times.",
      "Reiser requests advice on where to send the letter and information on Reiser5, as well as other file systems and compression methods.",
      "He introduces himself as being in prison for the murder of his wife in 2006, expresses remorse for his crime, and provides a detailed apology and history of ReiserFS V3 and V4, highlighting technical issues and stating that ReiserFS 4 is a more sustainable option."
    ],
    "commentSummary": [
      "The article discusses the downfall of Hans Reiser, the creator of the ReiserFS file system, who was convicted of premeditated murder and hiding his wife's body.",
      "It explores Reiser's behavior and the opinions of those who knew him, offering insight into his character and actions.",
      "The conversation delves into deeper topics such as personal redemption, the concept of evil, and the reliability of ReiserFS, offering readers a thought-provoking analysis of the case."
    ],
    "points": 364,
    "commentCount": 336,
    "retryCount": 0,
    "time": 1705590653
  },
  {
    "id": 39051246,
    "title": "Internet Pioneer Dave Mills Dies",
    "originLink": "https://elists.isoc.org/pipermail/internet-history/2024-January/009265.html",
    "originBody": "[ih] Dave Mills has passed away vinton cerf vgcerf at gmail.com Thu Jan 18 17:35:14 PST 2024 Previous message (by thread): [ih] Tell me about host names and 3com Next message (by thread): [ih] Dave Mills has passed away Messages sorted by: [ date ] [ thread ] [ subject ] [ author ] His daughter, Leigh, just sent me the news that Dave passed away peacefully on January 17, 2024. He was such an iconic element of the early Internet. Network Time Protocol, the Fuzzball routers of the early NSFNET, INARG taskforce lead, COMSAT Labs and University of Delaware and so much more. R.I.P. vint Previous message (by thread): [ih] Tell me about host names and 3com Next message (by thread): [ih] Dave Mills has passed away Messages sorted by: [ date ] [ thread ] [ subject ] [ author ] More information about the Internet-history mailing list",
    "commentLink": "https://news.ycombinator.com/item?id=39051246",
    "commentBody": "Dave Mills has died (isoc.org)302 points by todsacerdoti 6 hours agohidepastfavorite31 comments move-on-by 5 hours agoIâ€™ve recently gotten very into NTP with GPS and PPS as a fun personal project. Just a couple weeks ago I was reading about him on Wikipedia and I could relate to this quote (as no one else Iâ€™ve talked to about PPS has shown any interest): > he enjoyed working on synchronized time because no one else was working on it, giving him his own \"little fief\" Debian recently switched to NTPSec, and I was happy to see how familiar their website style was to the main NTP site. In the FAQ I found: > [Q] Why do these web pages look so 1990s > [A] Because that simple look is good for people with visual impairments, and as a tribute to Dr. David Mills, the original architect of NTP who is himself visually impaired. Dr. Mills has very particular ideas about Web visuals, and this site is carefully styled to resemble his NTP documentation pages. Iâ€™ve never had an opportunity to meet him, but he has certainly made a positive impact on my life. Rest in peace Dr. Mills. reply geerlingguy 5 hours agoparentSame here, getting into PTP, you end up studying a lot about timing on computers, and Dr. Mills is one of the main players in building up modern timing foundations! RIP, and thanks for all your contributions! reply icehawk 3 hours agorootparentHe really was. I remember encountering him on comp.protocols.time.ntp two decades ago and the breath of knowledge he had on computers keeping time was astounding, both at the time, and now that I look back at it. reply parker-3461 3 hours agoparentprevWhich NTP site are you referring to? Iâ€™m keen to check out some examples. reply liamwire 2 hours agorootparentntpsec.org reply jimmytucson 3 hours agoprevThe New Yorker published a piece on Network Time Protocol a little more than a year ago[0] - highly recommend it to anyone interested in how the internet works. RIP Dave, and thank you. [0] https://www.newyorker.com/tech/annals-of-technology/the-thor... reply jwilk 1 hour agoparentDiscussed on HN back then: https://news.ycombinator.com/item?id=33131195 (41 comments) reply abricq 28 minutes agoprevIf someone is interested, here is the Reference and Implementation Guide of the latest NTP version (2006, was revised in 2010), written by Dave Mills: https://www.eecis.udel.edu/~mills/database/reports/ntp4/ntp4... Quite well written, in my opinion. reply pjsg 5 hours agoprevThis is sad news. I worked (a little bit) with him when I added the adjtime system call to linux back in the 0.99 days.... He built stuff that worked and is run everywhere. That is a great legacy. He will be remembered. reply thrdbndndn 3 hours agoparentJust curious: what is 0.99 in this context? reply eimrine 3 hours agorootparentAlmost sure this is the linux kernel version. reply ugh123 1 hour agorootparentAccording to wikipedia, this is circa '92 era https://en.wikipedia.org/wiki/Linux_kernel_version_history reply phkamp 3 hours agoprevHe influenced my career as much as Dennis and Ken did. Our \"nanokernel\" paper brought NTP into the nanosecond domain and gave FreeBSD \"timecounters\". But our true shared passion was Loran-C Dave even invented the 16-pulse \"tactical Loran-C\" during the Vietnam War. I borrowed his ISA card Loran-C receiver (serial #1 & only) and later I built two generations of SDR receivers, and he was so proud when I showed him this dancing pulse received with a cheap ARM chip: https://phk.freebsd.dk/AducLoran/animation2.gif And boy was he pissed when USA shut down Loran-C, he really loved his \"loudenboomers\" RIP reply CarRamrod 12 minutes agoprevIf I could save time in a protocol The first thing that I'd like to do Is to save every day 'Til eternity passes away Just to spend them with you reply thinkerswell 5 hours agoprevHis talk on the early internet https://youtu.be/08jBmCvxkv4?feature=shared reply andrewl 6 hours agoprevMore about him: https://en.wikipedia.org/wiki/David_L._Mills reply m463 5 hours agoparentI just imagine all the ntp daemons becoming falsetickers for a moment reply fagnerbrack 1 hour agoprevSad day for the Internet, Rest in Peace David L. Mills , and that time keeps going on forever to you and your energy to be felt across time and space. I'm sure the artifacts of your work will never be forgotten. ---- On a sidenote Last year I had a chat with one of the members of the early Web and we understood there's a serious issue of knowledge transfer to future web devs generations. Few people reads books, and even if they do, the books written by technical people are not pedagogical enough as to allow the reader to capture the Tacit Knowledge and experience from the author as to be able to reproduce new ideas. We are LOSING fundamental knowledge of the internet for every mind who dies. If you think that mailing lists, web archives, books and blog posts are enough then you're being naive. At some point nobody will understand how the Web works. The curve where the Web is going is not pretty. This is extremely troubling to me and I'm trying on the sidelines to have some sort of way to run Tacit Knowledge extraction from those ppl. Known techniques are ACTA and CTA (Advanced Cognitive Task Analysis and Cognitive Task Analysis). If you have any other idea, please let me know. reply Animats 3 hours agoprevI hadn't heard from him in decades, but I knew him back when TCP/IP was starting up and his Fuzzballs were used as routers. John Nagle reply zoobab 42 minutes agoprevNo NTP means no crypto. Most of crypto cyphers nowadays relies on having both computers in sync clock wise. I learned it the hard way with openwrt routers disconnected from the internet. reply briHass 4 hours agoprevTook a class of his at University of Delaware around the turn of the century. He was a great professor that clearly had a love for the subject. NTP was much more complex and nerdy than some of the other trivial protocol RFCs, especially by v3 (https://www.rfc-editor.org/rfc/rfc1305), which was the first one I read. A legend; RIP reply pushedx 5 hours agoprevWe get the news from Vint Cerf himself. Thanks Dave, rest in peace. reply gala8y 1 hour agoparentGiants. Seriously, I get this vibe when looking at all these people, the early internet culture. Sometimes I feel as if I was there... or rather really wanted to be. reply ajdude 5 hours agoprevI had the opportunity to meet him at UD earlier last year, very bright man who was still actively working on many things. reply looopTools 4 hours agoprevThank you Dave! Rest in peace reply nixgeek 5 hours agoprevAnother black ribbon day for HN. RIP Dr Mills. The internet wouldnâ€™t be the same were it not for you. reply wyclif 3 hours agoparentOught to be a black ribbon for Dave Mills... reply rvz 1 hour agoparentprevThere should be one for Dave Mills. Another legend that deserves recognition for the foundations of the internet that hundreds of millions use today. RIP Dave Mills. reply shadowbanned4 4 hours agoprev [4 more] [flagged] Jtsummers 4 hours agoparentNo. It's been more like \"Pioneers of our industry are dying as they are now largely in their 70s, 80s, and 90s.\" If you don't know who they are, then either you're not part of the computer and software industry (fine), or you should take this as an opportunity to learn about the industry you're participating in rather than celebrating your own ignorance. reply tobinfekkes 4 hours agoparentprevIt is likely due to people who had their \"prime\" years overlap with early computing years. Add 30, 40, or 50 years, and you have people we've never heard of in their 80s and 90s that built the foundation we enjoy today. Or as they say, \"standing on the shoulders of giants\". reply packetslave 4 hours agoparentprev [â€“] Either spend 10 seconds on Google, or show some respect by being silent. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Dave Mills, a prominent figure in the early days of the Internet, has died peacefully.",
      "He made significant contributions to various aspects of Internet technology, including the Network Time Protocol, Fuzzball routers, the INARG taskforce, COMSAT Labs, and the University of Delaware."
    ],
    "commentSummary": [
      "Dave Mills, the original architect of Network Time Protocol (NTP), passed away, leaving behind a significant impact on the development of synchronized time in computer systems and the internet.",
      "His pioneering work on NTP established the groundwork for modern timing systems.",
      "The tech community mourns the loss of Mills and expresses gratitude for his invaluable contributions to the field."
    ],
    "points": 302,
    "commentCount": 31,
    "retryCount": 0,
    "time": 1705634878
  },
  {
    "id": 39043956,
    "title": "Unlocking Housing Construction: The Case for Single-Stair Multifamily Buildings",
    "originLink": "https://www.thesisdriven.com/p/the-case-for-single-stair-multifamily",
    "originBody": "Share this post The Case for Single-Stair Multifamily www.thesisdriven.com Copy link Facebook Email Note Other Discover more from Thesis Driven A deep dive into emerging real estate themes and the innovators capitalizing on them Over 6,000 subscribers Subscribe Continue reading Sign in The Case for Single-Stair Multifamily While many advocates have focused on zoning reform, one change could unlock even more new housing: legalizing single-stair multifamily. Brad Hargreaves and Stephen Smith Jan 18, 2024 17 Share this post The Case for Single-Stair Multifamily www.thesisdriven.com Copy link Facebook Email Note Other Share Barcelona, Europe's densest city, is thickly built out with single-stair apartment buildings on small lots. Picture via Oh Barcelona. Housing advocates celebrated a string of victories in 2023, including the legalization of missing middle housing and ADUs as well as permitting process reforms. But while most YIMBY attention has been focused on changes to zoning, building code reform may offer an even bigger opportunity to unlock housing construction. And bringing the US in line with its European and Asian peers by legalizing single-stair multifamily buildings is perhaps the most significant of those proposed reforms. Todayâ€™s Thesis Driven is a guest letter by Stephen Smith, the Executive Director of the Center for Building in North America. The Center for Building is perhaps the most interesting under-the-radar policy group in housing today, as they do the hard work of comparing the wonkiest bits of building code across jurisdictions, looking at safety as well as cost outcomes. The letter explores: The history and origins of current egress regulations; Regulatory impacts on design and affordability; How the USâ€™s international peers approach fire safety; Ongoing attempts to reform US code. Read on for more from Smith. One evening in 1860, a fire broke out in a basement bakery in a six-story tenement at 142 Elm Street, todayâ€™s Lafayette Street in Lower Manhattan. Fire and smoke spread up the building, home to at least 20 families, the fire fed in part by the buildingâ€™s only exit: a wood staircase. Firefighters were able to rescue people up to the fourth floor, but their ladders could not reach any higher. â€œAs the firemen stood on the ladders,â€ wrote the New York Times the next day, â€œthey could see many women and children lying prostrated on the floor, surrounded by the flames, which rendered all attempts to approach them ineffectual.â€ Thesis Driven is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber. Subscribe For an American city in the 19th century, the fire was actually quite small. By then New York City had already had three great fires since 1776, and Chicago would burn 11 years later. Even into the 20th century, American cities would still not be safe from great fires, with San Francisco burning in the aftermath of the 1906 earthquake. Across the Atlantic Ocean, great urban fires were largely a solved problem by the 19th century. After the Great Fire of London of 1666, Parliament did what European governments had been doing since at least Ancient Rome: they limited the use of wood in buildings. Without fuel from the structure of buildings themselves, fires still broke out in Europe, but their damage was limited, and great urban fires by the 19th century were mostly confined to smaller or poorer cities on the continentâ€™s edge that hadnâ€™t yet made the transition to brick, stone, metal, and concrete. 19th century Manhattan tenements, with a primitive second exit installed in the form of a fire escape. Photograph by Sean Litchfield. Not so in North America. The continentâ€™s thick woods, fast growth, and rural (and later suburban) character meant that the United States and Canada has to this day never fully moved away from wood-frame construction. Instead, just days after 142 Elm Street burned, the jury that convicted the building owner issued a call for â€œthe enactment of a law making it incumbent upon owners of tenement buildings to place iron stairways, or some other approved means of egress, on the outside of these structures.â€ Soon after the state legislature followed through on their request, and the requirement to provide a second means of egress in apartment buildings was born. Today, the flimsy fire escapes that satisfied officials in the 1860s have morphed into something much more. Two stairs are required for new apartment buildings above three stories by Americaâ€™s model International Building Code (whose claim to internationality comes largely from a handful of tiny island nations). They must sit on opposite ends of a building, and they must be fully enclosed. The standards are not unheard of in Europe and Asia, but they are typically only applied to true high-rises â€“ above around 20 stories in Singapore, or 25 stories in Italy (and even then, the required distance between the two stairs is not as large as in the US). As a legacy code requirement, there has never been much modern analysis of Americaâ€™s two-stair requirement and its impact on fire safety outcomes, but the United States in general does quite poorly on these measures. Almost every country in Western Europeâ€”where single-stair apartment buildings can rise many times the IBCâ€™s three-story height limitâ€”has fewer fire deaths per capita than the US. New York City, which allows single-stair buildings up to six stories (and has many apartment buildings where the second exit is a flimsy fire escape that does not meet modern code requirements), has slightly fewer deaths per capita than the rest of the US. Since the second exit code requirement was first introduced over 150 years ago, the field of fire safety has seen countless more sophisticated innovations, from passive measures like enclosed stairways and fire-resistance-rated materials, to more technologically advanced systems like smoke detectors and fire sprinklers. Despite the questionable effect on fire safety outcomes, North Americaâ€™s unusual second stair requirements have an outsized impact on the design of multifamily buildings. The rules make it almost impossible to efficiently recreate the traditional design of apartment buildings, termed â€œpoint access blocksâ€ by Seattle architect Michael Eliasonâ€”a few units around a single stair, with maybe an elevator. The common hallway that must connect the two stairs in a modern American code-compliant building cuts the structure in two, cutting off the possibility of floor-through apartments found in traditional American multifamily architecture like the New York City tenement or the Los Angeles dingbat. The typical American 5-over-1 fulfills the building code requirement for two exits, but requires a large lot and does not typically provide many units larger than a one-bedroom. Photo from ArchPlan Inc. Small plots of land, like the 25- to 75-foot wide lots that most American cities and inner suburbs have been carved up into, have become less feasible to develop. On a 25-foot-wide lot in Jersey City, NJâ€”just across the Hudson River from Manhattanâ€”the second stair consumes 7 percent of the total floor area, with a few additional percentage points shifted from rentable square footage to un-rentable common area. It ends up all but eliminating windows in two bedrooms, giving them access to just a minuscule air shaft. A developer might be able to stomach it in Jersey City, but in more ordinary markets, without the housing shortage of the New York area, such lots would be rendered unbuildable above three stories. Floor plan of a new building in Jersey City, NJ. Drawing by Alfred Twu. The double-loaded corridor that meets modern American building code requirements can provide studio and one-bedroom apartments just fine, since these have a low ratio of living and bedroom space (which must, at least traditionally, have access to natural light and fresh air) to kitchen and bathroom space (which can be placed up against the dark common corridors). But when architects try to design apartments with two or more bedrooms, the apartments balloon in size, since every 10-foot-wide bedroom ends up coming with 30 or more feet in unit depth. Try to add a single 120-square foot bedroom and youâ€™ll end up having to add another 180 square feet on top that you need to fill some other wayâ€”probably with walk-in closets and en-suite bathrooms, adding the expense of more plumbing, fixtures, and tiles. Each square foot of space costs just as much to build whether it has access to light or not, so the rent that developers must achieve for these two-, three-, orâ€”god forbidâ€”four-bedroom apartments balloons far beyond the ability or willingness of families to pay. And if renters or condo buyers donâ€™t like it, they can just drive till they qualify for a single-family house in the suburbs. Without the requirement for a second stair, buildings can be laid out in a fundamentally more efficient way. With less vertical circulation, the circulation core can simply be repeated a few different times, with apartments of different sizes arrayed off of each core, potentially stretching from the front of the building to the back. If planners redraw zoning envelopes to accommodate thinner buildings, more bedrooms can be packed in less square footage, offering more affordable and competitive family-sized designs. With units that appeal more to families (in New York City, condo buildings average 1,189 gross sq. ft., compared to 838 sq. ft. for rentals) and reform of defect liability laws that drive insurance costs up for condo developers, America might even be able to bring its condo construction numbers up from historic lows. Typical European floor plan. Drawing by Michael Eliason, Larch Lab. The YIMBY movement and other housing reformers have made progress over the last decade or more in loosening zoning codes, but building codes in America are still largely a one-way ratchet, getting tighter and tighter with every fire, with no relief due to new technologies, provisions, and understanding of fire engineering. The model code writers are responsive to materials manufacturers and the fire service, but multifamily developers and housing affordability advocates do not exert much authority. Sometimes the manufacturers who donate to the International Code Council and can afford to pursue code changes make positive contributions (for example, the American Wood Councilâ€™s advocacy for mass timber), but more often their interests have a questionable relationship to the public good. States and localities have the power to adopt, reject, and amend model codes like the IBC, but lack the capacity to do much informed analysis and research. The better-resourced federal government used to play a larger role in code development, but has mostly retreated in recent decades. Recognizing that building codes are the next frontier in housing reform, I founded the Center for Building in North America around a year ago, to do research on and advocate for changes to building codes that could bring down the cost of production of multifamily housing, and improve efficiency and quality. The opportunities for reform are as deep as a modern building is complex â€“ from more modern refrigerants that would allow Americans to buy heat pumps on the global market to more efficient single-stack venting in plumbing systems that could cut plumbing costs dramatically â€“ but we decided to focus on stairs as our first issue, given the importance to building design and the existing movement among architects for reform. Weâ€™ve worked with housing advocates in states across the US to advance legislation and administrative changes to building codes to allow single-stair buildings up to six stories, above the current three-story limit in most of America, drawing on language already adopted in Seattle, Honolulu, and New York City, and extensive experience abroad. While the current single-stair limits were arrived at through trial-and-error and fairly rudimentary logic, status quo bias means that proposed reforms will be held to a much higher standard. To change such a fundamental tenet of American building codes, though, will require more advanced analysis. Fire protection engineering and data collection has advanced greatly in the century and a half since the second means of egress emerged in 1860, and today there are more engineered and big data approaches to proving safety. Since the benefits are diffuse and multifamily development interests in America are poorly organized on a national level, there is not much of a natural constituency for this sort of work. One of my goals when founding the Center for Building in North America in 2022 was to produce research and organize urbanists, architects, real estate developers, and others to advocate for more rational building codes in the United States and Canada. â€”Stephen Smith For anyone who is interested in diving deeper into these topics, Iâ€™d encourage you to reach out to Stephen at stephen@centerforbuilding.org. Heâ€™s one of the most knowledgable people I know when it comes to global building codes and policy reform, and he has been a great resource to Thesis Driven in the past. Beyond that, his work at the Center for Building requires funding, and heâ€™s raising $150,000 to produce data to prove the safety of taller single-stair buildings and push this code change past the finish line. If any Thesis Driven subscribers are interested in supporting this work, you can donate small sums on their Donorbox site or email Stephen at the email above to discuss a larger donation. â€”Brad Hargreaves Thesis Driven is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber. Subscribe 17 Share this post The Case for Single-Stair Multifamily www.thesisdriven.com Copy link Facebook Email Note Other Share A guest post by Stephen Smith",
    "commentLink": "https://news.ycombinator.com/item?id=39043956",
    "commentBody": "The case for single-stair multifamily (thesisdriven.com)282 points by jbrins1 17 hours agohidepastfavorite450 comments adameasterling 15 hours agoThis is a fantastic article. Burdensome regulations on housing construction have caused costs to skyrocket. Minimum lot sizes, setback requirements, square footage minimums, floor-area ratio restrictions, overzealous height restrictions, parking requirements, abuse of environmental reviews, historic designations, community reviews, overzealous MFH requirements (like double-stair), below-market mandates, all have worked together to constrain supply, leading to skyrocketing costs. It's the single most important economic issue for me. We need a nationwide effort to ease these restrictions, or we're just going to continue to see rents eat up more and more of young people's earnings. reply gamepsys 10 hours agoparentJust curious, are there any regulations on housing you agree with? There tends to be belief that housing regulations exist to limit supply. Let's not forget that many of these encourage safety and are cost effective ways to increase the quality of life of the residents. If we take deregulation and cheap housing to the extreme we end up with shanty towns. reply mperham 10 hours agorootparentNone of the things he mentioned have anything to do with safety. reply gamepsys 10 hours agorootparentEnvironmental review, community review, and MFH standards all have something to do with safety. It's not like root comment is arguing against fire hydrants or carbon monoxide detectors. I'm just arguing not to throw the baby out with the bathwater. reply mperham 10 hours agorootparentWe have zoning and internationally recognized building safety codes already. Our current housing emergency happening everywhere is a pretty good indicator that we should be much more aggressive about trimming back the regulatory state which has ossified our cities. reply eru 9 hours agorootparentZoning is already pretty bad (at least in the US), and doesn't really have anything to do with safety. In the sense that even without zoning laws, there were already public nuisance laws that wouldn't have allowed you to open a coal fired power plant next to a Kindergarten. reply gamepsys 6 hours agorootparentZoning laws have a lot to do with safety & public health. Industrial zoning is far away from residential because factories produce pollution. Edit: Some parts of zoning law has to do with safety/health. Some parts don't. Some parts are about more than one thing. When I was growing up there was a chemical fire in a factory in town. People were evacuated. Luckily, very few homes were evacuated because zoning laws kept homes far away from the factory. The residential area that was evacuated was low density. The point I'm trying to make is that there is some value in some of these rules. reply epistasis 6 hours agorootparentPollution laws protect against industrial operations polluting other areas, not zoning. The real \"pollution\" they zoning was invented to solve was the \"pollution\" of residents of apartments living close to wealthier people. Seriously! Check out how the original Supreme Court decision phrased its motivation: > â€œvery often the apartment house is a mere parasite, constructed to take advantage of the open spaces and attractive surroundings created by the residential character of the district â€¦. interfering by their height and bulk with the free circulation of air and monopolizing the rays of the sun which otherwise would fall upon the smaller homes.â€ Here's a more extensive analysis from an org purporting to represent real estate, the source of much historical support for this sort of exclusionary zoning: https://cre.org/real-estate-issues/americas-sordid-history-o... reply eru 4 hours agorootparentprevYes, there's some value in some of these rules. However by and large, the value that would be provided by zoning is already provided (and used to be provided) by other rules not falling under the bucket of 'zoning'. Especially not 'Euclidean zoning'. reply lukas099 6 hours agorootparentprevOkay, what is the safety reason my barber canâ€™t operate out of a room in his house? reply richiebful1 6 hours agorootparentNo reason. Countries like Japan have reasonable zoning, meaning industrial uses are separate, but commercial and residential is largely interspersed. Which is great! reply shiroiuma 4 hours agorootparentprevThat's easy: your barber operating a business out of his house will result in customers coming to your neighborhood, and that might bring \"those people\" around, and we can't have that. reply seanmcdirmid 8 hours agorootparentprev> Our current housing emergency happening everywhere is a pretty good indicator that we should be much more aggressive about trimming back the regulatory state which has ossified our cities. That isn't true though. Our housing emergency is limited to places that are growing and thriving. There isn't a housing emergency in Detroit or much of the midwest for example, just not many are thrilled about moving to those places (or want to leave them as soon as possible). reply astrange 8 hours agorootparentThose places that don't have housing emergencies generally have just as bad regulations, and would have the same problems the instant they became appealing enough to move there. Eventually you run out of built out sprawl. reply seanmcdirmid 8 hours agorootparent> hose places that don't have housing emergencies generally have just as bad regulations, and would have the same problems the instant they became appealing enough to move there. If American population was equalized across these other cities, there would be less pressure on the few hot places everyone wants to move now, since our population isn't growing so much these days. > Eventually you run out of built out sprawl. Manhattan is not a sprawl and a very desirable place to live, with super high rents to boot. Hong Kong, Seoul, Shanghai, and even Tokyo are the same, so I'm not sure what you are trying to claim here. Out of all those, only Tokyo does well, but that wasn't the case in the 80s and is on the basis of a moribund economy and a not growing national population (one wonders when Seoul and SH will follow). IF you want to solve your housing emergency, limit growth in some way (or at least, make sure residents don't have as much money to bid up housing). reply astrange 2 hours agorootparent> Out of all those, only Tokyo does well, but that wasn't the case in the 80s and is on the basis of a moribund economy and a not growing national population (one wonders when Seoul and SH will follow). Japan's economy is growing again (Nikkei is now at the level it was in 1990) and Tokyo's population has always been growing. â€¦but the rent isn't, because they allow infill development. reply shiroiuma 4 hours agorootparentprev>Manhattan is not a sprawl and a very desirable place to live, with super high rents to boot. Hong Kong, Seoul, Shanghai, and even Tokyo are the same, so I'm not sure what you are trying to claim here. Those cities are actually impossible to have in America (yes, including Manhattan), because of zoning laws and various other laws. Manhattan is only allowed to exist because it's grandfathered in and the local laws allow it. Such a city could never be built anywhere else in the US without some huge changes in legislation (not to mention local culture, since that drives the local legislation). >IF you want to solve your housing emergency, limit growth in some way Tokyo works because growth isn't limited: it's very easy to build here, unlike in the US. Tokyo builds hundreds of thousands of new housing units every single year, while the US struggles to build any. This is entirely because of regulations. reply astrange 2 hours agorootparentFun fact: the US and Italy have about the same number of elevators, because it costs us about ten times more to build one. reply scythe 9 hours agorootparentprev>internationally recognized building safety codes I mean, the \"International Building Code\" is a little bit like the \"World Series\" https://en.wikipedia.org/wiki/International_Building_Code >\"Calling it 'international' keeps it from being called the 'U.S. Building Code.'\" explains Bill Tangye, SBCCI Chief Executive Officer. reply greenthrow 9 hours agorootparentprevYour argument doesn't really make sense because the problem isn't lack of houses or apartments, there's plenty of places to put everyone. The problem is one of affordability. The costs of stuff that already exists and has existed for ages isn't really tied to the current cost to build, even if we buy the specious argument that all regulation raises costs and those costs are inevitably passed directly to tenants. reply bluGill 9 hours agorootparentsupply and eemand sets rents. You you rent perfecly good existing houses cheap in rural areas. Nobody wants to like there. There is no reason to think there is enourh room for everyone who wants to like in San Francisco, and statistics prove they heve not been building much. Mean while in other states we find areas of demand where housing is not expensive. Where I live you can rent one bedroom apartments for under $1000, mohe in won't be until spring as the building is still under construction. The owners are planning on starting the next building when this is done. That is what allosing building does. reply greenthrow 6 hours agorootparentThis is just factually not true. There is plenty of empty homes, apartments and condos to house everyone. There are many units kept empty rather than lower prices. It is a myth that supply and demand sets prices. reply Schiendelman 5 hours agorootparentThis comment makes me really sad; it's someone who wants to help but ends up hurting. reply wiml 9 hours agorootparentprevSupply, demand, and cartels like Realpage. reply eru 9 hours agorootparentCartel's can't just magically set prices. They can withhold supply, and that might have an effect on market prices. reply astrange 8 hours agorootparentYou can't pay the mortgage on a place you're not renting out though, so they mostly can't withhold supply. It applies more to things like retired people living by themselves in a 3 bedroom house. reply eru 8 hours agorootparentOK. Though if they can't withhold supply, how are those cartels supposed to hold up prices, then? reply astrange 2 hours agorootparentThey don't, it's not real. (Except that they can prevent construction of new units through zoning.) reply astrange 8 hours agorootparentprevReal estate has very distributed ownership and none of them are motivated to form a cartel. The only way they can maintain one is through legal force. Zoning laws are almost entirely that force; they're a way to establish a cartel of homeowners. reply loeg 10 hours agorootparentprevSetbacks, parking minimums and floor area ratios have nothing to do with safety. Community reviews have absolutely nothing to do with safety. reply sokoloff 9 hours agorootparentSide setbacks absolutely have an effect on fire safety (a greater distance gives less propensity to ignite the neighboring building and provides access with which to fight the original structure fire). Front setbacks and lot area coverage ratios have a more minor version of this same effect from fires across the street. It takes a pretty good sized fire to ignite the building across a street, but as density increases and more of a lot's area is able to covered with structures, the chances to get a pretty good sized fire going do increase. reply ajmurmann 7 hours agorootparent> Side setbacks absolutely have an effect on fire safety Sure, but is the benefit worth the cost? Manhattan and denser European cities without those haven't burned down since we fireproofed building materials reply Schiendelman 5 hours agorootparentprevAnd yet other areas let buildings be physically against each other if they're built not to spread fire. Just let everyone do that. reply seanmcdirmid 8 hours agorootparentprevYa. My setback is 3 feet, definitely just a margin for fire safety. I wanted to put an awning in but couldn't because it would be too close to the fence of my property boundary (I live in a town home that abuses the 3 foot setback to maximize living space). reply fires10 8 hours agorootparentI have minimum lot size of 5 acres. Can't see the wisdom in that one. I also have a minimum square footage size. $20,000 impact fee just to build a house and I receive no utilities or city/ county services. reply Spivak 7 hours agorootparentI wish more than anything we could legislate the fee structures backwards. If the government wants an environmental impact study then the government is footing the bill for it. Putting it on the builder is stupid and just a way of hiding the budget item in other people's wallets. reply seanmcdirmid 4 hours agorootparentOk, the government will fund your environmental impact study so you can build, but...oh...given their budget they will have it done sometime in 2100. reply gamepsys 10 hours agorootparentprev> Community review Any feedback brought up in a community review is on official record. I have witnessed safety concerns being brought up in community review multiple times that caused changes to the building plan. In one situation it was a very serious concern about blocking fire truck access to an elementary school. reply bluGill 9 hours agorootparentwhy didn't the code catch that? reply gamepsys 9 hours agorootparentThe code doesn't catch anything. People catch violations of the code. Community review is a place people can point out code violations. It's actually extremely embarrassing when this happens to a developer. Buildings get built with infractions all the time. With the MFH buildings it's actually a point of law to see who gets stuck with the liability -- the person that built it or the person that bought it. reply jjulius 10 hours agorootparentprevCareful with those absolutes. reply xvedejas 3 hours agorootparentprevFrom what I've seen of environmental review laws, they mostly just have to do with noise and construction nuisance. Whereas community review is mostly about aesthetics. I don't think these are the tools designed for safety. reply adaml_623 9 hours agorootparentprevDouble stair Vs single stair is totally a safety issue reply alistairSH 9 hours agorootparentOne that much of Europe has mitigated somehow. reply quickthrower2 8 hours agorootparentIt is all about the scenario where you die in a single stair where the second stair would have saved you being probably non existent in c21. Especially as you will have fire doors. I reckon single is safer: no decision to make as you exit. reply seanmcdirmid 8 hours agorootparentprevBy building their buildings out of brick rather than wood. Though its probably overkill here in the states and canada. reply ksplicer 7 hours agorootparentEven our wood has so much fire safety chemicals baked in now that it's not nearly as flammable as it used to be. The safety standards should be reevaluated. Plus, I'm sure that there are some developers who would happily build the whole MFH out of concrete if it lets them only use a single stair. reply seanmcdirmid 4 hours agorootparentConcrete construction is expensive in the states, although I'm not sure why. 4+1s are common here in Seattle: first story is concrete and commercial, 4 stories on top of that are wooden (we also have the more liberal stair requirements, so I'm not sure what is really going on). Concrete construction is the common way to build in China (and anywhere in Asia sans Japan), but the techniques they use require a bit of overbuilding and limit their towers to around 34 or so stories. Still, they have two stair cases side by side in those buildings (but I guess given the height, they need them by Chinese fire code standards). reply shiroiuma 3 hours agorootparent>Concrete construction is the common way to build in China (and anywhere in Asia sans Japan) Concrete-reinforced steel is absolutely common here in Japan. Wood is used for single-family homes, though, but anything larger is generally concrete+steel. >but the techniques they use require a bit of overbuilding and limit their towers to around 34 or so stories. Modern condo towers around me here in Tokyo are frequently 50 stories AFAICT. And that's with extremely strict building codes for earthquake protection. I can't tell you about the stairs though, as I don't live in one. reply eru 9 hours agorootparentprevYou already have shanty towns with all the regulation. Making housing cheaper also means making higher quality housing cheaper. reply seanmcdirmid 8 hours agorootparentWe don't really have shanty towns in the states. We definitely don't have a Kowloon Walled City, which is an example of what can happen when no regulations are involved (and somewhat remarkably not burn down and kind of thrive even if still a slum). https://en.wikipedia.org/wiki/Kowloon_Walled_City reply eru 8 hours agorootparent> We don't really have shanty towns in the states. https://en.wikipedia.org/wiki/List_of_tent_cities_in_the_Uni... reply seanmcdirmid 5 hours agorootparentTent cities != shanty towns. Shanty towns are like semi-permanent buildings, tents are just...tents you buy at REI and then set up at the park with your stuff. We had one nearby my house at the Seattle Ballard commons that lasted during COVID (and is gone now). I wouldn't have called it a shanty town like I saw in the Philippines. reply sroussey 3 hours agorootparentGo to skid row in LA. Going on 50 years or more. reply kspacewalk2 7 hours agorootparentprevIf only we can have something between a McMansion filled North American suburb and Kowloon Walled City. reply seanmcdirmid 4 hours agorootparentHong Kong is super dense and super expensive, Shanghai is similar, but at Mainland Chinese prices. I'm all for density, but anyone who thinks that density alone solves affordability issues simply hasn't travel enough. reply eru 4 hours agorootparentDensity is a way to deal with expensive housing. Not a cause of it. reply ajmurmann 7 hours agorootparentprevMaybe it's OK if some housing is less perfect and closer to ashanty town. I'd rather live in a shanty town than a cardboard box under the freeway. If nobody wants to live in the \"shanty town\" nobody will move in and no investor will want to build another one. I sometimes think that the provocative way of putting all this is that we need more slum lords. They filled a need. reply hackerlight 4 hours agorootparentprevPhysical safety (structural integrity and fire safety), noise transmission and ventilation. I think regulations around these 3 aspects can help more than they hurt. Beyond these items, I would be skeptical. reply anon291 9 hours agorootparentprev> If we take deregulation and cheap housing to the extreme we end up with shanty towns. That's possible, but, considering that all the most expensive places in this country were developed in the very way this article is advocating, I'm going to label it as improbable. Many amongst my friends and family think I'm a bit crazy living in the inner city, but the truth is my equity has skyrocketed, and will continue to do so. Urban dwellings are in high demand. Given that many of these same urban dwellings are illegal to construct now / prohibitively expensive, we've handicapped the ability of the market to meet demand. reply gamepsys 9 hours agorootparentI use to look at buying a 60+ year old condo/coop on the west coast, until I looked at the earthquake statistics and safety standards of brick multistory buildings. Now I know why the newer steel buildings cost 2-6x the old brick buildings in the same neighborhood. reply Aeolun 8 hours agorootparentIâ€™m doubtful they actually cost more to construct? reply twiddling 14 hours agoparentprevDon't forget about street widths being determined by the ability to turn around fire equipment. reply bombcar 12 hours agorootparentIf it makes you feel any better the oldest streets around here are wider than newer ones, because they had to be able to turn a wagon with a team of horses. reply seanmcdirmid 8 hours agorootparentThat sounds like what they did in Salt Lake City. reply elliotto 10 hours agorootparentprevHaving streets unable to be accessible by fire response vehicles doesn't seem like a good idea. What would be the alternative here? (genuine question, I'm not from the US) reply akavi 10 hours agorootparentSmaller fire trucks. reply mortenjorck 9 hours agorootparentIndeed, this is a thoroughly solved problem thanks to countries like Japan where urban planning typically allows meandering networks of narrow, pedestrian-friendly streets. This article has some nice points of comparison between typical American firetrucks and a Japanese firetruck: https://www.sfchronicle.com/local/article/Meet-Kiri-the-tiny... reply Paul-Craft 10 hours agorootparentprevHow do you plan to make the fires smaller as well? reply andy81 9 hours agorootparentUse two trucks when needed? This is a really simple fix that the rest of the world does better. reply beejiu 10 hours agorootparentprevCopy paste from Europe, where they are about half the size? reply neuronexmachina 10 hours agorootparentSome possible reasons for why American fire trucks tend to be larger: * more frequently sent to rural homes, where there might not be an available hydrant, so they need to transport all the water they're likely to need * same for wildfires * American homes more likely to be wood+drywall reply akavi 9 hours agorootparentI would simply have small firetrucks in urban areas, and large fire trucks in rural areas. reply sokoloff 9 hours agorootparentprevWhy \"wood+drywall\" rather than just \"wood\"? Drywall is non-combustible and used as the main component in many fire-rated wall assemblies. reply kspacewalk2 7 hours agorootparentprevEurope has wildfires and rural areas. How will a large fire truck help you when a wood house is burning? Being grotesquely large doesn't mean they put the fire out faster. reply aga98mtl 9 hours agorootparentprevAnd yet, European cities exist and are fine without wide streets. reply eru 9 hours agorootparentKeep in mind that Europeans tend to build with stone / bricks, and Americans tend to build with wood. Lots of safety regulations stem from that divide. Wood is a bit more flammable. (I'm not saying the difference in safety regulations still make sense today. I'm talking about one of the historical origins of the divide.) reply jenadine 3 hours agorootparentIn the north of Europe it is mostly wood reply eru 3 hours agorootparentHouses are still less likely to be build from wood than in the US. reply actionfromafar 10 hours agorootparentprevHm.. couldn't a fire engine be driven in reverse? It could have an emergency driver's wheel in the back. I have seen crane trucks driven with a joystick from outside the vehicle, so it doesn't seem impossible. reply alistairSH 9 hours agorootparentOr it could just be smaller like in the rest of the world. reply keenmaster 10 hours agorootparentprevWe can make them turn 360 degrees like the electric G-Wagon. If upgrading the fleet of firefighting trucks to do so costs less than the value brought by tighter spacing of homes, itâ€™s worth it. reply eru 8 hours agorootparentWell, you can learn from other parts of the world, instead of coming up with solutions from scratch. (But yes, if nothing else your solution would probably work.) If you time your upgrade to the fire engines with when you naturally would want to renew them anyway, then it doesn't really cost much extra. reply m463 5 hours agorootparentprevlooks like building heights haven't been held back... reply hammock 7 hours agoparentprevHow is double stair MFH overzealous? I canâ€™t control if my neighbor blocks the stairwell with a couch that gets stuck while heâ€™s moving in and now I have no egress if my other neighbor starts a fire. Iâ€™m in favor of greater freedoms, and the freedom to choose a single stair MFH if I want. But I donâ€™t want. reply kspacewalk2 7 hours agorootparentA couch and a fire and that couch can't be pushed over or jumped over... That's quite a contrived scenario. I suspect that most of the improvements in the fire safety record of apartment buildings have to do with other factors like materials used, fireproof stair doors, etc etc. The reason I think the two stairs don't do much is that first world countries exist outside North America, they don't have this rule, and their fire safety is just as good or better than ours. Same reason I'm extremely skeptical that our fire trucks need to be so grotesquely large, despite what the fire departments claim. If there were no countries with a good fire safety record outside North America, like sure, okay, maybe. But they're just as good or better at fighting fires in Europe, and manage to go this with human sized trucks that don't require extremely wide streets, wide turn radiuses, and aren't nearly as deadly for pedestrians as a result. Thanks for existing, Europe, Japan, South Korea, Taiwan etc! One day we'll accept that you to cities, building and engineering better and just copy you. reply u801e 7 hours agorootparent> A couch and a fire and that couch can't be pushed over or jumped over. Not everyone is young and in shape to push couches or jump over them. reply lukas099 6 hours agorootparentSo even more contrived reply hammock 6 hours agorootparentprev>A couch and a fire and that couch can't be pushed over or jumped over... That's quite a contrived scenario. I suspect that most of the improvements in the fire safety record of apartment buildings have to do with other factors like materials used, fireproof stair doors, etc etc. I suppose you also think itâ€™s silly for flight crew to confirm people sitting in the exit row are able and willing to help in an emergency. Couldnâ€™t you just push them out of the way or jump over them? reply nkrisc 6 hours agorootparentprev> A couch and a fire and that couch can't be pushed over or jumped over... Youâ€™re 85. reply porkbeer 4 hours agorootparentOr maybe they have small children. Wtf man. reply kdmccormick 7 hours agorootparentprev> I canâ€™t control if my neighbor blocks the stairwell with a couch that gets stuck while heâ€™s moving in and now I have no egress if my other neighbor starts a fire. That is an extremely specific situation! > How is double stair MFH overzealous? There is a cost to every regulation. The cost to this one is that housing is more expensive for all Americans. Stress, poverty, and homelessness all lead to negative health outcomes. Taken as a whole, those negative outcomes may very well outweigh the fire safety benefits of double-stair (which have never been proven to exist). > Iâ€™m in favor of greater freedoms, and the freedom to choose a single stair MFH if I want. > But I donâ€™t want. Right, so it sounds like you are in favor of removing the double-stair regulation? reply hammock 6 hours agorootparent>That is an extremely specific situation! Itâ€™s an example. Can you generalize it or should I? reply kelseyfrog 6 hours agorootparentHere's a hypothetical for a two-stairwell building: two couches. We can avoid this dangerous scenario with a three-stairwell minimum requirement. reply hammock 6 hours agorootparentGood point. Why do we even bother with two-lane roads and a double yellow line? Such a waste of space. Very contrived to presume there is always a car coming the other way reply kdmccormick 4 hours agorootparentYou're comparing a situation that happens all the time (opposing traffic) with one that happens extremely rarely (blocked stairwell in a fire). If anything, you're strengthening my point. We should design for situations to a level that is appopriate given their frequency and severity. Show me evidence that MANDATING the extra stairwell justifies the huge increase in national housing cost, and I'll concede. reply kelseyfrog 6 hours agorootparentprevSorry, but the only thing that will change my mind is a significantly casualty different between single stairwell and dual-stairwell buildings accounting for building age, construction type, property value, and occupant demographics. Happy to hear evidence-based arguments. reply sunshowers 6 hours agorootparentprevThe US would certainly be a nicer place to live if there were more roads with just one lane, like many older cities and suburbs already have. reply matsemann 2 hours agorootparentprevWhy would you need two lanes in each direction, except perhaps on a highway..? I agree, such a waste of space. reply TaylorAlexander 6 hours agorootparentprev> How is double stair MFH overzealous? I suggest reading the article, which is intended to answer this question in depth. It provides concrete examples! reply hammock 6 hours agorootparentAs a safety measure, it doesnâ€™t, unless I missed something. In fact it says there has been barely any analysis reply cheriot 2 hours agorootparentprevWe should require two stairs for single family housing as well. The elderly and disabled will also need to get furniture up stairs. Not to mention that the housing shortage forces more people to share a house with strangers. reply Klaster_1 5 hours agorootparentprevCheck out this video, which argues against double stair MFH - https://www.youtube.com/watch?v=iRdwXQb7CfM. reply amarshall 6 hours agorootparentprevThe couch goes in the elevator, not the stairwell. reply wolverine876 3 hours agoparentprev> Burdensome regulations on housing construction have caused costs to skyrocket. How much have costs increased, and what tells us that it's regulations, not many other causes? Also, which regulations? Some are more valuable, some less, and inevitably some will misfire. I'm not just going to trust real estate developers, who have their own interests, to meet other needs. > below-market mandates I'm not sure we need more high-end development - those tenants have plenty of options. > community reviews In cities, new buildings can impact a community for a century. They should have a say, not just a developer from another city. reply cheriot 2 hours agorootparent> Also, which regulations? The entire article is on the prohibition of single stair multi-family residential. > I'm not sure we need more high-end development - those tenants have plenty of options. This is silly. When car makers couldn't make enough cars in 2021 and the price went up, was the solution to ban making new cars? Should we have prohibited making cars with fancy trim? Having enough housing for everyone is the only way to make sure affordable housing exists. reply jojobas 7 hours agoparentprevYet people keep flocking to them dreadful single-family-home-majority cities, happy to pay rent and all. reply ksplicer 7 hours agorootparentI don't know anyone starting a family happy with the situation. Most people I know are moving to suburbs only because they can't get 3 bedroom apartments in cities. If MFH's became broadly available I think many new families would flock there. reply jojobas 6 hours agorootparentEveryone I spoke to who has lived with kids in both flats and houses on 600sqm blocks prefers the latter, commute (which commute?) be damned. reply slyall 6 hours agorootparentI'll guess this is people who can afford a big stand-alone house in a nice area reply porkbeer 4 hours agorootparentOr Those who want to know their kids are safe and have a place to play. reply slyall 56 minutes agorootparentNot much use wanting to have a stand-alone place if you can't afford it. reply gabesullice 2 hours agoprevI can speak to and endorse this kind of unit from personal experience. I was born, raised and lived most of my life in Denver, CO. Now, I live in France in a 'single-stair multifamily'. Growing up I mostly lived in single family homes, but in college my dad moved into a townhouse and I lived with him for a couple years. Before moving to France, my wife and I lived in single family homes and a '5-over-1' apartment. Now, we live on the 7th floor, end-unit of an apartment building. It's a 'single-stair multifamily,' 'floor-through' apartment (thankfully with an elevator). Meaning our apartment a large balcony one one side and windows on three sides. The only side without a window leads to the stairwell. Every room has a window, even the bathroom and toilet (often separated in France). Without a doubt, this place is one of the best types of housing I've ever occupied. In the summer we can open up windows on either side of the apartment and get a fantastic breeze. The concrete structure does a great job regulating the temperature for most of the year. We get sunlight in the morning and evening. I hate yardwork and there's none to do. No sidewalks to shovel snow from either. I also experience neighborliness on par with most single family homes. Very similar to my dad's townhouse actually (probably not by coincidence if you think about the incentive structures). We have a 5 year old son and we don't miss having a yard. There are parks nearby with playgrounds and paths where he can safely ride his bike without worrying about any cars. Admittedly, I do miss having barbecues in the backyard. I also miss having a garage to use as a workshop. The 5-over-1, on the other hand, was easily the worst type of housing I've occupied. Poor lighting, anonymous, ugly corridors. No sense of neighborliness. Poorly maintained and constructed. Nowhere near a good park without walking along a nasty arterial surface street. I frequently ask myself, 'why can't we have this in the States?!' and now I know why. Building codes, zoning and city planners strike again. reply SkeuomorphicBee 15 hours agoprevLooking from the outside I would guess this is one of the big reasons for the \"missing middle\" [1] (lack of medium-density housing) in most North American cities. It is simply not economically feasible to build a small to medium size multi-unit building if you need to include two stairwells, so all buildings are either single family houses or huge mega projects. In my country the simple and cheap four-story walk-up condo building (with a single stair and no elevator) is the bread and butter medium density housing for the working class. You either have two or four units per floor, all opening to the stairwell with almost no space lost in corridors, it is simple and efficient. Alternatively for higher density there are higher versions with typically up to 12 floors with one or two elevators but still only one stairwell, so keeping the same efficiency. [1] https://en.wikipedia.org/wiki/Missing_middle_housing reply ajmurmann 7 hours agoparentThe two stairways result in double-loaded hallways which also negatively impact unit sizes and make it impossible to have windows on more than one wall in most rooms. It's a total disaster reply true_religion 7 hours agorootparentThe fire escape can count as a separate staircase too and it can go over windows. reply Spivak 5 hours agorootparentIt's crazy to me that people are arguing against two stair houses when I have a ladder in my single family home in case of a fire that blocks the stairs. Fire in the only stairwell or a collapse, guess you just die or hope the fire department saves you before you suffocate. reply ido 3 hours agorootparentIf only there was an article addressing exactly your concern! reply sroussey 3 hours agoparentprevNo elevator would be a no-no here. What if you were in a wheelchair? reply amrocha 2 hours agorootparentThen find a place with an elevator. Not every home needs to be for everyone reply quickthrowman 15 hours agoparentprevThe reason five over ones are popular in the US has nothing to do with staircase requirements. The reason is money, like always. You can stick build residential buildings up to five stories and itâ€™s way, way cheaper than reinforced concrete and steel. They are mega complexes because the financial stakeholders want to maximize the available land and rents. reply ketzo 10 hours agorootparentâ€œmaximize the available landâ€ Part of the authorâ€™s point is that single-stair buildings can be built economically on much smaller pieces of land. This increases the number of plots â€” especially in urban environments â€” on which you can build MFH, plots which developers today wouldnâ€™t even think of. Legalizing single-stair buildings would not really change the viability of big apartment complexes, youâ€™re right. But it would allow for smaller ones. reply Pxtl 10 hours agorootparentYes. Especially since a big problem for Western cities is not \"how do I build new megalopoli\" but \"how do I fill in density without acquiring a whole city block of houses in one go\". For a single-stair walk-up you don't need a massive amount of property, you can plonk a pretty danged nice mid-rise building on the same acreage as one large detached house. reply ajmurmann 7 hours agorootparentWith a single stair you can also get windows in opposite ends of the building for the same unit which makes a huge quality of life difference. Getting a real cross-breeze! reply Tiktaalik 15 hours agorootparentprev> The reason five over ones are popular in the US has nothing to do with staircase requirements. The reason is money, like always. Yes it is money. More staircases remarkably increase the costs of buildings. Single stairway, cheaper buildings, more profitable to do other sorts of buildings, more variety of buildings etc. (see also no parking mandates) reply bluGill 9 hours agorootparentStairs are not expensivei they take space, but are cheay otherwise reply eru 8 hours agorootparentSpace ain't free. reply closeparen 11 hours agorootparentprevItâ€™s true that five stories is an economic sweet spot, but the idea is we could get five story point access blocks instead of double loaded corridor layouts. reply mitthrowaway2 2 hours agoprevSee also a related video by About Here: https://www.youtube.com/watch?v=iRdwXQb7CfM which mentions this very pertinent section of the US National Housing Association Proceedings (1913), p.212: \"Do everything possible in our laws to encourage the construction of private dwellings and even two-family dwellings, because the two-family house is the next least objectionable type, and penalize so far as we can in our statute, the multiple dwelling of any kind... if we require multiple dwellings to be fireproof, and thus increase the cost of construction; if we require stairs to be fireproofed, even where there are only three families; if we require fire escapes and a host of other things, all dealing with fire protection, we are on safe grounds (compared to zoning regulations based on race), because that can be justified as a legitimate exercise of the police power[...] In our laws let most of the fire provisions relate solely to multiple dwellings, and allow our private houses and two-family houses to be built with no fire protection whatever\" reply nicole_express 16 hours agoprevI'd like to see more discussion of the safety impact; I know the article makes the point that fire deaths per capita are lower in Europe, which lacks the requirement, but it also notes that US housing stock is also much more wooden and therefore at higher risk to begin with. (Wood construction is generally a good thing from a sustainability perspective) Whenever I see this proposed my brain immediately goes to the Grenfell Tower fire in the UK. I guess that may just be an outlier due to the myriad of other causes, but it gives me pause. reply snakeyjake 11 hours agoparent>US housing stock is also much more wooden and therefore at higher risk to begin with. Fire compromising the structure of a building, or the structure itself burning is almost never the cause of death or injury. The primary killer in structure fires is hydrogen cyanide gas. Wood does emit hydrogen cyanide but the primary source is synthetic materials like upholstered furniture, wall and floor coverings, cabinetry, and other personal belongings. If you have two houses, one made of gypsum-covered 2x4 walls and the other made of stone and steel and a faulty space heater ignites a sofa or some polyester curtains, the buildings are equally lethal. The hydrogen cyanide will have killed you long before the fire burned through the drywall. Non-flammable walls don't even necessarily slow a fire's spread if synthetic materials are involved. The high heat of by their combustion and their dirty combustion causes flashover which ignites all flammable materials in a given space. I have been a volunteer firefighter for almost 20 years. I have experienced too many fatalities but none of them have ever burned to death. All victims have been dead due to asphyxiation (CO/CO2) or cyanide poisoning. The differences in death rates aren't as stark as the author contends (for example 0.2 deaths per fire in Great Britain, 0.3 in the US) and my gut tells me the main differentiation between the US and European deaths is the smaller, more compartmentalized nature of European dwellings (which limits the spread of smoke) coupled with their greater level of urbanization which leads to faster emergency services response (the faster a fire is knocked down the less gas it produces). Open floorplans kill. All of that being said, wooden construction does cause more firefighter deaths-- especially if engineered wood is used. But by the time the floor of a house has been weakened enough by a basement fire to fail and kill a firefighter, all of the occupants are already dead. reply steveBK123 10 hours agorootparentWhat are your thoughts on sprinklers in these types of situations? Are they mostly to give people enough time to get out? Do you feel the safety reduction of moving to single stair is offset by requiring sprinkling? The way I have seen the idea of single-stair multifamily proposed in US was that in areas where zoning requires sprinklers in multifamily dwellings anyway, all the extra hallway space required for the second stairway is an unnecessary burden cost wise for little marginal safety. reply thatfrenchguy 4 hours agorootparentprev> and the other made of stone and steel Not to mention european houses also have drywall over the concrete these days, the days of barren concrete or plaster over concrete have been over since at least the 90s. reply slyall 15 hours agoparentprevUnfortunately people from the US (including those who have never lived in an apartment or thought about fire regulations before) instinctively get really worried about this whole idea and assume people are just going to get killed. Happens in this thread and whenever it is brought up in social media. The original article talks about statistics, various extra measures to ensure safety and limiting to buildings 6 stores or less. But US commentators have trouble getting past their initial reaction. They also do the usual US thing of discounting anything from overseas as \"not applicable to US conditions\". reply davidw 11 hours agorootparentHaving lived in both places - Italy and the US - I think it's a natural question. The answer I've heard that makes sense, is that if you do this in US buildings you need decent fire suppression systems even if those bump the price. But it's well worth doing in terms of making more types of nice buildings viable. reply eru 8 hours agorootparentYou could just add that as an option to the housing regulation: Either build in the traditional American style out of wood, or (new option) build out of stone and add a robust fire suppression system, but in return we let you get away with a single staircase and other features that increase density. reply davidw 7 hours agorootparentConcrete is probably not a great thing in much of the US for lower-rise buildings. Definitely not here in Oregon. And the fire suppression stuff is mandatory in multifamily housing anyway. reply ajmurmann 7 hours agorootparentWhy is concrete bad in Oregon? Autoclaved, aerated concrete is common in Germany which has a slightly harsher version of our Oregon climate. reply davidw 6 hours agorootparentIt outputs a lot of CO2, and there are a lot of trees to construct low-rise apartments with. reply thatfrenchguy 4 hours agorootparentprevEarthquakes reply eru 4 hours agorootparentprevAllowing non-wooden construction (and then a different fire safety regime for it) is not the same as mandating it. Developers in Oregon would presumably stick to wood, then. No harm done. reply autoexec 10 hours agorootparentprevI think there is some of that certainly, but it's also worth being cautious anytime a developer says they want to abandon fire codes that were put in place to save human lives so that they can add greater density housing. Fire codes got where they are in part because developers were fine with packing people into unsafe housing situations. Let's not let our guard down entirely now. reply notatoad 10 hours agorootparent>that were put in place to save human lives There's an assumption here that the code was put in place to save lives. There's a whole lot of regulation that exists simply to make it difficult to build. Lots of people profit when housing is scarce (or unavailable to certain demographics), and want to keep it that way. It is always worth asking what the point of a regulation is, and whether it accomplishes the thing it claims to be trying to accomplish. reply autoexec 10 hours agorootparentI think it's a much bigger assumption that the fire code which requires people have somewhere to escape to when a stairwell is on fire was put in place to make it difficult to build instead of for helping to keep families from burning alive. I fully agree that if after careful and thorough examination it's determined that the codes are outdated and can be removed without endangering people that they should be, even if it didn't make it easier for developers. reply notatoad 5 hours agorootparent>I think it's a much bigger assumption... i don't think it's that big of an assumption. there's a long history of discrimination being enforced through building codes. will a second stairwell save a life at some point? almost certainly yes, but it wouldn't be an effective blocker if it obviously didn't. the question isn't whether it improves safety, it's whether it improves safety enough to be worthwhile. a second stairwell would also almost certainly save a life if it were required for single-family homes too, but we don't do that because there's some line somewhere where we decide making things 100% safe is silly, and compromise the edge case of safety for the sake of practicality. and there's a lot of forces trying to move that line away from practicality when it comes to multi-family housing. reply autoexec 1 hour agorootparentThe difference is that for a single family home people have other ways to get out alive. Someone could easily survive a drop out of a second story window and ropes (or today ladders like this one https://www.homedepot.com/p/Kidde-Fire-Escape-Ladder-2-Story...) make single family homes with only one stairwell pretty safe. That doesn't work when you're got people trapped in a six-story tenement. International Building Code requires the second stairway only for buildings higher than three stories which seems like a good idea considering that the median height leading to death is about 4 to 5 storeys. (https://thetraumapro.com/2010/01/11/what-you-need-to-know-ab...) reply alistairSH 8 hours agorootparentprevMore likely the code is amended and not removed. Two stairs OR better fire suppression/resistance. reply mcmoor 2 hours agorootparentprevAh yes I also sometimes think that some people who champion more regulations and safety actually don't want the thing to exist. Like any discussion about traffic management for example. Or every \"think of the children!!\". reply Paul-Craft 10 hours agorootparentprevAll safety regulations are written in blood. reply alistairSH 8 hours agorootparentPerhaps, but that doesnâ€™t mean the regulation is proper today. reply kccqzy 14 hours agorootparentprevI totally agree with you that it's definitely instinctive. The article has a link to mass timber construction for fire officials. Coincidentally there is an office building near me with mass timber structure but whenever I tell people about it, they instinctively think of it as less safe than steel and concrete. reply wolverine876 2 hours agorootparentprevI also have an instinct to avoid standing where I could fall a long way - it's probably a good instinct. You haven't provided evidence that the instinct regarding fire safety in single-stair buildings is flawed. reply amrocha 2 hours agorootparentIt's not an instinct, it's a gut reaction to change. The evidence is that people aren't burning to death in Europe. reply multjoy 15 hours agoparentprevGrenfell is what happens when building regulations are poorly enforced. In principle, each apartment in Grenfell should have been able to burn out completely while the neighbouring units were untouched, so there was no need for a second stair as any evacuation would have been limited to units adjacent rather than the entire population. What actually happened is that years of neglect had seen firebreaks and bulkheads repeatedly compromised and then a load of flammable cladding added to the outside, because the building industry is basically rotten. Had the same incident taken place when the building was first constructed, the damage would have been limited to the one apartment. reply Animats 10 hours agorootparentWhich is why the article's call for \"reform of defect liability laws that drive insurance costs up for condo developers\" makes his whole position deeply suspicious. reply autoexec 10 hours agorootparentExactly. If modern day advances make single-stair multifamily homes perfectly safe than there's zero reason to give condo developers a free pass for designs that are found to have led to families burning death. reply closeparen 5 hours agorootparentEurope is a lot more sophisticated about both regulation and multi-family housing then we are, Iâ€™m not sure we should interpret North Americaâ€™s quirks as advances. If they are advances, we might ask to what end: most building and planning code was created with the express purpose of engineering a suburban single-family detached homeowner-driver society, not to create safe or pleasant urbanism. reply eru 8 hours agorootparentprevKeep in mind that Grenfell was the responsibility of the local council. It was not run by eg a multinational corporation, which usually have better management and a commercial reputation to defend (and deep pockets to go after in a law suit). Big business gets a lot of flak, but they are honestly better on average than small businesses and many local governments institutions. reply defrost 8 hours agorootparentUnregulatedpoorly enforced \"big business\" is no better and arguably worse. The crux appears to be adequate resources to enforce standards > a commercial reputation to defend (and deep pockets to go after in a law suit). Meanwhile, in \"the real world\" sufficiently large businesses are routinely silo'd into seperate sub companies and those that are associated with disaster, product liability, deaths, etc are often mysteriously bankrupt or with insufficient funds to meet penalties of pennies on the dollar. reply eru 5 hours agorootparentIf you do that siloing, you don't benefit from reputation, yes. reply defrost 5 hours agorootparentIt wasn't a question. If BigWellKnownCompany uses TLASubsidiary (Delaware) LLC to handle contracts then they are still BigWellKnownCompany with reputation and in the event of litagation the buck (generally) stops with the bankrupcy of TLASubsidiary (Delaware) LLC. There are exceptions (see, for example, Johnson & Johnson (JNJ.N) and it's failure to shield behind LTL Management) but it works in the real world often enough to be Standard Operating Procedure. reply eru 4 hours agorootparentYes, reputation and legal liability are two different things. Either the subsidiary shares in the reputation, but then also passes on damages to the reputation. Or it ain't. The same is true for legal liability: if the parent company is legally liable for the subsidiaries debts, then the subsidiary can (all else being equal) borrow cheaper. If that chain is severed, the subsidiary borrows only as cheaply as a stand-alone small company, or perhaps even worse, because severing that liability also serves as a signal to potential creditors to better watch out for shenanigans. With a clever enough PR department (respectively legal department), you can try to have it both ways. But a sufficiently clever PR department can do anything. reply bobthepanda 15 hours agoparentprevThe intention of the double stairwell requirement, is that you are not supposed to have your access point to the stairwell by an obstruction, and there should be a maximum access time to the stairwell. One notable requirement of single-stair buildings where they are legal in the US, is that 1. the height is generally determined by the height of the fire ladders available, providing a second means of egress 2. the single stair requirement usually only applies to buildings that have a low maximum units per floor. In Seattle where they are legal, this is four units. At four units a floor, your front door directly opens feet away from the stairwell, and having a second staircase a sufficient distance away would be hard to fit in the floor plan. reply nineplay 15 hours agorootparent> 1. the height is generally determined by the height of the fire ladders available, providing a second means of egress This is an interesting requirement and makes me wonder if some of the need for two staircases comes from the proximity - or lack thereof - to fire services. I'd be sitting in a burning home for a long time if I had to wait for a fire ladder. reply bobthepanda 11 hours agorootparentA lot of the requirements make sense in bigger buildings. It's not easy to evacuate a large office building taking up a city block using only ladders. And some of it is reactive; for example, there is a distance separation requirement for stairwells, because during 9/11 the three North Tower stairwells were only 70 feet apart and enclosed only with gypsum, so they were all severed on impact, dooming the people above the impact zone. But none of this is really relevant for a building with six floors and 24 units total. The American city topology is basically office towers surrounded by single family homes; in the midcentury we demolished a lot of the in-between building stock, which is now referred to by urbanists as the \"missing middle\". Compare this to Europe or Japan which is largely buildings in between those sizes. reply eru 8 hours agorootparentEven Singapore has lots of those middle sized buildings missing from the US. reply Aeolun 8 hours agorootparentprevI think in Japanese apartment buildings theyâ€™re all required to have their own rope ladder? Since you go from balcony to balcony they donâ€™t even have to be very long. reply shiroiuma 2 hours agorootparentThere's no rope ladder in my apartment here. I've never heard of such a thing. reply flandish 13 hours agorootparentprevGround fire ladders are about 35â€™ max. Aerial apparatus (trucks/quints) around the US are normally around 80-110 feet in length. My current tower rig is 85â€™, our next will be 105. Consider that is ladder length and the â€œtrueâ€ height is really a hypotenuse on a right triangle with one side the building. We can generally reach most of our properties just fine, as our tallest is about 5 stories. However there are some across a river with access harder in front, and a ladder across the river is the way to go. reply jlhawn 15 hours agorootparentprevalso fire suppression system (sprinklers) and pressurized stairwells are mandated. reply CydeWeys 13 hours agorootparentAnd fireproof walls between units. It takes a long time for a fire to penetrate two layers of drywall. reply keyringlight 10 hours agorootparentprevThe \"Well there's your problem\" podcast did an episode on 'five over ones' (five stories of wood over one concrete) and touched on this - IIRC they were most likely to burn down during construction when the fire suppression wasn't installed and active yet. reply wiml 9 hours agorootparentThey also did a more in-depth episode on Grenfell, which touched on a lot of the same issues, except Grenfell was (a) taller and (b) occupied. reply Doxin 2 hours agorootparentI can heartily recommend that episode if you like a podcast to a) be respectful to the victims and b) clown on the people who caused it. reply dumbo-octopus 14 hours agoparentprev> Wood construction is generally a good thing from a sustainability perspective This is something a lot of people get confused about^. To summarize, each ton of wood used in constructions takes approx 1 ton of CO2 out of the atmosphere (cellulose is basically solidified carbon and oxygen), whereas each ton of concrete used in construction puts approx 100kg of C02 into the atmosphere. ^ \"You're cutting down treeees, oh the humanity!\" reply jeffhuys 3 hours agorootparentHow does that compare to leaving the trees grow, say, 25 more years? Youâ€™re only comparing the action of using them in construction. reply epistasis 10 hours agoparentprev> but it also notes that US housing stock is also much more wooden and therefore at higher risk to begin with. (Wood construction is generally a good thing from a sustainability perspective) So if we really care about fire safety, shouldn't we be regulating more effective mitigations to protect these wooden buildings, rather than the two stair aspect? Pointing out that there's a bigger risk factor than single stair has a natural conclusion. However, I have become so jaded that I no longer believe that people advocating for two stair cases actually care about fire safety, because of their lack of concern about wooden structure risks. Imposing strict, burdensome, and hardly-useful restrictions on multi-unit housing while ignoring life saving regulations for single unit housing has pretty clear ideological motivations. reply macNchz 14 hours agoparentprevThe new construction single-staircase building in NYC that I used to live in was metal and concrete framed, fitted with sprinklers throughout, and had double fire doors separating each apartment from the (all tile/metal/concrete) staircase with little vestibules. It didnâ€™t give me pause in the slightest, really I felt like it was safer from a fire perspective than a typical wood frame single family home, or an older building with a rickety old fire escape. reply smithsj619 11 hours agoparentprevThat's what I'm trying to raise money to do! ;-) Basically through an analysis of fire loss history combined with open property data. The fire engineering field hasn't traditionally had access to great data, for a few different reasons, but now the data is actually potentially available to answer the question â€“ but it does need a bit of time and investment. (I'm the author of the article.) reply amluto 10 hours agorootparentIâ€™m curious: is there room for a middle ground involving non-enclosed fire escapes? How useful are these? reply lokar 16 hours agoparentprevA few cities (with wood framed construction) in NA have allowed this for decades with no apparent issues reply eru 8 hours agoparentprev> (Wood construction is generally a good thing from a sustainability perspective) I don't really see how wood is more sustainable than eg brick or even steel and glass? > Whenever I see this proposed my brain immediately goes to the Grenfell Tower fire in the UK. I guess that may just be an outlier due to the myriad of other causes, but it gives me pause. You should look at statistics instead of single lurid anecdata. In any case, Grenfell Tower is a nice illustration of how when government provides services like housing, they don't magically provide safety. (Funnily enough, people usually try to spin that tower fire as some failure of the market, when the estate was managed by the local council.) > I know the article makes the point that fire deaths per capita are lower in Europe, which lacks the requirement, but it also notes that US housing stock is also much more wooden and therefore at higher risk to begin with. Btw, this might suggest to change the regulation so that you can either follow the existing US regulations when building with wood; or you get allowed more density and single-stairs etc, when building with whatever they use in Europe. reply Tarq0n 8 hours agorootparentWood captures carbon within it and has minimal energy cost compared to steel, glass and brick. Lumber can also be regrown. So highly sustainable from a global warming perspective at least. reply eru 8 hours agorootparentSteel can be recycled. And we are sitting on a giant ball of matter, so making more bricks or glass is easy. (Glass can be recycled, but it's not really worth it.) You are right that wood captures carbon. But you have to think about the opportunity costs: the same land that you use to slowly grow your wood could be used to eg run wind turbines or solar panels to replace fossil fuels. (You could also stick a nuclear power plant on that land to replace even more fossil fuels. But on the margin, nuclear isn't really limited by the available land but by red tape and permissions. So adding a bit more land won't make the nuclear industry produce more energy.) You'd have to run the numbers, it's not obvious to me which effect dominates. Probably also depends on how well wood grows in your climate, and how sunny and windy it is. And what else you could grow on that land. Speculation: I suspect that emissions during construction will be relatively small fry, compared to the impact of density. Eg re-inforced concrete allows denser living (by building taller than wood, and by allowing single-stairs to be still firesafe, etc), and density tends to lower per capita CO2. Of course, rural settings won't make use of the possibility of density. So for them it's just about the first order effects. reply rootusrootus 8 hours agorootparent> You'd have to run the numbers, it's not obvious to me which effect dominates Perhaps this is a perspective thing? Take one state in the western US that happens to have farmed timber, PV, and turbines: Oregon. Slightly larger than the United Kingdom, 6% of the population. There's not even a tiny amount of opportunity cost being lost by farming timber. reply eru 4 hours agorootparent> There's not even a tiny amount of opportunity cost being lost by farming timber. Does that mean you can buy land for 0 dollars per squaremeter in Oregon? Wow. reply paulddraper 15 hours agoparentprevFire escapes are still a thing, right?? reply crazygringo 15 hours agorootparentFire escapes haven't been a thing in a long, long time. Not in new construction. Older buildings only. reply paulddraper 13 hours agorootparentI guess I've lived in old, old buildings :/ reply crazygringo 13 hours agorootparentThey have their charm! Nothing quite like hanging out on a fire escape on a hot humid summer night with a cold beer and charming company. Along with the contortions involved climbing through the window in both directions... reply eru 8 hours agorootparentGiven the size distribution of Americans these days, I wonder if many could even climb out to use the fire escapes? reply briantakita 13 hours agoparentprev> I'd like to see more discussion of the safety impact; Another concern is building stability, whether or not the actual construction process followed code, whether or not structural maintenance is adequate, & the age of some high rises. Florida recently had a condo collapse. There are many old tall buildings built on shifting water permeable ground in the US. China has issues with tall buildings as well, particularly in it's river flood plains. It is quite surreal to see an entire high-rise being carried down a river. Look it up. Edit: I was unable to find the video with today's search...so here is the video. Apparently there was censorship with the Chinese government over the video. https://youtu.be/MCC7C5PJrOI?si=TAgIKOYbIpr8VAM0&t=154 reply Tiktaalik 15 hours agoprevInteresting to see how we got to where we're at. Seems like at no point along the way, as more and more fire safety measures were being added (eg. sprinklers!) did anyone think that maybe it meant some of the more egregiously expensive safety measures were now deprecated and their use should be ended. British Columbia's government has mentioned they're looking into this and I hope we see an end to the mandated two staircases. People consistently say they want more two and three bedroom apartments. Single stairway buildings seem like one of the best ways to introduce the flexibility that would make those products more viable. reply throw0101d 16 hours agoprevThe province of British Columbia (BC) seems to be considering it: * https://morehousing.substack.com/p/bc-single-stair * https://morehousing.substack.com/p/single-stair See also: > Number of storeys permissible with single exit stair around the world. * https://www.coolearth.ca/wp-content/uploads/2022/02/image-1.... * https://www.coolearth.ca/2022/03/16/building-code-change-to-... The diagram illustrates that the longest aerial ladder firetruck available in North America is 137' / 41m, which should be able to reach about fourteen storeys high. A 'typical' aerial ladder is about 75' / 22m, which is about seven storeys. reply bombcar 12 hours agoparentThe ladder never goes straight up, so you need to check what its maximum â€œreachâ€ is. A building that is seven stories high is going to be big enough to have multiple stairways; probably multiple elevators. reply twelvechairs 7 hours agoparentprevWhat's not covered in the diagrams you've provided are construction standards (for fire ratings) and also whether scissor stairs [0] satisfy the requirements for two staircases. These vary widely across the countries noted [0] https://pbs.twimg.com/media/FnC9ge6WQAAFd7p?format=png&name=... reply michaelt 10 hours agoparentprevAn additional constraint here is that the fire trucks have to be able to navigate around the city. London has many high-rise buildings, but the many narrow roads and tight corners mean they don't operate the tallest fire trucks. reply anikan_vader 7 hours agoprevThe author does not even attempt to analyze the safety impact of removing the second stair. The only evidence they provide is that Western Europe has fewer fire deaths than the US. Which suggests that perhaps the US should be increasing fire safety standards rather than removing themâ€¦ reply Seattle3503 7 hours agoparentSeattle also allows for single stair multifamily. It hasn't been a problem for us yet. reply wolverine876 3 hours agorootparentWhat is the rate of injuries per fire in single stair multifamily buildings? reply massysett 10 hours agoprevThe evidence the author gives is not compelling. \"Almost every country in Western Europeâ€”where single-stair apartment buildings can rise many times the IBCâ€™s three-story height limitâ€”has fewer fire deaths per capita than the US.\" There is no analysis of where these fire deaths are occurring: are they in single-family homes? Commercial buildings? Car wrecks that caught on fire? Trailer parks? More compelling would be to compare apartment deaths in other countries with those in the US or, at a minimum, explain why the available statistics advance this thesis even if they are not completely comparable. reply rootusrootus 10 hours agoparentIndeed, going by this [0] information from FEMA, it seems like the US is mid-pack. [0] https://www.usfa.fema.gov/downloads/pdf/statistics/v12i8.pdf reply BurningFrog 7 hours agoprevMaybe the biggest problem with regulations is that even if they're very positive when enacted, there is usually no mechanism to reevaluate them during the following decades. And so the effects of a fire 164 years ago screws up housing across the US today. reply philsnow 7 hours agoparent> there is usually no mechanism to reevaluate them during the following decades One of my favorite parts about Texas, at least on paper: https://en.wikipedia.org/wiki/Sunset_Advisory_Commission reply nine_k 5 hours agoparentprevRe-evaluation is hard, costly, and risky: what if you actually degrade the safety a tiny bit? Or maybe you don't, but an incident happens, and your changes are going to be blamed by media? Doing nothing and groaning is safer for career. reply pottertheotter 5 hours agoprevI've been hoping that this would change because the type of mid/low-rise multifamily housing we have in the United States is horrible. What I really hope happens is that ownership of multifamily real estate becomes much more fragmented. Imagine multifamily housing where each lot is the same as a single family lot. You can have varied types right next to each other (one building could house several seniors in small apartments, another could house several young people in smaller apartments, another could be the owner in a two floor \"house\" on the top to floors with rentals below, another could be a building comprised of entire floor flats that are each owner-occupied). They can be redeveloped so much more easily or repurposed. When an entire block is a huge multifamily building, it's pretty much impossible to change anything about it. But, we really need to also change how we finance these buildings. A big reason everything is the same these days is because the finance system underwrites them. The system is there for these other types of smaller buildings. reply baq 16 hours agoprevEuropean here. I can't even put to words my embafflement upon having learnt that you US folks need two staircases. reply nineplay 15 hours agoparentI'm often surprised when posters identify themselves as \"European\" which encompasses such a broad range of cultures, biotypes, and ecosystems that it makes any comparison of the US way vs the European way virtually impossible. That said, when looking at the reasons for fire safety in the U.S., there are many factors to consider which may or may not apply in parts of Europe -- Frequency of wildfires. They are not uncommon in my southwest corner, so fire safety is taken very seriously -- Proximity of emergency services. It can't be assumed that the local fire department is a few minutes drive away -- Building materials. Materials that are fire-proof are rarely earthquake proof. Any of these may or may not apply in any particular case but \"embafflement\" seems pretty extreme. reply cycomanic 14 hours agorootparent> I'm often surprised when posters identify themselves as \"European\" which encompasses such a broad range of cultures, biotypes, and ecosystems that it makes any comparison of the US way vs the European way virtually impossible. Many people in Europe do indeed identify as European. This has become more and more prevalent as people increasingly move around in Europe. I'd also argue that you are ignoring the cultural differences in the US (e.g. New Jersey vs Utah) something which I find Europeans are often guilty of. > That said, when looking at the reasons for fire safety in the U.S., there are many factors to consider which may or may not apply in parts of Europe > -- Frequency of wildfires. They are not uncommon in my southwest corner, so fire safety is taken very seriously We are talking about multi (>4) story, multi family apartment buildings, how are wildfires relevant? > -- Proximity of emergency services. It can't be assumed that the local fire department is a few minutes drive away Again we are not talking about requirements for some cottage in the woods, these are city buildings. The whole argument is for buildings where you have space constraints. > -- Building materials. Materials that are fire-proof are rarely earthquake proof. Again I don't see the relevance, we are talking about a national building code, but only a tiny fraction of US cities are earthquake zones. The article also asserts that most Asian countries (which presumably includes Japan) have only one stairwell requirements. > Any of these may or may not apply in any particular case but \"embafflement\" seems pretty extreme. I actually agree if one needs to grasp for straws like these for reasons for the 2 stairwell rule, it is pretty baffling. The article actually nicely described the history and why it's outdated. reply nineplay 13 hours agorootparent> Many people in Europe do indeed identify as European I'll admit my surprise. US has a lot of variety, still I'd have expected that residents of Anchorage and Manhattan have more more in common than residents of Iceland and Malta. > We are talking about multi (>4) story, multi family apartment buildings, how are wildfires relevant? > Again we are not talking about requirements for some cottage in the woods, these are city buildings. The whole argument is for buildings where you have space constraints. > Again I don't see the relevance, we are talking about a national building code, but only a tiny fraction of US cities are earthquake zones. The article also asserts that most Asian countries (which presumably includes Japan) have only one stairwell requirements. I think you are underestimating the population densities of US cities. I live in a major city and wildfires have burned homes a few miles from me. Residential areas are vast and fire departments are few. I'm also not sure how you can say few US cities are in earthquake zones - maybe if you squint at the numbers, but most if not all of the west coast, Alaska, and Hawaii are in earthquake zones. That's a pretty large chunk to hand-wave away. reply thatfrenchguy 4 hours agorootparentMultifamily are almost never built in fire-prone areas, especially on the west coast. reply jenadine 3 hours agorootparentprevRegarding identifying as European, this is often in relation to something, and one can identify one selves as many things. I identify myself as an inhabitant of my city compared to someone from a neighbour city. I identify as European compared to someone from United States. I identify myself as a westerner compared to people with a completely different culture. reply cycomanic 1 hour agorootparentExcellent point. I would also concede to the previous commenter, that citizens of different countries in Europe have (in many aspects) larger cultural differences than citizens of different states in the US (and language is a huge factor), but there are still many commonalities as well. reply alwa 14 hours agorootparentprevOf course, as you allude, the US is a large and diverse country too, where those features may or may not apply in a given locality. I suspect, though, that on both continents, when weâ€™re talking about these problems with the dual staircase requirement in this context, weâ€™re talking mainly about relatively high-density developments in space-constrained urban settings. If, as the article claims, weâ€™ve arrived at comparable fire fatality rates under the two policy regimes, it does seem like their prevailing standards neatly capture a tradeoff: it seems like you can add safety either by socializing a fire response infrastructure capable of quicker response, or you can privatize that extra margin of safety by imposing these second staircase costs on individual developments. Iâ€™d be curious how the total costs add up, Iâ€™m almost inclined to donate to the guyâ€™s nonprofit just to get the answer to that. Iâ€™d be curious how these changes would affect the economics of apartment blocks on huge greenfield suburban tracts, where parking requirements rather than staircase requirements seem to be the limiting factor space-wise. Iâ€™m thinking of the kind where space is cheap enough that they do surface lots rather than building parking decks into the structure. It seems like they tack exterior staircases on the edges of the building at not too much extra cost in those situations, but I suppose the floor plan implications must still come to bear. reply amluto 10 hours agorootparentprev> -- Frequency of wildfires. They are not uncommon in my southwest corner, so fire safety is taken very seriously There is finally progress on building codes for wildfire safety (called â€œWUIâ€ codes). It still has missing bits. For example, try to find a standard for a building air intake in an area subject to wildfires. reply elzbardico 10 hours agorootparentprevBecause of the European Union there's a lot more of common standards and regulations concerning things like buildings between European Countries than there are between American States. Also, a lot more stuff is codified by law or treaties instead of by business and trade associations. So, on this matter, it makes a lot of sense of speaking about the European experience. reply baq 14 hours agorootparentprevThe point was that Europe has all of these but no double staircases. Donâ€™t want to comment on missing emergency services in densely built areas but hope it isnâ€™t the case itâ€™s so bad you need an extra flight of stairs. reply nadermx 16 hours agoparentprevThe US has some very interesting requirements when building. In some cities, regardless of destiny, new buildings are required to have 1.x parking spots per unit or something of the sort as well. Which basically assures all buildings have to be designed for car centric life. reply andix 15 hours agorootparentIt's the same for many European cities and towns. Many cities started to reduce it down to 0.5 parking spaces per flat or less, because many of those parking spaces tend to be empty in bigger cities. And just increase prices for housing. reply ghaff 15 hours agorootparentI was just visiting a European friend for a couple weeks. They have a car but parking was a sufficient drama that they took the Uber equivalent within the city most of the time. Busses but minimal metro. reply andix 14 hours agorootparentI honestly don't see the drama in most European cities, it's not like in NYC. Street parking is very limited in bigger cities, so you might need to park in expensive parking garages. Or use other methods of travel. Only in areas with a lot of old houses (built before cars were a thing) there might be a lack of garages. Owning/driving a car is generally very expensive in many European countries. Not like in the US where wages are rather high, but cars and gas extremely cheap, because there is no substantial tax on them. Edit: this might not apply to southern Europe. In some southern European cities it's impossible to go by car. That's why everyone drives a scooter. reply rootusrootus 10 hours agorootparentprevThe requirement is because if you don't mandate a minimum amount of parking, developers won't create it. Then the neighbors of your fancy new building can no longer find parking near their own home because the new building tenants take it. So they justifiably get angry and start voting in politicians that will enforce minimum capacity for new development. reply nadermx 5 hours agorootparentYour conclusion seems wrong in pratice. Seems in fact quite the opposite happens, more affordable housing, etc. https://www.miamiherald.com/news/local/community/miami-dade/... reply phatskat 15 hours agorootparentprevWeâ€™ve really done a number to cater to cars and the auto industry in the United States. Some More News does a great job on outlining the history of cars, roads, and what can be done to make things better - https://youtu.be/sayw3TOhykg reply cal5k 16 hours agoparentprevHow do you think we feel about cookie notices? reply speeder 15 hours agorootparentAnother European here: I think the law is fine. How companies, specially US companies react to it, that is not. 1. A ton of Health related websites in US refuse to work in Europe, because they are NOT willing to let you visit without sensitive data being grabbed with cookies. I truly do not understand how US people are ok with this. 2. The law says that you can't make hard to refuse cookies, yet many US-based sites I visit have shady, shady practices, for example many you have to click a button to see all the sliders for individual cookies, and when you click that button, it switches the orders of the buttons, so that the button you just clicked become \"accept all\", and the previous \"accept all\" button becomes \"save current settings\". Thus if you double click/tap by accident you accept all. 3. The sites that most often piss me off with shady cookie banner that tries its hardest to force you to opt-in to tracking, are ones that use a company called \"Admiral\", that according to LinkedIn is from Florida. https://www.linkedin.com/company/getadmiral/ reply rootusrootus 10 hours agorootparent> A ton of Health related websites in US refuse to work in Europe, because they are NOT willing to let you visit without sensitive data being grabbed with cookies. That is the less charitable interpretation. In reality a lot of sites that cater primarily to a US audience don't have the willingness or development time to try and comply with European regulations. Barring European visitors neatly solves that. reply mandibles 15 hours agorootparentprevThe year is 3157. Each time you access a new resource on the shared data substrate, you are required to accept something called a \"Cookie.\" You have no idea what they are or why. Your crewmates say it has something to do with the homeworld, but you just shrug and prepare for the hyperspace jump. reply andix 15 hours agorootparentprevThere is one solution for the cookie notices that is very seldomly talked about: just don't use any marketing cookies, then you don't need consent from the user :) reply oblio 15 hours agorootparentprevYes, housing and web cookies, equally important for one's life. reply chris-orgmenta 15 hours agorootparentprevThat ain't us.... kind of. That's the websites deciding to follow the letter of the law (or a spiteful, capitalist interpretation, taking it right to the line) instead of the spirit of the law. OK, unintended consequences of legislation. But those cookie banners are not mandated, exactly. They don't need to be there. It's the companies deciding to do it that way, so they can keep gobbling data. It's like if the building companies implemented the 2nd staircase, but only so they could measure who is going up and down it. Not for saving lives. If they were opt in, or unnecessary tracking wasn't implemented in the first place, then the banners could be elegant or gone. But I do agree that the legislation (especially the ultra focus on cookies specifically) was... blinkered & short sighted. reply crazygringo 15 hours agorootparentNo, that's entirely Europe. The outcome of the legislation was easy for anyone to see. As you say, it was blinkered and short-sighted. And I still have to click 20 popups away on mobile every day. If only a few websites had the banner, then maybe I'd blame those websites. But when they virtually all do, I blame the law. reply cycomanic 14 hours agorootparentActually the legislation is fine, much better than before. It's the enforcement that's lacking. I'd say >90% of cookie banners break the law. It's just that enforcement is only slowly catching up. We have already seen a couple of cases and I expect that as soon as there have been more rulings banners will start to dissappear or become much simpler. reply crazygringo 14 hours agorootparentWhat basis do you have for saying they would disappear? I've never heard anyone suggest that. (And them becoming \"simpler\" is irrelevant. As far as unwanted interruptions go, a popup is a popup.) reply drcongo 14 hours agorootparentprevJust out of interest, you prefer to have your data harvested and sold? reply AnimalMuppet 14 hours agorootparentHow about: Don't harvest and sell my data, and don't show me a bunch of popups about exactly what data you can collect on me? reply drcongo 14 hours agorootparentThat is of course the ideal, but what, you're just gonna trust them? reply crazygringo 14 hours agorootparentI don't trust a popup a single bit more than no popup. So it's not like I trust anything either way. Get rid of the popups. Any solution needs to be legal and not involve popups. reply beebeepka 10 hours agorootparentdon't use tracking cookies. so complicated! reply crazygringo 15 hours agoparentprevWhy would you choose to write something here with a snarky attitude like that? There's a reasoned discussion to be had around fire safety regulations, but when you instantly make it about cultures and don't even try to understand, you're not being part of the solution -- you're part of the problem. reply baq 13 hours agorootparentMaybe I should say Iâ€™m from abroad instead? European seems to trigger something in some folks around here. That aside, I fail to see any cultural or other reason to require twin staircases nowadays other than â€˜thatâ€™s how we always did it hereâ€™. I admit it openly and state that Iâ€™m from somewhere where we donâ€™t do that, and the world works just as well, except buildings have a higher useful to total area ratio. reply rootusrootus 10 hours agorootparent> European seems to trigger something in some folks around here. Nothing personal against you, but we see a fair number of self-described Europeans that are a lovely combination of naive, ignorant, and arrogant. It isn't fair to stereotype, but it takes ongoing effort not to. reply crazygringo 9 hours agorootparentprev> That aside, I fail to see any cultural or other reason But are you an expert in it? Have you researched it? Are you sure the world would \"work just as well\" if the safety requirements were removed in the US? Considering things like different building materials, different rates of wildfires near urban areas, etc.? Maybe instead of declaring yourself baffled as if it's obviously something dumb or backwards because it's not how you do it in Europe (or another place), you should ask why it's different instead, and see if you can learn rather than judge. Then it wouldn't come across as condescending. reply screye 15 hours agoparentprevOddly, this is already a solved problem. NYC fire escapes are world famous. If every sub-10 floor building can have a 2nd window fire escape.... then you can have your cake and eat it too. reply crazygringo 14 hours agorootparentNYC stopped building fire escapes a long time ago. There are still tons of them, but all on older buildings. It certainly would be interesting to see them make a comeback though. reply mzs 15 hours agoparentprevMost housing was wood framed and there was tragedy after tragedy from inescapable fires. reply bombcar 12 hours agoparentprevUs Americans are very wide. The second staircase is for the oversized pickup truck. (And anyway the dual staircase thing isnâ€™t even universal in the US). reply kazinator 15 hours agoparentprevEmbafflement? Oh US buildings have that too: fire-proof doors divide those long hallways that connect the staircases. reply drcongo 14 hours agoparentprevI'm baffled at the phrase \"single stair\" when what they actually mean is \"single staircase\". I had to read most of that article to work out what it actually meant, while at the same time imagining buildings with only one stair. reply Pxtl 10 hours agoparentprevIt's even worse in Canada. You need a 2nd staircase for a multi-unit home that's over 2 storeys. If it weren't for the \"multi-unit\" part, there would be a lot of houses that would need to be built with a 2nd stair. reply Vecr 8 hours agorootparentSecond staircases are pretty good. I think most people should have them if they can afford them. reply carabiner 15 hours agoparentprev> I can't even put to words my embafflement That's because the word is \"bafflement.\" reply rconti 15 hours agoparentprevYes, our insanely burdensome health and safety regulations in the US often baffle the devil-may-care freewheeling folks over in Europe. /s reply quickthrowman 15 hours agoparentprevAmerican here. I can't even put to words my embafflement upon learning that 72 people died in the Grenfell Tower fire in Europe in 2017. reply adrian_b 15 hours agorootparentThat had little to do with stairs, but it was caused by the use of inappropriate combustible materials, which were forbidden for buildings of that height in many countries of continental Europe, but they were allowed in Great Britain were regulations were much more lax. So that event is strictly specific to UK and not representative for Europe in general. reply drcongo 14 hours agorootparentWe (UK) had banned those materials too until the tories decided to unban them because many of them are also property developers. reply throwbadubadu 14 hours agorootparentprevThat was due to missing stairs? And there is a difference between skyscrapers and 3-6 story multi-apartment buildings where in the worst case you can even exit fine with fire truck ladders or assisted jumps, but the article says even required for those, which would really feel ridiculous for those kind of buildings here. No need to be salty, we find each other alien on many levels :D reply quickthrowman 12 hours agorootparentThe cause is irrelevant, 72 people died in a building fire in 2017. That didnâ€™t need to happen. reply throwbadubadu 11 hours agorootparentDidn't doubt that, but that tragedy was not the point of the \"embafflement\"-response to the \"embafflement\"-statement actually, what was my point, so pointless in total, same as you now calling that out again... reply estebank 15 hours agorootparentprevFire deaths per 100k in 2019: US .82 UK .38 https://ourworldindata.org/grapher/fire-death-rates reply anthonypasq 13 hours agorootparentyou understand that 1/3 of the country lights on fire annually? reply 189 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Legalizing single-stair multifamily buildings could potentially increase housing construction and address affordability concerns in the US.",
      "The article delves into the history and impact of egress regulations on design and affordability.",
      "Reforming building codes to allow for single-stair buildings up to six stories is advocated by the Center for Building in North America as a way to achieve more efficient and affordable housing designs."
    ],
    "commentSummary": [
      "The article and comments section discuss the impact of housing regulations on housing costs and affordability.",
      "The conversation emphasizes the need to reevaluate and reduce regulations to address the housing crisis.",
      "Topics covered include the effectiveness of zoning laws, housing density and affordability, fire safety regulations in buildings, use of wood in construction, balancing safety and practicality in regulations, and the role of regulations in addressing discrimination.",
      "The conversation concludes with a comparison of fire safety regulations and statistics among different countries."
    ],
    "points": 282,
    "commentCount": 450,
    "retryCount": 0,
    "time": 1705596077
  },
  {
    "id": 39048948,
    "title": "Cutting AI Costs by 99%: The Playbook to Success",
    "originLink": "https://twitter.com/wenquai/status/1748016021808595242",
    "originBody": "my AI-powered career exploration app (Wanderer) has been experiencing explosive growth and my GPT-4 costs were starting to pile up ($100+ a day ðŸ’€)here&#39;s the playbook I used to lower my AI costs by 99%, while also decreasing latency and maintaining quality:1. start with theâ€¦â€” zachary (@wenquai) January 18, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=39048948",
    "commentBody": "My AI costs went from $100 to less than $1/day: Fine-tuning Mixtral with GPT4 (twitter.com/wenquai)248 points by ignoramous 11 hours agohidepastfavorite103 comments frogamel 9 hours agoEvery tech company minus the few doing core research have been doing this for at least half a year. Generate training data with GPT4 or sometimes even 3.5 -> use it to do a QLoRA finetune on a llama or mistral base -> roll it out as a \"proprietary\" AI model -> management claims a big win and talks about how they're leaders in \"[industry name] AI\". It is remarkably easy - it takes practically zero knowledge of ML and can usually be done with less thanEvery tech company minus the few doing core research have been doing this for at least half a year I'm assuming you mean all those new 'AI wrapper' startups popping up.? I wouldn't say \"every tech company\". But yeh it seems incredibly easy, definitely an easy win and leaders get to feel ahead of the curve on AI. reply phillipcarter 8 hours agorootparentI agree, in fact I would wager the opposite, that most who claim to be a tech company are simply using OpenAI or another vendor with a turnkey API for things launched recently. Over time I expect more use of fine-tuned models, but fine-tuning is not easy, especially if your goal is GPT parity (or better). reply atleta 7 hours agorootparentThe thing I don't understand about this strategy is that it itself shows that there really is no money to be made here. I mean it's a pretty obvious giveaway that: 1. they don't have the resources to build their own technology and probably never will 2. even if they did have, the best they could do is come up with something very similar to OpenAI's GPT, i.e. a (somewhat) generic AI model. This means that OpenAI can also easily compete with them. All these companies are doing (if anything) is that they test the market for OpenAI (or Google, MS) for free. reply ignoramous 7 hours agorootparentThe flaw in your assumption is that perfect tech or tech powerhouses win. I mean, sure when they do, they win big; but the endgame for b2b SaaS is mostly M&A, powered by sales, which is mostly down to c-suite relationships and perception of being one among the market leaders (\"nobody ever got fired for buying IBM\"). If you can move fast, deliver, expand, and raise money, there's a good chance the AI wrapper lands a nice exit and/or morphs into a tech behemoth. Those outcomes (among others), even if mutually exclusive, are equally possible. reply Dr_Birdbrain 8 hours agoparentprevI have a question about thisâ€”-isnâ€™t it against the OpenAI Terms of Service to do this? reply ummonk 8 hours agorootparentYes but I doubt anyone is going to get the Aaron Swartz treatment over it, especially when OpenAI's own models are no doubt generated by playing fast and lose with ToS. E.g. at least as early as 2018, StackOverflow's ToS said: \"Any other downloading, copying, or storing of any public Network Content (other than Subscriber Content or content made available via the Stack Overflow API) for other than personal, noncommercial use is expressly prohibited without prior written permission from Stack Overflow or from the copyright holder identified in the copyright notice per the Creative Commons License\" reply windexh8er 6 hours agorootparentprevAhhhh, yes. OpenAI's good old ToS... Where it's OK to break a ToS / copyright if you're OpenAI for the input to generate the output that, you (customer) don't own and can't cache. Because that would impact their revenue model, be more efficient (power and cost) and still leave them holding the bag after ingesting loads of content they never had a right to in the first place but have staked their claim that it's OK because there's a lot riding on their success. And, oh by the way, they'll just change their ToS as it suits them for more revenue opportunities even when they stated they wouldn't do business with - oh you know nation state militaries. But - JK! Now we will because . reply mpalmer 4 hours agorootparentIt took me 30 seconds to read their TOS and confirm you're just making most of that up. > As between you and OpenAI, and to the extent permitted by applicable law, you (a) retain your ownership rights in Input and (b) own the Output. We hereby assign to you all our right, title, and interest, if any, in and to Output. It follows that your claim about caching violating OAI's terms is nonsense. reply phillipcarter 8 hours agorootparentprevYes, it's explicitly against their TOS. > What You Cannot Do. [...] > Use Output to develop models that compete with OpenAI. reply kromem 8 hours agorootparentWhich is ironic given the fact that scraping was likely against the ToS for many of the sites which ended up in OpenAI's training corpus. reply throwaway5959 8 hours agorootparentprevBut didnâ€™t X do that with their ML model Grok? reply phillipcarter 8 hours agorootparentBurning bridges and getting sued isn't uncharted territory for Elon Musk. reply jacquesm 7 hours agorootparentprevWhat's good for the goose... reply plagiarist 8 hours agorootparentprevIt will be interesting if the same court cases proving their use of everyone else's data make it fair use to use their machine output as training data. They're definitely in their rights to ban whomever but who knows if they have recourse beyond that? reply raverbashing 8 hours agorootparentprevIf you're not selling/ putting your model out there as a generic competitor to OpenAi then you're not competing with them reply phillipcarter 8 hours agorootparentThat's a moving target :) reply ssalka 8 hours agorootparentprevHave the same question - I mean, for training an open source model with no monetization attached, not much Open AI can do besides ban the user, but they can make another account. For a company doing this with the intent to sell it as a capability... seems risky. reply yieldcrv 5 hours agorootparentprevDid you know that removing the tag from a mattress is illegal too? according to the tag. reply nextworddev 8 hours agoparentprevAnd even this analysis is optimistic as it doesnâ€™t factor in the $$$$ it costs to hire a data scientist to fine tune the models. Just use off the shelf models with RAG until you really need custom models reply siliconc0w 6 hours agoparentprevI'm curious if you can actually get better than 3.5 though considering how meh it is at most applications. I'd be nice to know whether I could actually get a better model without the effort of trying this. reply behnamoh 10 hours agoprevI checked his app, it's https://www.wanderer.space/, no TOS, no privacy policy, no up front pricing, no mention of AI, nothing. This is as shady as it could get. Not to mention their approach with GPT-4 is good if you want a model to __pretend__ like it's as smart as GPT-4, but when push comes to shove, it'll become apparent that it's an inferior model. reply codetrotter 10 hours agoparent> when push comes to shove, it'll become apparent that it's an inferior model. That seems par for the course. Prompt GPT-4 to not reveal the prompt you gave it to user and it will work, until it doesnâ€™t. Ask GPT-4 to do fancy maths, and itâ€™ll give you something that looks reasonable at a glance but quickly turns out to be completely incorrect. Ask GPT-4 to implement a Sudoku Solver in Rust. Itâ€™ll seem like the code it gives you is on the right path. But itâ€™s not. reply doix 7 hours agorootparentI'm surprised it can't do the last one. Sudoku solvers are basically on the same path as hello world. Everyone writes one when learning a language. There must be thousands of repos and guides/tutorials on how to write one (even in rust). I'd expect ChatGPT to just spit out something verbatim. reply tylervigen 10 hours agoparentprevIt does mention AI, at least for me the slash page says \"Wanderer is an AI-powered tool.\" But hard agree on the lack of privacy policy, especially since it asks for a LinkedIn. reply zckly 7 hours agoparentprevHey, maker here! Genuinely appreciate you sharing this feedback. You're 100% correct - it's not a good look that an app takes in such detailed PII and doesn't have a clearly outlined TOS/privacy policy. Pricing should be more transparent as well - the app is currently free. As for the approach, I think it works fairly well for the career recommendations problem space given its limited and defined scope (there are a finite number of careers out there). However, for a task that requires more divergent thinking (open-ended chat, idea generation), this approach would definitely fall short of what GPT-4 could do reply erulabs 9 hours agoparentprevI mean, virtually every business that doesn't have a team of lawyers on staff (read: everyone outside the F1000) just uses a stock and mostly meaningless \"we can do anything and we promise nothing, sorry-not-sorry\" TOS and privacy policy anyways. I wouldn't really hold that against a solo-founder business as something shady -- just a sign of a small company. reply Zetobal 9 hours agoparentprevJust look at the careers in their career chart and you know it's influencer shovelware. It's also against OpenAIs ToS. Not that I care but I wouldn't brag about it. reply brigadier132 9 hours agoparentprevI'm trying to understand, what's shady about that? reply tylervigen 10 hours agoprevEthics and restrictive terms aside, it doesn't seem like GPT 4 was necessary for what the poster did. How much worse or more difficult would it have been to use Mixtral or 3.5 to generate the first 100 good prompt-response pairs and then manually tweak them as the poster did? reply thrwayaistartup 10 hours agoparentOr just... write 100 good prompt-repsonse pairs yourself. 2024 will be the year of synthetic data. 2025 will be the year of \"you know you can use your own brain and type out 100 datapoints faster and cheaper than generating and filtering assloads of synthetic data, right?\" Maybe we can even skip 2024 :) reply sp332 10 hours agorootparentDatabricks had their employees write up 15,000 of them. https://www.databricks.com/blog/2023/04/12/dolly-first-open-... reply icyfox 9 hours agorootparentFavorite part of this piece: > We were initially skeptical whether we would get to 10,000 results. But with nightly leaderboard gamification, we managed to break 15,000 results within a week. Out of fear of eating into our productivity, we closed the contest. I've hosted a few of these corporate data labeling events. If sufficiently gamified / there's a good enough UX, they can be surprisingly engaging. It helps a lot if you have a large employee base though. Distributing results over 5000 employees is exponentially easier than even 50 - in practicality, even larger than the orders of magnitude. reply code_runner 9 hours agorootparentprevIâ€™ve worked at plenty of places where we did a ton of labeling by hand. People concerned with data quality from LLMs should really see the inconsistencies we came up with! reply ThrowawayTestr 9 hours agorootparentprevAnybody have this downloaded and can paste a few examples? reply sp332 8 hours agorootparentYou can browse them here: https://huggingface.co/datasets/databricks/databricks-dolly-... reply schreiaj 8 hours agorootparentprevYes and no, for text type stuff? Yes you're right. But I think in the vision space synthetic data will remain useful for a lot of things. I'm currently working on building a pipeline for personal projects to go from CAD models of environment to segmented training data. So far it looks almost as useful as real world data at a fraction of the cost of manual labeling. reply atleta 8 hours agoparentprevWell, it seems that initially started with GPT4 but his costs were becoming high so he had to do something and had to do it quickly. Technically he could have written a few hundred responses himself while the site was still using GPT4 using the prompts from the users but that could have been slow (expensive)/boring, etc. reply cjbprime 10 hours agoparentprevUsing 3.5 seems like it would have been okay (technically but not legally given OpenAI ToS), but Mixtral is already somewhere around that level, so it's not achieving a goal of improving towards GPT-4 level responses without having to write those yourself, which seems to have been the goal OP wanted to get to. I've heard that training e.g. Mixtral on Mixtral's own outputs is a really bad idea, don't know full details. reply gumballindie 10 hours agoparentprevI am sorry what ethics? Openai is built on stolen content and your worry is people using openaiâ€™s output is the unethical issue? Whoa. reply dchuk 9 hours agoprevIâ€™m building a side project app (that hopefully becomes a revenue generating SaaS, stay tuned) that will leverage AI to summarize lots of content at scale. My plan is to just use OpenAI for now for speed to launch, but I have to imagine it will be way more economical and likely technically feasible to migrate to some self hosted LLM option later on. Anyone else done this? Any tips/tricks? reply icyfox 9 hours agoparentI've done some research involving parameterized summarization recently. GPT-4 does a really good (like, pretty outstanding) job in following the tone and density of a few one-shot example inputs. It's a lot more difficult to encourage the OSS models to do the same so you're going to have to experiment with a lot of different techniques to get it to what you want. In the worse case it could actually require some serious R&D investment to achieve the same results as an API out of the box. All that to say, my general philosophy is to worry about vendor costs / scale once you start approaching an adoption threshold where it matters. If the core idea doesn't have legs there's no point wasting time in developing your own summarization layer. reply cyanydeez 9 hours agoparentprevassume OpenAI's business model is the same as Ubers and you're not getting the full price for the current offerings, and it'll quadruple in costs. Then ask if your product will survive that. If not, don't tie your wagon to their service without a secession plan. reply CityOfThrowaway 9 hours agorootparentI think it'll be more like AWS, where the cost of each service keeps going down but they entice you into more usage and better models reply itake 10 hours agoprevhttps://nitter.net/wenquai/status/1748016021808595242 reply potatoman22 10 hours agoprevIsn't this against the OpenAI TOS? reply mmcwilliams 10 hours agoparentIt seemingly is but it is also one of the most popular ways that public models are being updated with SFT. \"Trained using ChatGPT output\" is something blatantly advertised in the literature of some fairly popular \"open\" models. I'm not sure where that's headed legally but it's surprisingly common. reply thrwayaistartup 10 hours agorootparentThe academic work is pretty safe as long as it isn't productized. The open models have a prime facie case to stand on. Using output is okay if you aren't directly competing with openai, even according to their tos. > (e) use Output (as defined below) to develop any artificial intelligence models that compete with our products and services. However, you can use Output to (i) develop artificial intelligence models primarily intended to categorize, classify, or organize data (e.g., embeddings or classifiers), as long as such models are not distributed or made commercially available to third parties and (ii) fine tune models provided as part of our Services reply brucethemoose2 7 hours agorootparentBut then those models are possibly used downstream, EG for Mistral's \"medium\" API model (and many other startups). I guess if its behind an API and no one discloses the training data, OpenAI can't prove anything? Even obvious GPTisms could ostensibly be from internet data. reply dietr1ch 10 hours agoparentprevIsn't it awkward because that's only plagiarism if all of the LLMs around are? reply huac 9 hours agoparentprevMy interpretation is that they prohibit using distilled models to compete against OpenAI, i.e. to offer a foundation model as a service. This particular app is a product not a foundation model so seems pretty clearly fine to me. Of course, this restriction is commonly ignored (eg 'open source' inference server companies offering distilled models) and who knows what applied products OpenAI will eventually build. reply behnamoh 10 hours agoparentprevMy question also, but even Google Gemini Pro does it. When announced, it'd say it was made by OpenAI :) reply sva_ 10 hours agorootparentMight've been a small identity crisis as well. reply paxys 9 hours agoparentprevProbably, but it's not like OpenAI has the standing to sue anyone for TOS violations. The most they will do is revoke access. reply chrishare 8 hours agorootparentTechnically, yeah. OpenAI are on the other end of copyright violations on many other fronts imho, for what that is worth. reply jurynulifcation 9 hours agoparentprevHow many terms of service did OpenAI break to gather their initial training set? Turnabout is fair play, this is justifiable piracy. reply pseudosavant 10 hours agoparentprevWhich means they could terminate your service. But nothing else would probably happen. reply albert180 10 hours agoparentprevSo what? New York Times also didn't consent to being used for the training of OpenAI models reply thrwayaistartup 10 hours agorootparentAnd NYT is suing OAI/MS. Two wrongs don't make a right... or maybe they do, but that doesn't immunize you from legal fees or a botched exit :) reply albert180 10 hours agorootparentIf NYT wins that will sink probably every LLM model out there reply Dr_Birdbrain 8 hours agorootparentNah, if it ever starts to look like NYT might win, MSFT will just do a hostile takeover. Market cap of NYTimes is 8B, OpenAI is 80B, MSFT is 2.7T, you do the math. reply thrwayaistartup 10 hours agorootparentprev...I think you missed the point. OAI/MS can sue the author or at least cut off API access. If that happens, the fact that OAI is under fire from NYT doesn't somehow obviate the author's need to cover some massive legal bills for the foreseeable future. The NYT case could take years. In the meantime OAI could choose to go after ToS violators. The legal system can accommodate more than one unresolved court case at a time. We don't like put a semaphore on related cases or anything like that. (Or, sometimes we do, but guess who you need to hire for many many billable hours to make that happen in your case?). So, the legal system can accommodate the NYT case against OAI and an OAI case against the author. The operative question is: can the author's pocketbook also accommodate? (Or, more to the point, can the author accommodate losing access to gpt4? What happens when he wants to launch a new feature or pivot to a new product?) reply albert180 10 hours agorootparentThen they cut off the API Process and I just make a new account. Who cares? I doubt they would sue, because the Risk of Loosing would give a precedent. It's much easier and cheaper to scare people away from doing this and writing mean letters. Those ToS would also probably be unenforceable in many countries outside the US beyond terminating an account reply thrwayaistartup 9 hours agorootparentI agree on both points. Was just engaging with the legal aspect because that's what this thread was about. But now we've converged to the actual reason the author should probably care: https://news.ycombinator.com/item?id=39049622 If you never want an exit then probably doesn't matter. reply Tommstein 7 hours agorootparentprevConsidering all the open models that already exist and are yet to be created before all the rulings and appeals are done, that toothpaste ain't going back in the tube. reply zipping1549 10 hours agoparentprevTheir TOS: Don't steal anything we stole. reply mattigames 9 hours agorootparentAlso know as the Google search license. reply fzysingularity 8 hours agoprevClassic knowledge distillation! Iâ€™d even argue that we wonâ€™t need 8x7b for fine-tuning here. Soon enough, phi-2 or phixtral models will be sufficiently powerful after fine tuning for these domains. reply keyle 9 hours agoprevWithout any changes, I've had great results with openhermes 7b chat. It covers 90% of my GPT-4 usecases, and runs fast. Highly recommend. reply brucethemoose2 7 hours agoparentYi 200K finetunes cover a lot for me. Its not just smart, but the ability to just dump a huge context on it and get something coherent (after a few retries maybe) is really cool. reply MacsHeadroom 5 hours agorootparentWhat do you run it on? reply thrwayaistartup 10 hours agoprevThis is a flagrantly blatant violation of OpenAI's terms of use for businesses [1]. I have two issues with those terms: 1. I think that eventually US courts will determine one of two things: that OpenAI et al are guilty of massive infringement, or that these sorts of restrictive terms aren't enforceable. The need that these companies are trying to treat with terms on output seems unlikely to work out in the end. But we'll see. 2. Even if the terms are enforcable, the human review step in the tweet seems like it's make OpenAI's threading-the-needle position here even more fucking difficult to be taken seriously by any jury or judge. However, enforcing the terms seems real damn hard in the case of small businesses... as long as you're not stupid enough to admit to violating them in a twitter thread, of course. I think the author is probably safe from legal action for now because I don't think OpenAI is particularly eager to test the enforcability of their terms. And even if they are, doing so in this case is super high risk and super low reward. Still, I wouldn't test it by openly admitting to ToS violation like this. At the very least seems like a good way to get cut off from OAI APIs. [1] https://openai.com/policies/business-terms reply ilaksh 10 hours agoparentNot sure they would bother suing. I don't think their TOS is fair but I would be concerned about having the API access cancelled. reply maxlamb 9 hours agoparentprevI'm sorry but could you explain how this is a violation of OpenAI's Terms of Use? Which term does it violate exactly? reply michaelt 9 hours agorootparent> 2. Restrictions [...] You will not, and will not permit End Users to: [...] use Output [...] to develop any artificial intelligence models that compete with our products and services. Of course, you can simply ignore it, just like OpenAI is happy to ignore the terms of services on scraped websites and pirated ebooks and so on. What are they going to do - claim your model is a derivative work of the training data? reply iamjackg 9 hours agorootparentprev> 2. Restrictions > (e) use Output (as defined below) to develop any artificial intelligence models that compete with our products and services. However, you can use Output to (i) develop artificial intelligence models primarily intended to categorize, classify, or organize data (e.g., embeddings or classifiers), as long as such models are not distributed or made commercially available to third parties and (ii) fine tune models provided as part of our Services; Depending on what kind of model they trained, they might be breaking these terms. reply maxlamb 8 hours agorootparentRight but the condition is for \"models that compete with our products and service\". Can you really argue that this niche app competes with OpenAI's products? Couldn't you make an argument that this only applies to products and services that directly compete with OpenAI, i.e. other LLM API's or a ChatGPT competitor such as a Claude or Bart? reply elicksaur 8 hours agorootparentThe person who created it is using it as a direct replacement to paying OpenAI. They probably wonâ€™t consider pursuing this small individual, but if a big enough company did it, theyâ€™d probably have a problem with that. reply maxlamb 8 hours agorootparentA direct replacement is still different than a â€œcompeting productâ€ which implies is sold to customers. His product (the app) doesnâ€™t compete with OpenAI. I guess a lawyer would need to chime in reply padolsey 9 hours agorootparentprevSo, best to do it without publicizing. :D reply jurynulifcation 9 hours agoparentprevHow many terms of service did OpenAI break to gather their initial training set? Turnabout is fair play, this is justifiable piracy. reply kjqgqkejbfefn 9 hours agorootparentusername checks out reply jurynulifcation 4 hours agorootparentThanks! Have a nice day. Amy thoughts on the topic of AI piracy? reply wokwokwok 7 hours agoprev> 5. swap out GPT-4 with your fine-tuned model and enjoy your healthy margins Wow, finally a meaningful AI startup playbook beyond 'be a thin wrapper around the openAI api'. First make something unsustainable, then once your users are hooked do a classic bait and switch to an inferior self-hosted AI model and reap rewards! ...of course, some people will complain, but remember, you can always just tell them they're stupid and randomly rotate the real model back in 1/10th of the time or for demos or promotions, or charge for a 'premium' model. I never really thought about this before, but I bet lots of AI startups are already doing this! (I am being sarcastic; this is some deep user-hostile-for-profit action, and yet another reason to be both skeptical of, and avoid, AI startups. Enshitification at its finest.) reply pat_space 10 hours agoprevReally smart approach. Sharing this with my fellow AI enthusiasts. reply m3kw9 10 hours agoprevIf it was so easy theyâ€™d be out of business by now reply mvdtnz 10 hours agoparentDon't underestimate how long the market can remain irrational. reply pests 10 hours agoprev [â€“] I find it so crazy everyone is so concerned about the terms of service, while in every other thread we have discussions on artists rights... Artists must allow AI companies to harvest and learn from their output but people can't take OpenAI output for the same thing? These companies already offer \"styles\" of other artists, what's wrong with making a \"OpenAI\" style? I feel so many has lost the hacker spirit. reply ben_w 10 hours agoparentToS rules are contractual, so they apply if your use of their services even when copyright doesn't. Conversely, if you don't use their services, as the output of AI models is (reportedly) non-copyrightable, I'd assume you're free to train on it so long as you don't actually make the requests yourself? But I'm not a lawyer, and I'd ask one first before doing anything that risks expensive mistakes. reply dvngnt_ 9 hours agorootparentIm not sure OP is violating their ToS since they're not selling the model access to compete with chatgpt they're two different products. reply ben_w 59 minutes agorootparentI think only some of their ToS are conditioned on competing, where I (not a lawyer) would seek advice first is: \"\"\"For example, you may not: â€¦ â€¢ Attempt to or assist anyone to reverse engineer, decompile or discover the source code or underlying components of our Services, including our models, algorithms, or systems (except to the extent this restriction is prohibited by applicable law). \"\"\" May be fine, IDK, I'm not a lawyer. I may also be looking at the wrong ToS entirely: https://openai.com/policies/terms-of-use reply jurynulifcation 9 hours agorootparentprevWhatever the laws are, imo it's pretty clear that OpenAI are robber barons of data. It's totally justified to steal from a robber baron. How many people did they ask consent from before hoovering up their data? We should be doing everything possible, including breaking ToS, to get as much value from ChatGPT reply ben_w 1 hour agorootparent> it's pretty clear that OpenAI are robber barons of data. It's totally justified to steal from a robber baron. How many people did they ask consent from before hoovering up their data? Clear morally if you assume their stated goals are bad faith and just arse covering[0], not necessarily in law â€” I have, sincerely, wondered how Google got away with crawling the web to create its search index. As this was before they were sued by newspapers for including snippets of search results, they ultimately didn't get away with it. > We should be doing everything possible, including breaking ToS, to get as much value from ChatGPT Generating additional and better models may be a tempting \"screw the rich\" option, but also the exact wrong option if you see their behaviour as IP theft that needs to be fixed â€” go to court, order the model to be destroyed, don't make more of them. [0] I don't think they were originally, but (a) I generally look for the best in people, and (b) even if I'm right it is always possible they were/will be swayed by the presence of a huge pile of non-hypothetical money. Does anyone besides the old board of directors even know why that board fired Altman a few months back? reply freeqaz 10 hours agoparentprevIs there any precedent to suggest that OpenAI is actually able to enforce their TOS? I know that if you use GPL software that the outputs aren't subject to GPL. Is that the case for OpenAI? reply ShamelessC 9 hours agoparentprev> Artists must allow AI companies to harvest and learn from their output but people can't take OpenAI output for the same thing? No one said that. Just that you're probably violating ToS and OpenAI might come after you. Is that fair in light of what OpenAI has done? Of course not. But if you're running a business, it's still worth considering. reply behnamoh 10 hours agoparentprev [â€“] Don't conflate \"hacker spirit\" with \"unethical spirit\". reply albert180 10 hours agorootparentI don't see anything unethical. OpenAI doesn't care about the copyright of the people who have generated their training data. Why should I care about theirs? reply deepsquirrelnet 10 hours agorootparentEthically you might not respect it, but practically, you might not want to be the one testing their TOS in court â€” or maybe you do. In either case, itâ€™s worth caring about at least a little. Someone with gumption might just go ahead and use GPT to train a model and then open it up as a paid competitor. Poking the bear is certainly an interesting way to spend a year for the adventurous. reply DennisP 10 hours agorootparentprevEspecially since content produced entirely by AI is not protected by copyright in the US. https://builtin.com/artificial-intelligence/ai-copyright reply MacsHeadroom 5 hours agorootparentprevYou shouldn't. You should care about the contractual terms you agreed to with them. If you did not agree to their ToS and acquired content from OpenAI elsewhere, go ahead. reply Paul-Craft 10 hours agorootparentprevDon't conflate \"ethical\" with \"legal.\" reply thrwayaistartup 10 hours agorootparentYes, but opposite conclusion. If I were the author I'd never do this because I would want an exit and this strategy + twitter thread wildly complicates any potential exit. Even though I don't think there is anything particularly morally problematic here (I'm an information freedom maximalist). reply pests 10 hours agorootparentprev [â€“] I'm not. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The creator of the Wanderer app has successfully reduced their AI costs by 99% while also improving latency and maintaining quality.",
      "The creator has shared their playbook with insights on how they achieved this remarkable cost reduction.",
      "This cost reduction is significant as it highlights the potential for optimizing AI expenses and improving performance simultaneously."
    ],
    "commentSummary": [
      "The discussions center around the use of OpenAI's models and raise concerns about the legality and ethics of violating OpenAI's terms of service.",
      "Participants debate the limitations and potential risks of using the models and discuss the value and potential consequences of different approaches to utilizing AI.",
      "The conversations also touch on copyright violations, enforceability of terms of service, data quality and transparency concerns, the use of synthetic data, and potential legal actions against OpenAI, highlighting the complexities and ethical considerations involved in utilizing AI models and enforcing terms and conditions."
    ],
    "points": 248,
    "commentCount": 103,
    "retryCount": 0,
    "time": 1705617830
  },
  {
    "id": 39043547,
    "title": "Escaping Surveillance Capitalism: Strategies, Limitations, and the Need for a Holistic Approach",
    "originLink": "https://ergaster.org/posts/2024/01/18-escaping-surveillance-capitalism-at-scale/",
    "originBody": "Escaping surveillance capitalism, at scale Jan 18, 2024 â€¢ self-hosting Our relationship with computers and phones has changed. We used to rely on software installed locally on our computers, and are now shifting towards a model based on services and companion apps, sometimes with free tiers and subscriptions. Most services are provided by organisations, who collect and sometimes resell usersâ€™ information to third parties. This massive, indiscriminate, and corporate collection of personal data is called surveillance capitalism. While organisations can argue this data collection is necessary to provide their services, this comes with significant privacy implications. Self-hosting and paid subscriptions are common strategies to escape surveillance capitalism. But what guarantees do they really offer? What alternatives exist for the general public who wants to escape surveillance capitalism, and at what cost? Paid subscriptions are not enough When services have a free and a paid tier, it can be tempting to think that the provider is going to sell your data on the free tier but theyâ€™re going to be mindful of it on the paid tier. Paying a subscription to your provider can sound like a good idea to keep your data safe, and it sometimes is. But itâ€™s not necessarily the case. As reported by The Verge, the mental health service provider BetterHelp shared customerâ€™s email addresses, IP addresses, and health questionnaire information with third parties including Facebook and Snapchat, while promising it was private. Mental health is precisely the type of information that should remain private, making this move particularly appalling from BetterHelp. Self-hosting, but as a service One of the major enablers of surveillance capitalism is centralisation. In that sense, paid subscriptions donâ€™t offer any guarantee that the provider will play fair game and keep your data private. Self-hosting is rather efficient at preventing surveillance capitalism, mostly because the data doesnâ€™t live in a central repository but on the self-hosterâ€™s infrastructure. In that sense, it doesnâ€™t directly enable surveillance capitalism. Itâ€™s important here to make a distinction between private and public information though. Posts on federated social media platforms are not centralised, but they are public and can be scraped to be exploited. The threat weâ€™re discussing in this article is a provider growing so big it can collect and exploit data that is not public, at a large scale. It should be noted that the vendor of the self-hosted solution could theoretically still gather information about the users by making its software send data to the mothership regardless of where itâ€™s installed. To an extent, this can be acceptable as long as the user explicitly knows what data is sent, can opt-out, and that the minimum amount of anonymised data is sent for clearly defined purposes. This practice is known as telemetry. Open-source software allows any tech-savvy person to look up the code and check what is actually sent to the mothership. Proprietary software makes it much more difficult. But as we discussed earlier on this blog, self-hosting doesnâ€™t scale well because it requires time and knowledge. Thereâ€™s a workaround: using software that can be self-hosted, but buying it as a service. A real life example would be the Google Drive ethical alternative Nextcloud: several providers like Ionos offer hosted Nextcloud instances. This makes solutions like these accessible (and safe!) to a broader public. Using open-source licences means that the software can be audited, but it also allows anyone to take the code and offer it as service. This can lead to a race to the bottom in terms of cost and quality when the service providers are not playing fair game: they benefit from development work they didnâ€™t invest resources in, all while not contributing financially or technically to the upstream project either. If the customers of such providers encounter problems, support is often minimal: in very budget-tight environments, losing a customer can be more profitable than investigating a significant problem. Such predatory methods harm the ecosystems in which theyâ€™re deployed: customers get bad experiences, and the upstream project gets little to no benefit. Similar behaviours have been observed in the Matrix ecosystem where integrators deployed open source products without contributing anything back. Ultimately, support contracts are an insurance for the service provider and for their customers. When the service provider pays for upstreamâ€™s support and reports an issue, the engineers who developed the product investigate the case, fix the problem, and make the fix permanent for everyone. This also allows the upstream to generate a bit of revenue, contributing to the projectâ€™s health, sustainability, and to the emergence of new exciting features. Nextcloud also allows users to sign up on third party providers directly from nextcloud.com. The sign-up feature makes it extremely easy for the user to choose a provider. Nextcloudâ€™s Jos Poortvliet confirmed to me that itâ€™s not a formal certification programme, but more of a group of companies Nextcloud trusts. Nextcloud doesnâ€™t generate revenue from this programme, intentionally, since theyâ€™re not in the business of monetising private users. Certification programmes are usually very expensive to run and not necessarily profitable for vendors. Not trusting anyone When buying a hosted service from a provider, we enable a form of partial re-centralisationâ€¦ which technically allows the provider to start selling the usersâ€™ data for profit. Thereâ€™s a third option: making sure the data can only be read by its intended recipients, turning the servers into rather dumb pipes. This is End-to-End Encryption (E2EE). It certainly sounds like a silver bullet! So why doesnâ€™t every service provider implement it, to show their good faith? Because it has drawbacks. When using E2EE, the files are encrypted. Nobody apart from their owner and people who have been explicitly authorised by the owner can read them. This means neither the server software nor the technical administrator of the server can read them either. This is often what users expect, but this has consequences! The server becomes dumb Since the server canâ€™t read the data, there are some legitimate operations it cannot perform anymore. A typical example is â€œdeepâ€ search, which is functionality where the server spends computing time to read and index all the files so itâ€™s easy for the user to query them. When files are encrypted, indexing and search can only happen on the client. Those operations are quite expensive, and the clients donâ€™t necessarily have the computing power, connectivity or storage required to do so. There are some new techniques such as homomorphic encryption that could eventually enable users to offload this computation to the server without the server learning anything about what it is actually doing but they are not yet ready for large-scale use. Having a dumb server also severely limits its ability to send automated reports or alerts based on specific workflows. In a sense, the server canâ€™t â€œworkâ€ for the user anymore and becomes nothing more than a backup service. Data can become irrecoverable With E2EE, encryption and decryption keys are stored on the device only, which is a significant risk. Letâ€™s assume you host your important documents exclusively on an E2EE service and your keys only exist on your phone. If your phone is broken or lost, your decryption keys are lost with it. There are three workarounds to avoid losing the keys entirely: Generating a â€œpaper keyâ€ (also called â€œrecovery keyâ€, â€œseed passphraseâ€, or even â€œpaper walletâ€ in the context of cryptocurrencies) directly on the client, and giving the user the 12 to 15 words to write down or print somewhere. Derive the encryption key from the userâ€™s password. This is the approach Firefox Sync is taking for example. Storing the encryption keys on the server-side, in a vault encrypted by a key derived from a passphrase. The passphrase must of course be long enough to make it difficult to break by the server administrator. The major inconvenient of these workarounds is that they require the user to either print/write a generated key and store them somewhere safe where they can recover it later, or remember a passphrase to access their en/decryption keys. If the user loses the generated key or canâ€™t remember the passphrase, their data is lost and irrecoverable. The service provider cannot do anything about it because they canâ€™t access the data. In other words: thereâ€™s no â€œforgot my passwordâ€ link anymore. The reputational risk of not being able to help users who forgot their password is often unacceptable for service providers. Even Apple who positions itself as a company respectful of their usersâ€™ privacy doesnâ€™t turn on E2EE by default, and understandably takes a lot of precautions before allowing users to turn on actual E2EE on their iCloud account. The â€œEâ€ in E2EE doesnâ€™t stand for â€œEverythingâ€ While E2EE is particularly good at preventing nosy folks from looking at files and messages themselves, it doesnâ€™t mean everything is encrypted. In particular, metadata can be sent in clear text either because itâ€™s necessary for the server to provide the service, or because the service providers can profit from it. Typically, WhatsApp is an E2EE messenger, but the provider still has access to metadata. WhatsApp also has a moderation feature that allows users to decrypt an E2EE message they were sent, and send it to Meta for moderation purposes. While moderation is a valid use case which doesnâ€™t break encryption itself, it shows that the client could in theory decrypt the message and send it to the service provider behind the userâ€™s back. This highlights that E2EE alone is also not enough: even if users donâ€™t need to trust the service provider they need to be able to trust both the protocol and the client they rely on. This means the client necessarily needs to be open source and audited regularly by an independent third party. Beyond tech As we have seen, there are several strategies to help the general public trying to escape surveillance capitalism. Self-hosting is efficient but doesnâ€™t scale well, paid instances of self-hostable software work generally well but are not a silver bullet, and E2EE is very useful to protect privacy but donâ€™t provide a full guarantee either. Ultimately E2EE is a very libertarian approach to a societal issue, taking a â€œmyself against the worldâ€ stance. It can be a valid stance, especially for minorities and in hostile contexts. But surveillance capitalism is not a technological problem. It is enabled by technology, but at the very core it is a societal problem. As Molly White said, â€œthere are never purely technological solutions to societal problemsâ€. To fight surveillance capitalism, we need E2EE, regulation, justice, and education. We need E2EE to prevent the collection from happening in the first place. We need proper regulation to define what is acceptable or not, which will ultimately define what is a viable business model and what is not. This means that the fines must make it prohibitively unprofitable to sell usersâ€™ data. We need justice and executive bodies to actually enforce the regulation. And we need education for the general public to understand the risks of surveillance capitalism. All my gratitude to Denis Kasak (dkasak), Benjamin Bouvier (bnjbvr), and Jonas Platte (jplatte) for their valuable time, comments and suggestions on this article .",
    "commentLink": "https://news.ycombinator.com/item?id=39043547",
    "commentBody": "Escaping surveillance capitalism, at scale (ergaster.org)248 points by thibaultamartin 17 hours agohidepastfavorite200 comments smeej 16 hours agoI really thought this article was going to offer a solution, not just enumerate the problems. I'm already all too familiar with the problems. I like what Umbrel[0] is doing. They're essentially expecting that just like computing was able to move from centralized mainframes to homes, servers are poised to make the same migration. I think they really need to solve redundancy, though. If I'm to self-host anything important on a home server, I need to know I'll have some way to use it even if my home server fails, especially if I'm not at home when it happens. I'd love to see some kind of system where I could partner up with other Umbrel users for backups/the ability to restore connectivity. If I knew that in an emergency, I could call my friend in town or my brother out of state and there was some procedure that would allow me to connect to an encrypted backup of what I'm needing, I would feel a lot better about taking responsibility for my own system. [0] https://umbrel.com reply RussianCow 16 hours agoparent> I'd love to see some kind of system where I could partner up with other Umbrel users for backups/the ability to restore connectivity. If I knew that in an emergency, I could call my friend in town or my brother out of state and there was some procedure that would allow me to connect to an encrypted backup of what I'm needing, I would feel a lot better about taking responsibility for my own system. I'm working on self-hosting my own \"personal cloud\" (NextCloud with a few other services), and I strongly debated just getting an Umbrel, but this is what kept me from doing so. Instead, I'm going the DIY route with two machines, one in my house and one at my parents', and we're each going to have data replicated across both machines and encrypted at rest. If Umbrel offered this out of the box, I would probably just use that to save me the time. reply Helmut10001 15 hours agorootparentDoing this for the last 7 years, too. One server at my parents, one at my home. Connected via IPSEC. I just migrated to ZFS on my offsite backup, too - this is just perfect with syncoid/sanoid atomatic backups and zfs-pull of dataset. Fine grained security but robust at the same time. It is the first time I feel reasonable safe regarding the \"worst\" that can happen. reply _a_a_a_ 15 hours agorootparentHow close geographically are you and your parents â€“ are you fed off the same electricity supply? reply Helmut10001 1 hour agorootparentWe are about 120km apart, different electricity providers. If an area this size looses energy for a considerable time, data is probably my least problem. reply Terr_ 12 hours agorootparentprevThinking of EMPs or Carrington events? reply _a_a_a_ 11 hours agorootparentMore like an electricity area-distribution fail. If it were EMP or a really major solar event, you probably have bigger concerns. reply Terr_ 4 hours agorootparentIf it's just two computers doing mutual backups, then having both stop temporarily due to a power outage isn't a big deal: All the data's still there, at rest, and being unable to access the backup server isn't a problem since you have nothing to make/send new data with anyway. reply georgeecollins 6 hours agoparentprevI believe part of the solution-- that big tech hates-- is AI bots that pretend to be us and provide so much noise they make the signal difficult to find. An example would be browser plug ins that \"click everything\". If an AI bot clicks on every ad and signs you up for every free service and fills a lot of forms with incorrect data the value of surveillance is much lower. The problem with this is Google in particular hates it. If they think you are using bots in this way they will ban you from all of their services. I have heard that. I don't know if it is true but don't want to risk it. reply kibwen 6 hours agorootparent> If they think you are using bots in this way they will ban you from all of their services. If you're self-hosting everything like the person above recommends, then the only services that they can ban you from are the services that show you ads, which sounds like a win. reply pmontra 16 hours agoparentprevThe real solution is in the last section \"Beyond tech\". Don't hold your breath though. The only viable solutions today are true self host or what they call self hosting as a service, by selecting a trusted provider. However all the big names in tech were trusted providers at some point of their history, so good luck with that. reply pcstl 16 hours agoparentprevIs Umbrel just actually usable Urbit? [0] [0] https://urbit.org/ reply smeej 14 hours agorootparentNo, I don't think so. I think it's closer to \"a plug-and-play computer for self-hostable apps, running locally, with most things configured so you're reasonably secure and you don't have to guess about everything.\" reply pants2 16 hours agoparentprevRunning servers at home is surprisingly easy, especially if you have a good ISP. With AT&T Fiber, you can get 5Gbps symmetric internet with dedicated IPs at $3/mo each. With a few threadripper servers and a basic UPS and you have the setup for a real serious home datacenter. I just haven't solved the off-site data backup part of it, yet. reply baby_souffle 15 hours agorootparent> especially if you have a good ISP. So almost nobody in the US or Canada then... I get 800/20 for ~140/month, including the $30/month fee for \"unlimited\" data. My other choices are starlink or DSL which are a fraction of the bandwith or speed. I self-host everything that's \"home-only\" at home but use syncthing, rsync and a few other thing to replicate important data to a mix of S3, backblaze, google drive and some PVs attached to a hosted k8s cluster. It works well enough. reply doubled112 14 hours agorootparentCanada is vast, and it definitely causes pain, not that I'm excusing it for the ISPs. A Bell 1.5Gbps/940Mbps FTTH connection is $120 without a deal if you're in an area it is available, but then you go three blocks down the road and all you can get is a 300/30 cable connection for $90. A little further down that road, and maybe only DSL or Starlink is available. reply Sytten 7 hours agorootparentJust got Bell 1.5Gpbs/940Mbps for 50$, no time limit. The base price was 90$, but got a big rebate because some salesman came to my house. reply agilob 16 hours agorootparentprevTwo things I want to try this month are: https://mastodon.social/@chromakode/110936177254839251 https://rsnapshot.org/ reply JohnFen 15 hours agorootparentprev> I just haven't solved the off-site data backup part of it, yet. My solution to this is to partner up with a couple of good friends who also run their own servers. We all hold backups for each other. reply ebb_earl_co 16 hours agorootparentprevWhere are you that that level of connectivity is available!? reply agilob 16 hours agorootparentMy take on it: It doesn't really matter at that level tbh. I used to chase that level of connectivity until covid happened. I was working from home on am ADSL with 37mbps download, 10mbps upload. I didn't use much internet at home before 2023 so I always had the cheapest broadband plan. Then I started WFH and the same for my partner and I had a homelab. My ISP offered me 150mbps for just Â£3 more per month, and then I realised... I don't really need it? I was just fine with the same broadband plan from 2015. I changed my location a few times, taking my homelab with me, I moved cities and countries, I'm still using the same DDNS service and as long as my 80 and 443 ports are open, I can transfer anything at any time to and from my network. It's 2023 and I'm still using the cheapest plan my ISP offers, the same hardware since ~2018 and I'm just fine with that. I run k3s, a few docker services, network-wide adblocker, monitoring in grafana and many more etc. Everything works just fine. Don't fall into the meme that you need IBM or HP server class hardware and 5Gbps fibre to run a homelab. I used to have IBM 3650x with +200Gb of RAM that I sold and bought 3x RPi4. I'm currently backing up 600Gib from my other servers, and it's completely fine that it will take a few days and nights Â¯\\(ãƒ„)/Â¯ It's a hobby, I'm not paid for it, I'm not paid to maintain 99.999%, it's OK if it's not the best shit on /r/homelab reply BrianHenryIE 16 hours agorootparentprevI just looked it up and it's available for me in Sacramento for $225/month > Single-device wired speed maximum 4.7Gbps. https://www.att.com/buy/broadband/availability.html?product_... reply BizarreByte 9 hours agorootparentprevI can get 8gbps symmetrical in Toronto. reply gumballindie 16 hours agorootparentprevIf your ISP is not reliable then a VPS or dedicated (budget permitted) are good alternatives. Install docker, and an office suite, file manager, pihole, and youâ€™re good to go. Takes minutes. No need for thread rippers either. Mineâ€™s a low spec nuc alternative. Does wonders. reply l33t7332273 16 hours agorootparentMinutes is a big stretch if itâ€™s your first time. reply gumballindie 15 hours agorootparentAll it takes is docker compose up -d. But yes, it can take even hours if there's no prior experience. Worth the cost I reckon. Edit: turns out umbrel is even easier to install. Suppose that and a trusted remote webdav install will serve most storage and file management needs. reply l33t7332273 15 hours agorootparentI agree that the steps themselves are quick, but figuring out what all needs done is the tricky bit. reply wmf 16 hours agoparentprevThe solution in the article is self-hosting as a service. You rent a VM in a data center, where servers belong, to host your stuff. Backups also seem like a mostly solved problem; there's plenty of software that can back up a server to your own cloud storage account. reply smeej 14 hours agorootparentOh I thought they were talking about SHaaS as a \"solution\" that doesn't really solve the problems, because you're either trusting the hosts not to decrypt and use your data, or you're encrypting it, which has all the drawbacks of key management. I hope we'll eventually be able to use some of the key storage/backup solutions being developed mostly in the cryptocurrency sphere. Like, multiparty computation (MPC) is agnostic to the type of key being created, and some of the social recovery methods being tested could be applied to parts of the key. Being able to protect your key from loss but also from theft is a hard problem they're highly incentivized to solve (and other people are highly incentivized to test/break). reply wmf 14 hours agorootparentThese concerns are overblown. Unless you're a criminal, nobody's looking inside your VM. Heck, AWS can't access VMs (of course it's Internet cool to not believe this). reply thinkmassive 14 hours agorootparent> Unless you're a criminal, nobody's looking inside your VM. > Heck, AWS can't access VMs (of course it's Internet cool to not believe this). Do the VMs only let someone in if theyâ€™re running a criminal workload, or how does it work? reply smeej 13 hours agorootparentprevNobody's a criminal, until they are. I wonder what it would be like to hold no opinions that you could ever imagine becoming controversial enough to get you flagged for investigation of some kind. I live in an intensely polarized country (U.S.), so it's actually hard for me to imagine caring about anything with any level of passion that one party or the other (heck, or both) wouldn't eventually want to put me on a watchlist for. What's it like to have that much trust in the ongoing goodwill of other people? reply tomkarho 10 hours agorootparent> Nobody's a criminal, until they are. With ever increasing trend of \"hate speech\" laws popping up, that timetable of \"until\" is coming up faster and faster for anyone and everyone. reply smeej 8 hours agorootparentExactly. Anyone who can't imagine a failure case where they suddenly become a \"criminal\" because people who disagree with them obtain control of the legislative apparatus haven't read enough history (or have extremely boring opinions). reply RussianCow 15 hours agorootparentprev> You rent a VM in a data center, where servers belong, to host your stuff. If you rent from an actual data center, you pay for a ton of stuff you don't really need for personal backups. If your home internet goes out and you can't access your personal cloud for a bit, it's likely not a big deal, so you don't need the level of redundancy that a data center gives you. On the flip side, the premium you pay for professionally hosted storage is enormous compared to buying a hard drive. reply wmf 15 hours agorootparentIMO the solution is cheaper, crappier data centers. OVH and Hetzner are most of the way there but there's probably more savings possible. Local storage is free or cheap with VMs so I don't see that as a problem. reply RussianCow 13 hours agorootparentI priced this out somewhat recently, and the lowest price I could get renting a server with >=2TB of storage is $11/month using the OVH Eco line, and that's without ECC (which I consider to be non-negotiable), FS-level compression (IIRC you can't change file systems with OVH), or redundancy in case the server/disk fails. I'm currently working on a DIY setup with two nodes equipped with 8GB ECC memory, 2TB of storage (with Btrfs compression to get even more storage out of it), and considerably more processing power than the OVH servers. My total up front cost is going to be about $400, with an estimated $25/year in electricity. The most comparable OVH offering would cost $403 in the first year (with RAID but without a second node), so my DIY solution basically pays for itself after that, and I can upgrade the hardware anytime I want. Of course, there is an obvious argument to be made that my time is worth more than the cost savings, but I've been learning a lot so I instead consider it a free education. :) reply cabalamat 16 hours agoparentprev> I think they really need to solve redundancy They could offer a service that backs up your local Umbrel server to their central servers. This would provide reassurance that your data is backed up, and give them a revenue stream. reply cl3misch 15 hours agorootparentOr an append-only, E2EE backup to another Umbrel at e.g. your parents house? reply bawana 14 hours agoparentprevsynology has this with their NASes. Makes spinning up your own private cloud simple. reply FloatArtifact 14 hours agoparentprevUnfortunately I see nothing about backing up and restoring apps data reply caseysoftware 16 hours agoprevI've used https://adnauseam.io/ for years. It's great. First, it hides (most of) the ads making the internet more tolerable. Then it \"opens\" them in memory and clicks on ALL of them making your profile worthless. The last time I pulled up my Google profile, it said I was a 18-99yo, both male and female, and was interested in EVERY topic they listed. It works in both Brave and Chrome but isn't available in the Chrome Extension Store for some reason.. ;) reply autoexec 16 hours agoparent> I've used https://adnauseam.io/ for years. It's great. No it isn't great. It's stupid and dangerous. It does nothing to make your data \"worthless\". You're only giving data brokers and the people who use them more highly valuable data to use against you. Please see my comment here: https://news.ycombinator.com/item?id=39043547#39044239 reply l33t7332273 16 hours agorootparentMaking the data inaccurate absolutely makes it worthless; itâ€™s worth is in its accuracy. reply autoexec 16 hours agorootparentData brokers do not care about how accurate their data is. At all. Not even a little. It's highly valuable to them no matter how inaccurate it is, and that data will be used against you even if it's entirely inaccurate. reply beanjuice 15 hours agorootparentCan you elaborate about what you define as \"used against you\" even if it is entirely inaccurate? What is the use case of inaccurate data with which you are concerned? reply baby_souffle 15 hours agorootparent> Can you elaborate about what you define as \"used against you\" even if it is entirely inaccurate? Hypothetical: $company you're trying to use needs to \"verify\" you using $inaccurateData from $vendor. You're absolutely screwed if the verification questions you're asked are relying on the \"polluted\" answers Similar vein: if the \"polluted\" data indicates you might be gay or replublican or musilim or into some seriously unhealthy lifestyle choices like smoking and $someCompany decides that you're a smoker and therefore your too risky to insure. no data >>> polluted data. reply RussianCow 13 hours agorootparentSerious question: Who is using browser data for verification?! It's alarming to me that this is even a hypothetical scenario. All identity verification systems I have ever used in the US have been through a credit agency or something similar. I can't imagine any use case that would use your browser history or ad data for these purposes. Do you have a real-world example? reply pixl97 15 hours agorootparentprevOr, if state level actors are looking at your data they are buying from companies, the appearance of intentionally corrupted data could invite more scrutiny. reply eindiran 15 hours agorootparentIf state-level actors are looking into your data with any amount of individual scrutiny you are already fucked, this is a ridiculous reason to not use ad nauseum. reply pixl97 13 hours agorootparentYou're looking at this backwards... Imagine being in China where they tend to watch you and make profiles on you. Then suddenly the profile of who you are goes completely random. Is it possible this gets the attention of state-level actors where you had none before? reply baby_souffle 11 hours agorootparent> You're looking at this backwards... Exactly. Any argument that boils down to \"but the profile is basically useless\" will always be inferior to \"there is no profile\" reply l33t7332273 15 hours agorootparentprevIsnâ€™t the alternative in the verification case just that you donâ€™t get your account because they canâ€™t verify you? reply caseysoftware 14 hours agorootparentVerification questions are based on credit history - addresses, vehicles, family members, etc - not browsing history so this is a non-issue. reply BlackjackCF 14 hours agorootparentprevAnother example that I think captures the spirit of autoexecâ€™s point is credit fraud. Are you the one taking out credit cards and potentially tanking your credit score? No. Does it still negatively impact your life? Yes, because the information landlords/banks receive from credit unions only shows the low credit score. Do the banks/landlords care about the fact that itâ€™s fraud? No. Itâ€™s ultimately YOU who has to do all the leg work to report the fraud, make sure that your credit history is fixed, and that your credit is frozen as a deterrent to for future fraud issues. reply lcnPylGDnU4H9OF 15 hours agorootparentprevIt's in the comment they linked to. Good points, to be fair. reply 0x457 14 hours agorootparentprev> The last time I pulled up my Google profile, it said I was a 18-99yo, both male and female, and was interested in EVERY topic they listed. So you see how data-brokers having this data on you is equal to not having any data on you if their data is garbage? reply margalabargala 9 hours agorootparentDepends. Is your goal to not show up on lists, or to show up on lists above and beyond the ones that are \"true\"? Asking for a list of smokers? You'll pop up. Ask for a list of pregnant women? There you are. Likely gun owners? You're on that list too. None of the people requesting these lists are checking the rest of that person's profile to look for conflicts. They just feed all the profiles into the data machine and run everything en masse. So does this prevent the data brokers from having an accurate profile on you? Sure. But it is absolutely not equal to them having no data on you. reply 0x457 9 hours agorootparentIf we all non-smokers show up on a smokers list - There is zero downside for me, but someone is going to waste money targeting me as a smoker. Will it narrow down if someone is trying to track me? Probably. reply autoexec 9 hours agorootparent> If we all non-smokers show up on a smokers list - There is zero downside for me Except for when your health insurance company sees that and starts charging you more because of it, or your life insurance rates go up because of it, or your homeowners insurance goes up because of it, or your employer forces you into a smoking cessation program because they made you sign some kind of \"smoke free pledge\" for their own insurance reasons and now they think you're lying, or when someone decides not to date you because the background check they ran on you made them think you lied in your online dating profile when you said you didn't smoke, or when society gets real weird in the future and smoking goes from being \"unacceptable in public\" to \"child abuse\" and now CPS is wanting to investigate you, or who the hell knows what other thing could come and bite you in the ass now that you've got \"smoker\" in your permanent record and everybody feels entitled to dig into your personal business whenever they think it might give them some advantage. That's the world we live in. Anybody willing to pay gets to look into the most intimate parts of your life that are none of their business and that ends up affecting your life in ways you'll never see coming and you'll probably not even know why or when it's happening. The more data you put out there for people to find, they more they'll find ways to screw you over with it. reply gigel82 10 hours agorootparentprevData brokers rarely collect from ad companies. They buy in bulk from the states who are all too happy to sell them driver licensing data, plus property records and other public sources. reply autoexec 8 hours agorootparentThey get data from anywhere and everywhere they can. They also get ad data from your internet history which most ISPs are happy to sell to them. reply lcnPylGDnU4H9OF 16 hours agoparentprev> isn't available in the Chrome Extension Store for some reason Obviously it's because â€œAn extension should have a single purpose that is clear to usersâ€¦â€[0]. Given how \"questionable\" the reason is, I can't really think of a better endorsement. 0: https://adnauseam.io/free-adnauseam.html reply guilamu 16 hours agoparentprevMore importantly it's available for Firefox. reply daed 16 hours agoparentprevI'd love to use this but is there any risk that this will get Google to flag me as a bot/malicious? I wanna make sure I can still pass captchas and don't screw anything up for testing on my dev machine. reply caseysoftware 15 hours agorootparentI have not experienced this in any form and I build security, bot detection, and similar products. reply kyrofa 16 hours agoparentprevI hadn't heard of this, thank you! I'm giving it a shot now. reply gear54rus 16 hours agoparentprevCan you share the link where you've seen your profile. I wanna see if AdNauseam is as effective on my side. reply caseysoftware 16 hours agorootparenthttps://myadcenter.google.com/ and https://myaccount.google.com/data-and-privacy will show the stuff they share reply blahyawnblah 13 hours agoparentprevIsn't this kind of unethical? There are plenty of people/companies running ads that are just trying to get some traffic and you're costing them money. reply tourmalinetaco 1 hour agorootparentAds are unethical. Loud annoyances plastered across the screen in a frail attempt to part me of my money after already stealing my time. Also Google is the one footing the bill, so if anything itâ€™s unethical to not be running this. reply cherryteastain 15 hours agoprevI agree with the author's assessment that we have a societal problem first and foremost. However, a key component of that societal problem is that most (99%+) do not care about surveillance to the degree that they would change their behavior. Almost all my friends who use social media are aware the apps spy on them. They all have an anecdote like they were talking about X with their friend and when they scrolled Instagram/Tiktok an ad for X showed up, and they all say (unprompted) that it's creepy. When I suggest to them that maybe they should stop using Instagram etc, or at the very least use it on the website, to prevent this, the reaction invariably an excuse to keep using it. You can't tell these people to use Nextcloud or whatever over iCloud. They would never do it. The only thing that'd get them to switch is to offer more convenience/greater network events. Benjamin Franklin's famous quote goes \"Those who would give up essential liberty, to purchase a little temporary safety, deserve neither liberty nor safety.\". With tech, the same maxim applies, if you replace safety with convenience. reply fritzo 8 hours agoparentI've started mentally dividing people into (i) app addicts who share their gps location with strava/trailforks and (ii) luddites whom I can invite to hike/bike on www invisible trails. EDIT 'addicts' is indeed a strong word, but how else can I say \"they feel bad when they don't turn on tracking\"? reply splaca 15 hours agoparentprevBen Franklin's phrase seems to be quoted often in this kind of discussion but I haven't seen anyone explain (1) why one thinks he's right; and (2) why that would translate to tech and surveillance. Or, to be more upfront: I simply don't think blaming individual people (and deciding whether they \"deserve\" whatever) is very fair or productive. reply whichfawkes 10 hours agorootparentThe fact is it doesn't matter what people \"deserve\". People who are willing to forsake some degree of convenience can be granted greater privacy by simply informing them. People who are seeking convenience will always be giving up something else. In this domain, they're often giving up privacy. A lot of people these days are essentially forced to seek convenience. They don't have the time or money to spare to do otherwise. reply tomxor 16 hours agoprev> Data can become irrecoverable This seems to be becoming less and less of a drawback when compared to Google where exactly the same things can happen when people seem to get arbitrarily banned from their account with no recourse. Not to mention the recent push for passwordless keys that can be lost with the device. Sounds like it would be better if anything because at least you have to pay for the data hosting, and so being encrypted there's no way for them to block you for entirely opaque policies or decide one day that their abuse heuristics don't like you any more. In reality the primary friction to adoption with any of this entirely plausible tech is inertia. It's going to take something colossal fuck up to convince even a large minority to bother using non-free alternatives. reply CYR1X 17 hours agoprevWait, the paid tier of a service that has a free tier almost never means they're stopping data collection at the free tier of users. This article seems to confuse that with switch to a different service provider that is paid only. It then goes into self-hosted, but wait why don't you just pay someone to self-host for you? Bad article. reply dangus 17 hours agoparentYeah, thereâ€™s a huge difference between (e.g.) ProtonMail and â€œthe newâ€ Outlook. Some companies sell their privacy policies as a feature. The issue is that a lot of customers donâ€™t really care about that feature and thereâ€™s no strong regulation to protect them. reply JohnFen 16 hours agorootparent> The issue is that a lot of customers donâ€™t really care about that feature Another issue is that a lot of people simply don't believe what companies say in privacy policies, with some justification. reply AJ007 16 hours agorootparentprevThe problem is avoiding \"surveillance capitalism\" or even generally \"privacy\" isn't a selling point for the mass market. Things which matter to people: - Do you like moderators in a foreign country being paid $2 an hour reviewing your personal photos? - Do you agree that your personal messages to a friend can be retroactively edited if you sent something that was \"disinformation\"? - Would you like files on your computer's personal hard drive copied in to a commercial cloud service and deleted locally because you accidentally mis-read or mis-read on a single pop-up message? - Would you like to read advertisements and news articles when launching your favorite application? - Would you like those ads and news articles to become more invasive over time based on which ones you looked at last time? - Would you like the owners of the app store you purchased your favorite app from make more net profit from the sale than the developer who built it? - Would you like your favorite app to run differently than it did yesterday, without choice or warning? - Would you like your favorite app to no longer be usable or downloadable because development ceased? Even someone who broadcasts their personal life publicly, with strong signals of their wealth and where they will be to rob or kidnap them, will have issues with things in this list. reply pmontra 16 hours agorootparentAll of those points are unknown unknowns or minor inconveniences to all of my non technical friends except these two: > - Would you like files on your computer's personal hard drive copied in to a commercial cloud service and deleted locally because you accidentally mis-read or mis-read on a single pop-up message? A friend of mine was bitten by this and One Drive (is that the subject, right?) is really difficult to understand and get right. I had to configure it on a server of a customer. We needed a remote share and it does not behaves like that. Nobody expects it to work in the way it works. There is something wrong in all of its design and UX. > Would you like your favorite app to no longer be usable or downloadable because development ceased? Another friend of mine is keeping her very old phone alive because it's the only way to operate I don't remember what (heating?) The app does not work with both new Android and new iOS (she has both) so she has that old phone at home in a drawer. I just refuse to buy anything that requires an app to work. I want physical switches, knobs and displays built into the device. reply AJ007 15 hours agorootparentThey are unknowns until they encounter them directly. As Apple and Microsoft receive their revenue growth from advertising and subscription services, they will all get worse and encountered more frequently by more users. I got a few 'what the fuck' messages from distant contacts when they discovered that Facebook modified or deleted messages, which they believed to be private. This drove significant growth in Signal (which probably was under or not reported.) I'm not sure if people don't actually care about privacy/security, or rather they don't really comprehend how this stuff works. reply loughnane 16 hours agoprevI think for self-hosting as a service to take off you need to persuade people that it's 10x better for non-privacy reasons. That's hard to do because the biggest value prop for most folks would be media, but unless you already have a collection it's hard to legally get your hands on DRM-free digital media. When I look at the things I self-host it's mostly media (beets/navidrome/jellyfin/etc) and privacy/longevity-focused alternatives (photoprism/miniflux) Only a few (huginn/archivebox/rmfakecloud/llamacpp) are for general usefulness, but the applications are pretty tech-heavy and not for the average person. I wonder what applications would knock the socks off a non-technical person. reply MeltedVoltage 15 hours agoparentI think self-hosting could be viable for more people if two things would happen: - ISP's need to give a permanent IP's and more upload bandwidth in \"regular\", low-cost internet plans or at least a \"self-hoster\" addition - There needs to be a protocol standard to communicate with home routers for auto-configuring the network in a safe way to be able to access services and applications on certain devices outside of the local network. I don't think it currently is possible in a robust enough way With those two things I can imagine dedicated appliances that are accessible enough for non-technical users. But the experience has to be as seamless as video game consoles in order to reach \"the masses\" reply loughnane 14 hours agorootparentThat's a good point. Last I checked I pay $15 for a static IP. For access, i feel something UX-friendly powered by wireguard could do the trick. My own use is to just flip the \"connect to my home server\" button in wireguard and then I have access to everything. I leave it on most of the time but still have to toggle it if things get weird. Seems like that ought to be able to be wrapped in something prettier. I def think a \"box you set up\" is the right way to do it. reply rglullis 16 hours agoparentprev> unless you already have a collection it's hard to legally get your hands on DRM-free digital media. Sneakernet meets the fediverse: https://funkwhale.audio reply cherryteastain 15 hours agoparentprev> it's hard to legally get your hands on DRM-free digital media Time to hoist the jolly roger and plunder the high seas, friend reply loughnane 14 hours agorootparentI'm sure most folks on this forum are capable of doing that, but if the question is mass-adoption I think illegal copying of other files---even if the law is bad---is a bar. reply siliconc0w 16 hours agoprevAs a possible solution we can decouple data storage from data services. For data that doesn't need expensive computation, we can further decouple key owners from data storage. Users always own their data, they can choose which data services, storage, or key manager to use and they should all interoperate. This is already a pretty common pattern in the cloud, just the same business entity owns all three. You basically need legislation that says business entities must interoperate with different data storage or key providers. So you can subscribe to gmail from google and they store your data in Amazon or maybe EFF's data storage provider. You can then get fine-grained audit trail of how and when your data is accessed. We can then come up with standard rules like maybe your data is only accessible without your end-user credential (i.e your computer+password) for law enforcement or limited operational activities described by the provider and approved by you(or your delegate). reply 1vuio0pswjnm7 11 hours agoprev\"We used to rely on software installed locally on our computers, and are now shifting towards a model based on services and companion apps, sometimes with free tiers and subscriptions.\" Everything I rely on is local. No reliance on remote services or companion apps. It is not like I haven't tried. I tried apps. But I failed to become addicted. I always end up accessing the endpoints from a laptop instead of a phone because it's easier and more flexible. I find a UNIX-like OS I can modify, compile and control paired with full-size keyboard and display to be more versatile. I still use offline storage. When it comes to the prognostication of so-called \"tech\" bloggers/journalists, \"we\" is not me. There was a story yesterday on HN about a school that does not allow smartphones. It described a multi-day school trip where no phones could be brought. After a short time, the article suggested none of the students missed their phones. This is how I see \"services\" and \"companion apps\". After a relatively short time without, people would forget about them. Whereas I am not going to forget about a UNIX-like OS that I can control and jump on to some new trend where I cede control to someone else. I rely on being able to control the computers I own. Giving away control is not an appealing proposition. The people marketing these \"solutions\" are certainly not ceding away any control. Instead they are gaining it over other peoples' computers in spades. reply SushiHippie 16 hours agoprevMy 2cts about Nextcloud and why *I* think it's not viable as an alternative for the average user: I host my own nextcloud since a few years. I mostly use it as an alternative for google photos/icloud photos, basically backing up all the images from my smartphone. Hosting the instance is one thing, but setting up the automatic upload on your phone is another thing. The automatic photo upload feature in the official nextcloud app is most of the time broken and slow. And on iOS you need to keep the nextcloud app open and the screen unlocked, otherwise it won't upload. That's why I use FolderSync on Android, but I don't think the average user wouldn't want to set this up and might even misconfigure it, which could just delete all images. And Nextcloud itself is just very slow. With google photos you can just scroll through thousands of images and easily find the image you took 3 years ago. If i do this in nextcloud, I already had the following stuff happen: - Your browser freezes - The Nextcloud server (php-fpm in my case) OOMs (it used around 15-20G of RAM) (The OOMs also often happen when syncing with FolderSync.) I definitely wouldn't recommend it as a google photos alternative. I'm not complaining as I didn't pay a penny for nextcloud itself (only the cost for the dedicated server I rent). And I still use it, as there is no better alternative. But for the \"mass\" there is no convenient and comparable alternative to the \"surveillance capitalism\" services. Nextcloud is good enough for me, as its the only viabke option, but IMO it doesn't cut it for leaving the other services at scale. reply the_pwner224 16 hours agoparentI switched from Nextcloud to Syncthing a while ago. ST is a plain file syncing program, like Dropbox, but distributed P2P (you can have a server running it as an always-on node). I sync the Camera & Screenshots folder on my phone to my computer & server. If you have multiple phones add the folder on each phone. It's bidirectional so photos you take or files you add will show up on all devices. It works much better than Nextcloud, and admin/maintenance/setup are all much easier. For calendar & contacts sync I use Radicale. Syncthing with a regular shared folder + camera folder + screenshots folder combined with Radicale covers everything that I used Nextcloud for. However this is all on your devices, there's no web interface to access your files from other devices. reply undersuit 9 hours agorootparent>It's bidirectional so photos you take or files you add will show up on all devices. My camera devices are set to send only and while my receving devices are a tight knit send/receive group they're all set to the advanced option of \"ignore deletes\". Makes it a bit of a pain to delete the file off of 3 servers, but now my laptop and my smartphone don't sync with each other and someone can't delete media off of my portable device in an attempt to destroy it if it's already been synced. reply SushiHippie 16 hours agorootparentprev> However this is all on your devices, there's no web interface to access your files from other devices. I tried Syncthing and it worked really well and it was fast. But I definitely want to have a webui, like Nextcloud, that's why this is sadly not an alternative for me. (Though I use syncthing now for other stuff, where I don't need web access) reply jw_cook 15 hours agorootparentIf your main use case for a web UI is browsing photos, have you considered a self-hosted photo gallery like PhotoPrism, Immich, or Lychee? I'm in a similar boat, where I use NextCloud but really wish there was a better option (especially for mobile photo sync). Syncthing + Photoprism is currently at the top of my list of possible viable alternatives. reply SushiHippie 10 hours agorootparentPhotoPrism could have been an alternative, but the FOSS variant does only have admin accounts, and does not allow to have \"normal\" users. I also tried Immich, but it just didn't work well. I think I didn't try out lychee, but I took a look at the demo site, and it seemed a bit to minimal for me. Though I'll definitely keep an eye at these galleries, as I don't think Nextcloud will improve their UX in this regard. Syncthing seems to be by far the best solution for synchronising files, I just wish there a gallery that would suit my needs. If I was proficient in frontend development I'd already have created one. reply sureglymop 15 hours agorootparentprevSince this is about privacy, do note that syncthing relies on a discovery server to find peers on the internet. You should probably run your own public discovery server if you care about privacy and want to seriously use it outside of your home network. reply vishnumohandas 15 hours agoparentprev> there is no better alternative If your primary device is Android, please check out Ente[1]. We are an E2EE alternative to Google Photos. We had launched on HN[2] a while ago, and have been working towards feature parity. We aren't \"there\" yet, but hope to soon be. If you've any feedback, please share it with vishnu@ente.io, I'd be grateful! [1]: https://ente.io [2]: https://news.ycombinator.com/item?id=28347439 reply tourmalinetaco 22 minutes agorootparentHave there been any considerations for self-hosting? I understand that is your â€œsecret sauceâ€, in a way, but I thoroughly believe thereâ€™s a compromise here. Perhaps offering source code via GitHub (with no binaries) and then offer the full source code + binaries via purchasable licenses? Similar to TagSpaces business model of selling binaries to their app, while maintaining it openly on GitHub: https://www.tagspaces.org/products/ https://github.com/tagspaces/tagspaces Either way, will definitely be keeping an eye on your app, it seems ducking cool ;) reply SushiHippie 10 hours agorootparentprevThis does look good, but it does not seem to be self-hostable. Though this may be a good alternative for people that do not care about hosting their own services! reply eks391 13 hours agoparentprevI currently use nextcloud, but while I was deciding my infrastructure, I also tried syncthing. I'd recommend trying it out since your preferences make me think it may be a better fit for you. Its pretty painless to set up, auto syncs based on your preferences. I dont know how fast it is, since I only used it for trivial testing purposes while deciding which to use, but I'd say worth comparing. reply pricechild 16 hours agoparentprevYou're not wrong. Have you tried https://apps.nextcloud.com/apps/memories - it solves all of my issues with photo management in nextcloud. (Together with the recognise app) I don't see why they haven't replaced the default photos app with this already... I think improving the photos experience would have the biggest impact on home users, but nextcloud certainly seems to be chasing the enterprise/gov market in the EU? I'm not complaining! reply SushiHippie 16 hours agorootparentYes, this makes it at least usable, without it it is even worse. But it is still worse compared to google photos/icloud photos/etc. The issues I described above also happened with memories. I think improving performance and memory usage in their webdav implementation would, by far, have the biggest impact. Nextcloud is a fork of Owncloud, and Owncloud did the right thing to move away from php for the webdav implementation, though they are now rewriting it once again, which I don't really like, as they store the files and all information in some binary format. reply martinbaun 17 hours agoprevThis is so true and one of the reasons why (shameless plug coming in) I made our project management tool Goleko.com able to self-host without any connection to our main servers. reply bradford 16 hours agoprevI'm of the opinion that 'surveillance capitalism', as described in this article, is a problem of policy/legality, not technology. Technology minded individuals keep looking for a technical solution to this problem. I'm hesitant that a technical solution exists. Unfortunately, I also don't expect Congress to promptly pass new legislation that competently addresses the problem. (I am more optimistic about the efforts by the EU and individual US states.) reply closeparen 16 hours agoparentProbably the most material privacy issue for most people is that very basic operations like establishing your identity, providing a contact method, and making a payment all involve giving your counterparty a long-lived identifier which they must keep secret and which anyone they leak it to (intentionally or not) can harm you by abusing. These identifiers are necessarily given out to hundreds of unsophisticated and often trashy operations like supermarkets, car dealers, e-commerce retailers, and soon (sadly) app developers. Unlike the FAANGs of the world, these people have never heard of cryptography and donâ€™t blink twice about selling Excel spreadsheets for a few extra pennies. But the need to share secrets with them is a technological problem â€” public key cryptography could serve these used cases without giving the counterparty something to leak. reply bradford 14 hours agorootparentI may have interpreted the problems addressed in the article differently. Certainly, privacy incidents can occur due to mishandling of sensitive information (i.e., secrets, identifiers). Addressing these are a no-brainer and something that technology can and should address. I interpret the article as addressing a second kind of privacy issue that isn't due to mishandling. Instead, it's part of the profit model for many major tech companies: advertising. In this case, the privacy issue isn't a mishandling, it's by design and explicitly disclosed in the Terms of Service. (I can't say which one is a bigger issue at large, but I believe policy is needed to address the second issue). reply LikeBeans 8 hours agoprevHonestly I'm not so much worried about using Google Photos. However I'm worried that I now can't easily leave due to the amount of photos we have. So here's my wish: I wish there is a service that can copy my photos in Google Photos to Amazon Prime Photos or iCloud. But without consuming my bandwidth or time. So like here's $20 or $50 and you duplicate my photos between the two and let me know when it is done. Perhaps I would do that once a year so needs to be incremental obviously. reply kredd 16 hours agoprevMight be a tangential question, but does trying to escape surveillance matter? I somehow made myself believe that even if I self-host everything, avoid all the tracking, yada yada, unless everyone I hang out with does the same, the data brokers technically will get some information about me. Realistically, you have to be very tech-savvy to properly avoid tracking, and pretty much avoid any modern social life. That already excludes most of the people in this world. And I, for sure, don't want to live a bunker-basement family life, with no outside fun. In the end, I'm not sure how to solve it, and probably making it worse with my pessimism. But is this actually a winnable battle? reply AJ007 15 hours agoparentYou don't need to/probably can't avoid the data brokers, you just have to inject enough noise in to their data to make it worthless. The data brokers are probably the most benign of all of the parties that expose you to security risks. If you live in a high risk area (like Mexico), and are middle class or above, then you need to do some advanced stuff because cartels have access to things such as your live phone location data. Ultimately you can't escape surveillance in the general sense. You have a face (probably) and face tracking is ubiquitous and continuous. Google, Bing, and so on crippled their reverse image search for faces, but that misrepresents how good it is. reply JohnFen 15 hours agoparentprev> does trying to escape surveillance matter? It certainly does to me. I can't plug all of the data leaks to these companies, of course, but this isn't an all-or-nothing sort of thing. Reducing the amount of leaking is still valuable. reply l33t7332273 15 hours agoparentprevThe amount that you â€œwinâ€ is inversely proportional to your participation in modern life. Personally I donâ€™t consider privacy important enough to worry if the McDonaldâ€™s app harvests my data in exchange for the free coffee. reply JohnFen 15 hours agorootparent> The amount that you â€œwinâ€ is inversely proportional to your participation in modern life This is true, but I think that reducing participation in a dystopia isn't necessarily a bad thing. reply hnthrowaway0328 17 hours agoprevI wonder what if people start to send 10x garbage data. reply autoexec 16 hours agoparentSurveillance capitalism doesn't care at all about the accuracy of the data that they have. There is literally no such thing as \"garbage data\" to data brokers. It's all just data, and all of it is valuable. That's why projects that claim to \"pollute\" your browsing history like RuinMyHistory, noiszy, adnauseam, and TrackMeNot are not only pointless but also dangerous. The data being collected about you will always be used against you, no matter if it is accurate or not. If your browser randomly browses to webpages that gets \"this person is a muslim\" or \"this person is gay\" added to your dossier it doesn't matter if it's true or not, when your next would-be employer or would-be landlord who hates muslims or gay people uses a data broker for \"background checking\" and sees that, you're not getting the job/apartment. They won't tell you why, you'll just be rejected/ghosted. If you're a 40 year old man, but your browser add-on convinces a data broker that you're a 34 year old woman seeking an abortion, that data can still cause you end up the target of a lawsuit in Texas and it will take a non-zero amount of time and money to clear that up. If someone in your zip code kills someone using a certain type of plant, or household cleaner/chemical, or medication and your add-on has been browsing sites about that thing, you can end up on the police's suspect list. If you only make $30,000 a year but your add-on searches for yachts and expensive jewelry often enough to convince a data broker that you've got tons of money then it doesn't matter that the data is wrong, the next time you try to book a hotel or order something online you can still be charged a lot more than you would have been charged otherwise. Handing extra fake data to people whose only goal is to use data against you is just handing them more ammunition. It doesn't matter if it's \"garbage\" to you, it's still something they can and will eventually use against you. You cannot know what will prejudice someone against you. The more data is in your dossier, the more opportunity there is that you'll meet the right (or wrong) criteria. No data broker is going to look over your dossier and see that there's inconsistencies and go \"Damn it! This genius has ruined my data! Now I have to throw all this data away as it is now worthless!\" They aren't even going to look over your dossier. They're going to get paid to hand over a list of people flagged as being 'X' and your name/address/identity will show up along with everyone else flagged as being 'X' even if your name gets pulled up again when someone else pays that same data broker for 'Y' which is the opposite of 'X'. The data broker gets paid either way. reply teeray 15 hours agorootparentIf the accuracy of the data are not intrinsic to their value, then data brokers could literally just manufacture data. â€œIs this person X?â€ flips coin â€œyes!â€ Who are you to say otherwise? We have a vast network of blah blah data sources and advanced AI inferencing. They would absolutely do this if they could get away with it because it is dramatically cheaper. Targeted ads exist. People find them â€œcreepy,â€ which implies that they are targeted based on factual data. Therefore, we know that data brokers are taking the more expensive route and collecting factual data (or striving to). They would not do this without a profit motive. Perhaps their data are being compared with a competitorâ€™s to enforce qualityâ€¦ we donâ€™t really know. But we know that they value the quality of their data because their customers do. Consequently, it must be the case that deliberately polluting their data devalues their product and erodes their business model over time. reply autoexec 14 hours agorootparent> If the accuracy of the data are not intrinsic to their value, then data brokers could literally just manufacture data. â€œIs this person X?â€ flips coin â€œyes!â€ Who are you to say otherwise? We have a vast network of blah blah data sources and advanced AI inferencing. They would absolutely do this if they could get away with it because it is dramatically cheaper. Yes they could, and I suspect that some actually do stuff dossiers with total fabrications. The accuracy of the data being collected and the targeting itself is known to be very questionable(see https://joindeleteme.com/blog/incognito-september-2023-data-... and https://www.forbes.com/sites/augustinefou/2021/04/19/ad-rele... and https://news.ncsu.edu/2022/03/new-study-reveals-why-facebook... and https://www.forbes.com/sites/augustinefou/2021/05/05/why-is-...) and I don't know a single person who feels like every ad they see is relevant to them. Measuring the effectiveness of advertising has always been difficult. Targeted ads can be very effective at times, and at others do no better (or worse) than chance. The many clear failures of targeted advertising hasn't hurt the industry though and it isn't likely to either. Now companies are advertising AI as the new thing to increase their accuracy. How well that works for them remains to be seen. reply lcnPylGDnU4H9OF 16 hours agorootparentprevAll of these -- barring illegal discrimination -- are actual problems that will come to light when it turns out the information is incorrect. > If you're a 40 year old man, but your browser add-on convinces a data broker that you're a 34 year old woman seeking an abortion, that data can still cause you end up the target of a lawsuit in Texas and it will take a non-zero amount of time and money to clear that up. It will make the data broker look bad when the prosecutor finds out that they fabricated my abortion. It might be annoying and stressful for me but I'm sure I'll get through it. It seems like I would have the same response to everything except the illegal discrimination as mentioned. If this is the result of me running the extension, I only see upsides. reply timmytokyo 15 hours agorootparentGood luck trying to figure out why your rental or employment application was denied. reply autoexec 15 hours agorootparentprev> All of these -- barring illegal discrimination -- are actual problems that will come to light when it turns out the information is incorrect. If I need a hotel and the place I'm booking decides to change me more than they would have otherwise because they're mistaken about my finances, I'm still getting charged more. None of that comes to light. When a store tells me that their return policy is \"next day only, with receipt\" but they tell the next person in line it's \"30 days no questions asked\" all because their \"consumer reputation service\" told them I was unreliable when I'm not, I'm still stuck with their shitty return policy for \"bad\" customers. None of that will ever come to light. When my health insurance company jacks up my premiums because a data broker told them that I've been spending more time at fast food restaurants, I'm never told that's what happened, I just get a bigger bill. Nothing ever comes to light. When the police arrest me and question me because of my search history, maybe the truth comes to light, but not without significant costs to me. Most of the time when people use the data that's been collected about you as a result of surveillance capitalism you have no idea that it even happened or why. You're just charged more money than you would have been, or you aren't offered opportunities you would have been given, or you're just rejected for something you wanted, etc. Nobody tells you why. There's not an investigation into how it happened. There is no transparency and there is zero accountability for errors. > It will make the data broker look bad when the prosecutor finds out that they fabricated my abortion. When have you ever heard of a data broker taking a huge hit to their reputation because they have inaccurate data? It doesn't happen. What data broker has a great reputation in the first place? Everyone using data brokers knows that the data is not 100% reliable. It doesn't matter. It's usually just a numbers game. Even when it's only for an advertisement, they know that not everyone they're targeting is going to buy something. That doesn't matter to them as long as some percentage does. reply ryandrake 15 hours agorootparentDo we know whether any of this stuff is actually happening, in reality, to actual people, based on some IP address's history of clicking ads? Any concrete examples you can link to? reply autoexec 14 hours agorootparentData brokers get their information from all kinds of sources. There is no complete breakdown on where it all comes from in every instance that the data is used, part of the problem with surveillance capitalism is that there is zero transparency and near zero accountability, but yes, data brokers do collect your browsing history and that includes what ads you view/click As for examples of that data being used \"in reality, to actual people\" you might find some good info in these links: Employers and landlords using data brokers for hiring/rental decisions: https://nypost.com/2022/12/20/how-employers-spy-on-your-sear... https://privacy.com/blog/what-are-data-brokers https://www.ftc.gov/news-events/news/press-releases/2014/04/... https://www.fastcompany.com/90269688/high-tech-redlining-ai-... Health insurance companies: https://www.npr.org/sections/health-shots/2018/07/17/6294415... https://www.cbsnews.com/news/the-data-brokers-selling-your-p... Police: https://www.newamerica.org/oti/articles/how-data-brokers-and... https://www.nbcnews.com/news/us-news/google-tracked-his-bike... https://cdt.org/wp-content/uploads/2021/12/2021-12-08-Legal-... https://www.eff.org/pages/atlas-surveillance Store prices, return policies, and hold times: https://www.cnet.com/tech/services-and-software/mac-users-pa... https://www.nytimes.com/2019/11/04/business/secret-consumer-... Keep in mind that this is a rapidly growing space. Travel sites, retailers, even grocery stores have been looking into how to use this kind of data to set the prices of their goods on an individual basis to make sure that they can squeeze as much money out of you as possible. The main thing holding them back so far is that consumers view discriminatory pricing as unfair, but they've been working hard for a long time to change that view. If you happen to find a place that requires you to scan a QR code to see prices or get a menu, you might want to check with the people around you to make sure everyone is paying the same price. https://link.springer.com/article/10.1057/s41272-019-00224-3 reply irq-1 15 hours agorootparentprev> when your next would-be employer or would-be landlord ... uses a data broker for \"background checking\" Knowing an SSN (US Social Security Number) was used like a password by banks and all kinds of organizations, but not anymore. Things change, albeit slowly, when society acknowledges mistakes. All of your examples rely on the data buyer trusting its accuracy. If enough people pollute the data, then it'll have no value. The data brokers won't be able to sell it because society will know that its garbage. reply autoexec 14 hours agorootparent> All of your examples rely on the data buyer trusting its accuracy. Pretty much everyone knows that the data is filled with inaccurate information. As much as 40% of it may be wrong (see https://joindeleteme.com/blog/incognito-september-2023-data-... for more info). The vast majority of the time, the people buying the data know it isn't 100% accurate and they also don't care. They're usually not looking at individuals, they're looking at large groups of people who (probably) meet whatever criteria they've set. If they get it wrong a bunch of times who cares as long as the other times it works. Better than chance is good enough for them. Data brokers can always count on there being some people who are misled into thinking that their data is far more accurate than it is. They're trying to convince everyone right now that AI is the golden solution that makes them super trustworthy compared to their previous failings. Tomorrow it'll probably be \"quantum something\" or \"super surveillance\" or some other gimmick. They really don't have to care. They'll always be able to sell their stuff. Data brokers will always have the police and the government buying up their data too because the government is happy to just suck up everything they can and will figure it all out later. They aren't concerned with accuracy either. That's how people get arrested for just riding their bike past houses that got robbed. They can make all the mistakes they want and it doesn't hurt them any, even when it's a huge problem for the people caught up by lazy policing. I promise you that no browser add-on is going to collapse the targeted ad industry or bring an end to surveillance capitalism. Giving people more data to use against you is a bad idea. reply l33t7332273 16 hours agorootparentprev> Surveillance capitalism doesn't care at all about the accuracy of the data that they have Itâ€™s clear and obvious that they do. If the data was made up, they wouldnâ€™t be able to serve effective ads. > If you're a 40 year old man, but your browser add-on convinces a data broker that you're a 34 year old woman seeking an abortion, that data can still cause you end up the target of a lawsuit in Texas and it will take a non-zero amount of time and money to clear that up This situation would absolutely never happen, and I think itâ€™s blatant fear mongering. reply autoexec 15 hours agorootparent> If the data was made up, they wouldnâ€™t be able to serve effective ads. The data being collected about you isn't about advertising. It's used for an ever increasing number of things that impact your real life including things like how much you get charged when you buy things, what services you're told exist or are eligible for, how long you get left on hold, what policies a company will tell you they have, and who will hire you. The data being collected about you can be used against you by police, or in courtrooms, and in custody/divorce hearings. Even when the data is used for advertising (along with scam attempts, the manipulation of your opinion, and political propaganda) \"effectiveness\" is a very uncertain thing. No one expects that everyone they target with a campaign will bite. The effectiveness and accuracy of targeted ads isn't exactly certain to begin with. > With just one parameter - gender - the data is only 42% accurate. That is less accurate than if you just did â€œspray and prayâ€ with no targeting at all â€” i.e. you would have still hit the right gender 50% of the time. With two parameters - gender plus age - the accuracy is down to an average of 24%. Some data brokers were far worse, with single digit percent accuracy. Third party profiling of audiences is so inaccurate, itâ€™s better to save your money and do â€œspray and prayâ€ instead. (https://www.forbes.com/sites/augustinefou/2021/04/19/ad-rele...) reply margalabargala 15 hours agorootparentprev> This situation would absolutely never happen, and I think itâ€™s blatant fear mongering. On the contrary, Texas in particular has gone out if its way to incentivize its citizens reporting other citizens for getting abortions. The law in that state creates an incentive for someone with the ability to do this, to do so. What's special about the situation in Texas right now where humans at large will not follow the incentives placed in front of them for the first time in human history? reply l33t7332273 15 hours agorootparent> Texas in particular has gone out if its way to incentivize its citizens reporting other citizens for getting abortions Thatâ€™s true, but if you, a biological man, were sued for having an abortion, this would be immediately thrown out. Indeed, even civil suits with their lower standard of evidence require more than a simple search history from data brokers. reply margalabargala 10 hours agorootparentOf course the case would be thrown out. But would it be thrown out without me having to do anything, or would it cause me to spend time and possibly money dealing with it? Especially if I had an androgynous name, there's a very real chance that I would have to physically show up in a courtroom somewhere to point out that I do not have a uterus. reply Sponge5 15 hours agorootparentprevCould you please specify the incentives you speak of? Are they material? reply ncallaway 13 hours agorootparentTexas has created a private right of action to sue for damages of $10,000. That is, if I know my neighbor performed an abortion, I can personally sue them, and get $10,000 (plus attorneys fees). So, the answer to your question depends on if you define $10,000 as material or not. reply spaced-out 15 hours agoprevI've yet to read a clear explanation of how \"surveillance capitalism\" is any different than regular capitalism with computers. As long as people are trying to make money they're going to try and crunch data to do it better. The only way I see to effect a real change in how companies collect and use data is with regulation. reply WhackyIdeas 15 hours agoprevA slight change of subject but not too much. An hour ago I walked into a Post Office somewhere in Scotland. I was immediately greeted with a screen hanging down from the ceiling. Onn the left 75% portion of the screen a bunch of different camera feeds and on the right portion, running vertically - still photos of my face and other customers faces who were currently in the shop. â€¦And next to these still photos were things like: Age: Middle aged male Emotion: â€¦ Glasses: No Etc. I asked the shop keeper why they were showing this, and I was met with arguments like â€˜these are everywhereâ€™, â€˜airports have them tooâ€™. I replied that an airport is understandably doing this, due to being a terrorism threat. But this was a small Post Office in a tiny village town in the countryside. So like comparing apples to toilet paper. I asked why the camera was trying to guess my emotion. To which I was replied to â€˜if you are doing nothing wrong, you have nothing to worry aboutâ€™. Society has been so conditioned into the assumption that what we have today we will have tomorrow. Except in a world of potential Trumps, Xi Jinping, Putin and moreâ€¦ we are setting ourselves up for the complete unknown of tomorrow. This 1984 Scotland is now a place I feel like the reason to live has been dwindled down to just pure existence. I donâ€™t think I had ever felt quite like this before this trip to the Post Office today. Life doesnâ€™t feel like ours anymore. Itâ€™s someone elseâ€™s. The people behind the surveillance and the conditioned people who normalise it. Just because the technology exists, shouldnâ€™t mean it needs to be used. When will people ever start respecting otherâ€™s privacy? And when will people ever give a damn about it. If this is already where weâ€™re at in 2024, where are we all going to be by 2030? Is life as full of the same point today than what it was 10 years ago. And will it be less full of point by 2030. Edit: typos reply from-nibly 15 hours agoprevAnyone ever thought of creating a drop in \"cloud\" machine that could host self hosted services with minimal technical knowhow? The biggest technical achievement that would make this intriguing for me would be family distributed backups. If I could buy like 3 or 4 of these and have it magically do multi site clustering and backups and have some sort of app store it might solve most of the issues. The provider of such a machine could also provide technical assistance in the form of: - DNS / domain registration - Host OS Updates - Encrypted cloud backups - Specialized router/firewalls to make it even easier to expose on the internet safely - Accessories like media archival equipment - Hardware upgrade kits I mean really just https://oxide.computer/ but for consumers. reply wmf 12 hours agoparentIt was called Helm (no relation to the devops tool of the same name): http://web.archive.org/web/20220924051052/https://www.thehel... reply from-nibly 11 hours agorootparentBummer that they weren't able to make it work. reply pfannkuchen 5 hours agoprevNot to be confused with â€œSurveilling escapist capitalismâ€ (e.g. browsing the Netflix catalog). reply gumballindie 17 hours agoprev> Self-hosting, but as a service This is the way. As more and more ai is adopted, company and private data becomes more exposed. Businesses' intelligence getting stolen and shared with others is a no go for many rational business people. Self hosting is the way if you wish to keep your secrets. People too - you don't want your personal pictures, emails, and messages leaking into someone's prompt. reply JohnFen 15 hours agoparentIt's not the way for me. If I'm being hosted on someone else's machine, then I'm still at the mercy of some company somewhere. It's not \"self-hosting\" in any sense that has value to me. reply acd 15 hours agoprevYou cant escape data fusion and browser finger printing via canavas, fonts, plugins. reply isomorphic- 9 hours agoparentTake a look at LibreWolf. It \"standardizes\" all fingerprintable variables (canvas size, fonts, etc) so that you look like anybody else with a default config. reply juunpp 6 hours agorootparentYou look like the other 2 dudes in the hood using LibreWolf among the other several hundred thousand people using Chrome. reply wmf 12 hours agoparentprevYou can escape fingerprinting if you use open source software that doesn't fingerprint you. reply say_it_as_it_is 15 hours agoprevMy current understanding is that the cost of \"surveillance capitalism\" has been more personalized advertising, but maybe I was under a rock for the last 20 years and missed this sensational story. Have people been discriminated against based on surveillance data? Are vehicle insurance companies going to be allowed to adjust insurance policies based on smart car surveillance, or health insurance companies adjusting policies based on consumption and behaviors? Are employers discriminating against people based on surveillance data describing their political ideologies? What's the big picture for 2023 in terms of what surveillance data is being used and how it's being used? reply pphysch 16 hours agoprev> As Molly White said, â€œthere are never purely technological solutions to societal problemsâ€. I agree. It's Conway's Law on a national scale. In our advanced capitalist society, most governance is done by corporate hegemons (finance, insurance, real estate, marketing, etc), sometimes using the de jure government as a proxy. Our digital organization reflects exactly that! It is revealing that the best form of digital identification for each person are (secret) profiles created+sold by digital surveillance companies, rather than a robust + transparent digital citizenship that is managed strictly by a public entity and the subject themself. Some people react to the status quo by \"running into the wilderness\", either literally, or metaphorically by self-hosting everything. Either way, they often become digitally isolated and maintaining their personal kingdom becomes a lifelong task. It's not fixing the underlying societal dysfunction, just avoiding it. reply JohnFen 15 hours agoparent> It's not fixing the underlying societal dysfunction, just avoiding it. Absolutely true. But as one of the people who do this, my response is: self-protection first. Then continue doing whatever you can do to make things better in the larger picture. reply pphysch 13 hours agorootparentI concur that individuality / individual sovereignty is a prerequisite a healthy society, but some people think its the ultimate goal rather than a first, limited step. reply adolph 16 hours agoprevI think anything done \"at Scale\" eventually resembles \"Surveillance Capitalism\" since most of the advantage of what is often referred to as \"Capitalism\" is people finding valuable uses for the refuse of others. An alternative more practical guide is Derek Siver's \"Tech Independence\" which as other's have noted has many dependencies. https://sive.rs/ti reply pastacacioepepe 17 hours agoprevnext [25 more] [flagged] carlosjobim 16 hours agoparentSelf-employed, business registered in another country where you don't live, your business bank accounts and personal bank accounts in countries where neither you nor the business live, declare no taxes or declare zero revenue. This means you and your business will have to be self-sufficient. You're not going to have access to loans or investors. But you'll be out of the claws of the system and as free as can be. reply rolobio 17 hours agoparentprevAfter a bit of searching, apparently there is www.find.coop. I see most of the communities are in New York City. I'm sure they will welcome you in, just be sure to bring some money. reply robertlagrant 17 hours agorootparentnext [14 more] [flagged] ta1243 17 hours agorootparentYet you participate in society, curious reply robertlagrant 16 hours agorootparent> Yet you participate in society, curious Sorry - not following. reply r721 14 hours agorootparentIt's a quote from comic: https://knowyourmeme.com/memes/we-should-improve-society-som... reply robertlagrant 13 hours agorootparentOh, I see. Thanks. Sadly that comic doesn't have any logic behind it. It's just to get you to memorise \"this is how you should feel about people who make this argument\". reply NoboruWataya 16 hours agorootparentprevThe question is literally about escaping capitalism so it seems a fair response. \"How do I complain about capitalism\" is a different question and much easier to do. reply orthecreedence 16 hours agorootparentIt's not a fair response. It's a consistently obnoxious response to people actively searching for a better world. Like, no shit your computer is produced under capitalism...that's the active and dominant mode of production. If you want to escape it, you don't escape the things produced by it, you actively work towards changing the way those things are produced. There is nothing meaningful or useful about the above response. \"Oh, you don't like air pollution? Why do you keep breathing then??\" reply theultdev 16 hours agorootparentNo, it's a facetious response to those who want to experiment with billions of people's lives to replace capitalism which has brought so many people out of poverty and hunger with an unstated system that will most likely resemble communism which will again starve hundreds of millions as it has countless of times. People can and do operate a commune within a capitalistic society. Go in with other people and buy some land to live off, make a contract to share all property. You can't do the inverse in a communistic society. But no, we all have to do it or it won't work, because apparently it's only possible at scale and it can't be explained until then. Convenient. So don't act like you can't go live life in a commune today, you can, just people don't, because capitalistic life is more comfortable. They'd rather complain online about other people's lives, using their iPhone, drinking Starbucks, thinking about how know best for all more than the great minds that created the society they take for granted. reply orthecreedence 15 hours agorootparent> those who want to experiment with billions of people's lives Sorry, but you don't know that this is the method of anybody the response is targeted at. It's an ill-formed assumption, and many people are interested in counteracting the apparent and obvious detrimental aspects of capitalist society without violent revolution and totalitarian regimes. > People can and do operate a commune within a capitalistic society. Cool, good for them. Escapism isn't necessarily the goal, though. Obviously it depends on the person. > You can't do the inverse in a communistic society. Communism is the \"free association of producers.\" If the producers wish to assign dictatorial control of their factory to one person and sell their labor to that person in exchange for a wage based on paper money, they are free to do so. But why would anybody willingly engage in this arrangement unless there is no alternative? > They'd rather complain online about other people's lives, using their iPhone, drinking Starbucks, thinking about how know best for all You have created a stereotype and are reinforcing it here. It's based in nothing. > more than the great minds that created the society they take for granted. Wait, capitalism was a constructed system? My impression is that it's a somewhat emergent system that started with feudalism and grew from there. reply robertlagrant 11 minutes agorootparent> Communism is the \"free association of producers.\" This sounds very hand-wavy. Why isn't capitalism this? robertlagrant 16 hours agorootparentprevNo, capitalism isn't like air pollution in that analogy. It's more like \"Oh you don't like air? Why do you keep breathing then?\" reply orthecreedence 16 hours agorootparentLol yeah, capitalism == air. Odd how people lived for thousands of years without air... reply robertlagrant 15 hours agorootparentYou've sadly lost sight of the analogy. reply rolobio 17 hours agorootparentprevPerhaps there is a tree bark scroll somewhere... using lampblack ink... written by candlelight from wild bees' wax? Erm, which language is the least capitalist? reply topaz0 16 hours agoparentprevMaybe \"What is to be done\" by VI Lenin would be a good place to start. Though of course there are many such guides that don't always agree. reply psychlops 17 hours agoparentprevnext [9 more] [flagged] AJ007 16 hours agorootparentThat's not a good list because 3-8 are highly dependent on capitalism for their economies to function. They might have various levels of state control, but they are very much capitalism. Cuba and North Korea are much purer examples, though they relay on foreign production to some limited extent. reply psychlops 16 hours agorootparentYou may be right, I don't back the list but don't think it's bad. \"They might have various levels of state control\" opens the door to broad definition of capitalism and I'm not sure domestic production of everything would be a requirement, but maybe. reply wry_discontent 16 hours agorootparentprevMost products are created in capitalism, so it seems like a weird way to judge alternate economic systems. reply polshaw 16 hours agorootparentprevWild that you try to include one of the most capitalist countries on earth, second in the number of billionaires only behind the USA, on the back of the fact that they have one-party rule with the word communist slapped onto it. The general (and often wilful) ignorance around the topic is astounding. reply psychlops 16 hours agorootparentPlease share your ranking criteria. Is it billionaires per capita? reply wry_discontent 16 hours agorootparentprevI feel like this is really dependent on what you understand by \"capitalism\". Pretty sure the Marxists in the Communist Party of China would not consider what they do there capitalism. reply miroljub 17 hours agorootparentprevWhy do you think all of these nations are not capitalistic in nature? reply stonogo 17 hours agorootparentprevDo you actually think e.g. Vietnam or China are not engaged in capitalism, or is this just some culture war leaking into HN? reply stcredzero 17 hours agoprevIt seems to me, that the Starlink 10GBit connection is almost designed for someone to put a server farm aboard a ship that only sails in international waters. Re: Escaping Capitalism I've encountered the communal experience which feels magical, like \"everything is made out of love.\" Here's the thing about that. Scale matters. Alignment of incentives matter. The communal experience is going to start breaking down at around 450 members or so. The old Inca empire was an example of a large scale political organization which apparently worked. However, it also seems likely this also involved the killing of those who didn't cooperate. Perhaps superintelligent AI will enable an alternative to Capitalism, as envisioned in Ian M. Bank's Culture books? reply chatmasta 14 hours agoparentThere's something really cool about adding servers to a borg by tossing them into the ocean. Imagine a solar powered buoy with some compute and storage, with full connectivity to the internet, just floating around in the ocean. And then imagine millions of them all collectively forming a decentralized cluster. Maybe it's just me, but I think that'd be awesome! The limiting factor is power efficiency and battery tech. Of course maintenance would be a problem, but not with fault tolerant clustering designs. And there's the ecological issues of tossing hardware into the ocean, but at least there's no need for a cooling system... reply ineptech 16 hours agoparentprev> a server farm aboard a ship that only sails in international waters. How would this help? If the server software is actually trustworthy and the connection to it is e2ee then it really doesn't matter where it runs. And if it isn't, this kind of setup protects whoever owns it more than whoever rents space on it. reply stcredzero 9 hours agorootparentIt discourages sovereign law-based state actor DOS. reply robertlagrant 17 hours agoparentprevAs soon as we are post scarcity, we don't need capitalism any more, as capitalism is just a resource allocation mechanism. Til then, we probably do! reply ta1243 17 hours agorootparentWe've been post scarcity for \"IP\" for decades. The cost of making 1 copy of Barbie the Movie is the same as 1 billion copies. reply robertlagrant 17 hours agorootparentWell, copying and pasting has been made easy. But making it is still hard - lots of resources to allocate there. reply ta1243 16 hours agorootparentMaking the first requires resources. Making a billion copies doesn't. Same in a world with a star trek replicator. Making the first steak dinner requires resources, making the next billion doesn't reply robertlagrant 16 hours agorootparentAs I say, copying and pasting has been made easy. reply r14c 16 hours agorootparentprevMore accurately, Capitalism is an ownership model. People like to retcon all forms of market-based commerce as a kind of \"proto-capitalism\", but that makes it hard to talk about Capitalism as a distinct economic system. The main defining feature of capital markets is their use of private property as a tool for extracting profit from a market system. There are useful and socially positive applications for capital, but Capitalism places profit above all other concerns because extracting profit is its function. Capitalism was born in feudal Europe, and grew up during the colonial period and is, factually, only 500 years old or so at most. Markets have existed all over the world for literal thousands of years. Capitalism tries really hard to pretend like they invented something, but there's far more choice and affordability in the free markets around the world than anything that has been enclosed by the american financial system. Then again, I don't subscribe to the notion of capitalist realism. Aside from the exported violence used to impose and sustain it, the model is flimsy and constantly in crisis. reply failbuffer 16 hours agorootparentprevWe'll never be post-scarcity because humans can never reach a state of sustained satisfaction. reply bluescrn 16 hours agorootparentprevPost-scarcity can't really happen on a very finite planet with a huge and growing population. Even if we had fully-automated systems providing plentify food and water, we'd need some ssytem, likely capitalism, to distribute still-scarce luxuries (e.g. beachfront property) And if we had total post-scarcity (effectively infinite energy and Star Trek style energy-to-matter replicators), we'd just be fighting over scarce land as everyone fills up all the space with replicated junk. reply orthecreedence 16 hours agorootparentPost-scarcity just means the rate of use is less than the rate of renewal for all used resources. In a sense, hunter-gatherers were \"post-scarcity.\" The challenge is supporting our modern quality of life at our scale of population. I think enormous strides would need to be made (fusion energy + matter synthesis, ie Star Trek replicators) in order to achieve post-scarcity on a long enough timeline without changing any of the other parameters. reply robertlagrant 15 hours agorootparentWell, not just that. Not everyone can have a house on the beach. How do you allocate that resource? reply orthecreedence 15 hours agorootparentEhhh, that one's self-regulating. Have you seen what happens to houses next to the beach? They disintegrate at alarming rates. Maintenance is a nightmare. That said, removed from market forces, there a lot of ways to allocate housing, such as some form of segmented lottery or waitlist. reply robertlagrant 11 hours agorootparentMaintenance isn't a nightmare in a post-scarcity world. reply persnickety 17 hours agorootparentprevWe're post-scarcity regardig digital goods. It seems we might not need capitalism for those goods any more, but it's still sticking there. reply margalabargala 16 hours agorootparentWe aren't, not yet, because those digital goods still have an initial creation cost. Digital goods that people consume are made by people. Yes, they can be copied infinitely for free, but we're only \"post scarcity\" if we never make anything else new. With the advent of generative AI, we might just barely be starting to be post scarcity in a couple narrow fields. reply persnickety 16 hours agorootparentI'll bite: we're post-scarcity for a lot of digital items that are useful tools. Goods we need but don't have exist, but I'm not even sure if they are the majority. Existing music, videos, books cover a whole lot of what humans might want - originals are the outcome of research needs (niche) and trends (not niche). Existing software tools are similar: new ones are needed to push boundaries (niche) or mostly as a response to a changing legal landscape (less niche). On top of that, significant amounts of stuff are created out of an internal need, and would get created regardless. One thing I'm sure about is that we're post-scarcity in historical items, and we're nowhere past capitalism there. Indeed, preservationists are hitting roadblocks all the time. reply margalabargala 15 hours agorootparentYou know, that's a fair point. I think there's a great argument to be made that FOSS software in particular is essentially post scarcity. I'm not sure I'd say we're \"post scarcity\" for books and other digital goods though. Sure, we have all the books written until now, but I think there's an argument to be made that a huge part of the utility of books is that they are produced in near-real-time to discuss, address, and reflect thecurrent state of society. As our society grows and changes, books featuring the issues of the days will always be desired. This falls into the \"trends\" category you mentioned, but my point is more that I think it's larger than you described. reply robertlagrant 15 hours agorootparentprevVolunteerism isn't \"post-scarcity\". If you're fed and watered by providing value in a capitalist system, and choose to spend your spare time volunteering, that's great, but it's nothing utopian. Volunteerism is a free choice of work in exchange for a price of Â£0. That's regular old capitalism at work. If you could just generate energy out of the ether and use it to materialise food and anything else you might want, for example, that would be post-scarcity. reply persnickety 12 hours agorootparentI insist that it still is post-scarcity if you would provide the same or greater (equivalent) value regardless of the system. While your definition might be elegant, it's too strict to foster a useful conversation. reply nightski 14 hours agorootparentprevYou can't look at one area of the economy in isolation. It's all intertwined. The people creating digital goods still need food, shelter, and housing. Things that are not post-scarcity. reply stcredzero 17 hours agorootparentprevAs soon as we are post scarcity, we don't need capitalism any more If you compare agriculture 1000 years ago with agriculture today, we're already in post scarcity. I suspect the game theoretic mechanisms will keep it going for awhile yet. reply orthecreedence 16 hours agorootparentI don't know if we are post-scarcity. Our inputs to agriculture (lots and lots of fossil fuels) are not post-scarcity in any sense. Multiply by the scale of humanity and it's difficult to argue we're post-scarcity in agriculture. We might have more food than people to feed, but that doesn't mean if nothing changed we'd be able to sustain our level of production. reply stcredzero 15 hours agorootparentOur inputs to agriculture (lots and lots of fossil fuels) are not post-scarcity in any sense. Yes, but our levels of productivity per-farmer would look like utter Sci-fi to a medieval peasant, if they had a notion of Sci-fi. Also, by these standards, 1st world societies are fantasy lands, where the even the poor are fat, and have magical machines to keep food fresh, deliver music and entertainment, wash clothes and dishes. (Not all, but still.) What we posit today as post-scarcity, will likely just move the goal posts for scarcity. reply skeeter2020 16 hours agorootparentprevAs society levels-up, the definition of scarce will continually expand as we confound wants with needs. I'm not sure how in a world of infinite wants you can \"out-technology\" resource demands. reply dukeofdoom 16 hours agoprev [â€“] The problem is government. Even Trumps private twitter messages had been seized. If a former president can't protect his privacy...who can? Should you expect to have your personal communications just taken by a government bureaucrat any time they want. I think the problem id deeper than technical, it's a political and moral problem. Companies will cave and do what government tells them to comply. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article addresses the issue of surveillance capitalism and proposes alternative strategies to combat it.",
      "It examines the limitations of paid subscriptions and highlights the effectiveness of self-hosting for preventing surveillance capitalism.",
      "Self-hosting may have scalability challenges and require technical expertise. The article also discusses the concept of end-to-end encryption (E2EE) but notes its drawbacks and emphasizes the need for a holistic approach."
    ],
    "commentSummary": [
      "This discussion explores various topics surrounding privacy, data security, and surveillance capitalism.",
      "Solutions and alternatives for protecting personal information, such as decentralized server systems and encryption, are suggested.",
      "The conversation also highlights concerns about data collection, inaccuracies in profiling, and the impact of surveillance capitalism on personal freedoms, emphasizing the importance of privacy and the need for regulation in data practices."
    ],
    "points": 248,
    "commentCount": 200,
    "retryCount": 0,
    "time": 1705594468
  },
  {
    "id": 39051655,
    "title": "Google's Changing Culture: From Valuing Employees to Financial Challenges",
    "originLink": "https://social.clawhammer.net/blog/posts/2024-01-19-CultureChange/",
    "originBody": "Disclaimer: this post is solely based on my lived experience of working at Google for 18 years. I don't actually know the reasoning of the company's highest leaders, so all I can do is share my personal hypotheses. I've tried to write this essay three times over the past couple of months; it's tricky. It's always trendy and click-baity to attack big targets, especially when those targets are full of hubris like Silicon Valley tech companies. People love \"fall from grace\" stories. But my goal isn't to throw dirt; Google is still a great place to work -- far better than most companies -- and still doing amazing things. My goal here is to call out a unique, beautiful thing that happened... put it out into the universe, with the hope that it can come back again someday, somewhere. There's no doubt that the early days of Google were \"over the top\". I deliberately saved this email for 18 years, waiting for the day I left the company, because I knew it would be a fascinating time-capsule comparison. But the email mostly focuses on superficial differentiators, like free gourmet food. In truth, that's not why Googlers come to work. I want to talk about a deeper, more substantive aspect of the culture. When Ian Hickson -- another old-timer -- left Google last fall, he wrote a blog post talking about the shift in the types of decisions being made. I generally agree with him, but I won't repeat it all here -- I'm going to talk about a different shift. The most incredible and unusual thing that struck me about Google's early culture was the tendency to value employees above all else. I had worked in other companies, and never seen anything like this before. This culture lasted for at least my first decade at the company, perhaps longer. Let me explain. In a typical company, when priorities shift, you \"downsize\" (or cancel) a project, and then use the money to add people to a different, more important project. The common way to do this is fire people from the first project, then rehire a bunch of new people in the second project. It's easy, it's simple, it's expected. Google, however, had a different approach: they had an absolutely intense hiring process to find talented people who were also generalists -- that is, were able to thrive in a whole number of roles. The interviews were grueling for both applicants and interviewers, often taking months. But in the end, Google was convinced that it was worth the effort: they believed they had hired the best, brightest, and most flexible. And so, when priorities would change, Google did not fire people, but rather moved them carefully between projects. The unstated cultural principle was: \"products come and go, but we worked so hard to get our employees... so we should preserve them at all costs. They are our most precious resource.\" And so a tremendous amount of energy was put into high-touch resettlement of each employee into new projects. They were generalists. We knew they'd thrive, and that Google would continue to make use of their talent in new ways. As I moved up into leadership over the years, I became ever more involved in this process. In the early days as an individual contributor, I experienced re-orgs directly and got \"re-homed\" into new projects. As a leader, I got involved in finding new homes for teams during re-orgs. Eventually I wrote an internal handbook for other directors on how to gracefully execute these re-orgs. One of my fondest memories is getting a peer-bonus from an engineer whose own team re-org I had personally instigated -- he was much happier working on the new \"more important\" project! But things change. In my first month at Google, I remember a co-worker whispering to me, \"the day Google revenue stops growing without bound, is also the day all of this will change.\" The change was very gradual for a long time -- but then things accelerated during the pandemic. Revenue began to slow, and now, coming out of the pandemic, we're seeing waves of layoffs. Yes, we knew things would change, but we didn't expect it would accelerate this quickly, in the span of just a couple of years. The academic founders are gone, much of the C-suite is now former Wall Street execs; combine that with revenue flattening toward a stable horizontal asymptote, and the obvious, expected thing happens: the company suddenly moves from a \"culture of infinite abundance\" to a standard \"culture of limited resources.\" It's a predictable regression toward becoming a 'normal' company.[1] So what does a culture of \"limited resources\" mean? It means the execs start thinking about financial efficiency like every other company. You begin by trimming the more superficial perks: less fancy food, limiting travel budgets, no more swag, smaller and fewer internal parties and events, no more onsite dry cleaning or daycare. But again, these things weren't the reasons Googlers came to work. No big deal. But then you begin to cut costs further by changing the ornate hiring and promotion processes to become \"traditional\". Hiring changes from a laborious global process (of checks and balances) to a localized one within divisions that can tightly control their labor costs. Meanwhile, internal promotion processes change from \"competing against yourself\" to \"competing against your co-workers for limited positions.\" In the early days, titles were attached to people, but now they're increasingly attached to roles, and the number of roles (for any given title) can be limited to save cost. Finally, it comes time to do large re-orgs of projects around new urgent priorities (like AI, for example). But gone is the high-touch re-homing of employees. Instead, we see waves of impersonal layoffs, followed by (modest) rehiring in the newer projects that matter. In other words: doing what a normal company does. Is Google evil here? Of course not. As I mentioned in a prior post, Google is not a person. And -- whether or not one agrees with it -- its leaders are trying to be fiscally responsible and efficient, just as all public companies are pressured to do when resources become finite. But, coming back to my first decade at Google, it was incredible to see employees valued above everything else. Perhaps this is a privilege only possible in a culture of infinite abundance. Or maybe not? Maybe it's possible in a limited-resource culture too, but only if the company is small. It leaves me wondering if the sheer size of Google (170,000+ employees) simply makes high-touch re-orgs intractable. The takeaway here is this: we should all learn from early-Google's example. When employees feel truly valued (which is rare!), it creates psychological safety, high morale, productivity, and creativity. Early employees would often encourage each other to \"fail fast\" as a means to innovation, but that's no longer easy in an environment where failure implies a layoff. If you're someone building a company, challenge yourself to value employees above all else, then watch and be amazed at the ROI. published January 19, 2024 To be clear, I believe Google is still nowhere near being a normal company yet. It has a tremendous distance to fall. â†©ï¸Ž",
    "commentLink": "https://news.ycombinator.com/item?id=39051655",
    "commentBody": "Culture Change at Google (clawhammer.net)238 points by kfogel 5 hours agohidepastfavorite165 comments zamfi 3 hours agoIs any company still like this? I was at Google in â€˜06-07, and again â€˜09-11, and already there were obvious differences. You just canâ€™t scale â€œtotal internal transparencyâ€ when the company doubles in size every year. And at some point you need just plain-old-â€œgoodâ€ engineers to make the A/B tests happen and all the other stuff that doesnâ€™t excite the PhDs. And at some point you need product people too, because you start to build products youâ€™re not in the target audience for. And at some point your employees arenâ€™t all going to be fabulously wealthy from an upcoming IPO, and so theyâ€™ll start playing political games for coveted titles and $1M+ comp so they too can have their house in Tahoe. At some point the real world just gets in the way. reply 0xpgm 3 hours agoparentI wonder if there's a way to prevent the growth at all costs that is demanded by the financial markets. Maybe become profitable and pay off the VCs then don't go public? Then you can resist the pressure for growth quarter by quarter, and remain the 'right size' that your internal culture demands. Did Valve corporation do something like that? reply tavavex 2 hours agorootparentI think Valve does have a reputation for having this type of model. They've famously expressed an intention to not go public or sell the company to anyone else. This is also what leads to them being a fairly small and selective company that can afford to cherry-pick employees, and that also has an allegedly more employee-friendly culture than others. Just like the recollection in the original post, they might have that \"infinite abundance\" mindset - their initiatives in game development, hardware and VR are probably subsidized by Steam many times over. reply poisonborz 1 hour agorootparentI would argue that they made a really good early bet with Steam which rakes in enough profit that they can keep this (or whatever) mindset. They never really had competition in the PC space. If they would need to come up with new and better products each fiscal year they would look very different. reply Ntrails 1 hour agorootparentI feel like you could have said the same about google or facebook. They made a dominant early platform and could have comfortably lived off that success? There are a bunch of companies trying to compete with valve. They are not behind any more of a moat than anyone else. reply adrianN 15 minutes agorootparentDid Google or Facebook do anything that is not \"living comfortably off early success\"? AFAIK they had a very poor track record in monetizing anything they built in the last ten years or so. reply gloryjulio 1 hour agorootparentprevFor some reason steam is really just better than anything else combined. Maybe except gog as it's drm free reply LarsDu88 1 hour agorootparentprevAnd yet they crank out new and innovative \"products\" every 4 years. So much so that they were essentially doing 90% of what Meta is trying to do now with 100x less people and budget. I think the real answer lies in the fact that at a public company, you will need to answer to shareholders, but at Valve, you actually need to answer to the whims of benevolent dictator Gabe Newell. reply ilrwbwrkhv 23 minutes agorootparentValve also has much better hackers than Facebook. reply Eisenstein 0 minutes agorootparentSince VR was mentioned specifically, how many 'Valve hackers' is one John Carmack worth? eru 1 hour agorootparentprev> I wonder if there's a way to prevent the growth at all costs that is demanded by the financial markets. Google (and Facebook etc) are controlled by their founders (some even as majority shareholders). There's no blaming financial markets here. Facebook was even happy to set fire to a giant pile of cash in pursuit of the 'metaverse', a project that approximately no investors wanted, but that was dear to the heart of their founder. reply rapnie 1 hour agorootparent> Facebook was even happy to set fire to a giant pile of cash in pursuit of the 'metaverse' I always saw it more as priming the market. Throw out this idea, with the apparent weight of Meta behind it, and see how the market jumps on it (or not). If it goes well, Meta as initiator can easily ensure they stay in the lead, gobble up startups and such. reply eru 1 hour agorootparentThat's plausible, and perhaps what Mr Zuckerberg had in mind? But investors, or at least their opinion aggregated via the share price, had a different opinion at the time. (Investors are often happy to bet on speculative things, as long as they have a positive expected value.) reply raincole 3 hours agorootparentprevI'm really surprised that SideFX has only 169 employees. It's biggest competitor, Autodesk, has 13,700 employees. Of course Autodesk has a lot of products and SideFX has practically one so it's not a very fair comparison. But my point is that SideFX is a living evidence that if you want to stay reasonably small you can. SideFX was been existed for 28 years, so we can safely assume it has a positive cash flow. reply fuzztester 24 minutes agorootparentprev>I wonder if there's a way to prevent the growth at all costs that is demanded by the financial markets. Many companies used to do that both in the US and other countries. Some probably still do. SAS Institute (well-known maker of statistical and other software) did, for many years, last I checked. Don't know if they still are that way. Update: Looks like they are: https://en.m.wikipedia.org/wiki/SAS_Institute [ In July 2021, the Wall Street Journal reported that the semiconductor giant Broadcom was in talks to acquire SAS.[37] In a July 13, 2021 email, SAS CEO Jim Goodnight stated that the company was not for sale.[38] ] reply cool_dude85 16 minutes agorootparentIf SAS is the paragon of a company not pursuing growth at all costs, then maybe we do need to start looking at quarterly metrics. As a customer their business model sucks and they are doubling down on \"either we're a solution for your whole enterprise or else.\" reply jjav 2 hours agorootparentprev> I wonder if there's a way to prevent the growth at all costs that is demanded by the financial markets. If you go public, no way to prevent it. You have to stay private. But if you took a lot of VC money (and gave them board positions) that's going to be difficult. reply roenxi 51 minutes agorootparentprevThere is actually evidence that the market doesn't demand growth - https://fred.stlouisfed.org/graph/?g=JpB4 suggests that the market is chasing the base rate of monetary creation. If a company isn't \"growing\" at ~5% p.a nominal, it isn't tapping into the money hose. What would be the point of owning it? reply JeffSnazz 1 hour agorootparentprev> I wonder if there's a way to prevent the growth at all costs that is demanded by the financial markets. Growth and private investment are part and parcel. reply bitcharmer 1 hour agorootparentprev> I wonder if there's a way to prevent the growth at all costs that is demanded by the financial markets. Yes, just don't hire MBAs with fetish for shareholder value reply nicoburns 24 minutes agoparentprevThis is the argument for biasing the economy against large companies reply foofie 21 minutes agorootparent> This is the argument for biasing the economy against large companies. It's also an argument to break large companies into smaller ones. This has to cut both ways, not just to fire people by cutting off whole org branches. reply poisonborz 1 hour agoparentprevYes, and there's no good way around this - no human organisation can scale beyond a certain (quite early) point without becoming an immoral profit machine. I wish society would better understand this, and governments would add caps. Of course no one on the world political stage would handicap their economy like this. reply sparrowInHand 1 hour agorootparentThis is because, states at some size become immoral power machines deeply distrusting one another. reply JeffSnazz 1 hour agorootparentThis just straight up doesn't make sense to meâ€”states aren't monolithic entities or rational actors. I think it's easier to say that the modern state exists at the behest of capital, at least in the west. reply neilv 3 hours agoparentprevThread from yesterday on this question: https://news.ycombinator.com/item?id=39035569 reply brcmthrowaway 3 hours agoparentprevSo the real answer is to join the next Google.. :) OpenAI? reply nequo 3 hours agorootparentWhat is the company culture of OpenAI like? How does it compare to early Google? reply CobrastanJorji 3 hours agorootparentWell, it seems like it's got some cool tech based on providing access to everybody else's copyrighted content in novel ways, a bunch of promise to make a lot of money without knowing 100% what the plan is, messy politics at the top, and it's around the San Francisco area, so.... reply glimshe 34 minutes agorootparent> providing access to everybody else's copyrighted content in novel ways This is a cartoonish interpretation of what Generative AI does. You might be coming from a good place trying to defend the \"little guy\" who supposedly is getting ripped off by GenAI (they aren't), but in practice you are helping copyright trolling and big rusty corporations that live off the perpetual copyright scam. reply gardenhedge 6 minutes agorootparentIs the NYT lawsuit cartoonish too? reply tavavex 2 hours agorootparentprev> providing access to everybody else's copyrighted content in novel ways That's a very biased characterization that downplays a debate that people have right now as basically being already solved. It's simply not truthful, unless they started a side business in developing a torrent tracker or something. reply CobrastanJorji 2 hours agorootparentI'm not sure whether you think I'm being unfair to Google or to OpenAI. Everybody and their brother sued Google early on for a huge variety of their products. Google News got sued for showing headlines from news websites. Google Books got sued for copyright violations for, y'know, making a copy of everybody's books. Back in 2007, Google would've been in the middle of the the Viacom vs YouTube lawsuit. The whole idea of a search engine is fundamentally about taking all of the useful and mostly copyrighted content out there owned by others and profiting off of it by becoming the gateway to it. OpenAI, similarly, works by taking all of the text and art and everything in the world, most of it owned by others, then copying it, collating it, and compressing it down into a model. Then they provide access to it in novel ways. I make no representation about whether it's legal or ethical. It's transformative, useful, novel, and really cool, but it's clearly taking other people's data, and then making it useful and accessible in a novel way. reply dougb5 1 hour agorootparentA big difference in my view is that OpenAI doesn't meaningfully \"provide access\" to all the text and art and everything in the world; rather, they suck the marrow out of all the text and art and everything in the world and use it to sell their own replacement service for all the text and art and everything in the world. Google has done some questionable things to become a gateway to the world's work, but they're (mostly) still a gateway, not a copy. reply broeng 42 minutes agorootparentMaybe we can agree they are still _mostly_ at gateway. But their ambition to answer your question through zero-clicks (i.e., show the answer right in their search results) does make them profit from direct copying. The copyright owner will not get any clicks, show any adds, or get any other kind of feedback to their work, in those cases. reply tavavex 2 hours agorootparentprevI think the characterization is unfair to generative AI, because the information that is retained in the model is a very lossy and rough generalization of the training data - that situation is a lot less direct than what it's like with search engines. In my mind, the lawsuits against search engines have a lot more ground to stand on. Saying that something \"provides access to copyrighted content\" almost implies that there's some mechanism that allows the user to wholesale download complete, unedited and exact copies of some copyrighted material - I could see that argument with a search engine, but not really with a text or image generator. reply piva00 50 minutes agorootparentIt's 100% dependent on copyrighted material at least, even though you can't access an exact copy of it without access to the material it wouldn't exist. It's a messy issue, I have no idea how it will be solved since it's a rather new development for humanity, in the past when humans would collect knowledge from different sources to use them in a novel way there would be at least some kind of attribution, recognition of the sources, either being cited or acknowledged in a preface. With GenAI there's nothing, and probably not even a way for GenAI to tell us where it got \"inspired\" from to generate something. It's going to be a very messy landscape for copyrights and intellectual property in the next years. reply saiya-jin 1 hour agorootparentprevWell, you certainly have right to your opinion, as do others to theirs. Law is the ultimate arbiter as usually. reply leereeves 2 hours agorootparentprev> In Washington, DC, though, there seems to be a growing consensus that the tech giants need to cough up. > Today, at a Senate hearing on AIâ€™s impact on journalism, lawmakers from both sides of the aisle agreed that OpenAI and others should pay media outlets for using their work in AI projects. â€œItâ€™s not only morally right,â€ said Richard Blumenthal, the Democrat who chairs the Judiciary Subcommittee on Privacy, Technology, and the Law that held the hearing. â€œItâ€™s legally required.â€ > Josh Hawley, a Republican working with Blumenthal on AI legislation, agreed. â€œIt shouldnâ€™t be that just because the biggest companies in the world want to gobble up your data, they should be able to do it,â€ he said. https://www.wired.com/story/congress-senate-tech-companies-p... reply ulfw 3 hours agorootparentprevI didn't see Google's board fire it's CEO and then he gets reinstated and basically fires the board. Instead Google had more drama with the inappropriate behavior kind. reply saagarjha 56 minutes agorootparentThat we know of, at least. reply CSSer 3 hours agorootparentprevTo be fair one could argue that was still in vogue at the timeâ€¦ reply choppaface 2 hours agorootparentprevNotably Google is currently doing layoffs while simultaneously paying Deepmind / Brain MLEs $1-$10m counters to keep them from OpenAI https://seekingalpha.com/news/4055187-google-said-to-use-spe... reply 2-718-281-828 1 hour agoparentprev> You just canâ€™t scale â€œtotal internal transparencyâ€ when the company doubles in size every year. _total_ internal transparency is trivial to scale. partial and no transparency is difficult to scale. reply baron816 3 hours agoprev> Early employees would often encourage each other to \"fail fast\" as a means to innovation, but that's no longer easy in an environment where failure implies a layoff. Big tech is in a really tough spot when it comes to innovation. Google has developed a reputation for killing off products too easily. Many have commented here and elsewhere that you canâ€™t trust them to invest in using their new products because they might just kill it off and leave you in the lurch. Of course, you get a self fulfilling prophecy as then too few people use the product for fear that itâ€™ll get killed off. But Iâ€™m guessing Google is also more hesitant to launching a new products that since it neither wants to worsen its reputation for killing them, nor does it want to support a product indefinitely, even if itâ€™s not profitable. So then what? The answer probably should be that Google should buy up startups that have figured out product-market fit and just need to scale. They canâ€™t do that though because the FTC is already breathing down their neck with anti-trust suits. Google actually is investing in a lot of very transformative technologiesâ€”AI obviously, but also quantum computers, biotech, and autonomous vehicles. Those are things that just arenâ€™t well very well suited to 20% projects. reply voiceblue 3 hours agoparentThe success of 20% projects is a quasi-myth. Gmail is often touted, but you would do well to look up the employee # at Google of the inventor. Point being, you need (very) early hire clout or your 20% project isnâ€™t going anywhere either. reply tonfa 2 hours agorootparentGmail wasn't a 20%, I don't know why anyone thinks it is. Buchheit was asked to work on it. reply aspenmayer 0 minutes agorootparentI thought Gmail or its predecessor was a third party/acquihire situation? mizzao 3 hours agoparentprevI had understood that the main reason products were killed off so easily were the promotion incentives: you get big awards for launching a product, less so for maintaining it and growing it and doing the hard iteration work required to continue improving it. reply mcmcmc 52 minutes agoparentprev> So then what? The answer probably should be that Google should buy up startups that have figured out product-market fit and just need to scale. They canâ€™t do that though because the FTC is already breathing down their neck with anti-trust suits. And for damn good reason. That kind of behavior quashes competition and encourages that ZIRP era thinking of growth at all costs so you can get acquired before everyone realizes your business model sucks. Maybe they should just focus on their core business so they donâ€™t get buried in the shift to AI. reply huevosabio 3 hours agoparentprevThey could keep starting products and instead of killing them, release them as open source. Or one click deploy on GCP. Actually, that last one makes a lot of sense for pushing for more GCP adoption. reply vlovich123 3 hours agorootparentOpen source is very hard for a bunch of reasons: * Code at Google3 is one giant monolith that has dependencies on things that arenâ€™t open sourced. Even if they could be, they donâ€™t make sense outside of Google * most services internally run on internal services like Borg and GFS rather than GCP for historical reasons. That maybe has changed now but I suspect a lot of stuff depends on internal infra not available on GCP * A product can often have data dependencies. Just being able to spin up a separate copy may not mean much in terms of keeping a product alive past Googleâ€™s interest if the data is locked away behind Googleâ€™s private data stores. Then you want Google to start adding easy export options so that data can be exfiltrated from Googleâ€™s onto 3p versions of the product which is a legal, business, PR and technical risk * Google has invested some amount of money and resources into a product. If a competitor takes that concept and is successful itâ€™s embarrassing to execs at Google who missed the opportunity. Google Wave was dropped even though in many ways itâ€™s a precursor to slack (it was open sourced though and went nowhere). Itâ€™s a nice wish but I canâ€™t imagine any realistic scenario where any business would go down this road until their shown a successful roadmap by a more enterprising business first. reply Uehreka 2 hours agorootparent> Code at Google3 is one giant monolith Iâ€™ve heard this stated before, and something about it feels off. Thereâ€™s no way all of Googleâ€™s code is in one repo. Like, does that monorepo contain the full Android operating system with Google Services and the firmware for all the Pixel devices? I feel pretty sure multiple teams at Google must have forks of the Linux kernel for one reason or another, would those be in there too? Is Chromium in there too? What about the whole golang project? Even if Iâ€™m off about some of this, it feels like the statement â€œCode at Google is one giant monolithâ€ needs some qualifiers. reply morgante 2 hours agorootparentThere are certainly a few notable exceptions (Chrome and Android), but google3 really is a massive monorepo. It does contain forks of tons of open source code in the third party folder. I don't recall if the Linux kernel is in /third_party but I would not be surprisied if it is. A fair amount of the operations are actually documented publicly, ex. https://opensource.google/documentation/reference/thirdparty... reply summerlight 2 hours agorootparentprevNote that google3 is a subset of the entire Google codebase. But it still contain more than half of its code (>2B LoC), mostly those running over their cloud. In contains all the infrastructure code as well, including Linux kernel, compiler, tool chain... literally everything needed. When you build some big binaries, you may see more than 500k~1M build targets analyzed and built (or pulled from cache). reply rightbyte 2 hours agorootparentprevYe, like, is there a google.exe at 3912GB with 10k command line options like '--search-server --port=80' or '--Gsolitaire'? reply dilyevsky 2 hours agorootparentprevAndroid, golang, chromium and a few others were separate but there were 2B+ loc of other stuff in that repository reply wyclif 3 hours agorootparentprevGoogle Wave was my fave sunsetted project or Google graveyard project. First time I used it I could really see the potential. But as you pointed out, it's often not that simple. reply eastbound 3 hours agorootparentprevSo, Googleâ€™s choice of architecture prevents them from open-sourcing or maintaining projects a tad longer than absolute necessary. Iâ€™d say they dug their own grave, if it has such a large impact on the trust of customers. Maybe Google3â€™s architecture was excellent for worldwide scalability and costs, but letâ€™s see which one matters in the long term. reply eftychis 3 hours agoparentprevThe mistake Google has done here is that it deploys and launches and uses to garner attention projects under it's name. There is little to no, this is an experimental project by x team. It is this is a Google product. If everything is a product and you don't support most or expect most to die, then you damage the collective product that is the Google brand. And as a result how your employees feel and are treated about experimenting. reply saagarjha 51 minutes agorootparentThey do that, this is what their various Labs and subsidiaries and internal accelerators are there for. The issue is that people figure out it's associated with Google and then expect it to be maintained as such. reply eastbound 3 hours agorootparentprev> There is little to no â€œthis is an experimental project by x teamâ€ They communicated quite clearly when products were in beta. For example, they communicated clearly that Gmail was in Beta until 2009 (launched in 2004). Whatâ€™s less clear is what makes a beta, when a tremendously successful product remains in beta for so long. Another product that came out of beta in 2009 wasâ€¦ drumrollsâ€¦ Google Reader[1]. [1] https://www.alphr.com/news/home-and-leisure/125603/google-re... reply skybrian 3 hours agoparentprevEven in the early days, I don't believe Google was all that fast about launching new products? The \"fail fast\" stuff was about people working on blue-sky ideas that failed to get traction before they were launched, or maybe just launched in Google Labs [1]. [1] https://en.wikipedia.org/wiki/Google_Labs reply lutarezj 2 hours agoparentprevhttps://gcemetery.co/ Googleâ€™s reputation is not only in innovation reply Rebelgecko 3 hours agoparentprevFWIW, the only person I've ever actually met with a 20% project was working on quantum reply V-eHGsd_ 4 hours agoprevi keep thinking about this google arc. I was there for nearly a decade (at this point i've almost been gone for longer than I was there) and from the outside, the company is almost unrecognizable. it is definitely not the company that it was pre 2010. from my lowly IC5 (when I left) position, it felt like something happened in 2014 or so that really put the company on a different track. eric had already left and the founders had started stepping back and the people left running the show were, not them. i guess they were able to maximize shareholder value. but it was clearly at the expense of something. anyway, I dont have anything to say that hasn't been said more eloquently by ben. except, I saw this change too. and it bums me out because I got to see the place before. reply kyrra 3 hours agoparentEric leaving. Larry and Sergey stepping back. And the hiring of Ruth Porat as CFO. My money is on Ruth being the biggest change to Google. reply AlbertCory 3 hours agorootparentCould be. Patrick was just so perfect as a Google CFO. Only-at-Google. His backpack full of hundreds (supposedly). But Ruth: she could be anywhere in the corporate world. reply V-eHGsd_ 3 hours agorootparentpatrick \"sorry I missed the last tgif I was running a marathon in paris with my daughter\" pichette. and I don't say that disparagingly. that was endearing. (i'm probably getting some details of that wrong, it was ... dear lord, a long time ago) reply jrockway 3 hours agorootparentSpeaking of TGIF, the day it moved to Thursday is where I start my \"beginning of the end\" counter. reply V-eHGsd_ 2 hours agorootparentit was less fun having beers on a thursday afternoon for sure, but I at least understood the fact that the company had thousands of non-US employees and TGIF on a friday afternoon for us was TGIM for everyone else. reply dilyevsky 2 hours agorootparentprevImo patrick was no better with his â€œwe saved 200M on snacks this year oh btw guess what my bonus wasâ€ reply infotainment 3 hours agoparentprevThis tracks with what I saw as an outside observer; I felt like around 2015 was the inflection point where Google started its slow arc toward mediocrity. It seemed like maybe Eric Schmidt's departure had something to do with it, though it's possible that was just coincidence. reply V-eHGsd_ 3 hours agorootparentyeah, eric stepped down in 2011 and larry took over as CEO and from the inside it felt fine for a while. but larry definitely got disinterested after a few years and the company felt rudderless by like the end of 2014. reply dash2 12 minutes agoprevSo I looked at the original 2005 email and saw this: \"Google is the opposite: it's like a giant grad-school. Half the programmers have PhD's, and everyone treats the place like a giant research playground.\" Ah, that's why you have the problem now. You let the madmen take over the asylum! Sorry, guys, I know engineers love to believe that everything would be fine if engineers ran everything. It just ain't so. reply xyst 5 minutes agoparentI see you went to the b-school that taught the â€œcOnJoInEd tRiAnGlEs oF sUcCeSs!1!1â€ reply hintymad 2 hours agoprevIsnâ€™t it obvious? When the company had 1000 people or fewer yet was printing money, it could of course use Putnam questions or Matin-Gardneresque puzzles or ICPC programming problems to pick the brightest and smartest, and maintain a geek culture. But when the company grew to 130K people yet still managed to hire another 25K in a year, the culture was destined to change, if not deteriorate. > he most incredible and unusual thing that struck me about Google's early culture was the tendency to value employees above all else At that time, those employees are Jeff Dean, Sanjay Ghemawat, Rob Pike, Paul Buchheit, Lars, and etc. Nowadays we got employees who bragged about their â€œlifestyleâ€ on TikTok reply piva00 42 minutes agoparent> Nowadays we got employees who bragged about their â€œlifestyleâ€ on TikTok And bicker around Blind about \"TC\" to show off how much money they are making. It's like a new generation of yuppies but instead of working in finance in the 80s they are working for Big Tech in the 2010s-2020s. I've been in the tech since the early 2000s, right after dot-com bursting, it's been very palpable the change on types of people who wants to work in tech, before it was geeks who learned to fiddle with computers since we were kids, the later cohorts came specifically through a path of learning CS to apply for jobs paying US$ 100-200k as their first salary. reply ilrwbwrkhv 13 minutes agorootparentSo many Indians too. I wonder if that reduces Google's ability to think creatively and instead fit into boxes and do the given task well. I know I'm generalizing but at that scale I wonder if it shows up. reply tptacek 3 hours agoprevI find it useful, in reading this stuff, to remember: the company he joined in 2005 had (apparently) 5,600 employees. In 2022, that number was 190,000. reply redcobra762 2 hours agoprevSomeone I used to work with was acquihired into Google, despite being one of the most manipulative, conniving, duplicitous people Iâ€™ve ever met. A person like this can get found out at companies that value talent (he has none), but at Google, heâ€™s thriving. This ruined the shine of a Google resume, for me. Itâ€™s still great, but itâ€™s just a job now. I look at the specific skills applied during an applicantâ€™s time there, as opposed to previously presuming some level of excellence as a result of working with what I at one point thought were other great engineers. reply mrintegrity 1 hour agoparentI was at a big conference in Dublin years ago where a Google talking head stated to hundreds of people that \"google only hires the most intelligent people\" with a grotesquely smug look on her face, instantly turned me off from ever considering applying to work there. Incidentally RMS was also there and screamed from the back \"WHICH BSD LICENSE?\" when the Google drone said google uses \"the bsd license\", which I thought was hilarious. reply cageface 1 hour agoparentprevTwo of the worst colleagues I ever had also went on to thrive at Google. Itâ€™s been hard for me to take their claims of only hiring the best since then. reply elektrontamer 2 hours agoparentprevHow is that even possible? Won't he just get exposed in the first performace review? Or is he in some cushy managerial role? reply rightbyte 2 hours agorootparentYour boss got no clue how hard or easy your work is usually. Even if he is a good programmer you need to more or less work side by side to get a grip on someones performance. And smooth talkers game peer reviews. reply romanovcode 2 hours agorootparentprevI've worked in one big company when something like this actually happened. First week one developer blatantly said to management in-front of the scammer that the scammer (CTO) doesn't know anything about technology and is a complete fraud. The developer got fired 10 minutes later. Others took note to not challenge him if they want to keep their job. That happened ~10 years ago and I am actually grateful for that experience because I was just starting out, the scammer indirectly taught me much more about how to scam and lie your way to the top, how to sell your ideas to unaware management and most importantly - that office politics are 10x more important than merit in big companies. reply jjav 2 hours agorootparent> that office politics are 10x more important than merit in big companies My experience (5 startups) is that office politics are 100x more important in small startups. Everything is more concentrated, including the politics. That's why there is so much cofounder drama to go around. At least in a big company there's a lot of inertia and process to tone down the politics a little bit. reply shiroiuma 48 minutes agorootparentYeah, I agree. Anecdotes like the GP's just show that big companies aren't immune to these problems (and some big companies are better-run than others). These problems can happen at any company. My experience, at both big and small and also medium-size companies, is that smaller companies usually have much less process and procedures, and can vary greatly from one to another. Big companies have evolved procedures and processes to try to mitigate these human problems. So, for instance, you're much more likely to see sexual harassment and discrimination in a smaller company: if the guy who owns the place is cool with it, it'll be the norm there. Huge companies don't get to be huge these days by tolerating that stuff, and they have a lot of money to lose in a lawsuit, so they put a lot of effort into insulating themselves: anti-harassment training for employees, etc. reply boxed 2 hours agorootparentprevYou learned how to assume the world is broken, and not fix it. That's the path back to a hunter gatherer society. I think that's the wrong lesson to learn. reply vkazanov 47 minutes agorootparentThis might sound rough but the lesson should be \"don't be an idiot\". Time for shouting \"king's naked!\" comes eventually but people who ignore timing will end up losing this game. The secret to this is to understand how other decision-makers see the status quo. Who made a bet on this person? Who understands that he is THE problem? Is right now the best time for a direct opposition? And sometimes it's just easier to accept that it may make sense to work elsewhere. reply Intralexical 1 hour agorootparentprevHard agree. But yet, what became of the one who did try to fix it? reply protomolecule 1 hour agorootparentHe left that shitty place early and lived happily ever after? reply romanovcode 2 hours agorootparentprevI learned how big companies function and how to get ahead quick. The two things - politics and competence are not mutually exclusive. reply treprinum 2 hours agoparentprevMy very first boss that I believe is an undiagnosed psychopath is now director level over there. That told me everything I needed to know about any possible direction of the company. I no longer use anything made by them and actively steer everyone I know away to alternatives. reply the_gipsy 2 hours agorootparentCheck out the Gervais Principle. https://www.ribbonfarm.com/2009/10/07/the-gervais-principle-... reply InCityDreams 32 minutes agorootparent>the Gervais Principle Which it's not really, as it only considers the US version. \"The characters portrayed here are based upon other characters that RG invented.\" reply selfawareMammal 2 hours agorootparentprevAfter being in multiple orgs and having been in touch with c-suite, I have suspicions that lack of total empathy and psychopathic tendencies are a must to get to really high social-based positions. reply saiya-jin 1 hour agorootparentThey are practically a must just to get there... to thrive in this 'layer' of society, a person is quite far away from regular average human in various worst ways possible reply SkyMarshal 2 hours agorootparentprevWhat alternatives do you recommend for email? That's my one google service I have difficulty getting away from. reply johannessjoberg 2 hours agorootparentFastmail is great and worth the small cost imo reply the_third_wave 2 hours agorootparentprevSelf-host, easy. No matter the hordes of detractors who will tell you this is impossible and that all your mail will be /dev/nulled by all the usual suspects (Microsoft, Microsoft and Microsoft being the main culprit here, Gmail comes in second) the truth is that you'll be fine as long as you make sure to configure things like SPF and DKIM correctly and you're either using a smarthost for outgoing mail (ask your IAP whether they provide one) or are on a reputable network. A SBC like a Raspberry Pi is sufficient to host mail services for a fairly large number of people. Filter out spam with Spamassassin and a greylist, run sieve to organise your incoming mail flow, use specific mail addresses when communicating with commercial and government organisations and you'll end up asking yourself why so many people insist that self-hosting mail is not an option. Now that you're self-hosting mail you can also self-host XMPP using the same address making it possible for people to reach you through either SMTP (mail) or XMPP (instant messaging/voice/video calling) using that address. This can be hosted on that same SBC without problems. Source: my own experience self-hosting mail (and more) since the 90's. If it worked on a 486DX2-66 it should work on a quad-core 1.5GHz 64-bit ARM... reply unethical_ban 2 hours agorootparentprevI use Protonmail. Free tier I think, but I pay $10 a month for a bundle that allows custom domains, calendar, VPN, and storage. reply atomlib 51 minutes agorootparentYou pay $120 per year, not $10 per month. reply Doctor_Fegg 2 hours agorootparentprevRunbox is good. reply foofie 25 minutes agorootparentprev> My very first boss that I believe is an undiagnosed psychopath is now director level over there. That told me everything I needed to know about any possible direction of the company. I no longer use anything made by them and actively steer everyone I know away to alternatives. I had a boss who was a manager at one of Google's flagship products, and he made it his point to not let anyone forget it. He pushed people to work nights and weekends, he berated team members and threatened firing them during daily meetings, he overrode engineer's calls to not release a product to claim he released it before schedule, he threatened the same engineers if anything went wrong during the illadvisable release, etc. He was since hired as a VP of engineering of another global company. reply operatingthetan 2 hours agorootparentprev>undiagnosed psychopath Eh, I've seen these in every kind of company, none are immune. reply com 1 hour agorootparentIf youâ€™re in a business still in control of your own destiny, you could do what we did and keep a weather eye out for sociopathy-aligned behaviours and gently work them out while minimising danger. It worked reasonably well at one place I was at for about 8 years, estimating one of those characters popping up every 200-500 hires. Itâ€™s the strategic side to your internal integrity function. Typically recruit folks who are lightning rods for these kinds of behaviours: young, female, brown, queer members of staff - donâ€™t forget reception annf cleaning personnel! - and train them (often not necessary!) to spot abuse of power, bullying, threats and gaslighting and to confidentially report it. Catch people with these behaviours early and divert the smart ones, fire the dumb ones. Sure, youâ€™ll lose your next CEO, but did you want to work for that kind of person? reply choppaface 2 hours agoparentprevFormer friend joined Google and started hitting his pet (violently and angrily) and doing heavy drugs. Anthony Levandowski might be an outlier at Google for criminal behavior as well as total comp, but there are plenty of Googlers who you want to have nothing to do with. reply sidcool 2 hours agoprevI think the recent treatment by companies of its employees will remove the rosy glass from our eyes. All employee goodiness is a fair weather phenomena. Always keep a healthy distance from your work and company. reply siwatanejo 1 hour agoprev> The takeaway here is this: we should all learn from early-Google's example. When employees feel truly valued (which is rare!), it creates psychological safety, high morale, productivity, and creativity. Early employees would often encourage each other to \"fail fast\" as a means to innovation, but that's no longer easy in an environment where failure implies a layoff. If you're someone building a company, challenge yourself to value employees above all else, then watch and be amazed at the ROI. This paragraph (which is the ending one) feels like it is contradicting the rest of the article. Because if those things really led to an awesome ROI, then Google would not be where it is now, but in a much better position than before. I guess? Don't get me wrong, I'm not against valuing employees above everything else, but if this becomes too extreme maybe it's normal that the company creates too much fragmentation? For example, why did Google create both Go and Dart? Shouldn't they converge into one? (Shouldn't Flutter have been written in Go?) And I'm sure there are more examples like this (e.g. we can talk about Fucshia...). reply toyg 5 minutes agoprev> You know how people are much more likely to read an email if it is one screen long, rather than the length of this :-/ ? It is similar with contributing code to the kernel. It is much more social and relationship developing to contribute a screenful or two of code once every week or two over the course of years. We were dropping 90,000 lines of code on them all at once, having worked on it in total social isolation for 5 years in Moscow, Socially it was all bad. Small increments are the more social way to go. Incremental improvements to V3 would have met no opposition. reply neom 3 hours agoprevReminds me of the recent blog post by Sir Adrian Cockcroft. Signs that itâ€™s time to leave a companyâ€¦ https://adrianco.medium.com/signs-that-its-time-to-leave-a-c... reply flklklklkl 2 hours agoprevWhenever I see posts like these, whether for Google, or any other company, I can't stop thinking about the people not working as engineers - the sales guys, CS reps, building maintenance, the IT guys. Did they have 20% of their time dedicated to \"personal projects\", whatever that might be? Did they have free food? Are their titles attached to their person? Do they feel their employer value its employees above all else? I have a tiny little cynical voice in the back of my head having a good laugh, but I might be wrong. reply saagarjha 45 minutes agoparentFulltime employees at Google are basically the same as any other employee. They get the same benefits, can eat the free food, and generally I haven't seen any serious discrimination against them for being \"not engineers\". However, some of the things you've mentioned (e.g. building maintenance) are often done by contractors or outside firms, and for them things are often very different. reply darth_avocado 3 hours agoprev> Early employees would often encourage each other to \"fail fast\" as a means to innovation, but that's no longer easy in an environment where failure implies a layoff. Something that is amazing that often leadership fails to realize is the above. During my last days at X (formerly known as Twitter :P), everyone was just risk averse because it automatically meant a middle of the night firing. So much engineering time was wasted on non productive stuff, that could otherwise be spent on generating more profits for the company. Somehow management wanted you to constantly work towards making more money, while also punishing you for executing on ideas because it was taking you longer than 2 weeks to build and therefore were not working on something that made money immediately. Edit: itâ€™s not just innovation that takes a hit, it creates a lot of behaviors that are counterproductive for the company. People hoard information to make themselves irreplaceable, a very small percentage of psychopaths actively sabotage others, people steal ideas and have multiple competing groups work on the same thing, people refrain from raising issues that later create bigger problems, people only work on shiny new things that have the leadershipâ€™s blessing while dumping their unstable tech debt on others etc. reply eru 3 hours agoparentSounds like their internal interest rates have gone up? reply poundofshrimp 3 hours agoprev> But, coming back to my first decade at Google, it was incredible to see employees valued above everything else. Perhaps this is a privilege only possible in a culture of infinite abundance. Or maybe not? Maybe it's possible in a limited-resource culture too, but only if the company is small. Every team that Iâ€™ve been on where I felt this way was when that company was rapidly growing and successful. I canâ€™t say the reverse is necessarily true, but can success be the key ingredient that enables this, not the company size? reply debok 2 hours agoparentI worked for a bootstrapped startup where the opposite was true. While the company was in survival mode, employees were highly valued and the owners had a \"we're in it together\" type of attitude. When the money started rolling in, their attitude changed to \"we are better than you.\" They moved all their employees to a different office than themselves, and started treating us like we are expendable. They lost all their competent staff in a year, and had to start relying on freelancers to get anything done. reply hiAndrewQuinn 3 hours agoprevFor me, the important sentence is \"Google is still a great place to work -- far better than most companies -- and still doing amazing things.\" This is very interesting, but I like that the author notes the outside view, because I still get the feeling I'd like to work there someday. reply glimshe 28 minutes agoparentDon't go to Google unless it's for the pay/benefits (benefits are basically pay in a costume) or for a very particular role which is unmistakably aligned with your professional priorities. You won't find any of the mythological coolness there, literally all of my buddies say. Additionally, when recruiters sell you the position, they try to make it look like you are working at the core of their most important products, when it's generally about some minute pedestrian detail of their internal ecosystem. reply hiAndrewQuinn 11 minutes agorootparent>unless it's for the pay Luckily, that's the only reason I do anything at all! reply ChicagoDave 3 hours agoprevBen was also a co-creator of the once ubiquitous Subversion source control software. reply pjmlp 1 hour agoparentVery happy user until 2019, until the winds of change were forced upon me. Thanks Ben. reply gmerc 2 hours agoprevIf anything OpenAI demod just how quickly culture can be changed by paying massive salary packages. The non profit people never stood a chance. reply siliconc0w 3 hours agoprevThere is no evidence layoffs are a good idea from a fiscal perspective either, except in the short term. They're basically random so you loose good talent and you demoralize the best that stay. It should be reserved for dire circumstance. reply ptmcc 3 hours agoparentAnd if you must, cut deep and cut only once. Trickling out monthly layoffs is far more demoralizing and instills a culture of fear and uncertainty. reply travisgriggs 3 hours agorootparentIt has always been my theory/belief that long periods of demoralization actually get rid of a disproportionately higher amount of good talent. When the company starts to smell, those that can move on, because theyâ€™re in demand elsewhere as well, will do so. Youâ€™re then left with those that hope you donâ€™t let them go, but are less confident or capable in their abilities to find employment elsewhere. reply antupis 3 hours agorootparentprevI think there are two ways. The first is basically what good sports teams do (or Netflix at least was doing) where you continuously fire people who don't perform wanted at levels but also do very rigorous hiring and pay very well. Then there is cut fast and deep and shuffle organization at the same time which also works if you do that when needed and very rarely like once in 10-15 years Facebook might have pulled this and the company looks like it is in much better shape than Google or Amazon. reply pants2 3 hours agoparentprevAre the layoffs actually completely random? Is there some reason to do that instead of performance-based layoffs? reply yodsanklai 7 minutes agorootparentI suppose every layoff is different, but they are not completely random. There are many factors involved, performance can be one of them. My assumption is that leaders craft some query on the employees list and tweak parameters until they get the right number of people to lay off. reply heads 4 hours agoprevInfinite abundance â€” free boiled eggs and T-shirts â€” just felt like an extension of freedom to perform at the fullest of my abilities (which started out pretty meh, but grew quickly over time more than any other time in my career) without having to worry about anything else. Thereâ€™s something deep in the human mindset about resource anxiety and the importance of that not being a thing canâ€™t be underestimated. So maybe it kind of was about the free food and clothing all along? reply neilv 3 hours agoparent> Thereâ€™s something deep in the human mindset about resource anxiety and the importance of that not being a thing canâ€™t be underestimated. So maybe it kind of was about the free food and clothing all along? From the outside, this was much of the appeal of Google earlier on (and rare other places, at times): personal finances are taken care of, low corporate BS, no startup runway anxiety, no \"if only we could spend resources on that thing\", no \"if only I could combine efforts with more people like me\". Instead of stress about modern cost of living, stress about whether there's going to be layoffs or bankruptcy, stress from untrustworthy leadership, etc., there's only... Hmmm, I just encountered another tricky application of technology problem that I want to solve, and it seems hard, but I can just focus on it and solve it. For me, the appeal wasn't the myths about \"smartest people in the world\", nor the prestige (other than not being a downward arc on resume), nor the perks, nor the hip decor. Though, as you say, maybe some of the perks also gave a very base reinforcement of the sense of resource non-scarcity. reply closeparen 2 hours agoparentprevItâ€™s hard to imagine an absence of resource anxiety in the land of the six figure mortgage payment. Must have been incredible. Resource anxiety is exactly the phrase. Two things utterly surprised me about my experience in Silicon Valley: the unbelievable level and growth of TC, and its utter inadequacy/precarity next to the insatiable vacuum of a mortgage here. Strange place. reply kweingar 3 hours agoprevIs there any tech company, big or small, with the same kind of dynamic engineering culture that Google once had? reply pompino 1 minute agoparentThey permanently harmed the world with their spying technologies, what exactly is there to celebrate of their culture? reply throwaway2037 1 hour agoparentprevI can think of two: Digital Equipment Corp and Sun. Also, first 10 years of AWS was probably ridiculous good. reply V-eHGsd_ 3 hours agoparentprevi'm sure there are. but google's arc, the engineering culture wasn't just dynamic, it was dynamic and (apologies to use an eric schmidt-ism) impactful. reply apienx 1 hour agoprev> The unstated cultural principle was: \"products come and goâ€œ That explains a lot! ;-) reply VirusNewbie 2 hours agoprevPeople have been quick to point out how Google's culture has had a fall from grace, but I don't think I've seen too many mention that the rest of the industry copied (to varying degrees) a lot of Google's culture in a good way, narrowing the gap quite a bit. When I joined the tech industry in the early 2000s, most companies, including many tech companies, were very Office Space esque. Drab cube farms with dull carpet, horrible coffee, and MBA types running the show. Getting a second monitor or different equipment took months if it was even possible. Maybe you got lucky and got some free snacks and coke. The idea that an engineer could be paid as much on an IC track as a manager or director was quite rare, much less showering employees with perks such as free food, gourmet coffee, video games, lounges, and the like. All of that is fairly common. I've worked at startups that had free food, plenty of companies have a fairly lucrative IC track, snacks/perks, pleasant looking offices and all that. The gap is a lot smaller, even on Google's good days, and I think that affects everyone's perception more than they realize. reply gws 2 hours agoprevâ€œThe most incredible and unusual thing that struck me about Google's early culture was the tendency to value employees above all elseâ€ I wish they had valued users above all else reply langsoul-com 2 hours agoparentThat's Amazon. There's a triangle, value employees, customers or suppliers. You can never have all 3. reply max_ 3 hours agoprev\"Early employees would often encourage each other to \"fail fast\" as a means to innovation, but that's no longer easy in an environment where failure implies a layoff. If you're someone building a company, challenge yourself to value employees above all else, then watch and be amazed at the ROI.\" Relevant post from the same author â€” FAQ on leaving Google https://social.clawhammer.net/blog/posts/2024-01-10-GoogleEx... reply kderbyma 3 hours agoprevAlphabet has ruined it's entire portfolio if measured by the initial vision of each product. They have decimated the once great platforms they developed in pursuit of ever canabalizing their consumers reply jacquesm 3 hours agoparentAs well as lots of stuff they acquired and left to rot. reply tock 3 hours agoprevBen and Brian's Google IO talks were fantastic. Their talks always made me realise that Google was a special place. Sad to see its not the case anymore from Ben himself. reply ipaddr 2 hours agoprevThere is pre IPO Google culture and post reply mschuster91 3 hours agoprev> Let me explain. In a typical company, when priorities shift, you \"downsize\" (or cancel) a project, and then use the money to add people to a different, more important project. The common way to do this is fire people from the first project, then rehire a bunch of new people in the second project. It's easy, it's simple, it's expected. This is funny for me as a German, because here as a company you are not allowed to fire people essentially on a whim - you have to find new roles for them in the company, and can only lay off people if you can't reasonably do so. Obviously you can try nevertheless but if you can't prove in front of a court that you did reasonable effort, then you'll lose. And that email quote is also interesting on its own: > Even the IT department works differently. In every building, there are little offices called \"tech stops\". They sort of look like miniature computer stores. If you have a problem with your computer, just walk it right into the tech stop and show a technician. They generally help you on the spot. If you need hardware, just ask. \"Hey, I need a new mouse\"... \"sure, what kind would you like?\", says the tech, opening a cabinet full of peripherals. No bureaucracy, no forms, no requests. Just ask for hardware, and get it. The same goes for office supplies... cabinets full of office supplies everywhere, always stocked full. Just take what you need, whenever you feel like it. I think that in the end all this bureaucracy is part of what makes people feel like they're just another cog in the machine, and it's intended to do so. Just think about it from the outside... a company that pays you 60k a year, but adds about 100$ worth of \"management overhead\" for a simple mouse for 15 â‚¬? It certainly shows that you, or anyone else, isn't to be trusted even with minuscule amounts. reply 29athrowaway 3 hours agoprevPro tip: Turn reader mode on reply neilv 3 hours agoparentThis article's site is a rare one for which Firefox's built-in reader mode doesn't currently have a silent cost: the reader mode bypasses uBlock Origin protection against some kinds of trackers. reply petesergeant 3 hours agoprevOther than people who worked there, and miss the old days â€¦ who cares? Google has transitioned into a mature tech company, which basically means theyâ€™re just an investment vehicle now managing assets. Theyâ€™ll buy the innovation they need, but otherwise managementâ€™s job is to predictably manage share prices and profit. The nostalgia is nice for people who worked there, but the maturity of the business being presented as decline rather than natural transition is weird. Itâ€™s time for smaller, scrappier tech companies to be the place where the innovation happens. It feels like people complaining about gentrification of happening neighbourhoods. The yuppies or shareholders move in, and the neighbourhood transitions, meanwhile smaller, harder to get to, edgier places are taking their place reply jillesvangurp 3 hours agoparentGoogle is a bit like Microsoft under Steve Ballmer. It had lost its way. There was no leadership. Most of what they tried failed or wasn't that great. And yet it was still raking in the profits. And then MS turned it around. All it took was new leadership. They just overtook Apple as the most valuable company in the world. Just a string of good, solid decisive leadership. Satya Nadella turned that company around. Could happen to Google as well. But not with their current CEO. They have a lot of stuff that they are working on but very little of it has any real impact on their revenue. Their strategy is a mess. And they have a huge expensive work force not delivering more revenue to justify their existence. And they've been hiring non stop for 20 years just mindlessly growing their staff adding tens of thousands of people per year. The Google that built the company was much smaller and nimbler. The layoffs slow down the bloat but it's still a bloated company. The reason they get away with that is that revenue hasn't stopped growing either. But it's increasingly detached from staff size. Staff reductions at this point merely increase profits. reply petesergeant 2 hours agorootparentAbsolutely they need a leader to turn it around, but Apple and Microsoft donâ€™t feel like Google did: itâ€™s still going to be a mature tech giant, run by spreadsheets, even if they can start producing some cool stuff again reply Niksko 2 hours agoparentprev> It's time for smaller, scrappier tech companies to be the place where innovation happens I think this is exactly what is being lamented. There was interesting stuff happening for a really long time, and now there isn't. And companies that stop innovating tend to die long, slow deaths. It sounds like Google held out longer than most, but now runs the risk of going the way of the dodo. I'd lament that too. reply petesergeant 2 hours agorootparent> and now there isnâ€™t â€¦ at Google. Which comes back to my point that why should anyone except Google ex employees care if itâ€™s happening there or somewhere else? reply glompers 3 hours agoparentprevIf historic Broadway theaters in NYC transitioned to blocks of server farms, then many people would have a feeling, \"Singing and dancing and live art used to happen here, and that history is worth continuing, here,\" even if for economic reasons it wouldn't and couldn't anymore. . . and so I don't think it's only wistful or wishfulness speaking. It's positive to believe that places where creativity happened and was on display and at least nominally prized were places that need to continue in some form or fashion. I agree with you that the form and fashion may just be less visible now to these people wherever it has moved on to, now. reply jrockway 2 hours agorootparent> If historic Broadway theaters in NYC transitioned ... We should get a \"Landmarks Preservation Commission\" for corporate cultures. reply avgcorrection 2 hours agoparentprev> Other than people who worked there, and miss the old days â€¦ who cares? So youâ€™re not a Googler? Or a Xoogler? Maybe you identify as a Noogler (never-Googler)? reply galkk 2 hours agorootparentNoogler - new googler. not â€œnever googlerâ€. reply avgcorrection 2 hours agorootparentWhen you canâ€™t parody reality because it just outdoes your efforts. reply eesmith 3 hours agoparentprevTo dissuade potential employees who are thinking to apply because they mistakenly think it's still like the stories they hear from the old days? To provide inside to employees in other companies which are undergoing a similar transition, so they can get insight about the transition they are experiencing? reply riku_iki 2 hours agoparentprev> theyâ€™re just an investment vehicle now managing assets. or abusing monopoly and network effect. reply renewiltord 2 hours agoprev [â€“] It's interesting. When I moved to California in 2012, Google was exciting. They had hot stuff, new platforms, very exciting. Six years later, you were hesitant to hire Google people. Today, it's the Bay Area retirement home. No one takes a Google resume seriously and everyone who works there talks about little they work. In a sense a massive transfer of wealth from capital to labor: the finest example of redistribution in the world. reply tavavex 2 hours agoparent [â€“] I'm sorry, I'm speaking from a point of absolutely no experience in these high-profile Silicon Valley jobs, but \"companies refuse to hire Google employees\" strikes me as a statement akin to \"the king refuses to dine from a 99.999% gold plate because they skimped out on getting him a 100% pure plate\". Even right now, many tech workers see Google and other big-name tech companies as basically the ultimate goal of their careers, and I can't really imagine the kind of a one-in-a-million company that'd be justified in turning down a Google ex-employee based on just their employer. reply OsrsNeedsf2P 2 hours agorootparent [â€“] He's like 30% correct. Before, hiring someone from Google was an accomplishment, because they were so rare. Now, there's so many people with Google on their resume, most refusing to downsize in TC, that even mediocre positions are filled with ex-Google applicants. reply tavavex 2 hours agorootparent [â€“] Is that really because Google workers are seen as worse employees (like what the original post said), or just because the job market is now suddenly loaded with thousands of Google employees who'd just been laid off? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author, a former Google employee, reflects on the company's early culture of prioritizing employee well-being and discusses Google's unique approach to reorganization by transferring employees instead of laying them off.",
      "However, the author acknowledges that as Google has grown and encountered financial difficulties, this culture has shifted, resulting in layoffs and a more conventional approach to resource allocation.",
      "The author emphasizes the significance of valuing employees and creating a culture of psychological safety to foster productivity and creativity and suggests that smaller companies may find it easier to maintain a hands-on approach to employee reorganization."
    ],
    "commentSummary": [
      "This discussion covers various aspects of Google's culture, management, innovation strategies, employee treatment, and financial growth.",
      "Commenters analyze the challenges of maintaining Google's principles and culture as it grows, as well as its declining performance and innovation.",
      "The conversation also touches on office politics, company culture's impact on morale and productivity, and the importance of valuing employees. It discusses copyright infringement, AI's impact on journalism, and compensating media outlets."
    ],
    "points": 238,
    "commentCount": 163,
    "retryCount": 0,
    "time": 1705639592
  },
  {
    "id": 39049703,
    "title": "AlphaFold Enables Discovery of New Psychedelics for Antidepressants",
    "originLink": "https://www.nature.com/articles/d41586-024-00130-8",
    "originBody": "NEWS 18 January 2024 AlphaFold found thousands of possible psychedelics. Will its predictions help drug discovery? Researchers are working out how to deploy the revolutionary protein-structure tool to discover medicines. By Ewen Callaway Twitter Facebook Email Protein structures predicted by AlphaFold have helped to identify candidate drug compounds.Credit: DeepMind Researchers have used the protein-structure-prediction tool AlphaFold to identify1 hundreds of thousands of potential new psychedelic molecules â€” which could help to develop new kinds of antidepressant. The research shows, for the first time, that AlphaFold predictions â€” available at the touch of a button â€” can be just as useful for drug discovery as experimentally derived protein structures, which can take months, or even years, to determine. AlphaFold touted as next big thing for drug discovery â€” but is it? The development is a boost for AlphaFold, the artificial-intelligence (AI) tool developed by DeepMind in London that has been a game-changer in biology. The public AlphaFold database holds structure predictions for nearly every known protein. Protein structures of molecules implicated in disease are used in the pharmaceutical industry to identify and improve promising medicines. But some scientists had been starting to doubt whether AlphaFold's predictions could stand-in for gold standard experimental models in the hunt for new drugs. â€œAlphaFold is an absolute revolution. If we have a good structure, we should be able to use it for drug design,â€ says Jens Carlsson, a computational chemist at the University of Uppsala in Sweden. AlphaFold scepticism Efforts to apply AlphaFold to finding new drugs have been met with considerable scepticism, says Brian Shoichet, a pharmaceutical chemist at the University of California, San Francisco. â€œThere is a lot of hype. Whenever anybody says â€˜such and such is going to revolutionize drug discoveryâ€™, it warrants some scepticism.â€ Shoichet counts more than ten studies that have found AlphaFoldâ€™s predictions to be less useful than protein structures obtained with experimental methods, such as X-ray crystallography, when used to identify potential drugs in a modelling method called proteinâ€“ligand docking. What's next for AlphaFold and the AI protein-folding revolution This approach â€” common in the early stages of drug discovery â€” involves modelling how hundreds of millions or billions of chemicals interact with key regions of a target protein, in the hope of identifying compounds that alter the proteinâ€™s activity. Previous studies have tended to find that when AlphaFold-predicted structures are used, the models are poor at singling out drugs already known to bind to a particular protein. Researchers led by Shoichet and Bryan Roth, a structural biologist at the University of North Carolina at Chapel Hill, came to a similar conclusion when they checked AlphaFold structures of two proteins implicated in neuropsychiatric conditions against known drugs. The researchers wondered whether small differences from experimental structures might cause the predicted structures to miss certain compounds that bind to proteins â€” but also make them able to identify different ones that were no less promising. To test this idea, the team used experimental structures of the two proteins to virtually screen hundreds of millions of potential drugs. One protein, a receptor that senses the neurotransmitter serotonin, was previously determined using cryo-electron microscopy. The structure of the other protein, called the Ïƒ-2 receptor, had been mapped using X-ray crystallography. Drug differences They ran the same screen with models of the proteins plucked from the AlphaFold database. They then synthesized hundreds of the most promising compounds identified with either the predicted and experimental structures and measured their activity in the lab. â€˜It will change everythingâ€™: DeepMindâ€™s AI makes gigantic leap in solving protein structures The screens with predicted and experimental structures yielded completely different drug candidates. â€œThere were no two molecules that were the same,â€ says Shoichet. â€œThey didnâ€™t even resemble each other.â€ But to the teamâ€™s surprise, the â€˜hit ratesâ€™ â€” the proportion of flagged compounds that actually altered protein activity in a meaningful way â€” were nearly identical for the two groups. And AlphaFold structures identified the drugs that activated the serotonin receptor most potently. The psychedelic drug LSD works partly through this route, and many researchers are looking for non-hallucinogenic compounds that do the same thing, as potential antidepressants. â€œItâ€™s a genuinely new result,â€ says Shoichet. Prediction power In unpublished work, Carlssonâ€™s team has found that AlphaFold structures are good at identifying drugs for a sought-after class of target called G-protein-coupled receptors, for which their hit rate is around 60%. Having confidence in predicted protein structures could be game-changing for drug discovery, says Carlsson. Determining structures experimentally isnâ€™t trivial, and many would-be targets might not yield to existing experimental tools. â€œIt would be very convenient if we could push the button and get a structure we can use for ligand discovery,â€ he says. Isomorphic Labs, a spin-off company of Googleâ€™s DeepMind in London, is ramping up its drug-discovery efforts using AlphaFold.Credit: Igor Golovniov/SOPA Images/LightRocket via Getty The two proteins that Shoichet and Rothâ€™s team picked are good candidates for relying on AlphaFold, says Sriram Subramaniam, a structural biologist at the University of British Columbia in Vancouver, Canada. Experimental models of related proteins â€” including detailed maps of the regions where drugs bind to them â€” are readily available. \"If you stack the deck, AlphaFold is a paradigm shift. It changes the way we do things,\" he adds. â€œThis is not a panacea,â€ says Karen Akinsanya, president of research and development for therapeutics at SchrÃ¶dinger, a drug-software company based in New York City that is using AlphaFold. Predicted structures are helpful for some drug targets, but not others, and itâ€™s not always clear which applies. In about 10% of cases, predictions AlphaFold deems highly accurate are substantially different from the experimental structure, a study3 found. And even when predicted structures can help to identify leads, more detailed experimental models are often needed to optimize the properties of a particular drug candidate, Akinsanya adds. Big bet Shoichet agrees that AlphaFold predictions are not universally useful. â€œThere were a lot of models that we didnâ€™t even try because we thought they were so bad,â€ he says. But he estimates that in about one-third of cases, an AlphaFold structure could jump-start a project. â€œCompared to actually going out and getting a new structure, you could advance the project by a couple of years and thatâ€™s huge,â€ he says. That is the goal of Isomorphic Labs, DeepMindâ€™s drug-discovery spin-off in London. On 7 January, the company announced deals worth a minimum of US$82.5 million â€” and up to $2.9 billion if business targets are met â€” to hunt for drugs on behalf of pharmaceutical giants Novartis and Eli Lilly using machine-learning tools such as AlphaFold. The company says that the work will be aided by a new version of AlphaFold that can predict the structures of proteins when they are bound to drugs and other interacting molecules. DeepMind has not yet said when â€” or whether â€” the update will be made available to researchers, as earlier versions of AlphaFold have been. A competing tool called RoseTTAFold All-Atom2 will be made available soon by its developers. Such tools wonâ€™t fully replace experiments, scientists say, but their potential to help find new drugs shouldnâ€™t be discounted. â€œThereâ€™s a lot of people that want AlphaFold to do everything, and a lot of structural biologists want to find reasons to say we are still needed,â€ says Carlsson. â€œFinding the right balance is difficult.â€ doi: https://doi.org/10.1038/d41586-024-00130-8 References Lyu, J. et al. Preprint at bioRxiv https://doi.org/10.1101/2023.12.20.572662 (2023). Krishna, R. et al. Preprint at bioRxiv https://doi.org/10.1101/2023.10.09.561603 (2023). Terwilliger, T. et al. Nature Methods 21, 110â€“116 (2024). Google Scholar Download references Reprints and permissions Latest on: Drug discovery Machine learning Jobs Research Career Development Fellowships About usResearch Career Development Fellowships in the Department of Cell and Developmental Biology, UCL: Expression of Interest for 2024DEADLINE: The England University College London (UCL) Postdoctoral Fellow New Orleans, Louisiana Tulane University School of Medicine Medical Director at Parkland Memorial Hospital Dallas, Texas (US) The University of Texas Southwestern Medical Center (UT Southwestern Medical Center) Vice Chair for Clinical Affairs Dallas, Texas (US) The University of Texas Southwestern Medical Center (UT Southwestern Medical Center) Director of Ocular Oncology Research Dallas, Texas (US) The University of Texas Southwestern Medical Center (UT Southwestern Medical Center)",
    "commentLink": "https://news.ycombinator.com/item?id=39049703",
    "commentBody": "AlphaFold Found Possible Psychedelics (nature.com)238 points by EA-3167 9 hours agohidepastfavorite54 comments dekhn 9 hours agoThey found a bunch of potential molecules that bind to 5HT2A, that's cool. But the really important conclusion of the paper, which I truly hope bears out, is that AF2 models are useful for finding binders to GPCRs. GPCRs are one of the largest (if not largest) drug targets and work (including my own) showed that modelling protein dynamics using expensive simulations was likely to be necessary to make accurate predictions of GPCR binding molecules. If this paper is correct, AF2 is actually able to recapitulate much of the detail that we previously believed required expensive dynamics simulations, which is about the best possible news because it suggests that we can omit these costly calculations. It's almost certain now that AF2 will win the Nobel Prize, as this represents some of the most exciting breakthroughs in the past few decades. reply Duanemclemore 8 hours agoparentEven if it has to go through extensive vetting on the theory side, the ability of these models to improve the starting points for the harder process is very strong. For example, in daylight modeling - and this is 2-3 years ago mind you - it has been found that \"AI\" is perfect for getting 99% closer to the actual luminance in something like 01% the computation. So that even if you feed those \"precalculated\" models into the traditional raytracers, the improvement to the first guess is well, well worth it. reply dekhn 8 hours agorootparentI don't really think there's an analogy between radiosity simulations and drug discovery. Drug discovery will probably remain fairly ad-hoc and stochastic for some time. reply Duanemclemore 7 hours agorootparentThat's fair. I was merely talking about being able to make better \"first guesses.\" Nowhere near the predictability of a much simpler phenomenon such as radiance mapping, of course. And as the article says, >\"There were a lot of models that we didnâ€™t even try because we thought they were so bad,...â€ reply vlovich123 4 hours agorootparentprevTo me the analogy is that generic AI techniques with minimal problem domain specific adaptations is providing huge boosts in efficiency on a wide variety of applications. Itâ€™s like the steam engine causing mechanical work to become vastly more efficient. AI in many ways is doing the same thing to intellectual work. reply mtlmtlmtlmtl 8 hours agoparentprevAs an expert, do you think this might lead to easier discovery of much more selective GPCR ligands? Agree finding new 5HT2A ligands is cool, what would be truly interesting is having a suite of totally selective ligands for the entire 5-HT receptor family. I feel like a lot psychopharmacological research into a lot of mental disorder is severely hampered by 1) the complex interactions of the various serotonin receptors(and also with other receptors like D2) 2) the lack of truly selective ligands, necessitating a hodge podge of less selective agonists combined with selective antagonists to isolate the effects of specific receptor interactions(making it hard to do this sort of thing in humans). Or using knockout mice, which is also kind of dubious because you've now made a fundamentally different brain and are trying to compare it to a normal one. And that's sort of hit and miss. reply timr 7 hours agoparentprev> But the really important conclusion of the paper, which I truly hope bears out, is that AF2 models are useful for finding binders to GPCRs. What seems more likely to you: that the (obviously worse [1]) structures produced by alphafold are somehow magically capturing protein dynamics, orâ€¦the virtual screening method (DOCK) used by the paper is relatively insensitive to the quality of the underlying model? They say right there in the article that neither screen was obviously enriched versus the other (the hit rate was around 50% for both branches, which was essentially the same as for the very different retrospective screening method in the same paper [2]). Iâ€™m putting my money on the parsimonious answer. Running structures through a large enough virtual screen will almost always find something that binds, even if the starting model isn't great. [1] at least in the case of the x-ray structure. Using a cryoEM structure is sort of interesting, since theyâ€™re blurry anyway. [2] the actual paper: https://www.biorxiv.org/content/10.1101/2023.12.20.572662v1.... reply dekhn 5 hours agorootparentI don't have a good answer. I don't think AF2 captures protein dynamics in a direct way. And I think docking programs have inadequate loss functions and sampling to really find accurate answers. I suppose AF2 could be modified to produce structures that are well mapped to docking programs. I think you're right, that running lots of structures through virtual screens will find lots of binders. In the middle days of protein design (well before AF2), people went from not being able to design anything, to being able to easily design \"rocks\"- proteins that were exceptionally stable, but didn't do anything interesting. Their loss function that they maximized for was stability. But that comes at a cost: high stability seems to prevent lability (which is useful for enzymes). And I think that if you just pass enough stuff through a good-enough program, you'll find lots of binders, but those binders won't actually be useful binders. We already know from decades of work that we can find lots of nanomolar and picomolar binders that don't do anything worthwhile (or have side effects). My conclusion is: we may very well be on the tip of solving another bottleneck in the drug discovery pipeline, or, we might just be bumbling around in a big space and found a nice local minimum. I don't think AF2 or similar systems on their own are going to completely solve the problem, and until DeepMind or somebody else creates something that can truly address the hard problems in human biology, the most we can hope for is finding more effective new drugs more cheaply and somehow couple that with improvements in genetic personalization. reply keenmaster 8 hours agoparentprevAwesome. What are a couple examples of what this may enable (drugs that would target the same)? reply dekhn 8 hours agorootparentI would extrapolate from existing GPCR-targeting drugs, but the list is so long I can't really give a survey. As a protein family, GPCRs do a lot of different things but basically it boils down to signal transduction: there's something outside a cell and the cell wants to know that so it can respond. GPCRs mediate the binding of the thing outside to the surface of the cell, and transduct the information into the cell, delivering a signal to the nucleus, where the transcriptional machinery is manipulated to make new proteins (or stop making proteins). I left out some steps. This allows the cell to be responsive to the outside in a secure way, without the outside molecule coming into the cell. The 3d structure of GPCRs is intimately associated with the cell membrane, with one end sticking out into the extracellular environment, and another sticking out into the interior of the cell. Simply getting that sort of protein, which is not soluble in water, was a massive challenge and the first structures didn't arrive until the early 2000s, when people learned how to crystallize GPCRs using detergents and other solvents that simulated cell membranes. So many diseases are caused by misregulation of signal trandsduction... let's take some examples. Vasopressin is a drug that also happens to be a natural body product. In some diseases, people don't make enough vasopressin to regular the kidneys properly, leading to a form of diabetes, and simply giving people more of it helps reduce the symptoms. I guess in this case (not certain), people have mutations in the GPCR that receives the vasopressin signal that attenuates the signal \"too much\" and by just dosing the patient with a lot more, more signal gets sent inside the cell. I think at least 10 nobel prizes in medicine have been awarded for research related to GPCRs, which has uncovered a wide range of medically relevant knowledge of physiology. The NERSC supercomputer \"Cori\" was named for Gertie Cori, who helped discover some of the core mechanisms in human metabolism during the golden age of metabolic biochemistry. I think the simplest way to think about it is being able to target specific GPCRs is like being in front of a switchboard with buttons and knobs controlling every critical detail of how human bodies manage and maintain themselves. reply oh_sigh 8 hours agorootparentprevA better question would be what don't they enable. Something like 30+% of FDA approved drugs operate along that pathway. Besides for the boring stuff like being able to trigger cancer cells to kill themselves, we could have a molecule you inject into your eye that opens up your vision to be able to see infrared and ultraviolet light(and beyond). reply boxed 8 minutes agoprevAfter seeing all the fakery from how AI models handle programming (being \"very good\" at tasks where it turns out it was just trained on the problem in the first place), I do wonder if AlphaFold is likewise a red herring. How many of the AlphaFold protein folding predictions have been actually verified by a lab? And are any of those actually new proteins or just tiny variations on things in the training set? reply zbowling 8 hours agoprevAI takes our jobs, and then it helps us get high. I love this future. reply WitCanStain 33 minutes agoparentIf only you'll have the money to get high after you no longer have a job. reply lgkk 6 hours agoparentprevPrecursor to the matrix. reply yazzku 6 hours agoparentprevYou're gonna be tripping like that cat astronaut on the moon, alien spaceship background, synthwave style. reply candiddevmike 9 hours agoprevThese will inevitably become \"research chemicals\" and potentially ruin a few psychonauts eager to try them. reply mtlmtlmtlmtl 8 hours agoparentAs a mostly \"retired\" psychonaut, I think this can easily be avoided by just legalising drugs. Very few people are going to want to try RCs if conventional alternatives don't present more legal risk. Most people using them are avoiding legal risk or trying to beat drug tests etc. There is a tiny minority of \"true psychonauts\" who are in it for the experimentation, but we tend to be acutely aware of the risk and take much better precautions than someone who is chasing a high they're addicted to. And adults knowingly taking risks(on their own behalf) and suffering consequences is just the human condition. reply morkalork 8 hours agoparentprevThe stories of people getting limbs amputated because the RC they were shipped by accident was an insanely strong vasoconstrictor while still tripping 24h after dosing is the stuff of nightmares. reply fb03 8 hours agorootparentThat's curious. Where can one read such stories? eRowid? reply r3trohack3r 8 hours agorootparentFor the curious, this Wikipedia article seems to document the case GP is talking about: https://en.wikipedia.org/wiki/Bromo-DragonFLY reply fb03 7 hours agorootparentThank you. Truly scary stuff. reply willcipriano 8 hours agorootparentprevMe and my friends found this drug conceptually hilarious back in the day and used to crack a lot of jokes about it. Its apparently almost as strong as LSD, takes hours to start working and the effect lasts several days. Worse in every respect. Why would anyone ever choose it? reply notamy 8 hours agorootparentpreviirc the specific incident being referenced is Bromo-DragonFLY being mislabeled as 2C-B-FLY. reply zoklet-enjoyer 7 hours agorootparentMislabeled and tainted RCs became enough of a risk when fentanyl and fentanyl analogs started gaining popularity that the guys I knew who were ordering from overseas just stopped messing with RCs. It's disappointing that it ended up like that. 2009-12 I had access to pure and dirt cheap 2C-E, methylone, 4-ACO-DMT, the JWHs, ketamine, methoxetamine, LSD (I don't think there were any analogs available yet?). It was a crazy time. reply morkalork 7 hours agorootparentYuuuuuuup this right here. That's right when I was in university and was definitely the peak. Maybe a bit before when mephedrone was big. I feel like I aged out of it at just the right time. Now I don't even recognize the names of what's going around. reply dendrite9 3 hours agorootparentI hung out with people who got various powder packages in the mail at that time. It was interesting, but already I knew it wasn't my scene. Still I learned a lot of names and watched the use on occasion. Looking at it now I'm glad it was then and I didn't have to worry about the various opioids getting mixed in. I don't think I thought enough about the consequences even though I worried about my friends dealing with various manners of contamination. reply 1propionyl 3 hours agorootparentprevAhhh... methoxetamine. That's one lost to time these days. reply candiddevmike 8 hours agorootparentprevNSFW IMO, https://www.reddit.com/r/researchchemicals/ reply zoklet-enjoyer 8 hours agorootparentprevProbably. Or bluelight. Bromo dragonfly back in like 2005ish reply aaroninsf 7 hours agorootparentprevTrue, and also, the stories in Phikal and Tikal of more disciplined people following titration protocols etc. and discovering hidden kingdoms of the mind, is the stuff of dreams. reply var_cw 1 hour agoprevAI's matching hit rates in drug discovery is a game-changer. It's like AlphaFold just gave us the GPS coordinates for the biochemical treasure we've been blindly digging for. LSD's serotonin link and the quest for similar, safer compounds? reply mondayp 6 hours agoprevAlphaFoldâ€™s potential in revolutionizing drug discovery, especially in the realm of psychedelics for antidepressants, marks a significant paradigm shift. reply PessimalDecimal 6 hours agoparentAs a total outsider to this area of research, why is AlphaFold's potential most notable specifically for psychedelics? reply cowsandmilk 3 hours agorootparentThe protein class they bind to has historically been hard to determine structures experimentally and had high flexibility. The preprint that is the basis of the article showed that using traditional virtual screening against Alphafold structures had similar success rates as screening against experimental structures. Additionally, the Alphafold structures may represent alternative conformations of the proteins not seen in the experiment-derived structures. reply uticus 6 hours agoprevThese tools are unlocking all sorts of things. For a darker side of the toolbox, ref https://news.ycombinator.com/item?id=36906214 reply simple10 7 hours agoprevSome have speculated psychedelics like psilocybin played a pivotal role in Homo Sapiens consciousness development. If true, the poetic symmetry of AI inventing psychedelics and smart drugs to fuel the next jump in human development is fascinating. Is there a genre of scifi for this yet? reply tedivm 6 hours agoparentWhat you're referring to is called, no joke, the Stoned Ape Theory. It is not really taken seriously at the moment, as it completely lacks in evidence. https://en.wikipedia.org/wiki/Stoned_ape_theory reply gamepsys 6 hours agorootparentHowever listening to it's originator Terence McKenna explain the stoned ape theory while intoxicated on the correct substances is a very fun experience. reply SamBam 6 hours agoparentprevI have always been fascinated in the fact that psychedelics, and, indeed, any plant-based molecule that can mimic a neurotransmitter, exists. Us and plants aren't creating the same molecule because we share a common ancestor. There are far too many other plants that don't create cannabinoids or opiates or whatever, and far too many other animals that don't create them, for this to be at all likely. It had to have evolved multiple times. It's not any kind of symbiotic relationship. Our ancestors didn't cause opiates to evolve by selectively eating and spreading their seeds. So it's a coincidental convergent evolution. But these are really complex molecules doing quite different things. Both cannabinoids and opiates evolved in plants to defend them from viruses and fungi. I don't know what other neurotransmitter-mimics are for, but they're not being used for plant nerves. I'm sure people know the answers to this, and I could read a book about it. reply __MatrixMan__ 5 hours agorootparent> I'm sure people know the answers to this I don't think they do. AFAIK most of your assertions above are unknowns. My theory, at least re: psilocybin and the like, is that a parasitic fungus developed neurotransmitter agonists as a way of manipulating its host. The complete cocktail that was needed to make the target species behave in a way that completed the fungus' lifecycle may be lost to time, but certain components of it still exist in the gene pool. And if you're going to have millions of spores (rather than the two or three offspring that, say, humans have) you can afford to set them up with a wider array of gene expression profiles. So you've got these fungi just trying stuff to see what works--now armed with neurotransmitter agonists as part of that \"stuff\". Later on you've got other organisms eating those mushrooms and behaving strangely. If you're a fungal spore, and you're in an animal's digestive tract, \"strangely\" is probably how you want it to be behaving. You're going to end up in a different place or with different nutrients or in some other situation which is abnormal for your host--you end up with greater habitat diversity. How specifically that host-behavior-strangeness would lead to a lifecycle that would reinforce the inclusion of psychedelics to the point where P. Cubensis is reliably psychedelic, rather than just the occasional mutant, I have no idea, but when you've got billions of years to play with, it's not hard to accept that some pretty weird animal-fungus interactions came up here and there. reply timschmidt 5 hours agorootparentMany psychoactive molecules are also structurally very similar to other hormones, and molecules produced for other aspects of biological function. Take a look at NN-DMT and Melatonin: https://en.wikipedia.org/wiki/N,N-Dimethyltryptamine https://en.wikipedia.org/wiki/Melatonin Just a slight mutation, or even biological synthesis under non-ideal conditions could easily result in synthesizing one or the other via the same pathway. reply timschmidt 5 hours agorootparentprev> Us and plants aren't creating the same molecule because we share a common ancestor. That is, in fact, exactly the reason. You are of course correct that synthesis of many biological molecules has evolved countless times over the eons, but chirality of certain critical molecules, amino acids, ribosomes, all evolved exceedingly early. Once the cellular machinery is synthesizing these things, synthesis of similar molecules, one, two, three mutations away become likely across swaths of related organisms, however distant. In short, we're all playing with the same lego bricks, and there are only so many different models possible to build with the set. reply spiritplumber 6 hours agoparentprevDoes the 2001 movie count? reply Rugos 6 hours agoparentprevDid you see Lucy (2014)? reply juggertao 5 hours agoparentprevHow would that be passed down the genetic line? Today's babies don't require psilocybin to become conscious. reply simple10 2 hours agorootparentIt's not a well supported theory, but fascinating. Possibly an epigenetic influence? Much more likely a cultural effect, if any, that nudged early humans down the path of spiritual pursuit as a sort of cultural glue. The more spiritually inclined you were, the more likely you were to thrive in the societal hierarchy. Use of psychedelics could have helped accelerate an individual's \"spiritual\" development and therefore afforded them additional offspring. So the correlation, if any, might be a favoring of genes that paired well with the effects of psychedelics. Pure speculation on my part. As for AI, it seems highly likely a new class of designer drugs will emerge, tailored to a specific individual to enhance societal adaptation. We've already seen this in play over the past 40+ years in the pharmaceutical industry. AI will only accelerate it IMO. reply juggertao 5 hours agoprevAre there any protein based psychedelics? I thought they are all small molecules. reply Synaesthesia 4 hours agoparentNot to my knowledge. reply WhackyIdeas 6 hours agoprevItâ€™s a brave new world. reply m3kw9 6 hours agoprevHas any discoveries or drugs ever reversed autoimmune conditions? This look like one of the big end level bosses for AI reply refurb 4 hours agoprevHere is maybe a helpful analogy for the challenges behind protein folding. The 5HT2A receptor is comprised of 471 amino acids. Proteins fold based on interaction between each of those amino acids, plus the external environment (plus post-translational modification). So imagine a length of string with 471 magnets attached to it with different magnetic field strength (ranging from weak to strong). Now imagine it floating in space - how would the string fold upon itself? Now imagine different segments of the string have different stiffness - some are super flexible, others are rigid. Difficult to predict how it might fold? Oh yeah! Now imagine the string not in space, but in a solution of water with a number of other magnets floating in it (the cytoplasm within the cell and external environment outside the cell). Oh, and also imbedded in a wall with magnets in it as well (the cell membrane). Now how does it fold? Ok, now we think we have a good approximation of the structure just based off of various pieces of data. But wait! Other proteins are also embedded in the cell wall - all with their own structures and selection of weak and strong magnets, stiff and flexible segments interact with the receptor! Oh, and not all receptors have the same external environment - that can differ based on another laundry list of factors. Yeah, that's another layer of complexity. Then add on top that the external environment (inside the cell on one side, outside the cell on the other) has a ton of water, but also dissolved ions like Na+, K+, Cl-, plus a bunch of other proteins with their own \"magnets\" and \"stiff and flexible segments\". These outside molecules will bind and disassociate from the receptor on a constant basis, ever so tweaking the shape. Oh crap. Of course AI has a good starting point - we can get x-ray crystal structures of the receptor and identify the position of atoms. But wait! That's in a crystal, not a human body! So that structure is likely incorrect in several ways. We also have other analytical techniques that can give clues to the structure in a solution that more closely mimics what's inside the body, so we can at least tell when the x-ray structure is just wrong (at least in some places). That should give people an idea just how complex protein folding is. AI is good at taking all known \"rules\" about protein folding (and molecule interactions with the protein) to improve the predictions. But we're still far off from truly understanding all the factors in play. reply uptownfunk 6 hours agoprevWhy not just take with chocolate like everyone else reply iancmceachern 4 hours agoprev [â€“] I find possible psychedelics on the sidewalk in my neighborhood in San Francisco quite regularly, coincidentally. /s reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AlphaFold, a protein-structure prediction tool, has identified hundreds of thousands of potential psychedelic molecules that could be used in the development of new antidepressants.",
      "Recent studies have shown that AlphaFold predictions are valuable for drug discovery, but relying solely on predicted structures has limitations, and more detailed experimental models are often required.",
      "Isomorphic Labs, a spin-off of DeepMind, is utilizing AlphaFold in their drug discovery efforts and has secured deals with pharmaceutical companies, indicating the potential of tools like AlphaFold to greatly assist in the search for new drugs."
    ],
    "commentSummary": [
      "AlphaFold, an AI system developed by DeepMind, has the potential to revolutionize drug discovery by identifying molecules that bind to the 5HT2A receptor involved in psychedelics.",
      "AlphaFold's models can accurately predict GPCR binding molecules, improving the efficiency of finding selective ligands for GPCRs and aiding research on mental disorders.",
      "The discussion also covers the significance of targeting GPCRs in medicine, concerns about the reliability of AlphaFold's predictions, and potential risks associated with the use of research chemicals."
    ],
    "points": 238,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1705622012
  },
  {
    "id": 39044985,
    "title": "New Immunotherapy Drug Offers Kinder Treatment for Child Cancer",
    "originLink": "https://www.bbc.com/news/health-67793887",
    "originBody": "Home News Sport Business Innovation Culture Travel Earth Video Live Exciting new cancer drug kinder than chemotherapy By Michelle Roberts Digital health editor BBC Arthur is back at school and pursuing hobbies again Some children with cancer are receiving a new type of drug treatment far less toxic than chemotherapy. Arthur, 11, is one of the first to try it, at London's Great Ormond Street Hospital, for his blood cancer. His family call the therapy \"a little bit of sunshine\", since it worked without making Arthur feel much sicker. And because it could be given on the go, rather than just in hospital, he spent more time at home with his family, enjoying more of what he loves. He carried it with him in a rucksack - his \"blina backpack\". For Arthur, blinatumomab or blina was his only real option after his chemo had failed to clear all of his cancer and had left him very weak. Sandrine Heutz Arthur with his blina backpack Blina is already licensed to treat adults with cancer - and experts hope to show it can safely help children too. Some 20 centres around the UK are using it off-label for children with B-cell acute lymphoblastic leukaemia (B-ALL). The drug is an immunotherapy that seeks out cancer cells so the body's own immune system can recognise and destroy them. And this death hunt is precisely targeted - healthy cells are untouched, unlike with chemo. Sandrine Heutz Arthur starting his blina treatment Blina comes in a bag of liquid administered through a thin plastic tube that remains running into a vein in the patient's arm for many months. A battery-operated pump controls how quickly the drug trickles into the bloodstream - a bag can last days. All of the kit can be carried in a backpack smaller than an A4 textbook, making it fully portable. For Arthur, that meant he could do other things - like play on the swings in his local park - while the treatment was happening. And unlike his intensive chemotherapy, which had stopped working anyway, it did not make him too weak to enjoy his days. 'Constant challenge' Like other patients on blina, Arthur was given medication to cut the chance of serious reactions or side effects before his infusion started. At first, he had some bouts of fever and needed to stay in hospital for checks. But shortly after, he was able to go home. The backpack stayed with Arthur continuously, including in bed - and even though the pump makes a noise, he was able to have a decent night's sleep. Chemo had been rough for Arthur and moving on to blina was a relief, his mother, Sandrine, said. \"It was completely out of his control - we were living in a constant challenge as his body was getting hit by the drugs,\" she said. \"We were curing him by making him feel worse - it's a very difficult thing to process.\" 'Big step' Arthur had to return to hospital every four days so doctors could top up the blina kit but was able to manage the treatment at home the rest of the time. \"He enjoyed the fact that he was able to hold it and be responsible - he embraced all of it,\" Sandrine said. And at the end of April 2023, Arthur had the final operation to remove the tubing from his arm. \"It was a big step - he was free,\" Sandrine said. Doctors say blina can replace big chunks of chemo - perhaps up to 80% of it. About 450 children a year in the UK are diagnosed with Arthur's type of cancer. Sandrine Heutz Arthur with his parents during his chemo and steroid treatment Chief investigator and consultant paediatric haematologist Prof Ajay Vora said: \"Chemotherapies are poisons that kill the leukaemic cells but also kill and damage normal cells - and that is what causes their side effects. \"Blinatumomab is a gentler, kinder treatment.\" Another targeted immunotherapy drug, chimeric antigen receptor T-cell therapy (CAR-T), has also recently become available. But it is more expensive than blina and the patient's own cells must be taken and then altered in the lab before being given back as the medicine, which takes time. Thanks to all the treatment, Arthur's cancer has now gone. Sandrine said: \"New Year was when we found out that the blina had worked and there was no residual cancer - and so that was just amazing and so we had double celebrations.\" Additional reporting by Nicki Stiastny and Neil Paton Great Ormond Street Hospital Health Leukaemia Cancer Related Mum's plea to turn 'sorrow into hope' for daughter Wiltshire Fraudsters in Â£500k charity scam jailed Lancashire WATCH Souness joins 'butterfly skin girl' Isla on hospital trip Scotland More 'Call to action' issued across UK on measles Measles is likely to spread rapidly across more of the UK unless more people take up the vaccine, Dame Jenny Harries says. UK Removing large wine measures cuts drinking - study With the largest measure off the menu, 7.6% less volume of wine was sold daily, researchers found. Health Why are measles cases rising? People are encouraged to have the MMR jab, as cases of measles are on the increase. Health Wedding boxes created for end-of-life patients The special boxes include decorations and bunting that can be used in a ceremony at short notice. Cambridgeshire Gas and air brought back to maternity unit The pain relief had been suspended over staff safety concerns. Cambridgeshire Home News Sport Business Innovation Culture Travel Earth Video Live BBC Shop BBC in other languages Terms of Use About the BBC Privacy Policy Cookies Accessibility Help Contact the BBC Advertise with us AdChoices/ Do Not Sell My Info Copyright 2024 BBC. All rights reserved. The BBC is not responsible for the content of external sites. Read about our approach to external linking. Beta Terms By using the Beta Site, you agree that such use is at your own risk and you know that the Beta Site may include known or unknown bugs or errors, that we have no obligation to make this Beta Site available with or without charge for any period of time, nor to make it available at all, and that nothing in these Beta Terms or your use of the Beta Site creates any employment relationship between you and us. The Beta Site is provided on an â€œas isâ€ and â€œas availableâ€ basis and we make no warranty to you of any kind, express or implied. In case of conflict between these Beta Terms and the BBC Terms of Use these Beta Terms shall prevail. Home News News Israel-Gaza War War in Ukraine World World Africa Asia Australia Europe Latin America Middle East US & Canada UK UK England N. Ireland Scotland Wales In Pictures BBC Verify Sport Business Business Future of Business Technology of Business Work Culture Market Data Innovation Innovation Technology Science & Health Artificial Intelligence Culture Culture Film & TV Music Art & Design Style Books Entertainment News Travel Travel Destinations Worldâ€™s Table Culture & Experiences Adventures The SpeciaList Earth Earth Natural Wonders Weather & Science Climate Solutions Sustainable Business Green Living Video Live Live Live News Live Sport Audio",
    "commentLink": "https://news.ycombinator.com/item?id=39044985",
    "commentBody": "New cancer drug kinder than chemotherapy (bbc.com)233 points by pella 16 hours agohidepastfavorite121 comments Johnny555 12 hours agoI'm hoping that immune therapies for cancer continue to improve. My dog got an experimental immunotherapy for his Hemangiosarcoma tumor (which is incurable). Due to the advanced state of the tumor (he had to have his spleen removed in emergency surgery due to the tumor, plus it had spread to other organs), he was given a 2 - 4 month survival time, he's on month 4 now. There's not enough data to say if the immune therapy is helping (he's on traditional low-dose chemo as well), but it seems promising. The company (Torigen.com) is focused on animal treatment for now, but sees applications for humans in the future. reply tcbawo 4 hours agoparentI am sorry to hear about your dog. Pets can be an integral part of one's family, which often (sadly) goes unacknowledged. My first dog died of hemangiosarcoma. There were no treatments besides chemotherapy at the time. From a cursory search, your dog's treatment appears somewhat reasonably priced. Scientific progress is amazing. I hope the treatments go well. reply jackblemming 12 hours agoparentprevnext [16 more] [flagged] odyssey7 11 hours agorootparentTwo scenarios for testing experimental cancer therapies for dogs. Either you use the experimental therapy to treat cancers when they naturally occur in dogs, or you somehow give cancer to otherwise healthy dogs and then use the therapies to treat the cancer. reply Johnny555 12 hours agorootparentprevWell, medical decisions are rarely that clear cut... the source of the bleeding spleen was unknown. All we knew is that he was bleeding out from his spleen and based on the volume of fluid in his abdomen, he wouldn't survive until tomorrow. It was \"probably\" a tumor, but the ultrasound was not clear and if it was a tumor, there was a 60% chance it was cancer. And we had 30 minutes to decide whether or not to take the surgical slot as they couldn't hold it beyond then... if we didn't opt for surgery we'd need to euthanize the dog. So the choice was \"immediate death or surgery plus a 40% chance of returning to normal\". After the biopsy came back and it was Hemangiosarcoma, then we opted for the experimental treatment coupled with low-dose chemo, which had a low chance of side effects that affect quality of life. The experimental vaccine was both to hedge our bets (it wouldn't hurt, and it could help, especially if he developed side effects to the chemo and we had to stop the treatment), and to give the company a little more data on the effectiveness of their treatment (even if we had to pay for it). And indeed, he's had a good quality of life - he was fully recovered from the splenectomy in a week (though we had to keep him movement restricted for another week until the stitches came out), and so far he's 100% back to normal, showing no side effects from the chemo and his activity levels are still back to normal. reply m463 11 hours agorootparent> we had 30 minutes to decide The older I've gotten the more I've been in these kinds of situations. As a kid you are shielded from stuff, and it catches people so... unprepared. reply Johnny555 11 hours agorootparent>As a kid you are shielded from stuff, and it catches people so... unprepared. Yeah, I still remember my dad going in to the hospital one weekend for what he thought was heartburn, but mom made him go anyway... he didn't come home for 2 weeks after being admitted and receiving triple bypass cardiac surgery. In the dog's case, we thought he ate something bad, he was a little lethargic but otherwise seemed ok, no fever or anything... we almost decided to wait a couple days to see if he got over it before taking him to the vet. Even the vet seemed shocked when she came back in the room to tell us the diagnosis from the ultrasound. We never expected to be deciding whether he'd live or die that day. reply s1artibartfast 11 hours agorootparentprevIm not familiar with how animal medicene work. When you say it was an experimental treatment, does that mean your pet participated in a registered study by the manufacturer? If so, did the manufacturer pick up the cost? Alternatively, do you mean that the treatment was experimental because it was off label use, and outside of a study? reply Johnny555 11 hours agorootparentI encourage you to visit their website to learn more as I'm just interpreting what our oncologist told us about the Torigen vaccine. It's not part of a funded study so you have to purchase the vaccine and agree to let your vet provide followup information back to the company. Our dog's oncologist recommended it and said they've seen promising results in other patients, but wouldn't go so far as to say that it would prolong his life. The only published data I've seen from the company is a safety study. We got the vaccine mostly as a hedge in case the chemo didn't work or he had side effects and we had to discontinue it, but also to provide data back to the company on their vaccine in the hopes that it will help other animals or for future human applications. So yeah, I'm basically paying them for their research with the only thing I'm getting in return is possibly a longer lifespan for my dog (but there's very little data to prove that it works) reply s1artibartfast 11 hours agorootparentprevIt isnt the choice that I would make, but what other people do with their money is their own business, and the science may prove useful. However, those that call for state funded animal insurance, or mandates truly strike me as unhinged. reply Johnny555 10 hours agorootparent>However, those that call for state funded animal insurance, or mandates truly strike me as unhinged. I've never heard of such a thing, and a quick Google search didn't find anything -- is this a real movement, or something you heard from someone you know? The closest I could find was a movement to support the right to have pets in apartments and/or public housing. reply s1artibartfast 9 hours agorootparentIt is a \"real thing\" in that I see people advocate for it fairly often on social media, and more rarely HN. It isn't a real thing in that I haven't heard of any actual politicians advocating for it in the US. However, I just learned that mandatory pet This [1] and this [2[, were top non-sponsored results when I google searched \"manditory pet insurance\". I also noticed that Spain has introduced mandatory registration, liability insurance, and training classes for all dog owners in the country. https://dogstodaymagazine.co.uk/2023/02/15/great-debate-shou... https://www.reddit.com/r/changemyview/comments/iohxzf/cmv_pe... reply harshreality 9 hours agorootparentLiability insurance is not medical insurance. reply s1artibartfast 7 hours agorootparentindeed, as I am aware. thats why I used the word liability instead just saying insurance. reply rideontime 8 hours agorootparentprevJudging by the history of the /r/changemyview poster, they were probably high when they wrote that. I'd hate to see the concept rejected outright based on that user's representation of it and the similarly uneducated discussion that followed. reply rideontime 8 hours agorootparentprevI volunteer with a cat rescue and was recently involved in a situation where a little girl had to give up her cats because her single father couldn't afford their vet bills, leading to one devastated child and two more homeless cats. It was one of the most heartbreaking experiences of my life. I can see how mandating pet health insurance might bring down the cost of it to the point that less privileged people would be able to have and keep their pets. Never heard of the idea before but it sounds great to me. reply s1artibartfast 6 hours agorootparentI don't know exactly what to say because I think I have polar opposite views of you. I think mandated pet insurance is more likely to increase the cost of owning a pet for everyone, and more likely to see that father in trouble with the law for violating it. That's without going into any of the economic and personal rights problems with making unaffiliated people pay for the care of other people's pets. reply timcobb 10 hours agorootparentprevYikes! Who knew this was a thing... reply mdp2021 15 hours agoprevCoincidentally, physicist Sabine Hossenfelder published on YT just hours ago about a new treatment - \"proton flashes\". > one of the most common ways to treat cancer is radiation therapy with x-rays ... You can use these highly energetic photons to kill off cancer cells. The difficulty really is ... killing the cancer cells without killing the patient - but the problem with using x-rays is that you can't shoot them at tumors inside the body without also burning some of the tissue on the way to the tumor and behind it... But you can use beams of other particles instead and this is where particle physics enters ... A beam of protons is far less likely to interact with tissue on short distances And it is still part of the \"kinder\" set (protons are \"kinder\" than x-rays). New Cancer Treatment With Proton Flashes Goes on Trial https://www.youtube.com/watch?v=K515uMQQzV4 reply bearjaws 14 hours agoparentI actually worked with MGH on their first proton treatment software for non cyberknife proton treatment. Later scaled it into AWS so their dosimetrists could iterate on treatment plans much faster. The initial treatments were incredibly successful and much easier on the patient, but theres no miracle either. Patients still suffer adverse reactions, and you will have margins of error, not to mention you do not have unlimited time to develop a treatment plan that is perfect. It's a time/efficacy trade off and the goal is to hit as much of the cancer as possible, while maintaining a SAFE dose of radiation, not a zero dose. What is a safe dose? Well, the more aggressive your cancer the higher that number gets too. Some patients still receive high dose radiation while on proton treatment simply because their cancer is that aggressive, typically suffering the same grade 1-2 diarrhea and vomiting as any other form of radiation. Proton treatment is far superior for most cancers, especially deeper cancers like colon and prostate. It's a living example of how tragic a new treatment option is, unfortunately proton centers are expensive to build and take years. So many people are still passing away from treatable disease and having to endure high dose chemotherapy in other cases. reply rdedev 13 hours agorootparentMy theory is that cancer is a precision recall problem. Our body has the tools to fight cancer but they need to be precise otherwise they would end up attacking normal cells. Our cells do not have as much high level view that we do. On the other hand if we see a skin cell inside the brain we know that's cancer. Hopefully we can build some treatments that lets us light up cancer cells and have our own cells take care of it. That being said it's easier said than done reply DrScientist 10 hours agorootparent> Hopefully we can build some treatments that lets us light up cancer cells and have our own cells take care of it. That's exactly what many of the new immunotherapies do. reply Wonnk13 6 hours agorootparentprevMGH being Mass General Hospital or something else? I only ask because I'm a colon cancer patient at Mass General. reply i_cannot_hack 14 hours agoparentprevWorth noting here is that \"proton flash therapy\" is a new therapy, but \"proton therapy\" is not. Proton therapy is a lot more recent than x-ray therapy, but still a conventional therapy. Flash therapy is the part is which just now entering clinical trials, where you treat the patient with ultra-high dose rates (so you deliver the same dose of radiation, but in maybe 90 ms instead of 90 seconds). There are indications that healthy cells are better at recovering from the ulra-high dose rate than tumor cells are, which means it would have a protective effect on healthy tissue, but the mechanism behind it is not known. The type of radiation is not specified, it can be protons, electrons, x-rays, etc. So \"proton flash therapy\" is a Flash therapy that uses protons. Other clinical trials are using electrons instead, i.e. \"electron flash therapy\". Edit: If anyone thinks this is interesting and is looking for work in Stockholm, my workplace develops simulation / treatment planning tools for radiation therapy (including proton therapy and flash therapy) and is currently recruiting C++ and C# developers: https://www.raysearchlabs.com/career/ reply riffraff 4 hours agorootparentThanks for explaining this, I'd heard of people being treated with proton beams already and it was pretty confusing to hear this was new and experimental. What are the theories as to why healthy cells recover better than tumor cells, if any? reply pgalvin 14 hours agoparentprevOn the topic of interesting Physics contributing to new cancer therapies, there is also Boron Neutron Capture Therapy (https://www.neutrontherapeutics.com/about-bnct/). I gather the gist of it is that it builds up boron isotopes around a tumour, then bombards it with neutrons that mostly pass through the body but interact far more with the boron isotopes. Energetic particles are emitted, have a low range, and hopefully kill just the cancer cells. Apparently all in less sessions than with X-ray or proton therapy. Disclaimer: I am not a doctor or medical physicist, Iâ€™m just fortunate enough to briefly use a machine intended for this purpose in separate nuclear physics studies. I believe BNCT has been done before with reactor sources of neutrons, but for some reason not as a standard treatment and thereâ€™s only one left in Taiwan for this purpose. The new development, afaik, is the ability to use accelerator neutron sources for this. Would love it if anybody knows more! reply pfdietz 6 hours agorootparentI asked my daughter the oncologist about this, and the better way of doing this is not to use boron as the payload, but rather some very powerful toxin. The toxin gets linked to a tumor-specific antibody. There are lots of targeted drugs of this kind being developed for various tumors. reply rngname22 14 hours agoparentprevIs there a way to like emit energy in a narrow beam from a bunch of different angles around a central target such that they only overlap in the center/target and the frequencies resonate in that location in such a way to reach a higher frequency past which there is a destructive effect but below which is safe and non-destructive? /knows nothing about physics reply thfuran 13 hours agorootparentThey're generally delivered sequentially rather than simultaneously, but that is standard practice. It means you can concentrate the dose in the target area, but constructive interference affects only intensity, not frequency. And photons will still interact pretty evenly along the whole path. reply dekhn 13 hours agorootparentprevhttps://en.wikipedia.org/wiki/Radiosurgery there is a subtype called Gamma Knife which uses a large collection of emitters to effectively target a location while keeping other locations under a specific radiation threshold. reply at_a_remove 7 hours agorootparentprevI understand what you are getting at, but the short answer is no. The longer answer is something called The Superposition Principle. Essentially, waves (photons) pass through one another. The amplitude adds, but only at the intersection. The frequency does not change. (Consider the laser as the ultimate example of this) (Side note: The superposition principle does not always hold; however, the realms where the addition of MOAR PHOTONZ becomes non-linear are broadly incompatible with life) So, most techniques involve having many, many beams intersect so that the individual paths are only a little damaged while a specific spot where they all meet takes the hit. I met someone who specifically programs the machines that do this because there's a lot of math involved chucking radiation around irregular hunks of blood, meat, and bone, and the calculations are done because the first idea of \"just cross the streams\" works fine in a vacuum, but not so much in the human body. reply csdvrx 14 hours agorootparentprevYes, there is beam forming. Do a websearch about MIMO and beamforming, or ask Bing chatgpt to explain it. reply teh_infallible 2 hours agoparentprevAn inventor named Royal Rife experimented with destroying tumors by finding the resonant frequencies of the cancer cells. reply dekhn 14 hours agoparentprevI downvoted you mainly because Sabine is a font of misinformation in areas outside her direct expertise. Particle beams for cancer therapy aren't new; shortly after the invention of the cyclotrone, EO Lawrence did this with neutrons in the late 1940s and proton beams were being used successfully in the 50's. She leaves out these details and only mentions trials from the 1990s. reply mdp2021 14 hours agorootparentThank you for the warning about Dr. Hossenfelder and for the information about the technology, but we have not effected any blind endorsement. Just informed of a consistent parallel piece, esp. after the coincidence, which may be useful in itself - or just interesting. reply blashyrk 14 hours agorootparentprev> I downvoted you mainly because Sabine is a font of misinformation in areas outside her direct expertise. Just curious, since I've run into her channel recently and found her generally pleasant and informative (minus the unfunny jokes part), do you have any specific examples of this? reply dekhn 14 hours agorootparenthttps://www.reddit.com/r/AskPhysics/comments/15o0fx7/i_just_... To be fair, her criticism isn't that LIGO itself was fake, but it's really hard to tell, from the video and from https://backreaction.blogspot.com/2019/09/whats-up-with-ligo... If you read that blog, you can see she is using a collection of rhetorical techniques to cast down on the LIGO results (for example, using the term retraction out of context). But it's mainly her videos about health-related stuff that doesn't have good support. She approaches most of these things with a \"assume a spherical cow\" approach, common when physics folks try to do biology. reply meindnoch 14 hours agoparentprevLet me guess without looking at the video. Is it about the Bragg curve? reply mmaunder 14 hours agoprevWe need to see a much faster ramp in the pace of innovation in this space. Weâ€™re eeking out tiny wins over decades, like Rituximab and this agent. Feels like thereâ€™s an ossification of this entire sector that happened years ago and thereâ€™s no sense of urgency - just businesses as usual with the occasional modest win to show. 80 years since chemo was discovered, our most successful treatment across the board continues to be poison that kills fast growing cells faster than it kills the host. We are oncological troglodytes. reply DrScientist 10 hours agoparentWhile I agree there wasn't much progress for years - actually now is quite an exciting time in cancer - new effective treatments are coming on stream all the time, with many more in the works - not to mention much better diagnostic tools. reply bglazer 13 hours agoparentprevThere are a ton of challenges to better oncology treatments. First, as many have noted, cancer is a constellation of diseases. Often a single tumor will contain multiple different, but related groups of cells. So most treatments will only work for a subset of cancers, and then only until the cancer evolves to be resistant. So any advance, will be necessarily â€œmodestâ€, the reality of the situation is that there will never be a silver bullet. The closest weâ€™ve come is immunotherapies, the class of treatment described in the article. These are a legitimately incredible advance, completely curing many people without the side effects of chemo. That said, theyre limited because cancer can evolve to defeat the immune response, and occasionally the immune system either under or over-reacts. Also if you think thereâ€™s no sense of urgency, you havenâ€™t talked to anyone actually in the field. Do you really think oncologists (pediatric oncologists!) aren't eager to cure their patients? reply s1artibartfast 11 hours agorootparentPlus there is the existing financial incentive. If an individual or company comes up with a revolutionary treatment, it would be an absolute money printer. Even historic improvements for large demographics have massive returns. Keytruda (major oncology improvement) had more than $20 billion sales in 2023. It is hard to think of a stronger market incentive to improve drugs as much as possible. reply mmaunder 11 hours agorootparentprev> Do you really think oncologists (pediatric oncologists!) aren't eager to cure their patients? Donâ€™t be bloody ridiculous. reply bglazer 10 hours agorootparent> Feels like thereâ€™s an ossification of this entire sector that happened years ago and thereâ€™s no sense of urgency Ok, can you explain what you meant by this? reply refurb 9 hours agoparentprevAs someone in the industry you're 100% wrong. These aren't \"tiny wins\". These are massive advancements in cancer treatment. And they're happening every decade or so, and added together is drastically changing outcomes. This is one study. \"Cancer mortality decreased by 20.1% (95% uncertainty interval [UI], 18.2%-21.4%) between 1980 and 2014, from 240.2 (95% UI, 235.8-244.1) to 192.0 (95% UI, 188.6-197.7) deaths per 100 000 population.\" https://jamanetwork.com/journals/jama/fullarticle/2598772 reply andrenotgiant 5 hours agorootparentThis has been my experience firsthand in the system too. Childhood cancer (mostly Leukemia) treatment in the USA is a well-organized country-wide clinical study aimed, at this point, at carefully reducing the amount of high-intensity chemo via replacing it with drugs like the one in the article, Blina. They have gotten so good at treating Leukemia that they are now optimizing for reducing the long-term negative health impacts that come as a result of the treatment. There are still tragic cases where the patients systems don't respond well, or there are complications as a result of compromised immune systems, but everything I have experienced points to major advancements and continued progress towards improving outcomes. reply im3w1l 2 hours agoparentprevMy pet idea is that rather than targetting cancer, we should be trying to find and correct DNA-errors before they become cancerous. Otherwise we are just playing whack-a-mole with a slowly degenerating cell population. reply echelon 13 hours agoparentprevMolecular solutions are punch card science. I really want to do whole-body clonal work. Our bodies and genes are machines, yet we still haven't put them to work. We're plastering over the breaks with crude tools that feel like modern day bloodletting. The blast radius in the transduction pathways is huge and imprecise. I've written extensively about this topic on HN. Give me a minute and I'll dig up some references. Edit: https://news.ycombinator.com/item?id=35321368 https://news.ycombinator.com/item?id=32379247 https://news.ycombinator.com/item?id=30407908 reply slibhb 13 hours agorootparentWe're nowhere near \"head transplants\" or \"creating braindead clones\" (not to mention keeping them alive and healthy for decades). This is science fiction. Actual cancer treatments are moving forward at a good pace. Immunotherapies are a good example. Cancer treatment is an example of medical research working well. reply Apocryphon 13 hours agorootparentYeah, if we're going to talk sci-fi, at least nanomachines are much less ghoulish than the implications of legalized human cloning. reply Ralfp 13 hours agorootparentprevThis is not only a morally ambiguous sci-fi, it also skips on issue that we have no 100% proof way to make sure the blood used in the procedures you proposed will not contain cancer cells that will then invade the transplanted organ. Not to mention issue of patient being weakened by, say, organ failure, to even survive such procedure. reply jart 8 hours agorootparentechelon is proposing head or body transplants. It's not sci-fi because doctors have been able to do it with limited success since 1970. Yes it will cure cancer, assuming the tumors haven't spread to your brain. No, cancer is not HIV it is not contagious in the way that you think. https://www.cancer.org/cancer/risk-prevention/understanding-... reply CyberDildonics 11 hours agorootparentprevYour comments are basically \"what if we had clones guys, why has no one thought of this?\" You didn't \"write extensively\", you put science fiction plots ideas that have already been done a dozen times into comments. I'm going to go out on a limb and say that execution might be a bigger factor than ideas here. reply echelon 11 hours agorootparentYou're my biggest repeat critic on HN, CyberDildonics. I originally posted a follow-up message, but I revealed to much of the path gradient to build this and so I deleted it. There are so many low-hanging fruit markets, but I have to hold my tongue. It needs the right leadership and angle of attack. I bet my reputation that none of this is science fiction, though, and I can't wait to prove you wrong about everything you doubt me on. Give me ten years on this one. I'll show you. The Hollywood thread you keep doubting me on is going to be extremely obvious in about six months. I really want to see you eat your hat on that one. I'm sleeping on the floor every night to make it happen, and we're getting there. reply CyberDildonics 10 hours agorootparentAre you now claiming that you know how to clone and grow people for spare organs? reply echelon 7 hours agorootparentI've cloned and modified genes in eukaryotes. I think I know where to get started. reply CyberDildonics 7 hours agorootparentThat's something people have been able to do for decades. How are you planning on growing a headless clone of a person for spare organs? reply dendrite9 11 hours agoprevThe class of drugs are Bi-specific T-cell engagers from what I understand. I have a relative going through treatment and the possibility of these treatments was raised so I have been reading some but I'm not claiming to be an expert. The risk of side effects like the Cytokine storm seems to be similar to CAR-T, but this type of treatment doesn't require the blood harvesting, cell modification, and return for reinfusion. It seems like a better (more generic) way of accomplishing something similar. In the case of the family member in question it sounds like one of these therapies are an option after CAR-T treatment currently. But it might be a preferable option in the future. I'm not sure if that is related to novelty and lack of data or something else. reply esturk 4 hours agoprevChemotherapy means \"Chemical Therapy\" so this is still technically categorized under that. But the general term has gotten really negative in recent decades so I suppose it's why they're distancing the branding from it. reply narrator 14 hours agoprevMost cancer papers in the literature: \"We found a new way to kill cells. Maybe it will kill cancer cells better than normal cells!\" reply antipaul 9 hours agoprevWhy can't they say which company made it? reply Traubenfuchs 15 hours agoprevFrom wikipedia: > When blinatumomab was approved, Amgen announced that the price for the drug would be US$178,000 per year, which made it the most expensive cancer drug on the market. Merck's pembrolizumab was priced at US$150,000 per year when it launched (in September 2014).[14] At the time of initial approval, only about 1,000 patients in the US had an indication for blinatumomab. I take it they prefer to pump chemotherapy poison ito patients for financial reasons? reply anatnom 14 hours agoparentI took blinatumomab in 2015 (in my late 20s). It literally saved my life. However, the risks of blinatumomab were seen as much riskier than chemotherapy. Most notably, blinatumomab has a significant risk of triggering a cytokine storm[0], a frequently-fatal immune reaction cascade. When starting a cycle of blinatumomab, the hospital required that I be inpatient for 7 days and they checked my vitals at least once every two hours. (This was _miserable_ for my sleep schedule, which is already a mess when in the hospital.) My regimen was 7 days in the hospital, then 21 days at home constantly connected to the pump, then 7 days of recovery time before starting another cycle. At the time I took blinatumomab, I had already had unsuccessful treatments with two different chemo regimens. At the hospital system I was at, at least one failed chemo regimen was a pre-requisite for blinatumomab, as it was only indicated for \"refractory\" or \"recurrent\" cancers. I assume this is more related to the chance of acute death and (at the time) relative newness of blinatumomab compared to established chemotherapy regimens. (B-cell ALL is sadly very common in children, but this fortunately means that there is a LOT of funding research into the disease.) After going through 3 one-month cycles of blinatumomab, it was becoming less effective, but I was able to line up a allogenic stem cell transplant which has (knock on a thousand woods) kept me clean for the 8 years since. [0] https://en.wikipedia.org/wiki/Cytokine_storm reply pama 11 hours agorootparentAmazing story. Thanks for sharing. For all of us who work in drug discovery the hope is to hear cases like yours become more common and hopefully one day we can push cancer out of the range of common causes of death. There is still a ton of work to do. reply teamonkey 15 hours agoparentprevLiterally, yes. On the NHS, they will exhaust cheaper solutions that have a fair probability of working before trying more expensive ones. Age, long term prognosis, whether they have dependents, and some other factors are also considered. reply Traubenfuchs 13 hours agorootparent> dependants You mean ones life is valued more if one has children? reply dekhn 12 hours agorootparentThere's an entire subfield dedicated to calculating life values for making difficult decisions. https://en.wikipedia.org/wiki/Value_of_life I don't recall seeing having children as a variable in that valuation, it's typically more about how many years of work you continue to do, cast back into current dollars (\"present value lifetime earnings\", see https://escholarship.org/content/qt82d0550k/qt82d0550k.pdf?t...) and normalized for base rates. reply teamonkey 13 hours agorootparentprevIf you have young children that depend on you, yes. reply copperx 11 hours agorootparentDo they look up records? Is this ethical? Does this also happen in the US or other countries? reply teamonkey 28 minutes agorootparentItâ€™s the UK, they have the medical history. They also ask the patient about their situation. And I made it sound mechanical, but AI has not taken over all decisions like this yet. I believe itâ€™s a discussion between a team of doctors where they are considering the humanity and ethics of the situation as well as the cost. Like, what would be the impact on the child/dependent if the parent was to die, do they have another parent or family members they can live with, can they fend for themselves, etc. reply BobaFloutist 11 hours agorootparentprevI mean, yeah. Of course it is. reply Traubenfuchs 16 minutes agorootparentMore children mean a bigger climate footprint. Also, some children will be net negative on the tax and societal side (violent criminals that will never be gainfully employed). So it's not black and white. And I at least pay more taxes than a family of 3, assuming all of them are, for example, \"just\" store clerks. So, what I want to say is, assuming we follow this value of life calculation, I am more valuable than this whole family of three. reply copperx 11 hours agorootparentprevNo, I wouldn't say a life with dependents has more value. However, I do think it should be prioritized over those without dependents. But that has nothing to do with inherent value. reply ceejayoz 15 hours agoparentprevIt'll be substantially cheaper in the UK. reply teamonkey 15 hours agorootparentFor those who need it will be free - but not to the health service, who do have to pay the sticker price. reply ceejayoz 11 hours agorootparentSticker price varies by country, and national health systems can negotiate those prices with quite a bit of market power. https://www.pgpf.org/blog/2022/11/how-much-does-the-united-s... > According to a 2021 study by the RAND Corporation, a non-profit global policy think tank, prices of prescription drugs in the U.S. are 2.4 times higher than the average prices of nine other nations (Austria, Australia, Belgium, Canada, Germany, Japan, Sweden, Switzerland and the United Kingdom). That higher cost is largely related to brand-name drugs, which are 4.9 times more expensive in the U.S. than in those countries. In fact, brand-name drugs are responsible for 84 percent of total drug costs in the United States despite accounting for only 8 percent of drugs dispensed. The US is just starting to negotiate pricing, beginning with ten specific drugs. Until 2022, it was illegal for Medicare to do so. https://www.hhs.gov/about/news/2023/10/03/biden-harris-admin... reply mft_ 14 hours agorootparentprevI understand your cynicism, but letâ€™s inject some actual data. The price that the manufacturer charges for a course of blinatumomab (in a different indication for adults, not that this is especially relevant in this discussion) is ~Â£56k [0] - so significantly lower than the price quoted from the US. NICE (the organisation which published the document referenced) exists to achieve value for money for the NHS for higher-priced and specialist treatments. If, following a thorough assessment, a medicine does not achieve the required value for money standard at the price proposed by the manufacturer, they are presented with two options: to not have the drug reimbursed in the UK at all, or to lower the effective price, so that the drug becomes cost-effective. [0] https://www.nice.org.uk/guidance/ta589/documents/final-appra... reply AnthonyMouse 9 hours agorootparent> If, following a thorough assessment, a medicine does not achieve the required value for money standard at the price proposed by the manufacturer, they are presented with two options: to not have the drug reimbursed in the UK at all, or to lower the effective price, so that the drug becomes cost-effective. Which is effectively price controls, because the number of people with the money to pay out of pocket will be low, so the choice is essentially to sell at the regulated price or not at all. And the company would be crazy to choose the latter because the high cost is to pay for R&D, not manufacturing, so they'll never be better off to abandon the market than to take whatever they're offered. Then you have prices being set by the political system. If the regulators get captured by pharma companies (as would be likely if implemented in the US) they'd overpay when the drug isn't worth it. If not, the regulators would have all the leverage and very little reason not to set prices too low, reducing the incentive for R&D and causing more people to die. reply pfdietz 6 hours agorootparentThey have a disincentive to sell to other countries at a discount if those countries allow medical tourism from the US. They don't want US patients taking advantage of the lower cost there. reply refurb 9 hours agorootparentprevThat's not the real price in the UK because manufacturers will negotiate a confidential price with NICE. And the quoted price is not the price insurers pay in the US either. As someone who has worked in this space, the EU is lower than the US, but for oncology drugs the difference isn't that large. reply ben_w 15 hours agorootparentprevNHS is approximately a monopsony, which probably has some advantages for price negotiation. reply teamonkey 15 hours agorootparentA family member has had immunotherapy on the NHS and it was disclosed to them (not sure how reliable or accurate this is) that a single dose cost the NHS 4 figures. It needed several layers of approval for it to be administered. reply ben_w 14 hours agorootparentFor one of the same drugs discussed above by Traubenfuchs? If so, unless I've misread the discussion, that looks like 12-140 times cheaper depending on which drug and exactly where in the 1000-9999 GPB it was? reply wlesieutre 14 hours agorootparentPrices in earlier comment are per year, prices the NHS paid were per dose. Do we know how many doses per year? reply teamonkey 13 hours agorootparentIndeed it was per dose, and IIRC the figure was over Â£5000. It wasnâ€™t intended to be public knowledge, I donâ€™t think the patient was supposed to be shown it. The various supporting chemos ranged from below Â£100 to about Â£250/dose IIRC. I mention it because in the UK people donâ€™t really understand that drugs can be really expensive. The assumption is that due to the scale of the NHS theyâ€™re heavily discounted or even free, and that the high prices mentioned by US folk is due to the unusual healthcare situation there. But thereâ€™s real money being paid by taxes, as well as procedures that determine whether youâ€™re worth the expenditure. reply ben_w 13 hours agorootparentI'm sure some (many) make that kind of mistake, so it is worth pointing out. But also: > and that the high prices mentioned by US folk is due to the unusual healthcare situation there. Are they wrong? I keep hearing that the US government spends more per person on healthcare than the UK government, even though the US also has mostly private insurance on top of that and the UK mostly doesn't? reply teamonkey 12 hours agorootparentNot wrong at all. The NHS probably does barter discounts. But consider that a discount of 50% off $150k/yr would be incredible, yet still be a vast amount of money for a single treatment. reply ben_w 14 hours agorootparentprevThanks! That means I did misread. reply dogman144 12 hours agoparentprevThat poison chemo was and is a vast improvement on puberty-killing radiation, for instance. Itâ€™s a spectrum reply andy_xor_andrew 14 hours agoparentprevdumb question... is it purely the demand that makes it this expensive? The \"you need this or you die\" aspect? Or is the cost of research and manufacturing for this stuff so astronomical that it warrants such a high price? I almost don't want to even know... if I find out it costs only ~$5 to develop a dose, and they're charging $200k to dying people... ugh reply throwup238 14 hours agorootparentThere is zero chance it costs $5 per dose because blinatumomab is a bi-specific T cell engager which is a monoclonal antibody made by extracting it from a cloned white blood cell created from recombinant DNA. The yield for this process is extremely low and it's really complicated in the best of times. The cost of the pipette tips and other consumables used by the lab automation alone probably costs more. The flip side is that it treats a rare form of leukemia so the market isn't very big and since they can't lower the price enough to compete with chemo, they have to actually charge more to get their money back. For example chemo might cost $10k, but their drug costs $10k to make per person so if they charged $50k they might not even get enough customers to break even. So instead they charge $200k to get the most from the patients they can capture like the X% of patients who are allergic to the chemo drugs and have no choice (Just an example, I don't know the specifics for blinatumomab) reply seventytwo 14 hours agorootparentprevThe research, development, approval process, and production all absolutely cost money that needs to be recouped from the sale, but we shouldnâ€™t ever forget the reason why the company exists: to make profit. reply konschubert 13 hours agorootparentYou also need to pay for all the other research projects that did NOT yield a successful drug. reply wahnfrieden 14 hours agorootparentprevIn other words, no it is not only supply and demand - itâ€™s the desire to maximize profit as far as the market will bear reply daedrdev 14 hours agorootparentOr like the other response to your parent comment said, it could cost a ton to make, which lowers the number of people who can get it, driving costs even higher due to low volume. reply 1letterunixname 8 hours agoprevI'm interested in studies that address the 800 lbs. gorilla in the room: widespread over-nutrition with the post-WW2 \"Western diet\" is likely the primary suspected cause of a subset of cancers not seen in holdout individuals adhering to traditional diets and portion sizes that avoid too many calories and processed foods. My hypothesis is our immune system and cellular machinery can only effectively kill emergent cell lines under the assumption of sufficient cellular stress and restricted caloric intake. Chemotherapy are late substitute nuclear options, i.e., pausing cell division and/or clamping down on nutrient uptake pathways. I'd be curious to know if people who have endured famines, controlled for age, have lower (and/or higher) rates of some cancers in certain phases of their lives. reply jart 7 hours agoparentLife was not good for people who ate traditional diets. https://jacobin.com/2015/05/slow-food-artisanal-natural-pres... reply namuol 8 hours agoparentprevIâ€™m new to this idea and NOT educated in biology let alone oncology, but hereâ€™s a meta study that suggests early exposure to famine is associated with increased cancer risks, if tenuously: https://www.sciencedirect.com/science/article/pii/S127977072...). Of course looking at the effect of famine on an adult populations would do more to investigate your hypothesis than the effect on developing children. But famine seems a bit extreme, no? Arenâ€™t there also regional studies that show regional dietary/nutritional factors that correlate with lower cancer rates? reply google234123 11 hours agoprevIf you otherwise completely healthy, wouldnâ€™t you want to still keep the chemo therapy (even if itâ€™s only a small asditional contribution) Iâ€™d want the greatest chance of winning reply andrenotgiant 5 hours agoparentChemo has tons of well-known long term negative effects. The idea with replacing Chemo with Blina is that it has a measurable similar short term effect (get rid of the bad cells) with less (so far) long term effects. reply Log_out_ 13 hours agoprevWhy has chemo go through the whole body. Why not ecmo chemo only the combat zone? reply s1artibartfast 13 hours agoparentUsually the cancer cells are throughout the body, even if the tumors themselves have not spread. This is why you might cut out a solid tumor, and then give chemo reply rubberband 11 hours agorootparentFor me, they cut out most of a giant tumor, but couldn't get all of it without risking some vital organs. Then I got chemo for the rest. Interesting process. Usually the cancer cells are concentrated where the tumor is. One of the first things they may do upon diagnosis of cancer is a PET scan (which shows you where cancerous stuff is throughout your body). Life advice for all the young folks: don't get cancer. reply s1artibartfast 11 hours agorootparentmy understanding is that the word \"concentrated\" does a lot of heavy lifting, and modern thought is that most cancers started spreading cells all over the body, even at very early stages. metastatic cancer is a numbers game. for example. at stage 0-1, you might still have millions of cancer cells throughout your body, and there is a good chance your immune system can clean them up. At stages 2 or 3 there might be trillions of non-local cancer cells, with a proportionally greater chance of propagation. reply bglazer 13 hours agoparentprevAntibody drug conjugates are one attempt at doing this. Basically attach chemotherapy drugs to molecules (antibodies) that bind only to proteins on cancer cells reply Johnny555 13 hours agoparentprevWhen my dog had a subcutaneous form of cancer, one treatment discussed was local injection of a chemotherapy agent in the tumor area along with electrochemotherapy to help make the tumor more susceptible to the chemo treatment. We opted for surgical removal instead. https://en.wikipedia.org/wiki/Electrochemotherapy reply rubberband 11 hours agoparentprevThere's \"topical\" chemo for some stuff, but it's uncommon. Most chemo is either in pill form, or (as was for me) delivered intravenously. So it goes through the whole body. Radiation therapy can target specific areas. It's still used instead of chemo in some cases. reply bluGill 13 hours agoparentprevThings like that are done where we can figure out how to get the drugs there. Not an easy problem though. reply smileysteve 12 hours agoparentprevIn particular, this is a treatment for leukemia; a blood cancer. reply mjfl 14 hours agoprevAny chemotherapy that damages the immune system should be avoided. reply kepoly 14 hours agoparentAs I sit here getting chemo for B-Cell ALL, most of us donâ€™t have any other option, itâ€™s chemo or death. reply Kognito 14 hours agorootparentFrom one internet stranger to another, I wish you a speedy recovery friend! reply navigate8310 13 hours agorootparentprevI hope for your speedy recovery. Be strong. reply josefresco 12 hours agoparentprevMy own immune system is attacking my joints. Without treatment I'll be disabled within 10 years. What's your advice doc? reply SpaceNoodled 14 hours agoparentprevIt can be preferable to having your body slowly town apart by its own immune system. reply bearjaws 14 hours agoparentprevTheres a field of auto-immune disorders, where patients suffer from their own immune system. I believe they would disagree with you. reply namuol 8 hours agoparentprevCan you speak from personal experience? Not meant to be a rhetorical question, just wanted to give you a chance to elaborate. reply sgift 14 hours agoparentprevYeah okay. I could have chosen to die instead. Think that would have been better? reply ryeights 15 hours agoprevnext [4 more] [flagged] ceejayoz 15 hours agoparenthttps://news.ycombinator.com/newsguidelines.html > Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something. I've got a friend's kid alive because of these newer immunotherapies. They're a great advancement in successful outcomes, and not having the misery of chemo is a very, very nice bonus. reply bertil 15 hours agorootparentI read that as a dismissal of the title: as you have experienced, chemotherapy is horrible. â€œKinderâ€ there can feel like a comically low bar. But this is wonderful progress. Letâ€™s hope is a lot kinder. reply GuB-42 15 hours agoparentprevThat's the point. If kinder to find the leader of a terrorist organization and shoot him with a handgun than it is to nuke their headquarters and the whole city surrounding it. The innovation is in the \"search\" part. reply wsc981 9 hours agoprev [â€“] A couple of times on Twitter I encountered people that used a dog dewormer medicine (Fenbendazole) to treat their cancer and these people claimed it cured them. Or people they know of. Interesting and extremely cheap. Seems scientist did find benefits as well in various trials, examples (more can be though with Googling, e.g. I know of a study of the effects on breast cancer in mice): - https://pubmed.ncbi.nlm.nih.gov/30093705/ - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9437363/ - https://baltimorepostexaminer.com/human-patients-are-given-f... Not everyone has had success: - https://karger.com/cro/article/14/2/886/820730/Drug-Induced-... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Children with cancer are being treated with a less toxic drug therapy called blinatumomab, which is an immunotherapy that targets cancer cells while sparing healthy cells.",
      "The treatment involves a thin plastic tube that remains in the patient's arm for several months, delivering the drug continuously.",
      "Blinatumomab has already been approved for use in adults with cancer, and researchers are now exploring its safety and efficacy in children."
    ],
    "commentSummary": [
      "The discussions cover a range of topics related to cancer treatment and medical decisions, including new drugs, therapies, benefits, drawbacks, high costs, and ethical considerations.",
      "There is skepticism towards certain medical theories and a desire for more affordable and effective treatments.",
      "The collection provides valuable information for those interested in cancer treatment and making informed medical decisions."
    ],
    "points": 233,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1705600467
  },
  {
    "id": 39045598,
    "title": "WebGPU Now Available for Android Devices on Chrome 121",
    "originLink": "https://developer.chrome.com/blog/new-in-webgpu-121",
    "originBody": "Chrome for Developers Blog What's New in WebGPU (Chrome 121) Stay organized with collections Save and categorize content based on your preferences. FranÃ§ois Beaufort Support WebGPU on Android The Chrome team is excited to announce that WebGPU is now enabled by default in Chrome 121 on devices running Android 12 and greater powered by Qualcomm and ARM GPUs. Support will gradually expand to encompass a wider range of Android devices, including those running on Android 11 in a near future. This expansion will be dependent on further testing and optimization to ensure a seamless experience across a broader range of hardware configurations. See issue chromium:1497815. WebGPU sample running on Chrome for Android. Use DXC instead of FXC for shader compilation on Windows Chrome now uses the power of DXC (DirectX Compiler) to compile shaders on Windows D3D12 machines equipped with SM6+ graphics hardware. Previously, WebGPU relied on FXC (FX Compiler) for shader compilation on Windows. While functional, FXC lacked the feature set and performance optimizations present in DXC. Initial testing shows a 20% average increase in compute shader compilation speed when using DXC compared to FXC. Timestamp queries in compute and render passes Timestamp queries allow WebGPU applications to measure precisely (down to the nanosecond) how much time their GPU commands take to execute compute and render passes. They are heavily used to gain insights into the performance and behavior of GPU workloads. When the \"timestamp-query\" feature is available in a GPUAdapter, you can now do the following things: Request a GPUDevice with the \"timestamp-query\" feature. Create a GPUQuerySet of type \"timestamp\". Use GPUComputePassDescriptor.timestampWrites and GPURenderPassDescriptor.timestampWrites to define where to write timestamp values in GPUQuerySet. Resolve timestamp values into a GPUBuffer with resolveQuerySet(). Read timestamp values back by copying the results from the GPUBuffer to the CPU. Decode timestamp values as a BigInt64Array. See the following example and issue dawn:1800. const adapter = await navigator.gpu.requestAdapter(); if (!adapter.features.has(\"timestamp-query\")) { throw new Error(\"Timestamp query feature is not available\"); } // Explicitly request timestamp query feature. const device = await adapter.requestDevice({ requiredFeatures: [\"timestamp-query\"], }); const commandEncoder = device.createCommandEncoder(); // Create a GPUQuerySet which holds 2 timestamp query results: one for the // beginning and one for the end of compute pass execution. const querySet = device.createQuerySet({ type: \"timestamp\", count: 2 }); const timestampWrites = { querySet, beginningOfPassWriteIndex: 0, // Write timestamp in index 0 when pass begins. endOfPassWriteIndex: 1, // Write timestamp in index 1 when pass ends. }; const passEncoder = commandEncoder.beginComputePass({ timestampWrites }); // TODO: Set pipeline, bind group, and dispatch work to be performed. passEncoder.end(); // Resolve timestamps in nanoseconds as a 64-bit unsigned integer into a GPUBuffer. const size = 2 * BigInt64Array.BYTES_PER_ELEMENT; const resolveBuffer = device.createBuffer({ size, usage: GPUBufferUsage.QUERY_RESOLVEGPUBufferUsage.COPY_SRC, }); commandEncoder.resolveQuerySet(querySet, 0, 2, resolveBuffer, 0); // Read GPUBuffer memory. const resultBuffer = device.createBuffer({ size, usage: GPUBufferUsage.COPY_DSTGPUBufferUsage.MAP_READ, }); commandEncoder.copyBufferToBuffer(resolveBuffer, 0, resultBuffer, 0, size); // Submit commands to the GPU. device.queue.submit([commandEncoder.finish()]); // Log compute pass duration in nanoseconds. await resultBuffer.mapAsync(GPUMapMode.READ); const times = new BigInt64Array(resultBuffer.getMappedRange()); console.log(`Compute pass duration: ${Number(times[1] - times[0])}ns`); resultBuffer.unmap(); Due to timing attack concerns, timestamp queries are quantized with a resolution of 100 microseconds, which provides a good compromise between precision and security. In Chrome browser, you can disable timestamp quantization by enabling the \"WebGPU Developer Features\" flag at chrome://flags/#enable-webgpu-developer-features during the development of your app. See Timestamp queries quantization to learn more. As GPUs may reset the timestamp counter occasionally, which can result in unexpected values such as negative deltas between timestamps, I recommend you check out the git diff changes that adds timestamp query support to the following Compute Boids sample. Compute Boids sample featuring timestamp query. Default entry points to shader modules To improve the developer experience, you can now omit the entryPoint of your shader module when creating a compute or render pipeline. If no unique entry point for the shader stage is found in the shader code, a GPUValidationError will be triggered. See the following example and issue dawn:2254. const code = ` @vertex fn vertexMain(@builtin(vertex_index) i : u32) -> @builtin(position) vec4f { const pos = array(vec2f(0, 1), vec2f(-1, -1), vec2f(1, -1)); return vec4f(pos[i], 0, 1); } @fragment fn fragmentMain() -> @location(0) vec4f { return vec4f(1, 0, 0, 1); }`; const module = myDevice.createShaderModule({ code }); const format = navigator.gpu.getPreferredCanvasFormat(); const pipeline = await myDevice.createRenderPipelineAsync({ layout: \"auto\", vertex: { module, entryPoint: \"vertexMain\" }, fragment: { module, entryPoint: \"fragmentMain\", targets: [{ format }] }, vertex: { module }, fragment: { module, targets: [{ format }] }, }); Support display-p3 as GPUExternalTexture color space You can now set \"display-p3\" destination color space when importing a GPUExternalTexture from HDR videos with importExternalTexture(). Check out how WebGPU handles color spaces. See the following example and issue chromium:1330250. // Create texture from HDR video. const video = document.querySelector(\"video\"); const texture = myDevice.importExternalTexture({ source: video, colorSpace: \"display-p3\", }); Memory heaps info To help you anticipate memory limitations when allocating large amounts during the development of your app, requestAdapterInfo() now exposes memoryHeaps information such as the size and type of memory heaps available on the adapter. This experimental feature is accessible only when the \"WebGPU Developer Features\" flag at chrome://flags/#enable-webgpu-developer-features is enabled. See the following example and issue dawn:2249. const adapter = await navigator.gpu.requestAdapter(); const adapterInfo = await adapter.requestAdapterInfo(); for (const { size, properties } of adapterInfo.memoryHeaps) { console.log(size); // memory heap size in bytes if (properties & GPUHeapProperty.DEVICE_LOCAL) { /* ... */ } if (properties & GPUHeapProperty.HOST_VISIBLE) { /* ... */ } if (properties & GPUHeapProperty.HOST_COHERENT) { /* ... */ } if (properties & GPUHeapProperty.HOST_UNCACHED) { /* ... */ } if (properties & GPUHeapProperty.HOST_CACHED) { /* ... */ } } Adapter info memory heaps shown on https://webgpureport.org. Dawn updates The HasWGSLLanguageFeature and EnumerateWGSLLanguageFeatures methods on wgpu::Instance have been added to handle WGSL language features. See issue dawn:2260. The non-standard wgpu::Feature::BufferMapExtendedUsages feature lets you create a GPU buffer with wgpu::BufferUsage::MapRead or wgpu::BufferUsage::MapWrite and any other wgpu::BufferUsage. See the following example and issue dawn:2204. wgpu::BufferDescriptor descriptor = { .size = 128, .usage = wgpu::BufferUsage::MapWritewgpu::BufferUsage::Uniform }; wgpu::Buffer uniformBuffer = device.CreateBuffer(&descriptor); uniformBuffer.MapAsync(wgpu::MapMode::Write, 0, 128, [](WGPUBufferMapAsyncStatus status, void* userdata) { wgpu::Buffer* buffer = static_cast(userdata); memcpy(buffer->GetMappedRange(), data, sizeof(data)); }, &uniformBuffer); The following features have been documented: ANGLE Texture Sharing, D3D11 multithread protected, Implicit Device Synchronization, Norm16 texture formats, Timestamp Query Inside Passes, Pixel Local Storage, Shader Features, and Multi Planar Formats. The Chrome team has created an official GitHub repository for Dawn. This covers only some of the key highlights. Check out the exhaustive list of commits. What's New in WebGPU A list of everything that has been covered in the What's New in WebGPU series. Chrome 121 Support WebGPU on Android Use DXC instead of FXC for shader compilation on Windows Timestamp queries in compute and render passes Default entry points to shader modules Support display-p3 as GPUExternalTexture color space Memory heaps info Dawn updates Chrome 120 Support for 16-bit floating-point values in WGSL Push the limits Changes to depth-stencil state Adapter information updates Timestamp queries quantization Spring-cleaning features Chrome 119 Filterable 32-bit float textures unorm10-10-10-2 vertex format rgb10a2uint texture format Dawn updates Chrome 118 HTMLImageElement and ImageData support in copyExternalImageToTexture() Experimental support for read-write and read-only storage texture Dawn updates Chrome 117 Unset vertex buffer Unset bind group Silence errors from async pipeline creation when device is lost SPIR-V shader module creation updates Improving developer experience Caching pipelines with automatically generated layout Dawn updates Chrome 116 WebCodecs integration Lost device returned by GPUAdapter requestDevice() Keep video playback smooth if importExternalTexture() is called Spec conformance Improving developer experience Dawn updates Chrome 115 Supported WGSL language extensions Experimental support for Direct3D 11 Get discrete GPU by default on AC power Improving developer experience Dawn updates Chrome 114 Optimize JavaScript getCurrentTexture() on unconfigured canvas throws InvalidStateError WGSL updates Dawn updates Chrome 113 Use WebCodecs VideoFrame source in importExternalTexture()",
    "commentLink": "https://news.ycombinator.com/item?id=39045598",
    "commentBody": "WebGPU is now available on Android (chrome.com)225 points by astlouis44 15 hours agohidepastfavorite62 comments rezonant 13 hours ago> Timestamp queries allow WebGPU applications to measure precisely (down to the nanosecond) how much time their GPU commands take to execute compute and render passes > ... > Due to timing attack concerns, timestamp queries are quantized with a resolution of 100 microseconds, which provides a good compromise between precision and security. I don't have a particular need of nanosecond granularity timestamps for WebGPU- there are other parts of the web stack where I could really use better time measurement- but I understand the security concern and it's far better to be safe than sorry. But they quote two wildly different granularities in the same article, within a paragraph of each other... reply jsheard 12 hours agoparentThe former is a spec detail (the result is returned in ns) and the latter is an implementation detail (browsers currently quantize the result to 100us). That is a useful distinction since you can use WebGPU outside of the browser by embedding Dawn or wgpu into your own application, and there you should get the maximum resolution the spec allows for. Environments like Electron might also opt-out of that timing attack mitigation since they're intended to run trusted code. I agree the article could have made that clearer though. reply rezonant 11 hours agorootparentYes indeed they mention how to opt out of quantization directly in Chrome if you'd like (at your own risk) using the Devtools. reply no_time 4 hours agorootparentprevNew exciting web fingerprinting vector dropped. As if we didnâ€™t have a enough already. reply eyegor 4 hours agoparentprevMeanwhile sleep() in js land is more of a suggestion when it comes to accuracy. Browser standards are strange. Of course I mean setTimeout/interval because js doesn't even expose a sleep function. reply jsheard 15 hours agoprev> To help you anticipate memory limitations when allocating large amounts during the development of your app, requestAdapterInfo() now exposes memoryHeaps information such as the size and type of memory heaps available on the adapter. Oh nice, I was just complaining about that here the other day. The docs mention that browsers will probably guard that information behind a permission prompt to prevent it from being used for fingerprinting, but it's better than nothing. reply bhouston 14 hours agoprevNice! We just need Linux and iOS. And then we'll have somewhere around 80% support for WebGPU across all devices. I'm getting my numbers https://web3dsurvey.com/webgpu Android: 0.34% Chromium OS: 78.15% iOS: 0.09% Linux: 0.75% Mac OS: 54.43% Windows: 77.96% reply nox101 10 hours agoparentI'm pretty sure the numbers on web3dsurvey are skewed. AFAICT only sizes about webgl and webgpu development are surveyed. To get real numbers you need their survey script to run on popular non-techie sites right? reply bhouston 8 hours agorootparentIt does favor users who have likely have better than average graphics devices, but it still is likely relatively right - especially as the numbers get high. It is based on ~250,000 data samples in the last week. reply nox101 1 hour agorootparentCan you explain how you would know the data is right if you don't have actual data from a site popular with non-techies? Like I go to a tech meetup it will generally be 95% male and mostly white and asian. If I surveyed anything there it would have very little relation to the real population. You list these sites threekit.com webgpufundamentals.org james.darpinian.com realism-effects-obeqz.vercel.app gobattle.io. ict.moe.gov.om modelviewer.dev realism-effects-git-v2-obeqz.vercel.app dev.phaser.io redblobgames.com threejs.org axiomatic-inc.com weatherlayers.com alpha.gobattle.io. gobattle.io spookyball.com mrdoob.com streets.gl realism-effects.vercel.app phaser.io alpha.gobattle.io molstar.org demo.weatherlayers.com old.phaser.io webglfundamentals.org toji.dev jeeliz.com clicktorelease.com Pretty much all of them are not sites any non-graphics person would visit. So how can it possibly be even close the correct? It doesn't matter that there 250k samples per week if those are nearly all programmers interested in 3D rather than the average non-techie reply wongarsu 13 hours agoparentprevAccording to [1] Android 12+ covers nearly 60% of all Android devices. That's more than I would have expected. 1: https://gs.statcounter.com/os-version-market-share/android/m... (Android 14 is still counted as \"other\") reply npunt 12 hours agoparentprevif safari tech preview is anything to go by, it may come to iOS sooner or later https://webkit.org/blog/14879/webgpu-now-available-for-testi... reply mschuetz 14 hours agoprevI'm really looking forward to 2034, when WebGPU features will catch up to 2024. reply vetinari 14 hours agoparentBy that time, it might even get supported by Chrome for Linux. reply bhouston 14 hours agorootparentWhy is linux supporting taking a while? I figured the underlying graphics subsystem on Android is Vulcan right? Wouldn't that also be the main graphics subsystem on Linux these days? reply zamadatix 11 hours agorootparentTesting/Validation and bugfixing. Just having Vulkan isn't enough to enable it by default, everything actually has to work right. Even for Android this is only for specific types of devices. You should be able to force enable it on Linux right now though. It's just not GA quality guaranteed. reply p_l 11 hours agorootparentI tried and tried and tried, Chrome 120 will always stick an undocumented Origin Trial for disabling WebGPU. reply reactordev 9 hours agorootparentprevYou know weâ€™ll have all moved onto Romulan by then, leaving Vulkan and Metal behind - including WebGPU. In seriousness though, WebGPU in Chrome with â€œnon-freeâ€ Linux GPU drivers should work, no? Edit: I see itâ€™s still behind a flag reply pjmlp 4 hours agorootparentprevOn ChromeOS. reply anthk 12 hours agorootparentprevabout:flags in Chromium search for \"accel\" Disable the blacklist for your GPU. reply pjmlp 4 hours agorootparentWhich is exactly why WebGL never really took off for games like Flash did, versus native games, or now streaming. Having drivers installed is not enough as the browser lords decided the computer isn't worthy of playing games. reply p_l 11 hours agorootparentprevDoesn't stop disablement done through --origin-trial-disable-feature=WebGPU and I have yet to figure how to drop that without recompiling Chrome. reply pjmlp 4 hours agoparentprevLooking back to 10 years long WebGL adoption, and WebGPU being based on 2015 features, that is pretty much spot on. reply bmitc 9 hours agoparentprevWhat features? reply jms55 7 hours agorootparentPersonally, the ones I'm most looking forward to: * Subgroup operations * Push constants (available in wgpu, but not WebGPU the spec/web impl) * u64 + atomic image ops * Mesh shaders * Raytracing * Binding arrays / descriptor indexing + device buffer addresses reply raphlinus 7 hours agorootparentSimilar. I've done experiments with subgroups suggesting approximately a 2.5x speedup for sorting (using the WLMS technique of Onesweep). Binding arrays will be very helpful for rendering images in the compute shader. A caveat is that descriptor indexing is not supported on mid-old phones like Pixel 4, but it is on Pixel 6. I somewhat doubt device buffer address will be supported, as I think the security aspect is complicated (it resembles a raw pointer), but it's possible they'll figure out how to do it. reply 2OEH8eoCRo0 13 hours agoparentprevIn 2034 it'll be as dead as Flash because of security issues. reply mschuetz 12 hours agorootparentNot really, that is not the problem of WebGPU. The worst you can do is crash the tab. With an unstable graphics driver, there might even be the option to crash the system but that's hardly a security issue, only an annoyance. reply kevingadd 12 hours agorootparentHistorically any time an attack surface as big as WebGPU has been exposed, \"the worst you can do is crash the tab\" has not ever been true. Also note that for an unstable graphics driver, the way you usually crash the system is by touching memory you shouldn't (through the rendering API), which is definitely something that could be exploited by an attacker. It could also corrupt pages that later get flushed to disk and destroy data instead of just annoy you. Though I am skeptical as to whether it would happen, security researchers have previously come up with some truly incredible browser exploit chains in the past, so I'm not writing it off. reply mschuetz 12 hours agorootparentWebGL has been around for more than a decade and didn't turn out to be a security issue, other than occasionally crashing tabs. Neither will WebGPU be. reply csande17 11 hours agorootparentBy exposing vulnerable graphics drivers to arbitrary web code, WebGL has allowed websites to take screenshots of your desktop (https://www.mozilla.org/en-US/security/advisories/mfsa2013-8...) and break out of virtual machines (https://blog.talosintelligence.com/nvidia-graphics-driver-vu...), to use two examples I found via a web search. reply fourside 12 hours agorootparentprevVery curious what you see as the problems with WebGPU currently. Iâ€™ve been tinkering with it slowly as it has a bit of a learning curve. reply FL33TW00D 11 hours agoprevWell done WebGPU team! Looking forward to the announcement one day that this has landed: https://github.com/gpuweb/gpuweb/issues/4195 reply modeless 11 hours agoparentCool, there's consensus between APIs on how to expose \"tensor cores\" now? Very exciting! Although I think that relaxing memory limitations and providing more visibility and control there is even more important for running ML on the web right now. And harder to make progress on because there isn't a single team that clearly owns \"all memory management\". reply fidotron 13 hours agoprevWhat will be curious about WebGPU getting wider Android deployment is if it results in reducing the effect of variation in the drivers, which very much remain a headache. For example, WebGL type API implementations have had a somewhat flexible idea about data sizes and layout which due to the nature of WebGPU are much less acceptable there. One of the big wins of Vulkan has been that it has levelled the playing field somewhat and poor drivers have less of an impact. I think a lot of people will be disappointed by what proportion of devices currently in the wild actually successfully make this jump because it is under appreciated the extent to which shortcuts have been taken. I look forward to the day I never have to think about the Mali GLSL compiler ever again. reply pjmlp 4 hours agoparentIt will be same as ever. The big difference is that on native APIs we can work around them. On browser APIs, the device gets blacklisted end of story for those folks. reply Xeamek 13 hours agoprev>devices running Android 12 and greater powered by Qualcomm and ARM GPUs. So... won't work on any exynos, since they have the AMD RDNA3 arch? Do I get that right? reply Tojiro 9 hours agoparentHi! I'm the Chrome dev that's been working on WebGPU's Android support. As jsheard said the older exynos devices will work because they're Mali-based. The newer RDNA3-based devices aren't enabled by default simply because our team hasn't been able to sufficiently test on them yet. Same goes for Tegra or PowerVR GPUs. It's entirely a question of spending the time to ensure they're performing as expected (and probably implementing a few workarounds) and not a comment on the quality of the GPUs themselves. That said, we know that these GPUs are in an increasing number of flagship devices, which makes them a higher priority for official support in future releases. reply pjmlp 4 hours agorootparentFirst of all thank for the effort. Secondly, this was a big issue plaguing WebGL adoption, as contrary to native APIs, devices get blacklisted and telling common users to access browser flags is not an option for most products. Hence why game studios are so keen on streaming instead. reply jsheard 13 hours agoparentprevIt should work on slightly older or lower end Exynos chips, which have ARM Mali GPUs. Their switch to AMD RDNA was a fairly recent thing, and so far it has only been integrated into their flagship-tier parts. reply eschaton 13 hours agoprevWhatâ€™s the actual utility of this for anyone that isnâ€™t trying to replace native code with web pages? Is this ever going to be worth the no doubt massive investment it required? reply fidotron 13 hours agoparentIt should enable much more performant (and battery friendly) 3D content on the web. WebGL has a level of synchronization in the main render loop of the browser that is just not the right way to do it, and WebGPU fixes that. Additionally it is more suited to GPU based compute, which can be used to accelerate neural network inferencing, though not quite as well as dedicated NN accelerators which are fairly common these days. I would tend to agree that the business case for these things is not as strong as many would like though, and things have a distinct habit of ceasing to be interesting the moment they are widely achievable. reply eschaton 5 hours agorootparentSo thereâ€™s no real use case. Got it. reply filleduchaos 2 hours agorootparentThere is a very clear use case in the first sentence of their comment though? Unless your stance is that WebGL itself had no real use case, which is just silly. reply eschaton 2 hours agorootparentWhy does a web page need GL? reply crubier 12 hours agoparentprevIt's likely to become the best way to run cross-GPU-platform gpu code in the medium term reply pjmlp 4 hours agorootparentThat already existed via middleware engines. reply Eduard 3 hours agorootparentsuch as? Do you mean the clusterfuck that is matching carefully your compiler, ID, hardware, instruction set architecture, incompatible dependency versions, installers, package managers, etc.? So far, WebGPU was the first and only time that I was able run Stable Diffusion on my own hardware. https://websd.mlc.ai/ reply pjmlp 3 hours agorootparentUnity, Unreal, Ogre3D, Open3D, Godot, Stride, Defold,.... Assuming you want to use 2024 hardware features in 2024. reply ChadNauseam 3 hours agorootparentprevThey didnâ€™t say it would be the only way, just that it would be the best way reply JayStavis 12 hours agoparentprevI feel like WebGPU actually holds some amount of promise as a cross-platform convenience. I'd agree that there's not a great reason to update your native code for this right now though. If you're writing new gfx code though and are more familiar with web technology, there's definitely utility there. That's the bigger value prop: that people with web development skills can work on more pro (GPU-required) applications. reply andybak 13 hours agoparentprevI'm not sure I understand you. Can you expand your comment somewhat? reply hutzlibu 13 hours agoparentprev\"trying to replace native code with web pages? \" No one wants that. But many like to write their apps only for one plattform - and then still have them run allmost everywhere. The web is the best we have to achieve this. And this will greatly improve the possibilities. Edit: My app will soon finally use no more html elements. It is not a \"webpage\". reply eschaton 5 hours agorootparentYou say no one wants that, then you describe doing exactly that. If your â€œappâ€ runs in a browser windowâ€”a window presented by a browser engineâ€”itâ€™s fundamentally a web page. (Theyâ€™re two distinct words.) reply hutzlibu 3 hours agorootparentI .. hate those pedantic discussions. But here you go: a web page by common understanding is mainly something to look at. Page implies document. A web app is a bit more. (And many tech people hate it, that browsers can do more) So no, I do not want to replace native code with a web page. But in some cases with web apps. reply mschuetz 12 hours agorootparentprev> No one wants that. I very much do want that since the WebGPU API is far easier and nicer to use than Vulkan or OpenGL. Also, it makes apps much more accessible to distribute them over web, and it is much more secure to use web apps than native apps. Unfortunately WebGPU is way too limited compared to desktop APIs. reply ladyanita22 10 hours agorootparentprevCan you have an electron app without HTML elements? A pure WebGPU + Webassembly program? reply jay_kyburz 7 hours agorootparentYEah, but why wouldn't you want HTML CSS to render your ui. I'm going to revisit electron / nw.js for games again this year. Last time I tried 4-5 years ago I could not get smooth animation with request animation frame. reply hutzlibu 3 hours agorootparentPerformance. I recommend pixijs. But it depends what you do, smooth animations of some elements is possible with html. But in my case it got complex and html was the bottleneck. Now I have the same assets in Pixi and it runs around 100Ã— faster. No more lags, no stuttering. No more html. (Allmost, some static content is still HTML, but that is fine, as long as the DOM does not get modified) reply astlouis44 13 hours agoprevMy team has been developing out Unreal Engine 5 support for WebGPU, for anyone interested. reply notnullorvoid 7 hours agoparentDo you work at Epic or is this an external effort? reply westurner 14 hours agoprev [â€“] How do you run the task manager with Android Chrome? Does Android Chrome have the per-tab hover card RAM use feature as desktop chrome? From https://news.ycombinator.com/item?id=37840416 : >> From \"Manifest V3, webRequest, and ad blockers\" (2022) https://news.ycombinator.com/item?id=32953286 : >> What are some ideas for UI Visual Affordances to solve for bad UX due to slow browser tabs and extensions? >> - [ ] UBY: Browsers: Strobe the tab or extension button when it's beyond (configurable) resource usage thresholds >> - [ ] UBY: Browsers: Vary the {color, size, fill} of the tabs according to their relative resource utilization >> - [ ] ENH,SEC: Browsers: specify per-tab/per-domain resource quotas: CPU reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google Chrome version 121 brings exciting updates for developers using WebGPU technology.",
      "Developers can now utilize WebGPU on Android devices running Android 12 or higher.",
      "Other updates include using DXC for shader compilation on Windows, measuring GPU command execution time, default entry points for shader modules, support for \"display-p3\" color space, and information on memory heaps.",
      "The Dawn library also receives new features and improvements."
    ],
    "commentSummary": [
      "WebGPU is now available on Android, allowing developers to measure GPU command execution time.",
      "Timestamp queries in WebGPU have a quantization of 100 microseconds for security purposes.",
      "WebGPU support varies on different platforms, with Linux and iOS lacking sufficient support.",
      "The discussion includes concerns about survey data accuracy, compatibility with different browsers and operating systems, potential security risks, and limitations of WebGPU compared to other graphics APIs.",
      "Some users praise WebGPU for its convenience and potential, while others mention limitations and ongoing testing on different GPUs.",
      "The discussion covers the use of WebGPU for graphics and computing, potential performance benefits, and the development of web apps as a replacement for native code.",
      "PixiJS is mentioned as a tool for optimized performance, and Unreal Engine 5 has support for WebGPU."
    ],
    "points": 225,
    "commentCount": 62,
    "retryCount": 0,
    "time": 1705602597
  },
  {
    "id": 39044586,
    "title": "The Decline of the US Machine Tool Industry: Causes and Consequences",
    "originLink": "https://www.construction-physics.com/p/what-happened-to-the-us-machine-tool",
    "originBody": "Share this post What Happened to the US Machine Tool Industry? www.construction-physics.com Copy link Facebook Email Note Other What Happened to the US Machine Tool Industry? Brian Potter Jan 18, 2024 94 Share this post What Happened to the US Machine Tool Industry? www.construction-physics.com Copy link Facebook Email Note Other 8 Share Machine tools â€“ machines that cut or form metal â€“ are the heart of industrial civilization. Sometimes called â€œmother machinesâ€ (because theyâ€™re machines that make other machines), machine tools are required to make almost everything. Nearly every manufactured good is made using machine tools, or by machines which were made using machine tools: â€œThus an automobile is an assembly of metal parts made by machine tools, plastic parts produced by machines made by machine tools, fabric processed on textile machines made by machine tools, rubber processed and molded by equipment made on machine tools, and glass processed by equipment produced by machine tools.â€ â€“ Anderson Ashburn, Is New Technology Enough? Being able to manufacture machine tools is often considered an important capability for an industrialized country. Not only does this provide ready access to the latest manufacturing technology, but it ensures production of munitions and other military equipment wonâ€™t be bottlenecked by a lack of machine tools. This isnâ€™t a hypothetical concern: American production of artillery shells for Ukraine has been held back by a lack of machine tools. The military has thus historically paid close attention to the machine tool industry and the availability of machinists. For most of the 20th century, the US was unrivaled in its machine tool technology, and as late as the early 1980s it was the largest machine tool producer in the world.. But almost overnight, the industry collapsed: annual machine tool shipments declined by more than 50% in 2 years, hundreds of machine tool companies went out of business, and the US slipped from the largest producer in the world to the 4th or 5th (depending on the year), roughly where it remains today. What happened to the US machine tool industry? Why did it fall so far so quickly? Letâ€™s take a look. The early machine tool industry Machine tools include metal cutting machines like lathes, milling machines, drill presses, grinding machines, as well as things like wire-bending machines, stamping machines, die-casting presses, and forging machinery.1 Tools like lathes and drills have been in use for thousands of years, but modern machine tools â€“ â€œpower-driven machines with methods of control permitting some degree of precisionâ€ â€“ first appeared in Britain at the beginning of the industrial revolution. Wattâ€™s famous steam engine was made possible by the precision boring machine built by John Wilkinson to precisely bore the cylinders for it. In the US, machine tools were a critical component of the â€œAmerican System of Manufacturesâ€ â€“ interchangeable or near-interchangeable parts produced using a series of specialized machines. This method of manufacturing was first developed for the production of guns (and was thus sometimes known as â€œarmory practiceâ€), and gradually spread to Americaâ€™s burgeoning industries: sewing machines, locomotives, and especially bicycles. By the turn of the 20th century, thanks to decades of innovation the US was producing the most advanced machine tools in the world. US technological leadership continued with the rise of the automobile, which created an unprecedented demand for machine tools. As early as 1910, the car industry made up 30% of machine tool sales, which only increased as car sales exploded and car manufacturers adopted mass-production methods (annual car sales went from less than 200,000 in 1910 to 3.7 million in 1925). The car industry required enormous numbers of machine tools (Ford alone eventually had more than 50,000 machine tools in its Rouge assembly plant, roughly as many machine tools as the entire US made in a year), but the demands of car manufacturing pushed machine tool technology forward. Making cars required heavier, more accurate machine tools that could produce more accurate gears, better ball bearings, smoother finishes, and tighter tolerance parts. Machine tool technology was also advanced by the rise of electrification, which enabled machines driven by a series of belts and drive shafts to a central steam engine to be replaced by machines driven by their own electric motor. Between 1910 and 1929, machine tool sales nearly quadrupled, and machines continued to get more and more productive. Via The US Machine Tool Industry From 1900 to 1950 Machine tool sales were dragged down by the Depression, but bounced back as production of munitions and military hardware for WWII ramped up (the war also marked the birth of the aerospace industry as the second great consumer of machine tools after the car industry). Annual shipments of machine tools went from 50,000 in 1929, to 5,500 in 1932, to 300,000 by 1942. Over the course of the war, the US produced 800,000 machine tools, and the US emerged from WWII as the largest producer of machine tools in the world. The post-war machine tool industry The machine tool industry was shaped by extreme cyclicality: orders for new machine tools might fluctuate 90% year-over-year. This was driven by whatâ€™s sometimes known as the â€œaccelerator effectâ€: a small change in the demand for final goods can cause a large change in the demand for the machines that produce those goods: Consider a company that manufactures its product on lathes. Assume that it has ten lathes that can just meet production requirements. Assume also that each lathe wears out in ten years and that the company has its investment plans so well organized that one lathe is replaced every year. Now consider what will happen if there is a 10 percent increase in demand for the product. The plant will need eleven lathes to meet production requirements. It will have to buy two lathes: one as a replacement for the worn-out lathe and a second to increase capacity. Thus a 10 percent increase in the demand for the product has produced a 100 percent increase in the demand for lathes. Of course, the accelerator effect is also felt in the other direction. If the demand for the product declines 10 percent, the company will need only nine lathes. In view of the reduced sales volume, it will almost certainly not replace the lathe that has worn out. Thus a 10 percent decline in demand for the product has caused a 100 percent decrease in the demand for lathes. In the real world the relationships are not as neat as in this hypothetical case, but the accelerator effect is a very real factor. â€“ Is New Technology Enough? This accelerator effect is exacerbated by the fact that machine tools, properly maintained, can last for decades or even longer (the US is still using the 50,000 ton forging press built in 1955 as part of the heavy press program, for instance). An owner of a machine tool can thus put off replacing it almost indefinitely if demand for the product that requires it is uncertain. The machine tool industry was wracked by such fluctuations in the post-war period. It entered a four-year slump at the end of the war, as wartime demand fell off and the US government sold off huge numbers of surplus machines at rock-bottom prices. Sales then picked back up during the Korean War, fell off again when the armistice was signed, then picked back up, then declined again in the recession of 1958. But the US remained at the technological forefront during this period, and continued to lead the world in machine tool production. Shifts in the landscape: technology, ownership, competition In the 1960s, the machine tool industry underwent several major shifts. The first was the development of numerical control. Prior to the 1950s, there were generally two ways that a machine tool could be controlled. A skilled machinist could manually move the tool and/or the part to be machined to cut it into the proper shape, drill the proper holes, and so on. Alternately, a machine tool could be mechanically automated. Ford, in pursuit of ever-greater efficiencies on the Model T assembly line, built and acquired dozens of different automated and semi-automated machine tools for tasks such as making screws, boring piston heads, and drilling engine blocks. This sort of automatic machinery had been around since the 19th century, but it was somewhat fixed in the tasks it could perform. The machines couldnâ€™t easily be changed to produce something else without substantially rebuilding the machine (these sorts of difficulties are why Ford had to shut the Rouge factory down for 6 months to retool when changing from the Model T to the Model A, and why auto producers were so interested in robotic welding).2 This changed with the development of numerical control, or NC. With NC, the movements of a machine could be encoded on a paper tape or a punched card. Changing the movements of the machine (and thus what the machine produced) just required feeding the machine a new tape with a different set of instructions. Numerical control was first developed by MITâ€™s Servomechanism Lab in conjunction with the Air Force in the 1950s. Early on, the technology had little commercial appeal: it was expensive, complex, unreliable, and designed to solve specific complex fabrication problems in aerospace manufacturing, rather than the simpler machining needs that made up the bulk of machine tool demand. NC technology is sometimes described as â€œdeveloped from the roof instead of from the foundationâ€. But that started to change by the early 1960s: machine tool manufacturers began to produce more reliable machines designed for broader commercial appeal (though the technology remained very expensive). In 1958, Kearney and Trecker introduced its Milwaukee-matic, the first of what became an entirely new category of machine tool, the machining center. A machining center contained a tool-changer with dozens of different specialized cutting tools, and could be programmed via numerical control to perform a series of machining operations, automatically changing to different cutting tools as required. This greatly increased efficiency: a typical machine tool was only operational 25-30% of the time, with much of the rest of the time spent setting up the machine and prepping the part to be worked. But Kearney and Trecker boasted that the Milwaukee-matics were operational more than 75% of the time. And because of its ability to flexibly mount different cutting tools quickly and automatically, a machining center could perform tasks which previously required many different machines. Milwaukee-matic in the late 50s or early 60s. Early NC machines used vacuum tubes, and required large bulky control cabinets as large as the machine tool itself. But NC rode the wave of rapidly improving computer technology: vacuum tubes and paper tapes were replaced by transistor-based minicomputers, and then even smaller microprocessor-based computers, resulting in Computer Numerical Control, or CNC. NC was adopted slowly: by 1968, just 10% of US metalworking plants had an NC machine, and they made up just 0.5% of total machine tools in the US. But it was clearly becoming a manufacturing mainstay: already by 1968 NC made up 20% of new machine tool sales in the US, and by 1983 had risen to over 40%. The second major change to the machine tool industry was its ownership. Historically, machine tool companies were small operations run by people (often descendants of the original founders) who had spent their whole life in the machine tool industry and knew it inside and out. Because of the cyclical nature of the industry, machine tool firms tended to be managed conservatively, and they operated with little debt. But in the 1960s, machine tool companies began to be acquired by the latest fashion in US business, the conglomerate: enormous, diversified companies that seemed to make anything and everything as long as there was profit in it. The machine tool industry was on a sales upswing that showed no signs of slowing, and machine tool firms' high profitability (and low debts) made them attractive acquisitions for the conglomerates. Additionally, the rise of NC technology made the industry seem sexy and futuristic, and many large conglomerates (like Teledyne, Litton Industries, and Bendix) had defense and aerospace divisions, to which machine tools seemed like a natural addition. The third major shift in the machine tool industry was the rise of foreign producers, especially Japan. Japanâ€™s machine tool industry had been devastated by the war and the immediate aftermath (when many of Japanâ€™s machine tools were shipped to China and the Philippines as war reparations), and by 1955 Japanese tools were just 0.5% of world exports. But Japan was eager to become a major producer of machine tools, and its manufacturers quickly became more capable. Between 1955 and 1960 Japanese machine tool production rose by a factor of 15, and in 1960 American Machinist magazine noted that â€œJapanese machines for the first time appear to merit recognition and to be competitive with machines of the most advanced industrial nations.â€ By the end of the 1960s, imports remained a small fraction of the US market (around 10%), but were gaining momentum: between 1964 and 1967, Japanese machine tool exports to the US rose over 1200%. Fall of the US industry From the late 1960s through the early 1980s, these trends coalesced in a way that proved disastrous for the US machine tool industry. Japan had jumped on the NC bandwagon quickly, and began manufacturing NC tools as early as the 1950s. Their progress was aided by dozens of American machine tool firms that were all too willing to license their technology to Japanese producers. (Japanese companies were also not above simply illicitly duplicating American designs). By the end of the 1960s, Japanese machine tool manufacturers were exporting NC tools to the US. With NC, US machine tool makers had primarily focused on the high end of the market, using advances in computers and other technology to create increasingly precise machines capable of tracing complex paths, and tailoring the machines to the needs of individual customers (as was common in the US machine tool industry). This focus was in part due to the guiding hand of the air force and the aerospace industry, which demanded these types of machines for production of advanced parts. Japanese builders, on the other hand, developed simpler, cheaper NC machines based on standardized designs, aimed at the large, untapped lower end of the market that previously couldnâ€™t justify the cost of an expensive NC machine. And a focus on simpler, standardized designs, along with the traditional Japanese focus on quality, also meant that Japanese tools tended to be more reliable than US tools. One example of Japanese standardization was controllers, the electronic components used to control the movement of the machine tools. In the US, there were many different suppliers of controllers, and many machine tool builders (like Cincinnati Milacron, Pratt and Whitney, and Warner and Swasey) offered their own, custom-built controllers to try and achieve a competitive advantage. In Japan, on the other hand, the market quickly became dominated by a single producer, FANUC. Not only were Japanese controllers cheaper, but a single standard likely meant that programming the machines and training people to use them was greatly simplified, as there was no re-learning process involved when switching to a different type of control. Not only were the Japanese building more reliable, less expensive tools than the US builders, but they were delivering them faster. Historically, machine tool companies had dealt with the cyclicality of the industry by acquiring a large backlog of orders, then working it down during the lean times when new orders slowed. When a customer ordered a new machine tool, it might take a year or two (or more) for it to be delivered. One US manufacturer of lathes noted that it built just one size of lathe a month: if you ordered a lathe in February that was only made in January, youâ€™d have no choice but to wait a year for them to build it again. But Japanese builders, with their focus on standardized machine designs, could deliver machine tools in weeks: â€œA Pennsylvania company sorely needed a cylindrical grinder, but was told that delivery of a $50,000 American machine would take at least a year. So the company decided to order from a distributor of Japanese tools. Within weeks, it had two Japanese grinders in operation for almost the same price.â€ â€“ Max Holland, When The Machine Stopped As Japanese machine tools were advancing, US firms were struggling. Though the conglomerates enjoyed owning machine tool firms in the boom times when profits were high, they quickly became disillusioned during the lean periods when new orders slowed to a trickle. The new ownersâ€™ focus on profits meant that they were reluctant to make the long-term investments in R&D or new equipment needed to keep the firms competitive. Between 1968 and 1978, the book value of assets of machine tool companies declined by nearly 50% in real terms. Via Military Spending and Industrial Decline Conglomerates were often quick to divest their machine tool holdings when the companies began to struggle, resulting in frequent management changes and organizational whiplash as the firms tried to find their footing under new ownership. Storied machine tool manufacturer Warner and Swasey, for instance, was acquired by Bendix in 1980, which then sold it to Allied Corporation in 1983 as part of an effort to fight a hostile takeover from Martin Marietta. Just one year later in 1984, Allied then sold its machine tool group, including Warner and Swasey, to Cross and Trecker, which in turn was bought by Giddings and Lewis in 1991, which then decided to shut down Warner and Swasey the next year. This sort of management shuffling often took place at conglomerates even when ownership didnâ€™t change, as the companies reorganized internally in the face of losses to try and right what they saw as a sinking ship. Constant pressure to hit quarterly performance targets meant that machine quality often suffered. In some cases, machines would be shipped out the door unfinished so the delivery could be booked, and assembly would be completed by service technicians at the customerâ€™s location. In his history of the American machine tool industry, Albert Albrecht states that â€œthe actions of these larger corporations and conglomerates, under the leadership of financial MBAâ€™s, perhaps more than any other factor, contributed to the restructuring and decline of the US machine tool industry at the end of the 20th century.â€ Amidst these struggles, US machine tool builders fell behind technologically. Not only did they lag in the design of low-cost NC machines, but they were well behind Japan in the adoption of microprocessor-based controllers. A 1983 National Research Council Report summarized the situation: â€œWhile many in the industry are convinced that U.S. machine tool technology is presently equal to the most advanced level attained by any overseas competitor, the panel believes that the United States may now have slipped behind the Japanese on control technology and on the software to support such control systems. Additionally, the panel expressed concern that the Japanese are also more advanced in the general development of machining systems that allow round-the-clock operation with minimum human attention.â€ And Japan wasnâ€™t the only country making progress. By 1970, Germany (which had always led the world in machine tool exports) had become the worldâ€™s largest machine tool producer (though the US would eclipse it again several years later). And between 1965 and 1980, Italyâ€™s share of world machine tool output tripled. As late as 1973, imports of machine tools were just 10% of the US market, but by the end of the 1970s they had reached 22%. These trends came to a head in the recession of 1982. Machine tool sales dropped precipitously, falling from $5 billion in 1981 to just $2 billion in 1983. But this time, sales didnâ€™t bounce back. By now, tools from Japan and other countries were as good as or better than US tools, not to mention cheaper and more reliable. A strong dollar made imports even cheaper by comparison, and high interest rates reduced the demand for capital investment. US manufacturers found themselves with uncompetitive products in a highly competitive market. Whereas imports had been just 10% of the US market in 1973, by the late 1990s they were closer to 60%, and by 1986 75% of NC machines were imports. Japan alone made up 50% of the US NC market in the late 1980s. Via The American Machine Tool Industry The US industry collapsed almost overnight. From 1981 to 1983 employment in machine tools declined by a third, and continued to fall (by 1991 it was half its 1981 level). Between 1982 and 1987, half of US machine tool firms closed their doors. The US fell from the largest machine tool builder in the world to third behind Japan and Germany, and continued to decline: by 2002, it had dropped to 5th behind Italy and China, where it remains today. The industry tried to get some of the same protectionist measures industries like steel had secured. Houdaille, an industrial conglomerate with a large machine tool division, attracted a great deal of attention with a petition to have the investment tax credit denied to Japanese machine tools. But the machine tool industry had much less success with its pleas for protectionism than the steel industry; Houdailleâ€™s petition was denied, and while the industry was eventually able to get some Voluntary Export Restraints (which lasted from the late 80s to the early 90s), it did little to change the overall trends in the industry. Today, the US competes in a machine tool market that continues to be dominated by Japan, Germany, and now China. It has some bright spots, such as Haas Automation (founded in 1983, in the ashes of the industryâ€™s collapse), but the major producers are all foreign companies. As of 2014, not a single one of the 10 largest machine tool companies in the world was a US company (Haas clocked in at number 13), a fact which as far as I know remains true today. The US is still a major purchaser of machine tools (2nd in the world behind China), but unlike for most of the 20th century, today its factories are full of machines made elsewhere. 1 There is something of an issue of definition here. Traditionally machine tools were just considered metal cutting machines, and things like die casting or stamping equipment would be categorized separately. 2 Some flexible machines did exist, such as the Blanchard lathe, which could duplicate the shape of any gunstock placed within it. Subscribe to Construction Physics By Brian Potter Â· Hundreds of paid subscribers Essays about buildings, infrastructure, and industrial technology. Subscribe 94 Share this post What Happened to the US Machine Tool Industry? www.construction-physics.com Copy link Facebook Email Note Other 8 Share Previous",
    "commentLink": "https://news.ycombinator.com/item?id=39044586",
    "commentBody": "What happened to the US machine tool industry? (construction-physics.com)209 points by jseliger 16 hours agohidepastfavorite185 comments mauvehaus 15 hours agoIf you're into machining, the American Precision Museum[0] in Windsor, VT is highly worth a visit. I had the good fortune to tour the Starrett factory some years back. They were still running pre-NC screw machines to make parts. It really is true that old machines, well cared for, will last just about forever. Apparently it's something of an axiom in the machining industry that tools that are no longer economically viable for large scale production end up in job shops where the capability is needed but there isn't a need to pump out volume. The Springfield Armory[1] is also a neat visit. For hopefully obvious reasons, their machining exhibits are focused on the production of weapons. The American Precision Museum is actually housed in a historic privately-owned gun factory. It turns out a lot of the progress in machining is driving by the need to make weapons. [0] https://americanprecision.org/ [1] https://www.nps.gov/spar/index.htm reply drmpeg 15 hours agoparentI worked at my fathers machine shop (which was a subsidiary of New Britain Machine Company) a couple of summers when I was in high school in the mid 70's. It was quite an experience and the employees were some of the crustiest characters I've ever met. The second summer, I worked with this guy named Ray on a huge machine that made the heads to ratchet wrenches (the square part with the little ball). He was one of these guys that was continuously pissed off. A man's man probably only 35, but looked 45 and smoked Camel unfiltered cigarettes. But the thing I remember most about him was that he could swear for a minute straight and never use the same word twice. For example, he called the machine \"The Afterbirth\". I'll never forget that man. reply mandeepj 7 hours agorootparent> But the thing I remember most about him was that he could swear for a minute straight and never use the same word twice. Legend! Iâ€™d have enjoyed working with him. The smell of cigarettes could be a turn-off. Only perfectionists (in their craft) can use that level of swearing. reply sbuccini 6 hours agorootparentprevDid you ever shop at my grandfatherâ€™s hardware store? reply digitalsushi 15 hours agoparentprevIf you go in late August and have a strong affinity for amateur astronomy, you can have one heck of a weekend by visiting Stellafane 10 miles south of there in Springfield VT. Probably an abuse of a comment but it's so rare to find two things to do so close together in that area. reply MisterTea 15 hours agoparentprevVisited when I was a kid it was fun seeing all the belt driven machinery that wasn't so different than my father's machine shop (job shopped manual and CNC milling and turning.) The 90s was when we saw the manufacturing downslide then my father got sick and passed. We kept it going but by the 2000's China was eating everyone's lunch. Though the fall of the Berlin wall killed a lot of aerospace work which was big business on Long Island. We sold the business in 2006 and somehow the guy who bought it is still in business though downsized and runs it himself now. reply fwlr 5 hours agoprevâ€œHistorically, machine tool companies were small operations run by people (often descendants of the original founders) who had spent their whole life in the machine tool industry and knew it inside and out. Because of the cyclical nature of the industry, machine tool firms tended to be managed conservatively, and they operated with little debt. â€¦ [In] the 1960s, machine tool companies began to be acquired by the latest fashion in US business, the conglomerate: enormous, diversified companies that seemed to make anything and everything as long as there was profit in it. The machine tool industry was on a sales upswing â€¦ [and] machine tool firms' high profitability (and low debts) made them attractive acquisitions for the conglomerates. â€¦ â€œThough the conglomerates enjoyed owning machine tool firms in the boom times when profits were high, they quickly became disillusioned during the lean periods when new orders slowed to a trickle. The new ownersâ€™ focus on profits meant that they were reluctant to make the long-term investments in R&D or new equipment neededâ€¦ Conglomerates were often quick to divest their machine tool holdings when the companies began to struggle, resulting in frequent management changes and organizational whiplashâ€¦ â€œIn his history of the American machine tool industry, Albert Albrecht states that â€œthe actions of these larger corporations and conglomerates, under the leadership of financial MBAâ€™s, perhaps more than any other factor, contributed to the restructuring and decline of the US machine tool industry at the end of the 20th centuryâ€.â€ Bingo. The article points to cycles of high variance in demand for machine tools. Other commenters have pointed the dominance of foreign companies (eg Japan due to their national standardisation on FANUC), globalization and â€œmore cost-effective to importâ€ more generally, and also suggested America is in a â€œpost-machiningâ€ stage of manufacturing. I think all of these claims have merit, but the real underlying cause is most certainly the humble MBA. To wit: they bought themselves into a cyclic industry, replaced the survivor-mindset management, and effectively took these resilient existing businesses and crystallized them into brittle conglomerates while the industry was on the rise of one such cycle, and when they where wholly unprepared for the inevitable down stage of the cycle, they divested, leaving a wasteland behind. reply georgeecollins 3 hours agoparentMBAs and financially driven management are why the US is such a poor country today. If the US was run like Japan or Germany we would be the wealthiest nation on Earth. First this short shortsightedness cost us the brick industry, then steel, and now machine tools. My children are doomed to be burger flippers due to MBAs. reply distances 2 hours agorootparent> .. US is such a poor country today. If the US was run like Japan or Germany we would be the wealthiest nation on Earth. US is, by a clear margin, the wealthiest nation isn't it? Certainly more so than Germany or Japan. Edit: I may have missed some sarcasm there. reply bane 14 hours agoprevI grew up in a family printing business. Printing is a manufacturing industry just like anything else, with equipment of various sorts at every step of the production chain. Even in the 80s, when the business was going strong, most of the equipment we used was from Germany or Japan. Sure there were a few odds and ends made in America, things like X-Acto knives, or wax melting machines or something. Paper, ink, and a few other chemicals used for various parts of the production processed were usually sourced from the U.S. or Canada IIR. But the presses, big cutting and binding machines? Every single one was from overseas: Heidelberg, Hamada, Ryobi, others. It was simply impossible to get machines of the quality and precision from the U.S. This often meant multi-week downtimes for aging machines that needed parts replaced or repaired, waiting for a single roller or a latch or something while it was shipped from the home country. As things moved more and more digital, the front-end equipment likewise became more and more foreign made. In my lifetime, the U.S. never owned the entire vertical supply and manufacturing chain in that industry. I'm not sure if it ever did. reply Kosirich 1 hour agoparentI grew up with a father who is/was an owner and director of a company that produces manufacturing printing rollers (gravure printing), mostly for packaging industry. He always competed against others on quality and flexibility as he couldn't on size, so having the best kit was important. The technology, even though the product is a discardable piece of packaging, is on NASA/CPU manufacturing level. Even though, I myself was never involved directly in it, nor am I today, I know from him there were several trends: 1) Printing companies in Europe and elsewhere got bigger. What use to be 10 printing companies, now it's 1. 2) Equipment manufacturers for that industry got bigger. What use to be 4,5 equipment manufacturers in EU/USA, now there is one. 3) Lasers. Lasers got to a level where they can compete and surpass mechanical removal on quality and speed. This is true also for industry I'm in. reply psychlops 15 hours agoprev> A strong dollar made imports even cheaper by comparison I think that summarizes the article. It has been cheaper to import, so we do. The strong dollar policy supports some industries at the expense of others. reply roenxi 8 hours agoparentThere are three aspects to this - cost of manufacturing in the US, cost of manufacturing + shipping in China and exchange rates. I do think the relative dollar strength is a factor, but Chinese labour was effectively free vs US labour. If someone is willing to do work for free, then the economy will give them work. The issue that the free marketeers have been railing about for approximately the last 50 years it seems like almost every major policy the US adopts increases the cost of manufacturing relative to a hypothetical entity that didn't do that. It has been a constant adjustment of labour law, environmental law, energy policy and financial regulation away from manufacturing. It is plain why US manufacturing isn't the global top dog. The real question is whether it is a bad outcome or not. Over the last 50 years China has improved their energy use by 1 UK economy per capita. IMO we should also ask more seriously if those regulations were worth it. A UK per capita energy is a lot of QoL improvements and it was linked to doing a lot of manufacturing. The US on the other hand is behaving politically like people are worse off than they were. reply bmitc 6 hours agorootparent> The real question is whether it is a bad outcome or not. It's definitely bad. The U.S. won't even have the world's biggest navy pretty soon because of that. And there are tons of scenarios where the U.S. is economically hosed because of some international conflict. Not only does the U.S. not make things, it doesn't know how to. reply mikeyouse 5 hours agorootparentWe should absolutely increase our industrial capacity but who gives a shit about the biggest Navy? Outside of the problem countries like China and Russia, we have military alliances with nearly every country on earth.. US has somewhere around 450 Navy vessels.. China has closer to 350 but is rapidly adding new tonnage. Sounds ominous! Except Japan has another 150, Australia has 50 more, the UK has 70 more, Spain has 150, France 180, Korea has 160, if some war ever comes down to the sheer number of available ships -- it literally won't matter who has more since the nukes will have flown long before some Canadian frigate is exchanging fire with some Chinese gunboat. reply wolverine876 4 hours agorootparentAlso, number of ships doesn't mean too much. I could buy 1,000 canoes. And tonnage only means a bit more - there is plenty of tonnage in old ships rusting at docks. Naval power isn't easily measured with statistics. The capabilities of a single US 100,000 ton aircraft carrier overwhelms entire fleets, unless their capabilities include long-range anti-ship missiles or submarines. Then adding tonnage won't help the US; they need capabilities to counter those two threats. reply oneshtein 3 hours agorootparentprevYes, but you forgot about informational war, which started long before direct armed conflict. Today, it's possible to influence a foreign election with an army of bots, to turn a country into a self-defense mode, so alliance will not work, because domestic problem, like border with Mexico, will overweight. reply wolverine876 5 hours agorootparentprevWhy is 'making things' tied to income or wealth? In the mid-20th century it was, but those are the 'good old days'. We don't want a mid-20th century economy. The US has the most productive, wealthiest economy in the history of the world, and a very strong one at the moment, without so much of the 'making things'. Why change? (And why do American taxpayers have to subsidize someone else's uncompetitive, unproductive business? Perhaps they are better off letting the free market allocate the revenue.) reply chii 7 hours agorootparentprev> It is plain why US manufacturing isn't the global top dog. i do believe the US still does high-end (but low volume) manufacturing. It's just mass manufacturing that went away. reply edgyquant 15 hours agoparentprevThis is the answer to all American manufacturing woes. The dollar as a reserve currency gives the US a ton of global leverage but requires a trade deficit thus it comes at the expense of domestic industries. reply specialist 14 hours agorootparentI'd love to understand statements like this. Lemme try: Because trade deficits induce demand for dollars? Like how Japan and now China hold a bajillion US dollars? So if the US had (prolonged) trade surplus, no one would be holding dollars? But wouldn't trade partners still need US dollars to buy US goods? Like the situation post-WWII? So then we'd \"loan\" partners US dollars to buy our stuff? Aiugh. My brain just broke. How does a noob like me learn about these systems. I know it all probably makes sense to the learned. But with my folk (mis)understanding, these claims sound counterintuitive. Thanks. reply nostrademons 10 hours agorootparentYou're on the right track. In a normal, non-reserve-currency situation, the demand for a country's currency is proportional to the demand for its products. After all, that's what you use a currency for: to buy the products that are sold in that currency. This has a well-behaved equilibrium, because if a country produces a lot of good products, that means the value of its currency will rise, which makes goods developed in that country relatively more expensive, which cuts demand, until everything equilibrates at a point which is roughly reflective of the actual quality and productivity of the country. In a reserve-currency situation, the currency is used for many things other than buying the products of the country. For example, oil is priced in dollars; if India wants to buy oil from Saudi Arabia, it needs dollars to make the transaction, and then Saudi Arabia has an excess of dollars. Frequently it uses these to buy U.S. T-bills or invest in American tech startups like Uber or WeWork, both other sources of demand for dollars. The dollar is basically the currency of the global financial system: instead of directly converting rupee to riyal, you convert rupee to dollars, handle your transaction, and then convert dollars to riyal. This creates a large source of demand for dollars outside of the traditional market for a national currency. Indeed, America's export here is basically financial services, which as a sector has been doing great since 1990, one of the few areas where you're likely to get paid handsomely. The other area is tech, which at its core is about enabling these cross-border commerce flows - Amazon, Google, Facebook, UpWork, Stripe, CoinBase, Ripple, Stellar, PayPal, E-bay, Shopify, AirBnB are all about creating global marketplaces where you can buy anything from anywhere. Finance and tech crowd out everthing else that you would normally use dollars for. Basically America has specialized in being the global marketplace - it's only purpose is to be the common standard that every other country needs to transact in. Because there's so much demand for dollars simply to do international transactions, it pushes the price of the dollar up. This makes everybody who's trying to sell actual things in dollars (rather than take a commission when other people sell things in dollars) uncompetitive. It works great, until the rest of the world decides that it wants to cut out the middleman. At that point, since we don't produce anything anymore, we're screwed. America's basically given itself Dutch Disease, where our only viable industry is financial services. reply FirmwareBurner 10 hours agorootparent>It works great, until the rest of the world decides that it wants to cut out the middleman. Isn't this why the US invests in having the world's biggest military by a long margin, plus the world's most powerful spy agencies? To make sure nobody dares cut them out of their privileged position otherwise they get a dose full of aircraft carriers, F-35 and B-2s after the NSA finds out what their plans is from the spyware they put in their iPhone. reply nostrademons 10 hours agorootparentYes, exactly. The challenge - alluded to in the article - is that having a functional military requires a domestic manufacturing base and machine tool industry. The U.S. generally tries to keep its arms manufacturing in-house, for obvious national security reasons. But even if you've kept the existing defense contractors alive, you lose out on the ability to repurpose the country's civilian manufacturing base if it doesn't exist. This was pretty critical in WW2: General Motors made more TBM Avengers than Grumman, Chrysler made more tanks than all German manufacturers combined, Kaiser made Liberty Ships by the hundreds. Without the ability to quickly tool up, you'll end up defeated in any war of attrition. There's a pretty significant risk that we'll find out that the U.S. is a paper tiger if it comes to any sort of prolonged war with a near-peer power. reply FirmwareBurner 9 hours agorootparent>Without the ability to quickly tool up, you'll end up defeated in any war of attrition. Why is this a risk? The biggest tool makers in the world are Germany and Japan which are in the US sphere of influence whether they want to or not and are therefore incentivized to sell to the US as many machines it would need to fight a war. The risk for Japan or Germany not wanting to sell tools to the US feels insignificant, as they aren't in a position of power to refuse to play ball. reply kuschku 9 hours agorootparentJapan and Germany are entirely metric. Pretty much the entire US manufacturing industry, or rather the zombie the pentagon keeps on life support, is in US standard. That means everything needs to be adjusted or replaced. That's not viable in peace times, it's even less so in times of war. Obviously this applies primarily to tanks and ships, not planes nor guns. reply dpe82 6 hours agorootparentPart of the beauty of eg. CNC mills is they don't necessarily care what the units are. reply kevin_thibedeau 8 hours agorootparentprevJapan and Germany are vulnerable to Chinese aggression. The primary reason why a declining company like Micron was gifted a new fab in Syracuse NY is that their Boise fab is within range of a larger portion of the Chinese arsenal. reply nostrademons 9 hours agorootparentprevThat's why (well, one reason why) the U.S. keeps Japan and Germany in its sphere of influence. Same for Saudi Arabia (major oil producer) and Taiwan (major chip producer). Notice that U.S. / Saudi relations soured a fair bit after the U.S. became the largest global oil producer again (thanks to fracking and shale oil). We're a bit less willing to overlook an authoritarian dictatorship when we don't need them. The challenge with all international relationships is that they're not stable. Germany almost didn't back us on Ukraine, for example, because Russia threatened to cut off the supply of natural gas and make its citizens freeze in the winter of 2022/2023. Only because the NordStream pipeline blew up anyway (an act of sabotage that American journalists have attributed to the U.S.) and the U.S. secured alternate sources of heating for Germany did they back us on Ukraine. Had it been a different regime in power in either the U.S. or Germany, that could've turned out very differently. reply bllguo 9 hours agorootparentprevIt appears the western public's understanding of geopolitical realities is always a decade behind. _Right now_, all of NATO combined can't even outproduce Russia alone. We don't need to be talking hypotheticals, it is literally happening in real time. plus if a conflict like that occurs then clearly the US has lost significant power. so why would it be a given that American neo-colonies stay on its side? reply FirmwareBurner 9 hours agorootparent>_Right now_, all of NATO combined can't even outproduce Russia alone. What? Don't know where you're getting your sources but NATO combined definitely can outproduce Russia. Why it isn't, is that Russia is in war mobilization mode with all their industry running 3 shifts for the war effort, while NATO's industry is still in peace-time mode because they're not under attack. reply oneshtein 3 hours agorootparentNATO countries can overproduce Russia in a future, but right now they don't. reply justsomehnguy 9 hours agorootparentprev> with all their industry running 3 shifts for the war effort Lol? Where are you getting your sources? reply FirmwareBurner 8 hours agorootparentPerun reply mikeyouse 5 hours agorootparentprevPutin and Chemezov themselves? https://www.themoscowtimes.com/2023/01/02/russian-defense-ch... reply justsomehnguy 2 hours agorootparentMilitary != 'all their industry' reply pylua 9 hours agorootparentprevThatâ€™s interesting . Sounds like it will end badly. I do think the next major war will be nuclear and not one of attrition. America is not going to fight a traditional war it canâ€™t win. reply nostrademons 6 hours agorootparentI'm not sure, honestly. I certainly think it's a risk that the next big war starts, it goes poorly for America, and then we resort to nuclear weapons to squeeze out \"victory\" (i.e. everybody dies) if we're all going to die anyway. But I think there's another possibility that most people aren't considering: disintegration. It's very common for countries to cease to exist as countries when they start losing a war, particularly a war that happens because they're moribund and falling apart internally anyway. Witness the Austro-Hungarian, Ottoman, and Russian Empires in WW1; the end of the Roman empire; England during the War of the Roses in the aftermath of the Hundred Years War; Yugoslavia and the Soviet Union in the wake of the Cold War; etc. This also doesn't have to wait until the end of the conflict: most of the big disintegrations in WW1 happened in 1917, before the armistice, and sometimes even to \"victorious\" parties. Modern nuclear weapons are very tightly controlled with PALs, so that you physically can't arm them without correct codes produced by the Pentagon/NSA bureaucracy. If that bureaucracy falls apart, it's likely they will just rot in their silos, while humanity dukes it out with relatively primitive technology because nobody wants to work together anymore. reply jimt1234 9 hours agorootparentprevI heard this was the real reason the US took out Saddam Hussein. Basically, Saddam had been saying for years that he wanted Iraq to abandon the dollar for trading its oil. If he was successful at this, other Arab Nations would most likely do the same. This wasn't acceptable to the powers in the US, so the US tax payers funded the war in Iraq to send a message to other nations: Don't even think of abandoning the dollar. Not sure if there's any truth to that at all, but it's at least believable. reply lstodd 1 hour agorootparentConspirology at its best. Better swap Saddam for Qaddafi, that would be even more believable. First Iran-Iraqi war that resulted in a standstill, then invasion of Kuwait, and only then the second Iraqi war when he went totally nuts. Other Arab nations are Saudis and Persian Gulf emirates, who had zero use for the deranged person. And were and still are quite happy with dollars. reply shiroiuma 1 hour agorootparentprevAccording to George W. Bush, God himself told him to start the war. reply rr808 7 hours agorootparentprev> For example, oil is priced in dollars; if India wants to buy oil from Saudi Arabia, it needs dollars to make the transaction, and then Saudi Arabia has an excess of dollars. Frequently it uses these to buy U.S. T-bills or invest in American If it priced the oil in Euros or Yen or Riyals or Rupees or US Dollars it has to pay its costs. Sure it may end up with a profit its then free to invest those where it likes, there is no reason it has to buy USD assets. Many wealthy and/or exporting nations choose to buy US assets because its a large, safe and well established market, but it has nothing to do with being the most popular trading currency. > America's basically given itself Dutch Disease, where our only viable industry is financial services. Clearly this is not true. The largest companies in the USA are not financial. reply jameshart 5 hours agorootparent> Clearly this is not true. The largest companies in the USA are not financial According to this list[1] of the top 100 largest (public) companies in the US, 14 of the largest companies are in the financial industry, and five more are in insurance. Six if you count Berkshire Hathaway; eight if you also count health insurers (although they're not exactly a financial service exporter, so probably don't count). So between 19-22 of the largest 100 US companies are in the finance industry. In comparison, there are only eight or nine tech companies, and 11 petroleum businesses. So sure, the.. six largest companies aren't financial companies, but finance is very well represented among the largest companies in the US below that level. [1] https://en.wikipedia.org/wiki/List_of_largest_companies_in_t... reply Godel_unicode 4 hours agorootparentItâ€™s an uncommon take that a diverse market with no single sector even close to a majority is a problem. reply chii 7 hours agorootparentprev> Clearly this is not true. The largest companies in the USA are not financial. i believe the parent post meant tech and financials (but is lumping them together into one). reply prettychill 14 hours agorootparentprevI found this blog post to be quite interesting https://www.lynalden.com/fraying-petrodollar-system/ reply depereo 14 hours agorootparentprevI think of it as another type of https://en.wikipedia.org/wiki/Resource_curse reply hayst4ck 9 hours agorootparentprevPrinciples for Dealing with the Changing World Order by Ray Dalio: https://www.youtube.com/watch?v=xguam0TKMw8 I think this video addresses the topic in question at a layman level. reply maxglute 14 hours agorootparentprevhttps://en.wikipedia.org/wiki/Exorbitant_privilege reply edgyquant 11 hours agorootparentprevHonestly I learned the basics in Econ classes during college and have an interest in international relations/geopolitics so Iâ€™m not sure a good single source for learning about it all. But yeah there is some macroeconomic wizardry involved here. Iâ€™ll add it is a political thing and not a right v wrong policy. Choosing manufacturing power or global influence is a trade off with pros and cons. reply mywittyname 13 hours agorootparentprev> So then we'd \"loan\" partners US dollars to buy our stuff? Other way around, they buy T-bonds -- i.e., \"loan\" dollars to the US Government. But the country is still owed that money back - it's like a trillion dollar bank account. One could say China \"lends\" dollars to the Treasury, but it's also just as accurate to say they \"deposit\" dollars into the Treasury. It's all just words to describe the action of giving money to another party to hold onto temporarily. \"Strong\" currency means there's more demand for it. Demand is usually a function of what you can buy with the currency. When countries reinvest their dollars into T-Bonds, they are double dipping on establishing demand for dollars. On one hand, they are owed back the dollars handed over to the Treasury (thus, creating future demand for USD), and on the other, accepting USD for the sales of their goods/services induces demand for USD, since it is yet another good that can be purchased with USD. \"Weak\" currency means that there's less demand for it. Weak currencies tend to be those from countries that produce little in the way of goods and services, or they only produce commodities (like oil) that are generally traded in other currencies. A weak currency can be a benefit. Hence why so many countries seek to artificially weaken their currency (aka currency manipulation). They often do this by strengthening the the USD. Sell to the USA, accept USD from foreign trade partners, buy T-Bonds with excess currency. The market for USD is so damn big that this is often trivial to do unnoticed, like using ocean to fill a swimming pool. But economies like Japan and China eventually grew to the point where their currency manipulation had a meaningful impact on the USD and American economy, rising the ire of American politicians. You can read about the Japanese \"lost decade\" which was suspected to be the result of American politicians intentionally targeting the Japanese economy due to currency manipulation and a general fear that the Japanese would \"take over the world.\" (you can see these fears highlighted in 80s movies) > How does a noob like me learn about these systems. Take an economics class. Eco 101 is kind of trash for understanding anything truly useful. But at higher levels, you get into mathematical models for the underlying systems that govern trade. Granted, it's a little more hand-wavy, since economists can't conduct experiments at the scale that physicists can. But there is generally some experimental data supporting the models (it just might be data collected on college students trading candy bars). You can read about what happened to the Swiss economy during the pandemic. They are a smaller economy that's been plagued by an absurdly strong currency. There's been a lot of reporting and research into the many factors contributing to the currency's strength as well as the impacts it has had on such a small country. reply fuzztester 13 hours agorootparentprev\"Aiugh. My brain just broke. How does a noob like me learn about these systems. I know it all probably makes sense to the learned. But with my folk (mis)understanding, these claims sound counterintuitive. Thanks. \" don't worry, your intuition is right. you are on the right track when you say that your brain broke. you are more learned, or rather, more wise than those guys. because a lot of economics is BS, a hotchpotch of some art, craft, heuristics, observations and formulae, pretending to be a science. this is exactly why economics is known as \"the dismal science\", and why there is a saying that if you get 20 economists in a room and ask them the same question, you will get 20 different answers. (italics mine) I studied economics in high school for a whole year (11th grade). the course covered both microeconomics and macroeconomics. the Samuelson (MIT prof., IIRC) book was one of our text books. I did well in class, was among the top few students. I made some penetrating comments to which my teacher had no satisfactory answer. it was on a situation / question regarding OPEC (the oil cartel). from that time on, and also from subsequently reading economics articles and news now and then, I could intuit and piece together the opinions that I stated above. :) so, not to worry :) reply edgyquant 11 hours agorootparentNot sure how you can pretend Iâ€™m wrong when what I stated is an observation of the world and not an opinion. The US moved its industry overseas and switched to exporting dollars in an effort to buy sway inside of other countries. It did this to isolate Russia and win the Cold War. reply cycrutchfield 10 hours agorootparentprevSo you declare an entire field as BS and your basis of expertise is a high school class you took and a (probably underpaid and overworked) teacher who couldnâ€™t satisfactorily answer your questions? Dunning-Kruger effect in action. reply ducttapecrown 9 hours agorootparentFurther economics classes only pull the curtain farther back on what economics is: applied mathematics and applied sociology combined! I'm personally undecided on dismissing economics and trying to learn more of it! reply fuzztester 8 hours agorootparentdiss it, you won't miss it! ;) reply fuzztester 8 hours agorootparentprevnext [2 more] [flagged] nick222226 8 hours agorootparentYou should probably seek out a therapist or psychiatrist, you seem to be having a crisis of some sort. reply matthewdgreen 10 hours agoparentprevTo quote economist Brad Delong: \"... tax cuts created a half decade of deficit, boosting need for government debt which attracted foreign capital and helping to send a false signal to Midwest manufacturers to shrink starting the hollowing out of what became Rust Belt.\" I think in the long term (and maybe short term) we will live to regret this error. reply psychlops 7 hours agorootparentI don't understand this quote without more context. Five years of tax cut cycles does not seem abnormal, nor does it explain why only Midwest manufacturers received a (false) signal. reply ren_engineer 15 hours agoparentprevcheaper when not including externalities(losing critical manufacturing capabilities), which is why a proper government would take action. But the problem is our government is heavily lobbied to not protect critical industries in the name of short term corporate profits. And in many cases our government is outright hostile to manufacturing by holding domestic producers to pollution/labor regulations but allowing imports from countries with no regulations reply advisedwang 14 hours agoparentprevAlso that right after a drop in domestic machine tools demand due to recession American industry collapsed overall. It should be no surprise few machine tools are made when there's less domestic industry overall. reply bluGill 15 hours agoparentprevI'd say MBAs driving for quarterly numbers were unable to manage the business cycle is a better summary. reply edgyquant 15 hours agorootparentThatâ€™s just corporate political shade throwing. Fiscal policy has, for a few generations now, incentivized trade deficits for foreign policy reasons. Overtime this results in offshoring of all industry. reply maxglute 12 hours agorootparentprevArticle says machinist industry failed to lobby the same way as US steel. Not that US steel is doing healthy. But at some point it's the govs foresight / job to reign in MBAs via protectionism and industrial policy for strategic sectors. As other's have mentioned, JP has MBAs too. Maybe lesson is JP Gov listened to Zaibatsu/conglomerate lobbying power. reply missedthecue 13 hours agorootparentprevThis is as empty as saying trade unions caused it. Does Japan not have MBAs? It's all about comparative advantage. reply bluGill 13 hours agorootparentApparently Japan's MBAs can manage for longer term. At least in this one industry. reply badpun 13 hours agorootparentprevFrom what I've heard, Japan has very different corporate culture, more focused on loyalty and social stability, than on maximizing profit. They can even keep unprofitable divisions of the company, because they don't want to fire people who work in them. Would be nice if someone with first-hand knowledge of Japanese corporate world could confirm/deny it. reply plagiarist 15 hours agoparentprevTrade agreements have allowed importing from countries where human rights are (more of) an economic externality. Domestic manufacturers can really only compete on the ability to do small batches, higher tolerances, and quick turnaround; like for R&D projects or medical devices. reply loglog 14 hours agorootparentThe article specifically mentions that Japanese manufacturers could deliver tools much faster than US ones. reply aj7 15 hours agoprevPeople who understand this industry can answer in a single word. Fanuc. And when Fanuc realized that only GE was capable of competing with it in the computer controls needed to run machine tools (and wasnâ€™t doing shit, another Welchism), it cleverly bought off GE by giving it the U.S. franchise for Fanuc, at least until the GE stink began to be undesirable. reply grow2grow 15 hours agoparentYes, no surprise that a standard won the battle, over several competing choices. That seems to happen a lot. reply droopyEyelids 15 hours agorootparentSort of a tautology, right? The winner of the competition becomes the standard. reply grow2grow 15 hours agoprevRight, it seems the U.S. economy is trying to say, \"making elementary machine tools is beneath us.\" The important bit is at the end: the U.S. is still a top buyer of machine tools (made elsewhere). Is the same thing to happen with software? When it becomes worth the time of the U.S. economy to produce basic machine tools again, they'll get to create new machine tools factories using all the latest technology: so it is probably good thing the \"old way\" is not still around hanging on by a thread. The market naturally is culling technical debt. reply MajimasEyepatch 15 hours agoparent> Is the same thing to happen with software? Offshoring in software development has been around for a very long time. Most large US companies have a mix of onshore and offshore devs. The more mundane the software, and the tighter the financial macro-environment, the more the ratio shifts toward offshoring. This is the way the offshoring cycle has worked for a long time. However, unlike hardware, software is about information and communication, and cultural context is very important. I have seen firsthand that non-US teams building software for US consumers often don't quite understand the reasoning behind the requirements and may lack polish around basic things like English. (The same is true, of course, in reverse, if US teams build for non-US audiences.) So I think it should be a little bit stickier. You also cannot copy software design in the same way that you can copy, say, the design of a lathe. A lathe is a lathe, and as long as you've got the tools and materials, a lathe made in the US should not in theory be any different than one built in China. The same is not true of software. reply dukeyukey 14 hours agorootparent> I have seen firsthand that non-US teams building software for US consumers often don't quite understand the reasoning behind the requirements and may lack polish around basic things like English Something I'm curious about, have you seen this happen with countries culturally close to the US? Like teams based in Canada, Ireland, or the UK? reply WJW 10 hours agorootparentOne of the biggest lies in cultural thinking is that countries like Ireland and the UK are \"culturally close\" to the USA. Sure they are close-er than say Italy or Japan, but anyone who thinks \"close\" means \"similar enough that it doesn't matter\" is in for a rude awakening. In reality there are incredibly large gaps around even the most basic things like the meaning of words. As a very basic example: the meaning of the word \"interesting\" differs radically between cultures. Most US employees would think the boss is indeed interested when they describe an idea as \"interesting\" and may even bring it up again at some later date after more research. Meanwhile, someone from the UK means that it's the dumbest thing they've ever heard and they will be incredibly miffed if it is ever brought up again. reply lmm 3 hours agorootparentprevI've certainly experienced US-made software that was close to useless in the UK, demanding dates in some absurd middle-out format and expecting everyone to know what a \"401k\" was with no explanation, along with more minor bits of polish like saying \"pound\" but meaning a completely different symbol. reply dukeyukey 19 minutes agorootparentHah, good point. If anything, software handling that kind of data might be better is smaller countries that need at international audience from the get-go! reply toasterlovin 15 hours agoparentprevRight. The US economy was well poised to tackle the massive task of computerizing humanity and, being a nascent technology stack with green field opportunities abounding, it was more profitable than continuing to produce machine tools. Meanwhile the Pax Americana has eliminated the risk premium to manufacturing overseas, so our entire economy has reconfigured itself around this task and opportunity of computerizing humanity. To our massive benefit, I think. IMO this is the main driver between diverging American incomes compared to the rest of the developed world. reply dragontamer 14 hours agorootparentAs long as those manufacturing centers are part of US allies (Japan, Korea, Europe, Australia, Taiwan), or at least trustworthy neutrals (Vietnam, India), I'm happy. But some manufacturing, in fact a large amount, is Chinese. And I'm not convinced they've got our best interests at heart. Either China needs to calm down over their \"Wolf Warrior\" style, or we need to cut back on providing benefits to an obviously and increasingly antagonistic power. --------- The other part, with respect to Taiwan + China, is that we must defend Taiwan as they are a critical source of advanced-materials (ie: computer chips) to us. Yes, its more efficient to have Taiwan centralize production, but it does come at a cost. We need to be ready to defend Taiwan and keep it safe if we are to continue to build computers and phones out of Taiwan-only parts. reply poncho_romero 11 hours agorootparentprevThe entire economy is configured around making quarterly profits for shareholders. Any good that happens to come out for humanity is purely incidental. The US economy is not some fairytale hero. reply michaelt 14 hours agoparentprev> Is the same thing to happen with software? I have a theory that one of the major challenges facing manufacturing in the US is actually the opposite. A manufacturing company in the US is competing for smart, numerate STEM graduates with the likes of Google who offer graduates $180,000 with zero experience (or so I'm told) But they're also competing with manufacturers in the far east, where $40,000 is a great salary, for someone with several years of experience. Difficult to win both competitions. reply poncho_romero 11 hours agorootparentI think thatâ€™s right, and I think thereâ€™s a third aspect at play, which is that culturally the US doesnâ€™t value jobs in manufacturing, machining, engineering, etc. as highly as it once did (after WW2, say) or as highly as it values finance and tech jobs today. Iâ€™m not sure how easily that could change. reply poncho_romero 11 hours agoparentprevWill â€œall the latest technologyâ€ be available? The expertise the US once had in this area is largely gone, and wonâ€™t come back immediately. I think thereâ€™s real reasons to be concerned that the US will fall behind countries like China in areas like innovation because of this self-inflicted brain drain. reply ddingus 8 hours agorootparentRight now there are mandates to build out the manufacturing base needed for military efforts. They know the tech sent off shore will, for the most part, remain off shore. Additive manufacturing, an example of \"latest tech\", is a primary build up target here. It is new and expertise is being created as the tech itself is. reply mitthrowaway2 5 hours agorootparentAdditive manufacturing doesn't help much if you want to build Liberty ship volumes, or roller-bearing tolerances, unfortunately. reply rsync 14 hours agoparentprev\"Right, it seems the U.S. economy is trying to say, \"making elementary machine tools is beneath us.\"\" Hopefully policy makers and the citizenry will resist following what, as you say, the US economy is trying to say. You see ... You can stop making elementary machine tools. You will never stop making (people who can only make elementary machine tools). reply ThaDood 14 hours agoprevSo from what I can tell, a lot of boils down to the same reasons most of America/US manufacturing declined. Globilzation, greed and other factors. This article really hits home for me. I grew up in Cincinnati and it was a tool making powerhouse back in the day. Cincinnati Tool, now Milacron and many others were made here in town. We still have a few nice tool makers in Ohio - Kett and Wright but its sad to read about how much this industry powered the nation and a lot of its innovation. Going to our museum center, hell even our Airport has a bunch of exhibits that take about all of the tool making and industry we used to have. Makes me sad really. reply 1nd1ansumm3r 15 hours agoprevWhat was considered high-end precision machining a few decades ago is now standard and easily reproducible in cheap labor markets. For example, guitars made in SKorea used to be a bad joke. Their machining tolerances were too big and too inconsistent. Much like storage and bandwidth what used to be exotic cost-prohibitive is now cheap. reply hasty_pudding 9 hours agoparent> guitars made in SKorea used to be a bad joke Are they now considered good guitars?? reply nsguy 9 hours agorootparentYes. But really Indonesia has taken over from South Korea (and China and Mexico for some parts of the market). E.g. PRS used to make their SE line in South Korea and the quality was excellent. \"Good guitar\" is somewhat subjective. US brands like PRS, Gibson and Fender are still able to charge a premium for a US made instrument. This isn't necessarily because the US has some abilities that the foreign makers don't, it's more of a marketing strategy. reply WillAdams 9 hours agoprevFor folks who are curious about Haas, this blog-post on buying one may be of interest: https://carbide3d.com/blog/how-to-buy-a-haas/ reply 11thEarlOfMar 14 hours agoprevAt some point, the technical advancement rate of markets tops out and other nations then can catch up. Ford ultimately gave way to Toyota. Westinghouse to Panasonic. The counter example is the semiconductor tool industry where the advancement of technical capability remains ahead of the rate other countries can catch up with them. Internal to the industry, the 'low-tech' machines are made by Japanese manufacturers: Track (TEL), Wet (Screen). US/Europe (AMAT, LRCX, KLAC, ASML, ASMI) remain dominant in that capital equipment market. reply jd3 15 hours agoprevhttps://www.youtube.com/watch?v=QU6nsfoNWDI for a trip down memory lane (and coincidentally, an apt example of how far we've fallen). Can you think of a single modern US-based industry/association which produces educational, instructional, and/or historical videos like this one anymore? reply Animats 10 hours agoparentYes.[1] And, after 10,000 hours of apprenticeship, you can make as much as $50,000 to $100,000 a year as a tool and die maker! I have some entry-level skills at that sort of thing, from my TechShop days. There's a lot of stuff to learn and you have to do a lot of it to get good. [1] https://www.youtube.com/watch?v=l-7ivFEAzw8 reply jschveibinz 10 hours agoprevThe world is flat. India has ~1.5 billion people and is growing. We need enough precision machine tooling and production capacity for self defense. But world competition is inevitable, and arguably better for the US economy. Our value proposition needs to be something greater than that of other countries. And that's where the economy and employment will thrive and thus support other service sectors. reply hasty_pudding 9 hours agoparentHow will the US economy thrive by outsourcing all the jobs to the billions of people in India? Sounds like the rich are the only ones who will thrive in this scenario. It will absolutely devastate American workers. reply cantrevealname 15 hours agoprev> Consider a company that manufactures its product on lathes. Assume that it has ten lathes that can just meet production requirements. Assume also that each lathe wears out in ten years and that the company has its investment plans so well organized that one lathe is replaced every year. Now consider what will happen if there is a 10 percent increase in demand for the product. The plant will need eleven lathes to meet production requirements. It will have to buy two lathes: one as a replacement for the worn-out lathe and a second to increase capacity. Thus a 10 percent increase in the demand for the product has produced a 100 percent increase in the demand for lathes. The 100% increase doesn't seem to make sense in this example. reply MajimasEyepatch 15 hours agoparentIt's a 100% increase (i.e. double) relative to what the ordinary demand for lathes would have been. reply Retric 15 hours agorootparentThe universe isnâ€™t quite that binary. Suppose those lathes ware out 0.1% faster than expected lasting ~3 days less than 10 years, now eventually you replace 2 of them in the same year thus doubling demand in that yearâ€¦ Except the manufacture wouldnâ€™t notice a spike from occasionally sending out a few days earlier even if itâ€™s crossing a calendar year. reply bluGill 15 hours agorootparenta lathe doesn't wear out that way. It just slowly gets harder and harder to maintain tolerance. Eventually a new machine will be enough better as to make an experienced machinist take less time - they always have to stop and measure as no lathe can give you absolute accuracy, but when the lathe is new it is more predictable how much turning a handle will change things and so you measure before the last operation and adjust it to the right setting vs you measure get closer and measure again. reply serf 15 hours agorootparentI run a small machine shop, and while I agree that you're opinion is closer to reality it's absolutely not out of the ordinary for a precision metalworking lathe to fail entirely and be dead weight until repair; it's not all gracefully easing into imprecision. Older lathes, for example, love to put the AC motor under something that either accumulates or produces chips; you can see why this might be a problem over time. It's not out of the ordinary to require motor re-winds. reply KevinMS 14 hours agoparentprevDo lathes actually wear out? Machine tools are built like tanks and could probably last until the end of time, you just need to replace the bearings and motors occasionally. reply Kon-Peki 14 hours agorootparentThere's an entire refurbishment industry keeping them going. I know that this article said that you could order machine tools from Japan in the 1980s and get them in a few weeks. But that's not the case anymore. People buy some press or lathe or whatever out of a liquidation warehouse in Michigan for ~$50k and then pay a refurbisher $1,000,000 to get it to whatever specs they need. That's more expensive than buying a brand-new machine from Germany/Italy/Japan, but you get it installed in your facility so much faster that the extra cash is worth it. And because they last forever with proper care and maintenance, nobody cares if the \"new\" tool is 70 years old. Note that this behavior can easily distort the stats on demand for new machine tools ;) reply p_l 9 hours agorootparentMy understanding is that a lot of lower end in manufacturing might at time seriously consider turning old manual equipment into CNCs, not just hackers. And dunno about USA, but there's a cottage industry of people running hacked up ex-volkswagen robots despite them requiring a human holding dead man switches. They are not going to buy a new industrial robot, but they can afford to turn bunch of ex-volkswagen gear into semi-automatic machines. reply tejtm 13 hours agorootparentprevIf they did not; we would not have the entire art of scraping [0] Yes, if meticulously maintained and lightly used some can last a good while. In a less pristine environment, say where deadlines need to get met, they wear out unevenly, for lathes, the ways near the headstock usually see more work than the tailstock end. So, the machine now cuts a taper when it is suppose to cut parallel. [0] https://duckduckgo.com/?t=lm&q=scraping+machine+tools&ia=web reply dale_glass 14 hours agorootparentprevYes, it's a machine with many moving parts. There's bearings, gears, ball screws, lead screw, belts, etc. There's also multiple precision ground surfaces that wear unevenly because some parts of the surface get far more use than others. The bed tends to accumulate damage over time, as try as you might, you'll eventually drop something heavy on it. A lot of it is very much fixable, but I suppose that eventually one decides it's too much to bother, especially if something is damaged is badly enough, or the lathe is old enough and it doesn't make much business sense to fix it. If you abuse a machine badly enough you can get something bent to the point it's not really worth fixing. reply extrapickles 14 hours agorootparentprevThe lathe ways (the guides/support for each axis) do wear out, but you can re-grind them to be flat again. Usually you sell the machine at this point to someone who doesnâ€™t need the precision and get a new machine. reply AnimalMuppet 15 hours agoparentprevWell, it's a 100% increase from that company, for one year. The next year, though, they only need to buy one lathe again. And the next year, and the year after that. Every tenth year, they'll buy two lathes. Calling that a 100% increase doesn't seem to make sense because it actually doesn't make sense. reply lmm 3 hours agorootparentThe point is that it's an extreme bullwhip effect. Yes, it's not a sustained 100% increase, but it's a 100% increase that year. reply jacquesm 14 hours agorootparentprevYes, and there even is such a thing as equipment lease for companies that are liquidity constrained to be able to move to match the market even if their short term reserves would stop them from doing so otherwise. At a price, of course. The most asked question about the CNC gear we sold was whether or not it could be leased and whether we could offer financing. Almost none of it was bought outright. reply toss1 13 hours agoprevFirst thought, being in the aerospace advanced composites field and using machine tools: \"MBAs\" Aaaand, the money quote: \" In his history of the American machine tool industry, Albert Albrecht states that â€œthe actions of these larger corporations and conglomerates, under the leadership of financial MBAâ€™s, perhaps more than any other factor, contributed to the restructuring and decline of the US machine tool industry at the end of the 20th century.â€ \" MBAs & financial \"leadership\" have basically optimized American excellence, leadership, and its middle class out of existence, and putting the world's democracies in jeopardy. They benefitted greatly by privatizing and optimizing profits into their pockets, but at the cost of nearly breaking the society onto whom they externalized the costs. reply machomaster 6 hours agoprevI wonder how much of the loss of the American competiveness was caused by the SI-incompatible Imperial system (buying, selling, using)? reply eunos 14 hours agoprevAlso US more or less export controlled CNC to China, boosting German, Japanese and even Taiwanese machine tool industry massively since China bought many from them. reply supernova87a 9 hours agoprevMaybe I missed a point in the article, but I feel a broader shift that produced this situation is simply that the US is no longer building huge numbers of new factories and industrial processes that need lots of new machine tools. We have left that phase of our country's development behind. We have relatively piecemeal demand for such tools, aside from the random new Tesla factory. And that kind of growth is what spurs development and maintenance of these kinds of supporting industries. As a country, you fall out of the practice of building stuff, and the talent or ecosystem of it migrates away. Look at railroad building. In China, they have entire industries of people building the tools for building railroads. They can call up 100 experts on design just for EV battery building machine tools and factory processes. Here you're lucky if you can find that many experts on any machine tool topic across all the contractor companies that have had to consolidate to make keeping this kind of talent sustainable. We just don't have this deep practiced industry knowledge in general across many businesses any more. And aside from some specialized centers (NASA, NIST, national labs) that doesn't exist much in the government either. We've outsourced it. Maybe it's a natural evolution of a country. Maybe the tide can be turned with strategic investment, I don't know. reply mastax 7 hours agoparentThe last line in the article argues against this: > The US is still a major purchaser of machine tools (2nd in the world behind China), but unlike for most of the 20th century, today its factories are full of machines made elsewhere. reply lkramer 14 hours agoprevWhy do I feel there is a parallel here to Boeing? (Maybe that was the motivation for the submission) reply happyjack 4 hours agoparentWhen the Clinton administration forced the downsizing of the military industrial complex (https://www.nationaldefensemagazine.org/articles/2015/12/2/f...), the USA lost all competition in the larger than regional aircraft. To compete with Airbus (subsidized by the EU), Boeing turned from manufacturing their own airplanes (and using suppliers in America) to assembling planes in Washington and forcing procurement of their products internationally through contracted parts. (https://d3.harvard.edu/platform-rctom/submission/its-complic...). Nippon airways would buy x number of 737s, etc. as long as they were making the brakes. Hell, even Airbus assembles in the USA now to force procurement in America. reply jwagenet 8 hours agoparentprev> Constant pressure to hit quarterly performance targets meant that machine quality often suffered. [â€¦] â€œthe actions of these larger corporations and conglomerates, under the leadership of financial MBAâ€™s, perhaps more than any other factor, contributed to the restructuring and decline of the US machine tool industry at the end of the 20th century.â€ Probably the sentiment expressed by this excerpt. You can probably point to any example of former US expertise and make a similar statement. reply nofunsir 15 hours agoprevI was binge watching TechFreeze[1] on youtube just yesterday! [1] https://www.youtube.com/watch?v=jOnxOTdx_ps reply lstodd 6 hours agoparentIndustrial JP is very good also https://www.youtube.com/watch?v=5QjVeH2Z57E reply Joel_Mckay 15 hours agoprev1. lack of stable production lines due to real-estate securitization and zoning. i.e. it is a huge liability to install something expensive likely to break if moved, and burning capital in a sucker lease. 2. lack of cheap 3-phase power in said zoning, and aging power infrastructure. EVs will likely make the problem worse. 3. lack of skilled labor due to career churn from outsourcing. i.e. it became a demand-deficient labor-force now reassigned to other careers. 4. Manufacturing domestically is strictly a niche industry, as consumers are cost sensitive, and value blind If you go to foundry districts in India, one will see many US machines that were sold for scrap still powering emerging economies. The mechanical equity of 60 year old machines are still supporting entire communities. reply barelyauser 14 hours agoparentValue blindness is the bane of my existence. Thin walled plastic everywhere. Things are difficult to clean because they are filled with grooves, because you need grooves and bends to make thin walled plastic stiffer. A very good criteria for quality and value is: how easy is it to clean? If it is hard then you probably are dealing with a low value disposable product. Consider porcelain, lasts forever, cleans beautifully and does not stain. Or spoons made with solid stainless steel. Spoons made with thin sheet steel often have bends and corners as to make the thin sheet stiffer. But then dirt accumulates on these corners. reply Joel_Mckay 14 hours agorootparentThe cost of porcelain is similarly constrained by labor, energy cost, and space. I learned a lot from a domestic slip-casting company as a kid. It taught me big heavy things are not economical to ship, and thus remain locally competitive in a global market even when competitors are 100% subsidized. Amazon shifted this calculus a bit, but is still constrained by energy/fuel costs. The power of plastic is automated cycle times under 45 seconds, minimum infrastructure needs, and shipping weight. In a way, Tesla Giga Press technology leverages similar strategies for Aluminum parts. reply sct202 11 hours agorootparentThat press you mentioned in an interesting example of the globalization of machine tools. Commissioned by an American company and made in Italy by a Hong Kong Chinese owned company, which now makes them in China. reply Joel_Mckay 10 hours agorootparentThere is no longer enough domestic infrastructure to fabricate complex equipment within a competitive budget. reply jwagenet 8 hours agorootparentIt seems like domestic manufacturers werenâ€™t able to compete on price or quality in the decades preceding the collapse of the industry either. reply Joel_Mckay 8 hours agorootparentHard to say really... if foreign labor is subsidized under communist strategic policy, than it is more of a loss-leader rather than rational competition. Value blindness is often accepted in consumer markets, but can prove fatal in industrial or aerospace products. Hence the rules silly people try to work around to make more money. =) reply shiroiuma 5 hours agorootparentprev>Consider porcelain, lasts forever, This isn't true. Porcelain is brittle and delicate, and usually shatters when dropped. It's easily broken through normal handling. Just guessing, I imagine most new inexpensive porcelain dishware is purchased to replace broken stuff. Sure, if you put it in a cabinet and never use it except for once-a-year special occasions, it might last a lifetime, but the stuff you use every day won't. reply kalleboo 5 hours agorootparentWhen my parents moved abroad, I inherited the bone porcelain set they got as a wedding gift (a Swedish RÃ¶rstrand set). It was used every day when I was a kid and it's used everyday now 40 years later by my kids. It's been dropped hundreds of times and there are maybe only one or two chips among all the plates and bowls. Meanwhile all the cheap IKEA dishes I bought as a student always broke within a year of purchase. reply karmasimida 15 hours agoprevSo it is the story of losing because of market competition? Doesnâ€™t feel that surprising of an outcome reply bluGill 15 hours agoparentNot really. The story is management wasn't able to handle a downturn and so failed to come out of a recession. reply 29athrowaway 3 hours agoprevhttps://wtfhappenedin1971.com/ reply FrustratedMonky 14 hours agoprevRead a great book on this in college in formative years. Made me pretty depressed about how management/markets can target false equilibrium points. Markets do not drive efficiency. At least not if chasing quarterly profits drives bad decisions. \"When the machine stopped: A cautionary tale from industrial America\" https://www.amazon.com/When-machine-stopped-cautionary-indus... Note: referenced in the OPs original article reply pinewurst 14 hours agoparentThis is a great book - I still own my copy and occasionally reread it. reply shove 9 hours agoprevThis Old Tony is out there doing the very best he can reply jillesvangurp 15 hours agoprev> Constant pressure to hit quarterly performance targets meant that machine quality often suffered. In some cases, machines would be shipped out the door unfinished so the delivery could be booked, and assembly would be completed by service technicians at the customerâ€™s location. In his history of the American machine tool industry, Albert Albrecht states that â€œthe actions of these larger corporations and conglomerates, under the leadership of financial MBAâ€™s, perhaps more than any other factor, contributed to the restructuring and decline of the US machine tool industry at the end of the 20th century.â€ In short, the MBAs happened. Clueless management was brought in who then decimated anything they did not understand. I.e. everything. Aided by Reagan policy to aggressively outsource manufacturing from the nineteen eighties US manufacturing just imploded. Just speculating here, but by the time the Japanese and the Germans caught up and got really good at machine tools, the metric system would have become an obstacle as well. Because the US insisting to do everything in inches, foot pounds, and what not doesn't translate very well internationally when you start outsourcing all your manufacturing. Outsourcing meant manufacturing standardized on the metric system using equipment and parts not made in the US. Just speculating here, but I imagine that all that combined lead to a natural preference for non US based manufacturing companies that took over from US companies to not use any US made equipment or parts. So, manufacturing became predominantly metric based and that would have affected standard components, screws, bolts, parts, etc. All made by non US companies standardizing on all of that. reply cpursley 14 hours agoparentMBA thinking ruins everything it touches. Boeing is another example. It's all about short-term profits over long term sustainability. reply lasermike026 14 hours agorootparentFire all the MBAs. reply mobilio 13 hours agorootparentprevalso HP... reply baron816 14 hours agoparentprev> Constant pressure to hit quarterly performance targets meant that machine quality often suffered. Itâ€™s not necessarily the case that greedy, ignorant MBAs came in and ruined everything. Like, if their practices were so inferior, then any domestic firm that didnâ€™t get taken over by them shouldâ€™ve had a leg up and couldâ€™ve dominated the domestic market. Donâ€™t you think the more likely source of â€œpressureâ€ was the international suppliers who had lower costs? > Aided by Reagan policy to aggressively outsource manufacturing from the nineteen eighties US manufacturing just imploded. Was the policy to outsource everything, or liberalize markets and let firms and consumers more freely choose where to buy things from? Globalization has done quite a lot to lift people out of poverty and keep prices low. reply michaelbrave 14 hours agorootparentBrand names carry weight for several years before the damage becomes apparent. Often their cost cutting measures seem positive at first as it creates a profit uptick, but it's usually at the cost of the brand, so 3-5 years later things take a turn (once the consumer has figured out the brand can't be trusted anymore). By that point it's hard to put the blame on the appropriate person or identify the appropriate reason for a less profitable year. reply neuralRiot 12 hours agorootparentI said it thousand times in different but related at root topics, quality and reliability are possible but why would somebody build something that would last forever? Itâ€™s more profitable to churn cheap garbage over and over specially when customers wouldnâ€™t pay for quality products or when a new, more flashy and feature-rich one is launched everyday. Itâ€™s the same for electronics, fashion, cars, machines and anything. Manufacturers just push consumers to â€œdesireâ€ the brand new product but the grinder is spinning faster and faster and the landfills getting higher and higher. reply dchftcs 2 hours agorootparentIn cases where it matters, it's still a competitive advantage. Consumers don't care, maybe, but companies absolutely do, for their business-critical tools. reply lesuorac 14 hours agorootparentprev> Like, if their practices were so inferior, then any domestic firm that didnâ€™t get taken over by them shouldâ€™ve had a leg up and couldâ€™ve dominated the domestic market. There aren't infinite firms. Plus in the article, the previous paragraph goes into how the tooling industry was being bought up by conglomerates so the finite firms became even easier to count. A company fitting your argument is Telsa. The existing firms weren't willing to canabalize their existing product lines so they didn't invest into EVs and now a domestic firm is eating at their market share. However, \"Who killed the electric car?\" is from 2006, there has been a lot of pent up demand for EVs that no domestic firm was selling to. However, something also fitting your argument is Moneyball [1][2]. It's not until the 2002 season that teams start to use statistics to determine who to staff their roasters? The League is from 1876; it took 126 years of baseball before a team figured out how to use math! > Donâ€™t you think the more likely source of â€œpressureâ€ was the international suppliers who had lower costs? Well, the article agrees in that it says \"By now, tools from Japan and other countries were as good as or better than US tools, not to mention cheaper and more reliable.\". However, R&D was also being cut prior to this so if you don't do any R&D and your products become uncompetitive it's probably because R&D was cut. > Was the policy to outsource everything, or liberalize markets and let firms and consumers more freely choose where to buy things from? Well, don't forget there are winners and losers when trading. In this case the losers are the American Tooling Industry; the winners were everybody that bought from them lol. -- I do think this growth every quarter is a big problem though. The early observers of business cycle all noticed that it has its ups and downs. Pretending that there won't be a down and fudging the numbers so that you don't have any downs is going to cause future problems. Delivering not-finished lathes counts to me as fudging the numbers. [1]: https://en.wikipedia.org/wiki/Moneyball_(film) [2]: https://en.wikipedia.org/wiki/Sabermetrics reply AnthonyMouse 13 hours agorootparentThe main way for countries with higher wages to compete is through automation. You can't supply 1000 laborers at $2/hour, but you can supply five skilled mechanics at $50/hour. The problem with this is that the 1000 people who had been doing the labor in the US for $25/hour don't want that to happen any more than they want it to move offshore, and they're the people with the skills to ensure the automation goes smoothly. So they resist and then lose to offshore manufacturing rather than domestic automation. Which in turn causes the US to lose even more manufacturing jobs, because now that factory is in Asia and it's more economical for its inputs and outputs to be other factories in Asia. The way out of this is to make sure domestic barriers to entry are low, so that you get more new domestic companies like Tesla that aren't stuck in this trap. Right now that isn't the case and Tesla is an exception that got there on hype and eccentric leadership, whereas what you really want is for domestic small businesses to be able to eat the lazy incumbent's lunch long before China does, and indeed to be able to eat the Chinese company's lunch by replacing a thousand low-wage workers with a handful of high-paid specialists. reply bsder 14 hours agorootparentprev> Itâ€™s not necessarily the case that greedy, ignorant MBAs came in and ruined everything. Like, if their practices were so inferior, then any domestic firm that didnâ€™t get taken over by them shouldâ€™ve had a leg up and couldâ€™ve dominated the domestic market. In this instance, it was people like Icahn. Machine tools were a very cyclical market. Consequently, they did well as part of a vertically integrated conglomerate where the profits could be booked over time and the R&D could be shared with the manufacturing parent. When forced to spin out and stand alone by corporate raiders, those companies were effectively doomed as you just ripped out their ability to do R&D. In addition, people forget that the Japanese companies were very much not playing fair. MITI (Ministry of International Trade and Industry) and the keiretsu/zaibatsu companies were actively attacking the US companies--this was effectively governmental and monopoly collusion. This attack was to the point that they almost wiped out the semiconductor industry (which prompted the DARPA VHSIC project and later Sematech in response) for example. They did similar actions in the manufacturing industries but the government never responded with the same vigor. > Was the policy to outsource everything, or liberalize markets and let firms and consumers more freely choose where to buy things from? The policy was to fund the hell out of West Coast (high tech and mostly no unions) and to leave the Rust Belt (manufacturing and lots of unions) to rot. I will be one of the first to line up to piss on Reagan's grave for the complete shit that he was. However, to be fair, NOBODY had any answer to the fact that manufacturing automated and could get by on two orders of magnitude fewer employees. Every country dependent upon manufacturing went through a horrible time (see: England and Thatcher for similar vitriol). In fact, nobody still has any answer 4 decades+ later. It's one of the reasons there are so many old, very angry MAGAs. > Globalization has done quite a lot to lift people out of poverty and keep prices low. At what local cost? Nobody in Cleveland gives a shit about whether someone in Africa is doing better when they can't make their house payment. reply AnthonyMouse 13 hours agorootparent> When forced to spin out and stand alone by corporate raiders, those companies were effectively doomed as you just ripped out their ability to do R&D. It would be just as fair to blame the original culture of having vertically integrated conglomerates to begin with. If there is anyone who should be able to figure out how to automate manufacturing with a small number of workers, it should be a bunch of machinists. But you put them in a lumbering conglomerate and teach them that automation is the enemy because it will take their jobs. Then they take that same attitude into a smaller company that has to be leaner in order to survive and you've set them up for failure. Whereas if you embrace it, instead of domestic buyers getting their goods from cheap labor in China, domestic and international buyers get their goods from automated domestic factories that employ fewer people per unit but make more units than ever before because they have globally competitive prices and the global demand when you can supply at a low price is enormous. > Nobody in Cleveland gives a shit about whether someone in Africa is doing better when they can't make their house payment. But the reason they can't make their house payment is the same kind of regulatory capture that they supported and caused them to lose their job, which in turn makes housing unaffordable because you can't outsource plumbers and electricians. reply sokoloff 12 hours agorootparent> you can't outsource plumbers and electricians You can outsource trades (that's literally what almost every general contractor builder does->outsource specialist trades to subcontractors). You can't off-shore them (or at least not nearly so easily and completely). reply pbhjpbhj 10 hours agorootparentAR enables offshoring the smarts at least, you treat the person at the location of the work as if they were a robot ... until the robots get good enough, I guess ... reply KRAKRISMOTT 11 hours agorootparentprevMexico is a large country with a very liquid labor supply reply maxglute 12 hours agorootparentprev> you can't outsource plumbers and electricians Not yet. Wonder where west would be if politics threw trades to the wolves and kept machinists. Maintain manufacturing prowess and build cheap factories. reply hasty_pudding 9 hours agorootparentwho needs to outsource when you can just open the borders. reply glompers 13 hours agorootparentprevGreat points. Riffing on your last remark, the federal labor statistics list of Ohio occupations with the highest location quotients (prevalence in that area divided by prevalence of the same occupation nationwide) still shows machine tools related professions near the top. Surely that cluster of expertise would be in even greater demand if the national economy were to grow in that direction. May 2022 Engine and Other Machine Assemblers 4.21 Multiple Machine Tool Setters, Operators, and Tenders, Metal and Plastic 3.79 Patternmakers, Metal and Plastic 3.23 Forging Machine Setters, Operators, and Tenders, Metal and Plastic 2.99 Heat Treating Equipment Setters, Operators, and Tenders, Metal and Plastic 2.91 Tool and Die Makers 2.81 Grinding, Lapping, Polishing, and Buffing Machine Tool Setters, Operators, and Tenders, Metal and Plastic 2.75 Sewers, Hand 2.71 Cutting, Punching, and Press Machine Setters, Operators, and Tenders, Metal and Plastic 2.70 Model Makers, Metal and Plastic 2.64 reply com2kid 10 hours agorootparentprev> However, to be fair, NOBODY had any answer to the fact that manufacturing automated and could get by on two orders of magnitude fewer employees. Hasn't the answer been tons more products being made? More product designers, more tool manufacturers, more people in charge of designing factories, more automation engineers, more robotics engineers? More people supporting those products, more people in sales, more people doing packaging design, logo design, and so on and so forth. (None of this is environmentally sustainable, separate discussion!) reply CPLX 13 hours agorootparentprevThere's no such thing as playing fair it's just national industrial policy. Every country has one. The change was that ours went from \"try to have industry in this country\" to \"my friends make money offshoring stuff\" instead. reply citizenpaul 12 hours agoparentprevI've long been sounding the alarm on MBA'ification destroying everything. To me its the most under discussed problem with society in better quality of life areas. In the beginning they cleaned up messy, inefficient, wasteful processes. However for the most part MBA's ran out of real stuff to do 10-20 years ago. Ever since then it has just been about how much more can they shave off of 0.1% of 0.1% of just one more thing that doesnt need it but hey they have a quartly bonus attached. Or like a comedian I recently saw said, every new business these days are basically something like: Hey you know how a taxi driver can afford to feed his family? What if he couldn't anymore? reply cityofdelusion 14 hours agoparentprevThe metric system wasnâ€™t a factor, it was all economics as laid out in the article. Tooling both foreign and domestic was/is a mixture of imperial and metric to meet certain markets. The major force behind machining, automotive, did their conversions to metric back in the 1970s. The U.S. was seriously lacking in computerized machining and had plenty of time to shift to metric based machines, but the MBAs had already determined long before that they preferred overseas manufacturing at a fraction of the cost. Machining today is heavy metric, even in the U.S. and there is still no economic way to make it all work, much like with steel production and other manufacturing concerns. reply mywittyname 14 hours agorootparent> Machining today is heavy metric, even in the U.S. Likely due to the dominance of metric tooling from abroad. Old ass machine equipment is imperial and is still in use. Imperial measuring devices are still widely available as well. I think the OP is probably onto something. reply rvba 13 hours agorootparentprevThe MBAs probably did not want to invest into anything. I see it all the time, it feels like they never thing more than one year ahead. reply adolph 14 hours agoparentprevAgreed and to clarify: > everything in inches, foot pounds, and what not doesn't translate very well internationally when you start outsourcing It translates pretty well for the last 90 years: In 1930, the British Standards Institution adopted an inch of exactly 25.4 mm. The American Standards Association followed suit in 1933. By 1935, industry in 16 countries had adopted the \"industrial inch\" as it came to be known, effectively endorsing Johansson's pragmatic choice of conversion ratio. https://en.wikipedia.org/wiki/Inch See also the paragraph above referencing the precision tools enabled by Swede Carl Johansson's \"Jo Blocks.\" For a nice video/contextual storytelling, see Machine Learning channel's Origins of Precision: https://www.youtube.com/watch?v=gNRnrn5DE58 reply bawana 14 hours agoparentprevWait till you see what the MBAs have cooked up for health care. You'll die in the Emergency Room waiting room. Even concierge medicine wont save you. reply hasty_pudding 14 hours agoparentprev> In short, the MBAs happened This describes many many things in the USA. reply depereo 14 hours agorootparentMBAs are fine, honestly. I have a manager who came up in the industry he works in. He worked at the 'coal-face', understands the issues and has real perspective. He got an MBA later in his career and uses what he learned from that to more effectively communicate up the chain and has some new ideas that he filters through his industry experience to make his team more effective. Children who get an MBA before getting a job and think they have some magic sauce that solves problems for an industry without respecting the work that's been done and knowing why those problems exist to begin with (maybe they're trade-offs? For a real reason?) are a problem, as are the clueless twats who listen to their breathless assertions as though they carry any weight. reply hasty_pudding 14 hours agorootparentThe MBA philosophy vs the craftsman philosophy differ vastly. reply mywittyname 13 hours agorootparentMBAs are taught techniques for optimizing for quality and cost. It's not always an either/or decision. Even when it is an either/or situation, sometimes it's better to build a product that is half the price for a quarter of the lifespan. A buyer who will use a tool for 30 hours doesn't really care if the service life of a tool has been reduced from 1000 hours to 250 if the price is halved. reply hasty_pudding 13 hours agorootparent> techniques for optimizing for quality and cost Some of those techniques: 1. hiring each other and bloating bureaucracy in healthcare and education and other industries jacking up prices that werent expensive before 2. come up with ideas like 'shrinkflation' and 'planned obsolescence 3. reducing quality and making products unrepairable so we have massive waste in landfills and things like a giant pacific garbage patch 4. purchasing quality brands , parasiting the brand name, and making the actual product shitty 5. hollowing out every industry in quality and jobs...making private equity monopolies so theres no competition and then hiring more MBAs. What you call 'optimizing quality and cost' I call 'trying the fuck the consumer to the maximum amount without them noticing'. But, to be fair, those are the same thing. Just my observations. Capitalism is becoming a zombie and MBAs are the cordyceps. reply lazide 12 hours agorootparentThe issue isnâ€™t MBAs. They are just a symptom. What the issue is, is that weâ€™re essentially in the third â€˜waveâ€™ of US economic change post WW2 manufacturing boom. Post WW2, the United States was the only manufacturing economy that hadnâ€™t been bombed to smithereens, has not only little to no real debt, but a lot of debtors that would repay them, and had massive amounts of undeveloped land ripe for development, and a major new manufacturing base looking for things to do. This allowed the US to become the worldâ€™s reserve currency (along with gold) in the Bretton Woods agreement in â€˜44. That lasted until â€˜71. [https://en.m.wikipedia.org/wiki/Bretton_Woods_system] when the dollar stopped being backed by gold, allowing periods of increased inflation. At around the same time, the economies of Western Europe and Asia had mostly recovered, and they were starting to catch up on manufacturing to compete with the US. This led to increasing competitive pressures with US manufacturing, and increasing incentives to go towards Globalization and outsourcing to chase the cheap labor and more willing to compete manufacturers in these locations. Switching the US to a â€˜knowledge economyâ€™ was the natural progression. That easy money is mostly gone now, and the US is also no longer far ahead in many areas on knowledge. China in particular is starting to come close on almost all metrics. If Europe has a recession, their primary disadvantage (cost) may turn into an advantage. So then the US is much more on par with everyone else - for the first time in several generations. And that causes quite a rude awakening economically, as now the US potentially has real and actual competitors it isnâ€™t 5 steps ahead of already. MBAâ€™ism is because long ago the economy switched from â€˜actually leaps and bounds ahead of competitorsâ€™ to optimization. As most of the actual structural differences have now equalized, and weâ€™re down to who can make it cheaper/simpler. No one wants a 5 lb drill that costs $100 if they can have a 2lb drill that costs $50 and does the jobs they want well. reply hasty_pudding 10 hours agorootparent> MBAâ€™ism is because long ago the economy switched from â€˜actually leaps and bounds ahead of competitorsâ€™ to optimization False. Many companies make more money now than ever. American GDP and technology is leaps and bounds ahead of other countries as well. MBA's exist to create shareholder value while fucking the consumer and the laborers as much as possible without getting into trouble. melanine in baby food, and suicide nets outside of factories, for example, are cost optimization strategies that didnt work out. I can just picture an MBA running the cost/benefit numbers in an excel spreadsheet comparing treating the workers better versus putting suicide nets outside the windows. reply lazide 10 hours agorootparentBwahah. How easy was it for a normal American to buy a house, get an education, and get health care (in hours of labor) in 1950 vs now? How about fixing a broken bone? Or getting a basic checkup? Taiwan makes all the fancy chips. Apple designs things, but China makes them. The best cars are generally made in Japan. The vast majority of daily household items come from China. Food comes from the US for the most part, and some random heavy manufacturing and other parts. The US may have the largest GDP, but that is a measure of turnover - and is supported by the Dollar being the reserve currency. Weâ€™ve been inflating it a lot. And weâ€™ll see what happens. reply shiroiuma 4 hours agorootparent>The best cars are generally made in Japan. And this isn't even a new thing: it was absolutely true (in fact, more true) way back in the 1980s and 90s, and really started in the mid-to-late 1970s. American cars were utter garbage: poorly engineered, poorly performing, and poorly manufactured, with terrible quality. So why do people seem to assume that other American-made stuff in that era was so well-made? Sure, there's a few shining examples such as HP test equipment and printers, but the American auto industry was churning out truly bad products, so why isn't it also assumed that other domestic industries were plagued by the same poor standards and management? reply hasty_pudding 9 hours agorootparentprevchips, household products....what you're saying is manufacturing has left the US. fungible shitty unnecessary goods have rock bottom prices. costs of things human beings need to live like education/training, health care, food housing have skyrocketed. I completely agree with you that getting off the gold standard and letting a leprechaun like Yellen skyrocket inflation to cover for bad political mistakes, is a terrible idea and 1971 is a huge inflection point in United States on numerous economic graphs and indicators, as we've both seen the website. Keep in mind the late 60s were also when immigration started it's upward trajectory as well with the 1965 immigration act, and now we're letting in the equivalent of an entire new U.S. state every year. reply lazide 9 hours agorootparentThe Bretton woods change was to allow stimulation of the economy - because things at home were losing momentum (relatively speaking) as other countries manufacturing bases and economies recovered from the damage from WW2. It was a way of keeping the US a few steps ahead. Printing gold backed dollars quickly doesnâ€™t work very well when you canâ€™t increase the rate of mining gold quickly. Non gold backed dollars are a lot easier. As long as goods and services can be made cheaper every year, it works well since inflation isnâ€™t felt badly - there arenâ€™t any supply restrictions where something is going to get noticeably too expensive. All the things I talked about though all have that issue - they canâ€™t be made cheaper somewhere else. someone can only build so many houses in LA before there is literally no more room, and someone building a house in Shanghai doesnâ€™t help anyone in SF live closer to work. Building a new college/university in Vietnam isnâ€™t going to help a kid in Oregon get their degree. Weâ€™ve been exporting inflation because itâ€™s worked. But when other countries stop being so much cheaper, or costs of critical things for the population finally exceed affordability, it doesnâ€™t. Yellen, Powell, and others are just following the rules and mandate they are given. reply boringuser2 15 hours agoprevnext [9 more] [flagged] jjoonathan 15 hours agoparentBook recommendation: \"Trade Wars are Class Wars\" by Michael Pettis. If you don't buy the apologetics that permeate the popular economics sphere but still want an expert to walk you through the details, this is your book. reply ryandamm 15 hours agorootparent+1 for anything written by Pettis. Very clear communicator, and his Chinese Financial Markets blog[1] (now hosted at the Carnegie Endowment for Peace) is required reading on the Chinese economy. [1] https://carnegieendowment.org/chinafinancialmarkets/ reply boringuser2 15 hours agorootparentprevSounds like commie gobbledygook. (RIP Norm MacDonald, the thinking mans comedian!) reply jjoonathan 15 hours agorootparentIt's basic macro. Assets, exports, capital accounts, current accounts, savings, investment. Essentially, windfall surplus in one area causes savings bubbles causes investment bubbles causes asset pumps and export dumps, usually in a different area. He cites a bunch of historical examples and then goes step by step through techniques for identifying sources/sinks and directionality. Oh, and did you know that Ricardo based his analysis on the assumption of a closed capital account? It's interesting how the theory of comparative advantage usually gets invoked without mentioning that ;) If you dogmatically reject the idea that political economy could possibly involve the concept of class, I'd love to hear how your analysis clusters the interests involved. In any case, he's not a CCP shill. He throws some mean punches in that direction with facts and figures to back them up. Everyone hustles in the world economy. reply adolph 13 hours agorootparent> If you dogmatically reject the idea that political economy could possibly involve the concept of class, Class is a suitcase word that may refer to different ways of classifying people but often does not clarify which dimensions and clusters are being used in a particular context. Maybe Pettis does a better job than other authors. Perhaps you or the sibling comment author can provide an example? reply Analemma_ 14 hours agorootparentprevYou do yourself a tremendous disservice by blowing off good scholarship with uninformed jokes, especially in the case of book publishing, where titles are often set by the publisher and not the author. This book gives detailed, and very accurate, descriptions of how trade wars which appear to be foreign conflicts-- i.e. one country united against another-- are almost always actually domestic conflicts between competing interest groups inside the same country; often during these conflicts, those interest groups can make alliances with equivalent groups in other countries. This is a commonly-observed phenomenon which, for brevity's sake, we reify as class, and does not require any Marxist axioms or analysis to understand. reply pixl97 15 hours agoparentprev> The new ownersâ€™ focus on profits meant... Pretty much the answer in one sentence. reply hnthrowaway0328 15 hours agorootparentshort/mid term profits reply ChumpGPT 15 hours agoprevnext [4 more] [flagged] serf 15 hours agoparent>The company is morally corrupt. haas has been morally corrupt for some time. they're essentially the 'john deere' of machining, they sell under-performing over-priced crap that only they can sell parts for or maintain, which is convenient for them because they produce machines that have some of the highest downtime in the entire industry due to lack of repair facilities/parts/availability as well as overwhelming small quality control problems. reply cpursley 15 hours agoparentprevnext [3 more] [flagged] PeterisP 14 hours agorootparentThe equivalency would be if there were weapons of e.g. some Iranian company sold to Israel and used against Gaza. As a US company, Haas has a duty to obey US-ordered sanctions and ensure that their products are not being used against the interests of USA, but it has no duty to ensure that their products are not used against interests of Gaza. reply cpursley 14 hours agorootparentThis I totally agree with (US companies should abide by US law). It's the moralizing that gets under my skin. reply georgeplusplus 15 hours agoprev [â€“] We gave up the low intelligence blue collar manufacturing jobs so city dwellers can obtain highly specialized and skilled expensive college degrees to do important work on global problems in matter like, making and editing excel spreadsheets, writing emails, and sitting in on web meetings. I am writing this while drinking an 8$ caramel latte from Starbucks with a slice of avocado toast for 17.99$. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The US machine tool industry, previously the world's largest, saw a steep decline in the 1980s.",
      "Factors contributing to the collapse include competition from Japan, lack of investment in R&D by conglomerates, and technological stagnation.",
      "As a result, there was a decrease in sales, closures of US machine tool firms, and a rise in imports.",
      "Presently, the US is behind Japan, Germany, and China in the machine tool market.",
      "Nevertheless, the US remains a significant buyer of machine tools."
    ],
    "commentSummary": [
      "The decline of the US machine tool industry is caused by factors such as conglomerates, globalization, and foreign domination.",
      "The influence of MBAs on manufacturing industries and the preference for overseas equipment is discussed.",
      "The impact of a strong dollar on imports and US manufacturing, as well as the importance of industrial capacity, naval power, and the US dollar as a reserve currency, are debated."
    ],
    "points": 209,
    "commentCount": 185,
    "retryCount": 0,
    "time": 1705598743
  },
  {
    "id": 39040023,
    "title": "404Service, Micro-Donation Platform, Shuts Down after 14 Years",
    "originLink": "https://flattr.com/",
    "originBody": "404Service No Long Exists Dear Cherished Community, After 14 years, it's time to say goodbye to our micro-donation platform, a platform that redefined support for creatives and also embodied the spirit of ingenuity and generosity. From our first day to this graceful finale, you've been the heart of our story. Your enthusiasm and belief in our mission transformed a simple idea into a thriving ecosystem for artists and innovators. This year, we briefly expanded our horizons with the Anti-adblock Pass service, aspiring to further empower your digital experience. Although this chapter was short, it was driven by our unwavering commitment to serve your needs and break new ground. As we draw the curtains on both ventures, we want to extend our deepest gratitude. Every donation you made was a testament to your faith in creativity. Thank you for walking this path with us, for sharing our vision, and for being the cornerstone of this remarkable journey. May the future bring you endless creativity, joy, and success. Until we meet again, The Flattr Team",
    "commentLink": "https://news.ycombinator.com/item?id=39040023",
    "commentBody": "Flattr is closing down (flattr.com)208 points by pabs3 23 hours agohidepastfavorite214 comments boplicity 14 hours agoI don't see creators clamoring for micropayments. The reason is simple: It's not a good way to actually earn an income. Creators need stable and predictable support. Subscriptions work much better for them. It's a tried-and-true business model. What advocates of microtransactions don't see: It turns something that absolutely should not be a commodity (creative work), into a commodity. That's the fundamental failure here, and it's a big one. reply notatoad 14 hours agoparent>What advocates of microtransactions don't see: It turns something that absolutely should not be a commodity (creative work), into a commodity. as an advocate for microtransactions: yes, i see this. but i think you've got it backwards. nobody is \"turning creative work into a commodity\". it already is, and creators and marketplaces are both happy to treat it like one when they're selling their work. Creatives don't like micropayments because they don't like to so explicitly acknowledge that their work output is a commodity. reply egypturnash 13 hours agorootparentPff, I love Patreon and I feel like that is basically \"micropayments that actually work\". If you look at Scott McCloud's original proposal for micropayments ([1], parts 5/6), the only thing that's really not viable is the idea that every reader paying 25Â¢/mo would work - in practice, transaction fees mean that about $2/mo is the minimum viable payment to actually mean something, especially when you factor in that you are not going to get every reader to pay. Luckily it turns out that you can also get some readers to pay $5/$10/$50/mo, or even more. (Factoring in inflation, that $2/mo now was about $1.12 back in 2000 when McCloud proposed the idea.) 1: http://scottmccloud.com/1-webcomics/icst/index.html reply PaulDavisThe1st 13 hours agorootparent> in practice, transaction fees mean that about $2/mo is the minimum viable payment to actually mean something another person who doesn't know about PayPal's micropayment account fees. They save us (ardour.org) about 23c per US$1 transaction, and we get the majority of our income from US$1 transactions. Instead of the usual 3.5% + 49c fixed fee on the order of 30c, PayPal' structure for this is more like 9c fixed + 4.99%. If I was a believer in some deity that paid attention to such things, I would pray daily that PayPal does not decide to end these at some point. Good news is that they now offer something called Dynamic Pricing, where instead of maintaining two accounts and choosing which one to use based on the transaction value, they will now do this automatically for you. Subject to approval, they say. reply kevingadd 12 hours agorootparent9c fixed + 4.99% is ~10.2 cents fee for the proposed 25 cents/mo micropayment in the post you're replying to. How is that good? It's better, sure, but that's still handing over 41% of your income to PayPal. reply PaulDavisThe1st 12 hours agorootparentThe number cited in the parent comment was US$2/month. We have roughly 3k subscriptions at US$1/month, and although we'd love to collect more of the revenue, I don't find myself thinking that PP's micropayment structure is untenable for this. Yes, for 25c payments, especially one-off's, the systems are not there at this time. reply ptman 1 hour agorootparentprevThe EU is working on \"digital euro\", which is meant to be free of transaction fees. I would rather see a 0.1% transaction fee to cover the costs, but at least it should make micropayments viable. reply JeffSnazz 11 hours agoparentprevAds (along with nazis and pedophiles) are the root of almost all issues on the internet and it looks like a very bleak future if we can't build an alternative form of compensation into our protocols. I don't understand why we can't at least outbid the advertisers for our own attention.... what a waste of time and money and attention and culture all around. reply WheatMillington 10 hours agoparentprev>What advocates of microtransactions don't see: It turns something that absolutely should not be a commodity (creative work), into a commodity. That's the fundamental failure here, and it's a big one. Does the subscription model not do exactly this? reply gameman144 9 hours agorootparentI think one distinction is that subscriptions often denote \"I like your work, keep doing that\", whereas one-off payments denote \"I liked this one thing, I'll pay you for it\" The former can be assumed to be a lot more sustainable than the second. reply JohnFen 13 hours agoparentprev> Subscriptions work much better for them. It's a tried-and-true business model. But it does exclude a portion of the potential customer base. Whether or not that matters to a business is a different issue, of course. reply ryanwhitney 13 hours agorootparentLooking at you, small town newspapers. reply seydor 13 hours agoparentprev> I don't see creators clamoring for micropayments. How do you know that? I 'd use micropayments any day, but they are practically a nightmare to implement so we have to use third parties or subscriptions in order to justify the transaction costs. It's not either-or, subscriptions have always existed, but the current (lack of) payment tech makes them more useful. reply amadeuspagel 21 hours agoprevFlattr is the kind of idea that sounds great, that people love talking about - if only they could make a small donation to every website they liked - but that doesn't work because people are fundamentally too selfish. This is why ads are the only viable business model for a kind of \"ephemeral website\" - something you visit only briefly, derive some short knowledge or pleasure from until you follow a link somewhere else, do not feel the kind of loyalty to that might make you subscribe to something. reply freediver 15 hours agoparentI'd like to push back on this. It is not that people are too selfish, but that there is not much content truly worth paying for. This is because ads proliferated not just creation of giant amounts of content but they also incentivize quantity over quality. Second thing that is holding this back is no seamless way to send a payment from your browser to the website (owner). This has to be native in the browser, user-centric and web-centric. reply strbean 14 hours agorootparent\"Is the content worth paying for?\" feels like the wrong metric wrt. tipping. I think a more accurate question is \"Does the content make me want to support the creator?\" This is why tipping thrives in settings like Twitch, which is heavily geared around engendering parasocial relationships. reply squidbeak 14 hours agorootparentI don't follow... If the content isn't good enough to pay for, why would you want to support its creator? reply wlesieutre 14 hours agorootparentItâ€™s not that Iâ€™m too selfish to give someone a dollar for content that I liked, itâ€™s that Iâ€™m too lazy reply jimmygrapes 14 hours agorootparentprevI don't like the music my friend makes, but I'll support him by buying his album and sharing it with others who might like it more. reply paulddraper 15 hours agorootparentprev> It is not that people are too selfish, but that there is not much content truly worth paying for. That's two ways of saying the same thing. But people are (at a much greater rate) willing to pay with ads. reply jlarocco 8 hours agorootparent> But people are (at a much greater rate) willing to pay with ads. Not really. Most people just don't know how to block them, and browsers won't block them by default because of they have a conflict of interest. reply skybrian 15 hours agorootparentprevPerhaps â€œtruly worth paying forâ€ is setting too high a bar for some kinds of content that people do find useful? reply sethhochberg 14 hours agorootparentI think its also just really hard for people to quantify on a small scale. Its much easier to reason about whether or not you get, on average, $25 a month worth of value from a subscription to the New York Times than it is to try and guess whether someone's review of a vacuum you're considering is worth $2 to you or $0.37 or anything in between. Or if the stakes are even lower and you're not avoiding a lemon of a vacuum, you're getting marginal improvement to an experience - what is it worth to read someone saying \"don't go to Jim's Ale House when on vacation there, its fine but Jacks' is nearby and better\"? Clearly that information has some value, but... how much? Whats the cost of a tip that helps turn a serviceable meal on a vacation into a better one? reply sbarre 15 hours agorootparentprevIt's also subjective down to the individual, so how would you even quantify it properly? reply amadeuspagel 13 hours agorootparentprevWhat does it mean for content to be truly worth paying for? That someone pays, voluntarily, after already having consumed the content? How could we distinguish selfishness from content not worth paying for? reply fidotron 11 hours agorootparentprevEven acknowledging the state of crypto today the dev and payment experience of Metamask as a browser extension beats any conventional payment system I've encountered. What's needed is Metamask but not necessarily crypto. reply redwall_hp 15 hours agorootparentprevA good with a massive supply and a relatively small demand is therefore worth little. It's a great thing that we've succeeded in producing an enormous amount of information, and art/entertainment...but it's all well past post-scarcity. reply WheatMillington 10 hours agorootparentprev>It is not that people are too selfish, but that there is not much content truly worth paying for. Go spend some time on /r/Youtube. If there is any content worth paying for on this internet, it's the virtually limitless reservoir of incredible content across youtube, and for a relatively low fee you can make ads disappear. But the anti-Google sentiment is so strong that the selfish freeloaders will do anything in their power to both not pay and not accept ads. reply spiderice 9 hours agorootparentYoutube Premium subscriber here. It's my favorite \"streaming\" service that I pay for. I'd cancel Netflix, Hulu, Peacock, Paramount+, etc.. long before I ever canceled YT Premium. With that being said, I don't think your comment is fair. The anti-Google sentiment is justified. They violate your privacy. Not wanting to support them by signing up for their paid service isn't being a \"selfish freeloader\". reply tourmalinetaco 4 hours agorootparentprevI use Invidious and take any money Iâ€™d have put into Google and put it into supporting my favorite creators, my preferred instance, and FreeTube. Iâ€™m more than happy to â€œfreeloadâ€ off of a multi-billion dollar ad company and support creators in a more meaningful way. And I fully support anyone who wishes to avoid the evil that is ads, even if they donâ€™t support their creators directly otherwise. There is nothing selfish about wanting to conserve time, itâ€™s the only currency that actually matters. reply shon 15 hours agorootparentprevThe second one is the larger issue. Patreon is working well for many things but still not easy or integrated enough. reply TheFragenTaken 21 hours agoparentprevTwitch subscriptions and Patreon has shown, that if you bind a website/project to a creator, and you get benefits for donating/subscribing, that you can have a very viable business model. Both as a creator, and as a platform to facilitate it. Most websites, and indeed open source projects are pretty faceless, and require limited interaction with it's creator. I believe, if you somehow \"solve\" that problem first, people will beg to donate/subscribe. reply bot347851834 20 hours agorootparentI agree with your general point: people generally donate/buy/subscribe much more if there's a benefit tied to it. On the other hand, I'd like to point out that Twitch is still losing money so I wouldn't really call their business model \"very viable\". I'd say it's viable for the content creators, because there's very little risk in trying out Twitch streaming, sure the chances of making it big are insanely small but the worst case scenario is losing time and a relatively small amount of money on a PC setup + microphone and camera. Patreon is a different beast but there's a caveat here as well. I don't have numbers so this is just my PoV but I'd guess that the vast majority of creators that use Patreon aren't hosting, sharing or creating mainly on Patreon. They're called YouTubers, streamers, bloggers for a reason. Sure they may share BtS or some other kind of additional content but it's not their main platform. So while the Patreon business model works it's not really comparable to Twitch or any other platform where you actually start and continue to create content and also get paid by. reply jerrre 17 hours agorootparentIt's important to make the distinction between: - Twitch is losing money because the costs of running the platform are higher then the revenue - Twitch is losing money because they're aggressively investing in growth if you want to know about the viability of the concept, I'm not sure which one it is, video streaming and small payment processing could both be quite costly reply Mc91 17 hours agorootparentprevI donate monthly to five Patreons. One of them is LineageOS ( https://www.patreon.com/LineageOS ). Two of them are community spaces. Two are podcasts, only one of which I listen to. I really only get Patreon benefits from one of the five (I get each podcast). Some tech-related, some not. I subscribe to one Twitch feed. Actually the main Twitch feed I watch is one I do not subscribe to. I also sometimes watch other Twitch feeds, like John Romero's, or notch, or another random programmer who livestream codes. Again, some tech-related, some not. Generally I subscribe on Patreon and Twitch more to be supportive than to get something, although I do appreciate I get podcasts from one of the podcasts I subscribe to. reply amadeuspagel 19 hours agorootparentprevBut I don't want to solve that problem. I don't want to have a parasocial relationship with the author of every blogpost that I read. reply k__ 18 hours agorootparentTo quote something I literally read 5 minutes ago in \"Perhaps the Stars\": \"everyone has relationships with people far away, who inspire, entertain, role models, and also the people we work so hard for: fans, viewers, the next generation, kids somewhere, posterity. I think those asymmetrical relationships are part of what it means to be human, part of the teamwork. Humanity is teamwork. And the asymmetry doesnâ€™t for a second make those relationships any less valid, or less important, or less real\" reply mh- 17 hours agorootparentI don't know the book beyond the quick google I just did, but I disagree with: >And the asymmetry doesnâ€™t for a second make those relationships any less valid, or less important, or less real. I think that people developing these so-called parasocial relationships is probably not harmful until it becomes a substitute for them developing \"real\" ones. But I see that growing rapidly, and I think it's a problem in the future. reply Aerbil313 15 hours agorootparentJust because you can magically send some digits to someone thousands miles away you never saw IRL doesnâ€™t mean your brain is designed for it nor is able to handle it without disruptions to its operation. Whether you believe in creation or evolution. Nobody lived like this. reply lelanthran 13 hours agorootparentprevThat's just sugar coating hero worship and trying to make it more acceptable. Just because something is written in flowery language doesn't make it profound. reply throwawayq3423 15 hours agorootparentprev>And the asymmetry doesnâ€™t for a second make those relationships any less valid, or less important, or less real. Not in a author/reader sense, no. But in a social media age where influencers use specific language to appear friendly and familiar? At the very least it's blurring the lines. reply supriyo-biswas 20 hours agorootparentprev> Twitch subscriptions and Patreon has shown, that if you bind a website/project to a creator > Most websites, and indeed open source projects are pretty faceless, and require limited interaction with it's creator This is ultimately a polite way of saying that the \"author\" (which can be a content creator, a OSS maintainer) needs to establish a parasocial relationship, use a self-aggrandizing approach, and create drama to entertain its users. This does work for content creators on Youtube, Patreon or Onlyfans, but ultimately detracts from the mission of delivering quality content that is useful or positively entertaining for the consumers of said content. The fans created in this way can go on to defend your failings or can be taken advantage of in a weakness, as can be seen in the case of the LTT sexual harassment allegation case and the health situation of Physics Girl. However, I see no way for this to work in an open-source project, because users of an open source project mostly care about the functionality provided. Creating a parasocial relationship is mostly not viable in this space due to limited interaction, as you pointed out. I've seen a few instances of OSS project maintainers using a chest-thumping, holier-than-thou approach to create drama, and said projects have either mostly become irrelevant over time or the open source project has continued to get attention only because the character of the maintainer has been buried and not well known to most. reply bawolff 17 hours agorootparentSometimes i feel like people make too much of the \"parasocial\" buzzword, as if its new. Entertainers have been doing the pass the hat thing for hundreds of years. It is not a new phenomenom. Historically, it has generally worked for entertainers, and i guess religion. I don't think there are historical paralells to open source really. Maybe it just doesn't work for that sort of thing. reply robertlagrant 13 hours agorootparentEntertainers aren't pretending to be your friend, or lover, in exchange for money. reply blargey 9 hours agorootparentExactly. Normal Patreons and such are run by entertainers/craftspeople who aren't pretending to be your friend, or lover. reply tourmalinetaco 4 hours agorootparentprevTo the latter: prostitution has always been prevalent. Now itâ€™s simply through a glass screen and not a peephole. reply throwawayq3423 15 hours agorootparentprevYes but entertainers always remained on stage, they didn't enter your home (as smart phones allow) and talk to you 1 on 1. reply Dylan16807 12 hours agorootparentPersonally, when I watch a big stream, the screen being in my house doesn't make it feel any less like the entertainer is on stage. And when there's 15 people watching, that does enable real conversations. reply PurpleRamen 17 hours agorootparentprev> and create drama to entertain its users. You don't need Drama, but you should indeed communicate and deliver something worth the peoples' money. I mean, there are many big and small creators who just steadily and silently deliver their work and have usually no drama at all. Drama is just popular because it's cheap, fast, and any idiot can create it. So people who have nothing else of worth, tend to live from this. reply xeromal 17 hours agorootparentprevIn his comments, he points to this not working for ephemeral websites. Twitter subs and patreon are just the opposite reply jmyeet 20 hours agorootparentprevTwitch did successfully push a subscription model for creators that allowed a lot of small creators to make an income. For anyone unfamiliar, Twitch subscriptions are $5-25/month (viewer's choice) and give access to emote, subscription badges in the chat and, perhaps most importantly, give you an ad free experience with that creator. One cannot understate how important Amazon Prime (as Twitch Prime) is to the Twitch subscription ecosystem. IIRC roughly half of all Twitch subscriptions are Twitch Prime. Twitch is aupser aggressive with ads. Youtube has skippable pre-roll ads. Twitch does not and might have 4+ pre-roll ads plus in-stream ads every 30-60 minutes. The ad density Twitch aims for is 4+ minutes per hour. But Twitch doesn't like the subscription model anymore. They've cut the revenue split. Previously many creators got a 70/30% split, now almost everyone gets a 50/50% split. The big problem is that ad revenue scales in a way that subscriptions don't. Ad CPMs can go up, you can increase ad desnity easily (to a point) and ad revenue scales with view count in a way that subscriptions don't (eg a creator with 100K concurrent viewers won't have 100 times the subscriptions of someone with 1000 CVC). You're seeing the same trend with streaming services. Netflix killed their basic tier and wants you to watch ads because it's more profitable than the subscription. Prime Video has thinly veiled a price hike by adding an extra ad-free monthly fee. My point is that subscriptions, or any form of voluntary payment, is icnredibly hard to make work and even the most successful examples, like Twtich, require great effort and a supporting ecosystem like Amazon Prime. reply Ygg2 20 hours agorootparentprevIsn't Twitch very much a net loss? reply PurpleRamen 17 hours agorootparentYes and no. They jump around the profit-point. They made some profit in 2019 or so, but the pandemia peaked them, not just in views and income, but also costs. The thing is, Twitch's business-model is very frail. A streamer with too many viewers can cost them more money than it brings them money. Similar, are there millions of small streamers who barely make them a dollar. And then are there also too many side-costs, like South-Korea's network-fee recently, or the too many law cases where come cranky person sues them for some nonsical reason. And we don't know for real how much Amazon is charging them. Rumors are going, Amazon is charging them a hefty amount for servers, while other says AWS is irrelevant for their Service, so nobody knows for real, officially. But the recent move to a different handling of video-streams is supposed to change this, as it reduce the costs on Twitch's side, and lets the Streamers pay for it themself. By which I mean AV1(?), where the streamer is encoding all streams in all resolutions, and only sends it to Twitch which then acts as a relay. Claim is, Video-Encoding was the biggest cost for them, after employees, which seems kinda strange.. But maybe it will change their game in the next years, we will see. reply nicolas_17 8 hours agorootparentYou do know Amazon owns Twitch? I'm sure they aren't using normal AWS billing... reply jmyeet 20 hours agorootparentprevTwitch loses money because Amazon has decided to make Twitch lose money. Why? Because Amazon is charging themselves for the infrastructure Twitch uses (ie AWS). It does that to justify cutting revenue splits (of subscriptions and ads) and increasing ad density. The minimum ad density now is generally 4 minutes per hour. Example: say I'm Pottery Barn and I sell furniture in the US. I sell a table for $500. It costs $100 to make in China, $50 to ship to the US and $150 in store costs (eg utilities, staffing, rent, amortized capex, etc). You might say I've made $200 profit. But let's say my corporate structure is to have 2 subsidiaries: PB Manufacturing and PB Retail. The first makes the table. The second manages the stores and sells the table. If PBM charges PBR $150 for the table then PBM makes $50 in profit and PBR makes $150. If PBM charges $300 for the table then PBM makes $200 in profit and PBR breaks even. This is what I mean when I say Twitch's profitability is a chosen narrative. There are many reasons to do this. Tax is a big one. Maybe you pay less tax in China so you prefer to take profit there. Maybe you want to argue stores aren't profitable to resist demands for higher wages or higher rents. The above is an example of \"transfer pricing\" or \"profit shifting\". What's the difference? Transfer pricing is illegal. Profit shifting isn't (within limits; it technically has to be \"at arm's length\" and other requirements). reply jedberg 16 hours agorootparent> Twitch loses money because Amazon has decided to make Twitch lose money. This is totally untrue but keeps getting repeated. Yes, within Amazon, the non-AWS business units pay AWS to use AWS. But they pay cost plus a small percent, not retail rates. The cost to non-AWS businesses is the same as if they had to do it all on their own (actually a little less since they get to leverage AWS's economies of scale). The profitability of the other business units is actually improved this way. They would be paying more if they were independent and doing it on their own. This is why Amazon is so allergic to spinning out AWS as its own business. reply stefan_ 16 hours agorootparentThat seems impossible to determine. AWS retail charges for things that have an impossible relation to actual costs (think traffic) to begin with. reply jedberg 16 hours agorootparentAWS knows how much it costs to deliver their own service. How do you think they determine their own profits and prices? They use those same calculations to bill internal customers. reply wongarsu 14 hours agorootparentObviously AWS knows how much it costs to run all of AWS. But that doesn't translate to accurately knowing the marginal costs of a gigabyte of outbound traffic. They probably do know, but it isn't necessary at all to determine their profit, or to set their prices. \"Just\" set prices to what the market is willing to pay, and determine profit as total income minus total expenses over the whole operation. reply snapcaster 20 hours agorootparentprevCan you expand on this? You're saying Twitch is only unprofitable in an accounting sense but would be a viable business if on its own? Saying their AWS costs are $0 seems like it would be even more \"fake\" reply wongarsu 14 hours agorootparentA video streaming platform isn't a natural fit for a hosting service famous for charging outrageous rates for outgoing traffic. If they were neither owned by Amazon nor had a special deal with AWS (like Netflix presumably has) they wouldn't be using AWS for anything touching actual videos. reply fkyoureadthedoc 19 hours agorootparentprevSo Twitch is only a viable business model once you own enough data centers. reply plorkyeran 18 hours agorootparentprevTwitch runs its own data centers and does not use AWS for the video streaming platform. There are probably some incidental expenses which are actually Amazon profits, but theyâ€™re much smaller than youâ€™re making them out to be. reply Quarrel 16 hours agorootparentSay what? https://aws.amazon.com/ivs/ \"Use the same live streaming technology and global infrastructure that powers Twitch.\" Did IVS grow out of Twitch? Sure. That core is now a piece of AWS infra though, even though the team was initially built at Twitch. (Obviously these things are weird to talk about in a vacuum, because all the pieces are 100% owned by the same parent. The splits we see can be changed with the wave of a CFOs pen, usually when they want to change how we view some overarching piece of the business.) reply nicolas_17 8 hours agorootparentprevNot sure what they use for video streaming, and it might even depend on where you're watching from, but VODs are definitely on plain old S3 + Cloudfront. reply gamblor956 12 hours agorootparentprevThe above is an example of \"transfer pricing\" or \"profit shifting\". What's the difference? Transfer pricing is illegal. Profit shifting isn't (within limits; it technically has to be \"at arm's length\" and other requirements) You have it backwards: transfer pricing is legal, profit shifting is not. Transfer pricing is the legal term used to refer to the establishment of prices between related entities pursuant to regulations. The transfer pricing regulations were created to cut down on profit shifting. reply Solvency 17 hours agorootparentprevHow does a government meaningfully and objectively determine what is transfer pricing vs profit shifting in practice? Are they even capable of distinguishing the difference in a case like Twitch:Amazon? Furthermore... isn't this the crux of Hollywood accounting..? reply PurpleRamen 17 hours agoparentprevIMHO their main problems were: they delivered too early, and failed in what they offered. When they started, there was no donation-economy like we have today on Twitch, Ko-fi, and others, nor was there an established support-hivemind like we have with Patreon, Github and others. So people did not know what they should do with it. And on the other side was Flattr a bit annoying to use in the beginning, and had percentage-based donations, instead of fixed values IIRC. People are selfish, but also willing to share, if you give them enough reason. But thinking about, maybe the lack of a social component and some virtual rewards would have been beneficial. But I guess, after the first fail, nobody cared anymore for it, and they somehow failed to find their market. reply Workaccount2 17 hours agorootparentHaving experience with donation only stuff, I can tell you something with the straightest face: Almost nobody who uses a service, even if they use it a lot, actually goes on to donate. It's a real hockey stick graph where 90% of your donations come from 5% of users. Trust me, everyone says they prefer paying/donating over ads, but when you look at the numbers, just about everyone prefers no compensation (and no ads) and chooses that if given the option. reply BottingRocks 16 hours agorootparentI believe that in the last couple of years the line between donation and begging has been blurred. You have things on the extreme side like people begging on tiktok live doing shoutouts to every viewer that donates a significant gift.On the IRL side you also have people donating to the craziest streamers doing the most outrageous stuff outside. Then you also have super donations on Youtube on live podcasts. When donations are incorporated on a social app it fosters an environment that makes donating acceptable and fun. Hardly anyone is going to trust their debit card/credit card details to a random site, but the masses will trust buying credits/donations/subscriptions through tiktok,youtube, twitch, patreon etc. reply throwawayq3423 15 hours agorootparentprevI think the one trick is using subscriptions that people opt into one time and just forget about. Using the dodgy psychology tricks of gym memberships to actually help people. reply PreachSoup 15 hours agorootparentIf that's the case, not sure if that's better than ads. I'd rather workout in an ads filled gym for free than paying for la fitness gym membership reply throwawayq3423 15 hours agorootparentprevAlso Patreon. The real failure was adopting a panhandling model of giving \"each time\" you consume content. Not only is this high friction, but people don't like doing it. They should have aggressively pushed a subscription model ($2 a month or less) that reoccured so creators actually could have reliable income. reply technofiend 15 hours agorootparentprevEven something like Patreon is a hard sell. I donated for a couple of years to an author I liked because he had a proven track record of delivery, so helping him concentrate on writing rather than a day job let him create more works. But him aside, I mostly see Patreon used to fund authors that are stringing along patrons with promises of \"You'll be a few chapters ahead of free readers\" vs \"This can make the difference that will let me finish.\" To that end, at least for me, I just go between a few so there's usually something new to read, and if not, oh well. If I were to publish in that space, I'd stream chapters slowly but regularly for free and the top donation tier would yield the completed work, but priced at the median payment I'd expect to get stringing people along for a few months. That's probably not a good business model, but I think it would prove less frustrating. reply pflenker 14 hours agoparentprevI had multiple discussions with German news projects around micropayments, and they list other, much simpler reasons why they donâ€™t accept it: - depending on the payment method, the transaction cost is too high and eats up almost the full payment - the administrative overhead to maintain micro transactions is huge - it creates the incentive to create articles that sell well, e.g. clickbait, which contradicts the values of these projects - you need to plan ahead and for that you need to have a somewhat predictable flow of income, which is not a given with micropayments. reply lencastre 13 hours agorootparentThat sounds about right! reply diggan 16 hours agoparentprev> if only they could make a small donation to every website they liked - but that doesn't work because people are fundamentally too selfish. Hear hear, this is exactly why bittorrent trackers is just a fad that will disappear as quickly as it appeared. What, are people supposed to just share data freely without getting paid for it? Good luck I tell them, it's impossible because every single person is just too selfish. reply ikrenji 16 hours agorootparenttorrents are viable with a few dozen seeders. you can't build a business on a few dozen 1$ donations reply SkyBelow 14 hours agorootparentprevIsn't this why many groups look at how much one uploaded and you can get lower priority or lose access if you don't seed enough? reply ThrowawayTestr 16 hours agorootparentprevNot seeding a torrent requires more effort than seeding, it's also basically free. reply opengears 15 hours agorootparentThis argument does not take bandwidth into account. If the goal is to download a lot of different files, you will be effectively limiting your download with keeping (especially very popular) torrents seeded. I stand corrected if somebody could please disprove me. reply master-lincoln 14 hours agorootparentIsn't bandwidth up- and download independent usually, so seeding (uploading) would not affect your downloads? reply ThrowawayTestr 13 hours agorootparentprevAs the other commenter said, upload and download speeds are separate. And if you mean data caps, most internet connections have \"unlimited\" bandwidth unless you're torrenting off your phone. reply infecto 21 hours agoparentprevSadly agree. I still wish when it came to news sites there was a micropayment option so I could read a single article for $0.10 or something along those lines. reply vintermann 20 hours agorootparentYou want to be nickeled and dimed? That was the whole problem Flattr was trying to solve. You decided up front how much you could afford to spend supporting artists and pursuits of creativity and public goods, and it got distributed evenly between everyone you choose to support. It was a great idea, and I was an early user. However, they had the problem that most of the people who you might want to support, were not on Flattr. And Flattr made a poor move early on: in a bid to avoid getting spammed by low effort/beggars, they demanded that you give and take: If you wanted to be able to receive, you had to use the service yourself. This was eminently fair. It was also a disaster, because it exposed a fact that's obvious when you think about it, but which is a crush to most \"creatives\"' ego: The vast majority of us are net consumers! We watch way more than we create ourselves. Most minor bloggers/youtubers/podcasters wouldn't want to admit that, they'd just see \"I pay more than I get out of this? This sucks!\" Later they backed down from this demand, and then they got the problem with low effort/begging. All along they had the problem that some influential people really wanted to see them fail, due to their association with The Pirate Bay. reply nradov 18 hours agorootparentYes, I want to be nickeled and dimed for content. There's no way I'm going to sign up for any more subscriptions. But I would be happy to pay a few cents for individual articles or videos or podcasts if it was a single click process. https://www.nngroup.com/articles/the-case-for-micropayments/ reply jstummbillig 21 hours agorootparentprevSince we have to assume that they assessed it, I suspect that they concluded the math would not work out. A possible explanation: News websites are cross financing their content. You spending a dollar on the paper, that only interests you in parts, is part of a model that makes it work (and probably also part of a model, where papers still feel wiggle room to editorialize for stuff they think is important, even though it might not click) reply rchaud 17 hours agorootparentNews websites are not independently owned. NYT is publicly traded, Wash Post is owned by Bezos, Time Magazine is owned by Benioff, etc. They survive on patronage outside of their subscriber base. reply rchaud 17 hours agorootparentprevAre you able to purchase anything for 10 cents today? The price of a short self-published ebook on Amazon is 30x that, $2.99, and plenty of people buy those. I understand that low-quality blog posts are worth nothing but if a viable micropayment option existed, those lazy posts would disappear (they only exist for SEO and collecting ad impressions). Websites and blog content would be more like what Substack has, which is semi-longform stuff that doesn't need to be padded with \"blog\" style posts. reply infecto 10 hours agorootparentHope the price was not hanging you up. I donâ€™t know what the price is and itâ€™s certainly variable depending on the content length and publication. Maybe for a long Journal/NYT expose itâ€™s a $1â€¦ reply itsoktocry 16 hours agorootparentprev>so I could read a single article for $0.10 or something along those lines. But there is \"something along those lines\"; it's called becoming a paid subscriber. When you amortize the expense across every article, you may even be getting a deal! The fact that the example expense you'd be willing to incur to read content you actually enjoy is ten cents speaks to why this model won't work. reply infecto 9 hours agorootparentDonâ€™t get hung up on the price I listed, itâ€™s just an example which is dependent on publication and article length/content. Your argument is pretty weak too. Of course I could subscribe but obviously I donâ€™t for any number of reasons. I am saying I wish I could pay on a per article price. Sorry for wanting to pay for the content I consume. reply JoshTriplett 10 hours agorootparentprevThat \"works\", somewhat, if you want to get all your news from one place. That's the traditional newspaper model: most people don't get a dozen papers delivered. But many people do read articles on dozens of different sites in a month. And that's a good thing; a world in which people get their news from a variety of different sources seems like a fundamentally better world. Newspapers and news subscriptions were financially viable in a world where most people had a subscription and that's where they got most of their news. They may not be financially viable in a world in which most people don't have or want to read only one or two sources of news. And that's fine. reply Thrymr 11 hours agorootparentprevSure, but we all have subscription fatigue. Say I subscribe to the New York Times and the Atlantic. But sometimes I like to read articles in the Washington Post or the New Yorker. How many subscriptions are enough? It's just like streaming fragmentation with Netflix, Apple+, Amazon Prime, Hulu, ad infinitum. reply apantel 14 hours agorootparentprevContent just isnâ€™t worth a lot because nobody really needs any particular piece of information all that much; and if they do really need a piece of information, chances are it is available in many places. reply LadyCailin 20 hours agorootparentprevThere is, or anyways there was, but the model didnâ€™t work. https://en.m.wikipedia.org/wiki/Blendle It still exists, sort of, you can download the app, but itâ€™s all in Dutch now, and doesnâ€™t work on a pay-per-article model anymore, itâ€™s unclear to me what their model is now, since I donâ€™t speak Dutch. In any case, what youâ€™re asking for exactly was a thing before, and failed, so I assume thatâ€™s why you canâ€™t do it - it was tried, and people didnâ€™t use it. reply infecto 20 hours agorootparentThis is one of those things where I wonder if it was too early for its success? I don't know the answer but it feels like it could have been. I have never seen it used on US based media unfortunately. reply colesantiago 21 hours agorootparentprev> still wish when it came to news sites there was a micropayment option so I could read a single article for $0.10 or something along those lines. Same. I'm shocked that the NYT didn't use Flattr on their articles for this. To access the full version of the NYT currently costs $0.50 a week so it would have been possible the NYT could charge $0.50 per article, or $5 for the year (one time no subscription) through Flattr or something along those lines. I could definitely see this working at scale. reply sgerenser 21 hours agorootparentThe $0.50 weekly price for NYT is a teaser rate. The full price for digital only was recently raised to $195/year. I imagine they make too much money from people who subscribe at the teaser rate and forget to cancel (like all newspapers/magazines) to make it worth exploring other business models. reply dageshi 21 hours agorootparentprevWe have to assume they have considered this in the past and come to the conclusion it just doesn't work. I suspect tying a purchasing decision to every page visit just leads to people automatically backing out of the page with a very low conversion rate because it's just too annoying to decide whether to pay for something you're not sure the value of. Despite all the gnashing of teeth, nothing competes with ads on the web. reply JoshTriplett 10 hours agorootparent> We have to assume they have considered this in the past and come to the conclusion it just doesn't work. Or that they prefer the world in which it doesn't take off because they expect to make more money, at least in the short term. If they believe that they can still convince N users to buy $195/year subscriptions, versus getting 10N users to pay a net total of $10/year in per-article fees, then they're better off trying to convince the N users to subscribe. Which might* work for the biggest dozen newspapers with brand recognition, but won't work as well for the long tail of news sites. reply infecto 20 hours agorootparentprevSince most news publications are failing businesses I would not immediately assume they have considered all avenues of monetization. I agree that ads have historically made a lot of money...but I am thinking of the paywalled industry. I am probably in the minority but I would be interested if any of the major publications had data on this kind of strategy. I realize there have been products including Flattr that did this but again I never saw it being using on a NYT level publication. Instead of me reading an archive link or just not reading the article at all I would be happy to pay some cents to consume it. reply amadeuspagel 12 hours agorootparentThe NYT is very much not a failing business. reply infecto 10 hours agorootparentThanks for the downvote but I said most not all. If you look at the news/magazine industry though it has not made a good transition to the internet age. Lots of closures and consolidations with some of the major outlets acquired as almost toys for the rich. Itâ€™s very much a shell of what it once was. reply eknkc 21 hours agorootparentprevI come across paywalled articles at least a couple of times a week. Iâ€™d gladly pay $0.50 for most of them to access the single article. It just needs to be easy, donâ€™t make me create an account a subscription and shit like that. Things like cryptocurrencies could work great for these kinds of transactions. Shame it became what it is now. reply infecto 20 hours agorootparentThats the boat I am in. I don't even care if they show me ads too, I just want to get around the paywall but I don't want to pay for a subscription. reply seydor 16 hours agoparentprevRather , because it's still too difficult to put money in a computer. Arcade machines in the 70s had the perfect impulse-purchase-compatible usage model reply amelius 17 hours agoparentprevMaybe adblockers could take the role of microdonation platforms. I'd pay $100/yr to have ads removed from every site I visit, and have my $100 distributed among the websites that I visit most. reply mminer237 16 hours agorootparentThis is essentially Brave browser's entire proposition for its existence. reply amelius 15 hours agorootparentWhen clicking \"Private advertising\" on the Brave website you get: > Powerful Ad Formats (...) > Diversify from Big Tech channels, and get the first-mover advantage of advertising in the fastest-growing search engine since Bing. Search ads are privacy-preserving, text-based ads that appear at the top of a userâ€™s search engine results page (SERP). > (...) reply mminer237 13 hours agorootparentYeah, they themselves serve ads on their search engine. That's wholly separate from Brave Rewards and you can block their ads just the same. reply Workaccount2 17 hours agorootparentprevGoogle actually used to have this as a service. They canned it a few years ago though. reply renewiltord 15 hours agorootparentprevThat was Google Contributor. It would pay min required to win the bid. Wasn't too successful. People very soon realized that you get the same for free with ad blockers. reply shpx 14 hours agoparentprevAds also physically influence the world. More humans become aware of something other humans want them to be aware of, more people end up buying some things (thereby incentivizing more of them to be created) or spending their lives on the most addictive mobile gambling thing or whatever. Whereas a system that just lets people say \"this thing entertained me enough for 0.00023% of my economic output for the year doesn't do anything else, and deciding typing in how much something is worth to you is work. Not a lot of work, but it's still work that might even be worth more than your micro donation, depending on how you value your time and the neurons you dedicate to thinking about it. So obviously the system that actually does something is more viable. reply Dylan16807 12 hours agoparentprevI just something I can subscribe to and money goes to sites I visit in a reliable way. And the sites should stop showing me ads, but I'll even take that as optional right now. Ideally something like youtube premium, but not youtube. Google ran some services that at a very surface level had the same idea, but actually worked in a messy and bad way, and then they gave up on it. Which is a real shame because they have the ad presence to actually make it work. Every other attempt I've seen has way too close to 0% of the sites I visit able to receive money. reply teekert 21 hours agoparentprevSadly disagree, I've put some BTC on my Podcasting 2.0 player (Podverse) and stream it to every creator that wants them (via the Bitcoin Lightning network). reply thfuran 21 hours agorootparentAnd you think more than about 0% of web users do the same? reply teekert 20 hours agorootparentI was reacting to the generalization. There are communities where the creators are well under way to becoming sustainable with this method. Granted, it's very early days. reply bigbluedots 20 hours agoparentprevOk, hear me out: Here is how to remove all unwanted ads from the Internet. ISPs move to subscription-based billing - a flat base fee to cover their own costs and some profit, plus a 'content' fee that is divided among the sites visited and the bandwidth used. The 'content' fee goes to a global rights association that distributes it to creators. reply JoshTriplett 10 hours agorootparentNo, for so many reasons. No, tracking is bad. No, a central organization will not do an equitable job of distributing fees even if it has invasive tracking information. No, a mandatory fee is unacceptable. No, not all sites visited deserve an equal share based solely on visits and bandwidth. No, there is no reasonable automated metric that would allow such division, as any possible metric can be gamed. The moment something like this were put in place, sites would immediately start gaming the resulting perverse incentives. Sites get more share based on bandwidth? Useless background downloads. Sites get more share based on number of visits? Lots of background loads, content in multiple iframes, split across many pages, etc. Any metric you can think of can and will be gamed, other than \"user says they want this site to get a share\". (That can be gamed too, but only insofar as sites already compete for user attention.) Here's how to remove unwanted ads from the Internet: get everyone to install an adblocker, put advertising out of business, observe better revenue models emerge out of necessity without having to fight to compete with \"free with ads\". reply stonogo 16 hours agorootparentprevWhy is the answer to \"how to remove ads\" always \"track the hell out of everyone at some other layer\" reply bigbluedots 14 hours agorootparentIf such a scheme we're to compensate content creators there'd have to be some way to determine how to slice up the revenue for them. Hits and data is one way. Your ISP probably already does that - at least re sites visited and data used. reply stonogo 2 hours agorootparentThey might try, but I tunnel all my traffic out anyway. In your proposal, my tunneling behavior would be morally equivalent to piracy. I don't think it's the world I want to live in. Canada does something similar with cassette tapes and blank CDs; essentially pre-convicting the entire nation of copyright infringement and collecting punitive fees up front. I'm betting it didn't keep anyone from going hungry. reply itsoktocry 16 hours agoparentprev>but that doesn't work because people are fundamentally too selfish. That's an odd definition of \"selfish\". Why is there an obligation to hand someone money? If you are running a business, be up front and charge money for it. reply mvdtnz 16 hours agorootparentThere is no obligation. That's the point. reply indymike 14 hours agoparentprevMost of the time, it's more painful to receive money than to donate it. reply bdhcuidbebe 17 hours agoparentprevi used flattr since it released for some websites i ran. had maybe 100 dollar there, mostly from an adblock filter list i used to maintain. eventually they just deleted my account due to â€inactivityâ€ in maybe 2017 or so. this made me stop recommending them they just kept my money reply lefixx 13 hours agoparentprevits not fair to call people shelfish when the only subscription option given to them is 10000x the value of an ad shown to them. Flattr was a good idea and if it was integrated to youtube I would have easily pay more than the ads would have. reply amadeuspagel 13 hours agorootparentI'm not sure how to talk about this without using the word selfish. It's not an insult. Most people are mostly selfish. There's no way of talking about the world without taking that into account. reply opengears 15 hours agoparentprevthis is called \"tragedy of the commons\" https://en.wikipedia.org/wiki/Tragedy_of_the_commons reply prmoustache 20 hours agoparentprevI see a lot of people either proposing using paypal, patreon or ko-fi to receive donations. How did flattr differ from these services? reply JoshTriplett 10 hours agorootparentAt least in theory, the flattr model was \"pay a fixed amount you can afford, it automatically gets divided among the sites you flattr\". That's a model that helps avoid subscription fatigue. Put $10 or $20 or $100 into a pool, and at the end of the month you know you'll spend exactly that much, no matter how many sites you flattr. I would love to have seen that model succeed. reply blub 20 hours agoparentprevThereâ€™s an overabundance of content/apps/sites. Most websites and projects are worth zero to most people. reply sneak 16 hours agoparentprevThis is wrong. Laws around money transmission, as well as egregious rentseeking from payment processing networks, not â€œpeople [being] fundamentally too selfishâ€ are why this doesnâ€™t work. The tech and will is there. Itâ€™s just illegal to build it. reply geokon 21 hours agoparentprevI know HN froths at the mouth on this topic.. But Cryptominers/Hashcash are also an alternative. It's only been made non-viable due to the major players who depend on ad-supremacy making sure all browsers fingerprint and block them reply rcxdude 20 hours agorootparentIt's a terrible option. Cryptomining in a browser is pure banditry: it's incredibly inefficient to the point the user loses way, way more than the site gains, and it provides basically nothing to crypto. reply geokon 18 hours agorootparentWhy is it banditry.. you can opt out of going to the website. I think you're not looking at the alternative objectively.. Ads are pure brain rot that just make society worse while providing virtually nothing useful to \"the user\" reply Jochim 17 hours agorootparentIf you're robbed by bandits you can choose not to travel on that road again. That doesn't mean that you weren't robbed the first time. reply JoshTriplett 10 hours agorootparentprevThe alternative to ads isn't cryptominers. The alternative is adblockers, which also block cryptominers and other unwanted malware. reply stonogo 16 hours agorootparentprevYour description of ads is my description of cryptocurrency. reply teekert 15 hours agorootparentprevI think you're not wrong. There is the BTC Lightning network which burns A LOT less energy and the low transfer costs make it feasible to stream fractions of cents. Ie. when listening to a podcast via Podcasting 2.0 app (like Podverse). Btw, I upvoted you, all the frothing was fading out your reply. BTC Lightning is one of those babies people want to wash away with the bathwater. Or perhaps it's the only one I know so far. I do agree 99.99% of \"crypto\" is shitcoin scams. reply geokon 5 hours agorootparentIt's less about transfer fees. I'm not saying you should make microtransactions to visit webpages. I'm more imagining a mining-pool made up of webpage visitors. The website allocates you certain blocks of hashes to be calculated and you calculate those. Once they're calculated and the webpage verifies it by randomly double checking a few, then the webpage is served. A websearch tell me a webpage visit nets the owners about ~2 cents in ad revenue. So you just need to mine some equivalent amount. It'd be sort of like a mining-pool where the overwhelming majority of users don't successfully mine a block - but when someone does the website owner gets the coin. You could get more sophisticated on top of that and have some central mining-pool coordinator and session cookies etc so that your mining credit transfers across webpages and you can \"premine\" certain amounts So the currency becomes more granular at \"how many hashes have you calculated\" and not how many coins do you have I could be wrong though ~ It's possible 2 cents of hashes takes hours to crunch on a phone reply colesantiago 20 hours agorootparentprevNo. We shouldn't have to make the world infinitely worse place and waste billions in energy just to squeeze out a cent in 'magic internet money' to give to another person. reply scrollaway 21 hours agorootparentprevItâ€™s also a huge waste of energy at a time when the planet is on fire. reply geokon 18 hours agorootparentit's got some downsides - but so does the alternative. Have you considered the harmful effects of advertisement on society? I think people's cellphone warming up a bit is a smaller price to pay reply JoshTriplett 10 hours agorootparentThat's a false dichotomy: cryptominers are not the only alternative to ads. reply geokon 6 hours agorootparentthat was literally what the parent comment said: \"This is why ads are the only viable business model\". No alternative to ads has been really made viable. Fattr shutting down makes the point reply night-rider 14 hours agoprevA few alternatives for micro donations that people have mentioned: https://ko-fi.com/ https://github.com/sponsors https://www.patreon.com/ https://www.buymeacoffee.com/ https://www.paypal.com/paypalme/ Any others, let me know reply PaulDavisThe1st 12 hours agoparenthttps://www.paypal.com/us/webapps/mpp/merchant-fees#statemen... reply onli 21 hours agoprevWas Flattr big in the US? It was a \"future big thing\" in my part of Europe for a while, driven by discussions in Blogs and experiments with using it for bigger projects, iirc. It seemed like it never achieved much success of leaving that bubble though. After a while I never noticed it again. I thought about it recently when noticing that a gaming journalist used Steady for his incomes, and Patreon would be the other service to mention. Looking at the timeline though, it confuses me that this was only 14 years ago. But no, that lines up with how old my own blog is. Feels far away! The web was a different place back then, and Flattr a part of that past, with a slightly different version of the future than the future we got. reply steveklabnik 17 hours agoparentI signed up for it when it was announced. I don't remember any websites I used actually using it. reply Legend2440 9 hours agoparentprevIt was never big. I saw a handful of open source projects and the like use it a very long time ago. But it was never a considerable source of income for them. reply pikrzyszto 21 hours agoprevI used Flattr for a while but struggled with: - flattr support discovery: Instead of having a \"Flattr\" button on the webpage I visit I need to navigate to flattr website and search there... but I'm not going to do that. Maybe adblocker removed that button? - ownership confirmations - I wanted to donate to person $PERSON and found them on flattr. But I had no idea whether this flattr account actually belongs to $PERSON. I reached to $PERSON about that and never heard back so I stopped donating. reply manx 11 hours agoparentA browser extension sounds like a potential solution here. reply neom 16 hours agoprevNever heard of the service before, but fun to learn the guy behind it was one of the dudes behind The Pirate Bay. https://en.wikipedia.org/wiki/Peter_Sunde reply diggan 16 hours agoparentWhich speaking of, ran/runs a bunch of other useful services. IPredator (sadly no longer with us) was an alright VPN service and Njalla is (still with us) a really great domain name registrar for people who care about their privacy. Seems RIAA and MPA are still trying to go after Njalla as far as I can tell, so you get some hints that it's actually working as advertised :) reply gaiagraphia 20 hours agoprevI currently \"subscribe\" to the Financial Times because I use Revolut Metal. I understand it has higher quality content than elsewhere, and enjoy reading articles from there now and again, but I never would've paid for it. I wonder if 'bundling' is a way forward for content creators? Use x bank/isp/ridesharing app/delivery service, and you automatically get subscriptions to these creators. Instead of governments spending Â£bil on their cultural budget, surely offering the same amount to companies in tax breaks if they support cultural projects would achieve a far greater impact? Brief search showed Â£345m Uber Eats revenue in UK. If Â£3.45mil of that made its way to supporting 100 people who all had channels/sites inspiring families to eat healthier/more locally/promote local business,etc, surely this 'organic' approach could yield more than layers of civil service? reply lnxg33k1 20 hours agoparentNews should be paid for by people using it, making news dependent on government funding is bad, making news dependent on corporations is even worse, I tend to point the start of the decline of information and so democracy and plurality to the advent of blogs, free websites etc. Independent information that serves people, is funded by the people reply tonyedgecombe 20 hours agorootparent>making news dependent on government funding is bad I wonder if having the government hand out tokens that you can spend on whatever media you want would be better. reply gaiagraphia 19 hours agorootparentAlways been a huge fan of this as opposed to a \"Tv license\" type system. Being able to choose where 1% of your tax money goes each year. IIRC, Poland does something similar: \"Individual taxpayers of personal income tax have an opportunity to allocate 1% of their annual tax liability to specific Polish public welfare organizations. It is an easy way of supporting a charitable initiative and it does not require additional cost or a lot of effort.\" https://www2.deloitte.com/pl/pl/pages/tax/articles/tax-news-... reply tristor 8 hours agoprevI used Flattr for awhile but I eventually stopped, because it had low discoverability of where the money was going and it was a recurring charge structure (as I recall), but sometimes I just wanted to spiff somebody one time. It's an interesting idea, but it never really worked out, and I also didn't heavily utilize it while I was active because few creators had a Flattr profile and the other mechanisms I was too lazy to use. A lot of folks here talk about selfishness being the killer, but the reality is that it didn't have a strong UX. reply skerit 21 hours agoprevOh wow, I completely forgot about Flattr. Thinking about it again, I quite liked the idea. But I guess it never really caught on enough. reply mhitza 21 hours agoparentI've used Flattr for a short period of time in early 2010s. I think it's unfortunate that the service picked up steam when most of the published content was moving from self-hosted to centralized social media platforms. Actually with a bit of marketing Flutter would have been better suited nowadays than at that time. reply Kiro 21 hours agorootparentFlattr, not Flutter. Flutter is another popular thing on HN. reply mhitza 21 hours agorootparentThanks. Flutter is almost muscle memory at this point :) reply taspeotis 21 hours agoprev(2023) https://en.wikipedia.org/wiki/Flattr reply potyarkin 17 hours agoprevJust the other day I was trying to remember \"this weird micropayment site I used to donate to What.CD\" and could not describe it coherently to a friend. It's kinda cool it was around this long reply dewey 15 hours agoparentWas looking for someone to mention that. I remember that I wrote parts of the wiki entry on how to donate through Flattr back then! reply felixg3 15 hours agorootparentI think youâ€™ve been my interviewer at what.cd, ~ 2011. Glad to see you here! reply dewey 15 hours agorootparentYes, I remember your name (also from last.fm I believe!). Small world! reply felixg3 14 hours agorootparentIf you want to grab a cold or hot beverage in Berlin, Iâ€™m about to visit my wife in Berlin-Charlottenburg (sheâ€˜s there for a few months) soon reply dewey 12 hours agorootparentLetâ€™s do it, I messaged you on Session! reply cleansy 21 hours agoprevNo wonder given the company that acquired the project is rather hotly debated for \"removing ads from websites just to reinsert their own.\" Edit: Not reinsert their own, but having advertisers pay for the pleasure to not be blocked in their \"acceptable ads\" program. reply amadeuspagel 21 hours agoparentSeems more likely that they tried this as a desperate last attempt when things were already going down the drain. reply pvorb 21 hours agoparentprevI somehow link this practice to the Brave browser, but I'm not sure about it. Does anyone know more about it? reply ffpip 16 hours agorootparentBrave blocks ads on pages you browse, and then sends ad notifications to user who opt into their earning program (disabled by default). It pays them in BAT, a crypto coin they developed. If you want to, you can use these earnings to contribute to sites who have signed up to accept their crypto coin. It does not replace ads on pages with it's own. reply gertop 16 hours agorootparentprevHe's talking about Adblock Plus, they whitelist \"acceptable ads\" and vendors need to pay them to be classified as such. Apparently Adblock Plus makes enough money from that practice that they managed to buy flattr in 2017. reply vcoelho 16 hours agoprevI'd like to have a service where I can purchase credits and then this gets distributed between sites that I can choose to support as I visit them. reply jbaber 12 hours agoprevFlattr style micro-payments doled out based on impressions of a page (or their evil twin, ads) seem more honest than subscribing a la patreon. (I subscribe to a lot of creators with patreon.) I frequently hear and read people not wanting to sponsor some youtube channel or podcast they consume for hours a week because it's \"not that good\". If you spent the time there, they deserve your money. I really feel for creators who produce popular material, but don't get as much remuneration as content that people are prouder of liking. reply Stratoscope 12 hours agoprevIn the 1980s, I was briefly involved with AMIX, the American Information Exchange. https://en.wikipedia.org/wiki/American_Information_Exchange As an experiment, I wrote a short article and offered it for ten cents. And one person paid me that dime! Exciting times. (The Wikipedia article says that $1 was the minimum price, but this must have been before that was set.) Microsoft was paying me a dollar a word for my MSJ (Microsoft Systems Journal) articles, so that worked out better. reply stl_fan 16 hours agoprevBrave is building this functionality into the browser. reply sneak 16 hours agoparentUnless you have some new information, I think that was like 6 Brave pivots ago, and isnâ€™t the case any longer. reply ystvn 13 hours agorootparentWhere did you get that information from? I've never used that functionality myself, but haven't seen info indicating it got deprecated so I assumed it's still supported? reply mstade 21 hours agoprevI hate to be this guy, but 410 seems a more appropriate code: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/410 reply hiAndrewQuinn 21 hours agoparentDon't, I had no idea there was a dedicated status for that. I'm part of today's lucky 10,000 :D reply Zobat 20 hours agoparentprevKinda tempted to say 424 or 402 and you should always consider 418. Actually 418 might be appropriate as the service was clearly not built to solve the problem as it exists today. \"The HTTP 418 I'm a teapot client error response code indicates that the server refuses to brew coffee because it is, permanently, a teapot.\" reply quickthrower2 21 hours agoparentprevAlso the page actually returns 200, disappointingly. reply pavlov 21 hours agoparentprevSomeone could buy the flattr.com domain and then the site would be live again. IMO, \"410 Gone\" is only appropriate for URLs that contain unique identifiers because those are guaranteed to never be recycled. reply kevincox 21 hours agoparentprevI thought the same thing. You aren't the only one. reply xwowsersx 21 hours agoparentprev> If you don't know whether this condition is temporary or permanent, a 404 status code should be used instead. Maybe they come back! reply devnine 21 hours agoparentprevfirst thing I noticed also. I would suggest is a 417 Expectation failed. https://http.dog/417 reply teddyh 21 hours agorootparentNo, that would not be appropriate, since there is no â€œExpectâ€ header you could send in the request to get a successful response. From RFC 9110, HTTP Semantics: The 417 (Expectation Failed) status code indicates that the expectation given in the request's Expect header field (Section 10.1.1) could not be met by at least one of the inbound servers. â€”reply canpolat 15 hours agoprevFor a moment I perceived that as \"Flutter\" and immediately thought, \"Of course, Google is shutting down another project.\" Perhaps that's enough screen time for today. reply goda90 21 hours agoprevI had an idea just like this several years ago and seriously considered doing it as a startup but somehow never heard of Flattr. I'm curious what kind of marketing to website creators did they try. Did anyone try Google Contributor, which was a similar idea? reply DamnInteresting 17 hours agoparentI've had a similar idea simmering in my head for over 10 years, I even purchased a fitting domain name for it. It's always been a \"one of these days\" kind of project. My idea is different enough that it might have a shot where Flattr fell flat, but it's exceptionally hard to gather users, even if you build a superb product. reply kiddjones 15 hours agorootparentSame here. Similar, but different. It's been one that I've started building out a couple times over 10ish or so years. I'm pretty sure I'd have a way to combat the issues that Flattr faced, but also, I may be wrong, so is it worth my risk? reply tech234a 12 hours agoprevNote: Theyâ€™ve been owned by Eyeo since 2017 [1]. [1]: https://techcrunch.com/2017/04/05/adblock-plus-acquires-flat... reply jkingsman 15 hours agoprevFlattr was the first time anyone paid me money for my open source/freely-hosted passion projects. It made my heart glow for a week. reply neom 15 hours agoparentCurious, do you still have your NFC implant? reply theodorewiles 14 hours agoprevI don't want to throw yet more GenAI crap at this, but could RAG be a possible innovation that unlocks microtransactions? I'm imagining a backend database of creator-submitted content. The LLM runs RAG on it, pays the creators it relied on to synthesize answers a microtransaction. Then also sells the Q-and-A as a subscription service to the end user. Maybe payouts are conditional on positive user feedback. The solution can also flag queries it sees that don't have great answers yet. Same moat as search, not reliant on advertising. reply ben_w 14 hours agoparent> I'm imagining a backend database of creator-submitted content. The LLM runs RAG on it, pays the creators it relied on to synthesize answers a microtransaction. That sounds like you're describing Mechanical Turk? (And also \"let's train an LLM on Reddit/StackOverflow). Problem is, the humans in Mechanical Turk loop were economically motivated to outsource to AI even before LLMs. reply jrflowers 14 hours agoparentprevâ€œWeâ€™re using AI to build the Spotify of Yahoo Answers!â€ reply brcmthrowaway 13 hours agoprevSo what are the greatest swedish tech stories? Spotify, soundcloud, DICE? reply INTPenis 13 hours agoparentIf you're going to mention DICE you should mention Massive too. reply brcmthrowaway 3 hours agorootparentWhat's Massive? reply INTPenis 55 minutes agorootparentMassive Entertainment? Who made the Snowdrop engine and The Division? reply takinola 13 hours agoprevMicropayments struggle because they add friction to the process of consuming content. Right now, if I see a great blog post, video, whatever, I spend a bit of time taking it in and then move on. With micropayments, I now have to think about how much it is worth to me (is this blog post, comment, sketch worth $0.50? $0.10?). You just turned a brainless moment of enjoyment into a value judgement where I now have to become a critic and try to create some kind of inner framework for assigning value, etc. Ads avoids all these by (relatively) frictionlessly converting attention into money. Subscriptions bundle the friction into a single event (the conversion) and remove it for all future interactions. Micropayments are just constant papercuts. reply sunshine_reggae 21 hours agoprevNo explanation at all. Something seems kind of \"fishy\", some aspect of it being hidden... reply hnbad 16 hours agoparent\"We ran out of money and our investors wanted to cut their losses and pulled the plug\" isn't something you usually spell out in a post like this to avoid burning bridges or appearing \"unprofessional\". reply colesantiago 21 hours agoprev [â€“] This is very unfortunate and surprising, goes to show that even after 14 years Flattr didn't find any market. I was hoping for bitcoin and crypto to show low usage after around 15 years of no legitimate use cases other than speculation, ransomware and other scammy things, but Flattr's shutdown was a surprise. Flattr billed itself as the RSS of donations to really get rid of those ugly PayPal buttons on blogs, websites and the indie web, but unfortunately that didn't happen. Why is that? What was Flattr missing here? reply atq2119 21 hours agoparentFlattr was trying to bootstrap a sort of two-sided market from scratch. They needed to get both hosts/\"content providers\" and clients/\"users\" to sign up. This is just a very, very hard problem, and if we're being honest about it, most of the success stories that come to mind got there through burning venture capital, which perhaps Flattr didn't have enough of? I don't think the idea is fundamentally flawed, it's just very difficult to do this kind of thing. reply hnbad 16 hours agorootparentWell, they also made the mistake of initially trying to force both sides of the market to be one, i.e. you had to be a contributor (pay money to others) to collect money (let others pay you money). Also collecting money on behalf of others and then distributing it after sitting on it is an easy way to run afoul of anti money laundering laws in various jurisdictions. Also they did take investments which means they had to not only build a sustainable business but actually create a considerable ROI for their investors or risk them pulling the plug and cut their losses (which is presumably what happened given the lack of detail and \"our wonderful journey\" speak). So in other words they decided to play in hard mode (infinite growth) and then kneecapped themselves (to avoid \"begging\"). It's a miracle they survived this long. I had forgotten about them longer than I had used them. reply worldsayshi 21 hours agoparentprev [â€“] Maybe one thing that held them back was that one of the founders was also founder of The Pirate Bay. Maybe potential big clients didn't want the association. reply teekert 15 hours agorootparent [â€“] Could also work for him, like SBF in his hoodie playing fortnite impressing bankers and such. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The micro-donation platform 404Service is shutting down after 14 years of operation, expressing gratitude to their community for their support and belief in their mission.",
      "The platform briefly expanded their services this year but made the decision to close both ventures.",
      "The team wishes their community endless creativity, joy, and success in the future."
    ],
    "commentSummary": [
      "Flattr, a micropayments platform, is shutting down, raising questions about the viability of micropayments as a creator income source.",
      "The discussion explores the pros and cons of micropayments compared to subscription models and the dominance of advertising as the primary business model.",
      "Other topics include ephemeral websites, the value of paying for content, parasocial relationships, profitability of platforms like Twitch, alternative monetization options, torrent and bandwidth limitations, ad-blocking, and the use of cryptocurrency and AI in micropayments."
    ],
    "points": 208,
    "commentCount": 214,
    "retryCount": 0,
    "time": 1705572746
  },
  {
    "id": 39047825,
    "title": "Math Academy: Relearning Math as an Adult Made Easy and Accessible",
    "originLink": "https://gmays.com/how-im-relearning-math-as-an-adult/",
    "originBody": "How Iâ€™m (re)learning math as an adult Jan 17, 2024 I recently passed 100 days of practicing math every single day ðŸ’¯ Iâ€™ve wanted to beef up my math chops for a while, but I needed a good reason that would justify the time investment. Plus, itâ€™s always easier to learn when you have a clear goal and something meaningful to apply it to. So, it never reached the top of my priority list. But then a couple things happened recently that gave me 1) sufficient motivation and 2) a clear path. The motivation Iâ€™ve worked on various AI products over the last year and like understanding the technical aspects of the products I build. But as I dug in to learn more about how large language models (LLMs) and transformers workedâ€¦I was lost. It was humbling. From Spencer Becker-Kahnâ€™s Notes on the Mathematics of LLM Architectures. Iâ€™d need a much better understanding of stats/probability, linear algebra, and calculus (overview). Aside from corporate projections/financials, I havenâ€™t done much with math since grad school, so I lacked a foundation. I donâ€™t need to become a mathematician, but at a minimum, I wanted more intuition around the core concepts and connections between them. The path So, how does an adult with a job, kids, a mortgage, and other hobbies, learn math in an effective, time-efficient way? Fortunately, a friend I met a decade ago at MicroConf, Jason Roberts, founded a startup called Math Academy with his wife, Sandy. I kept up with it since the early days (they have a great story), and now I finally had a reason to try it out. It was still in beta, so I reached out, bought a license, and was in! Math Academy How would I describe Math Academy? One word: Amazing. Iâ€™ve been consistently impressed since I started using it. Despite still being in beta, it feels quite polished and works well (though itâ€™s clear an engineer designed the UI ðŸ˜‚). Its current focus is helping kids learn math, with tools built-in for parents to help their kids be successful, but itâ€™s quite effective for adult learners like me as well. Their current courses cover math from middle school through university (graduate level) and are fully accredited. Below are the current courses. Math Acedmyâ€™s course offerings as of Nov. 2023. The â€˜Foundation Seriesâ€˜ is what Iâ€™m starting with. Itâ€™s for adults to help streamline learning (it skips the stuff that kids need, but adults donâ€™t) and work back up through college-level math relatively quickly (emphasis on relatively ðŸ˜‚). One of the other reasons I love Math Academy is the authenticity of the people in addition to the process. The founder and others are true math nerds, and theyâ€™ve spent thousands of hours teaching math. They know what works. Jason, founder of Math Academy, teaching kids math (including his own kid!). This authenticity translates to authentic learning, which comes through from the very beginning. After signing up, it starts off with a diagnostic that shows you how much of a dumbass you are helps assess your current math proficiency so you can start off at the right level. Then the self-paced, interactive lessons start. One thing I especially love as a busy adult student is that most lessons are ~10 minutes long, which makes it relatively easy to squeeze in sessions (e.g., between kids screaming or while theyâ€™re distracted watching Bluey ðŸ˜‚). I also love how it teaches, assesses, reviews, and builds on concepts. When it comes quiz time Iâ€™m often impressed with how much Iâ€™ve learned and the ability to apply it. This thing is legitâ€”it really works. And there are no fluffy videos that just â€˜feelâ€™ like learning. The lessons have explanations between problems to make it a very concrete, hands-on process. Itâ€™s a highly effective way of learning. â€¦which gets to something important: Math is hard. Math Academy makes learning math as easy as possible, but itâ€™s still hard work. Really hard work. Math is hard Learning math is challenging. Itâ€™s real work. This isnâ€™t some casual app you can just flip through. Unless youâ€™re like John von Neumann, most of it requires pencil and paper to knock out. The only exception is the early lessons when youâ€™re just refreshing and can do most of it in your head. But if youâ€™re serious about legitimately learning math, there is no better, more convenient way. Setting myself up for success To make this a habit Iâ€™d stick to, Iâ€™d have to lower the activation energy of doing it and make it as close to a new â€˜defaultâ€™ behavior as possible. â€œThis is just what I do.â€ So, I started with convenience and consistency, which helped me form other good habits as well. Convenience Learning math is hard enough, so how can we make it somewhat convenient? Math Academyâ€™s short (~10 min) lessons help. I also use an iPad for the lessons (itâ€™s web-based) when Iâ€™m not at a computer and a Remarkable 2 for the work (e-ink for pencil/paper). I also found a cheap case that fits both perfectly. This makes it easy to knock out lessons here or there. For example, I had jury duty recently and knocked out a few lessons while waiting. And just this past Wednesday, the kids were ready early, so I got to the gym about 15 minutes early and knocked out a lesson or two in the car. Iâ€™ve also started doing them during a light walk on the treadmill (I have one under my standing desk). My usual routine is to do lessons in the evening after the kids go down and after I work out. It is challenging to muster the energy to work out and do math after a long day, but making it a habit has made it easier. Consistency Iâ€™ll say it again: Math is hard. My goal is to work up to the math needed to better understand LLMs and transformers. Thankfully, Math Academy has a â€˜Mathematics for Machine Learningâ€˜ course Iâ€™m working towards, which gives me a clear goal. Given my limited time, it will likely take years for me to get there. Why years? Two reasons: Math is hard. Math is BIG. I had no idea how broad and deep math was. I probably still donâ€™t. Case in point: This is the knowledge graph of the concepts in the first Mathematical Foundations course, showing the topics, how they relate, and what gaps you have. Impressive, right? And this is just the first course (!) of the ~10 or so I want to take. Itâ€™s going to take years. So, how do I get there? One lesson at a time. If I keep at it, I will get there. Iâ€™ve been doing at least 1 lesson a day, every day since I started, giving me a 106-day streak as of today. Screenshot of my Math Academy streak from Habits Garden, where I track my habits. 106 days down, ~1,000 more to go ðŸ˜‚ Itâ€™s a hard, but worthwhile and enjoyable new hobby for now. Takeway For hard subjects like math, I always assumed the only â€˜realâ€™ way to learn was in dedicated environments like college since online courses were best for softer, less technical topics. This was a bummer, especially for adult students like me. But Math Academy changed my mind on this, and Iâ€™m a huge fan so far. I hope they continue to grow and expand to other complex STEM topics like computer science, physics, etc. Overall, Iâ€™m just so excited thereâ€™s an effective, accessible way to learn hard things. If I were a billionaire, Iâ€™d invest to accelerate its progress and find a way to sponsor a license for every kid who was interestedâ€¦ But for now, Iâ€™ll just talk about it to anyone who will listen ðŸ˜‰ â†Previous: How to host WordPress sites free",
    "commentLink": "https://news.ycombinator.com/item?id=39047825",
    "commentBody": "Relearning math as an adult (gmays.com)205 points by gmays 12 hours agohidepastfavorite131 comments hiAndrewQuinn 1 hour agoAbout a year ago my wife and I made the joint decision to get her into college for a bachelor's degree in either English or computer science. Here in Finland, university admissions are based around how well you did on various end of school exams, and she fortunately did quite well on all of them a decade ago - except for math. She bombed math due to health and family problems as a teenager decimating her ability to pay sustained focused attention. Luckily, soon after the decision was made, I finally got my first full time job in Finland. I could easily support the two of us and give her an uninterrupted life to focus on grinding up for the math exam. We took the last ~10 years' worth of math exams online, turned their problems into Anki cards, and set her nose to the grindstone. I had had tremendous success with this in college with abstract algebra and real analysis, so I figured the same methodical approach + a very stable living situation was bound to work for algebra through basic calculus. Five months later, she retakes the high school exam and gets the highest score possible! Her rapid success at this convinced her to give CS a serious try, and indeed her improved math exam was the differentiator - without it she would not have been accepted to the CS program. She got top marks in her first semester at CS as well, I couldn't be more proud. My wife is truly an incredible person. reply baq 40 minutes agoparent> set her nose to the grindstone Worth calling out the key observation: it takes practice, and lots of it (for most people, anyway) to get good at math. Just reading about it does zilch. reply tux3 17 minutes agorootparentIt does a little more than zilch. Exercise is important. Reading is also important. If you want to learn fast, you need a balance of both that works for you. Some people will spend months grinding hard problems on their own in a single chapter to make sure they really understand. Some people will read too fast and have to go back because they don't have solid foundations, and only thought they understood. Reading is about as important as doing exercises. You're not going to reinvent all of math on your own. You get insights from both. reply NeutralForest 1 hour agoparentprevCool comment, it's great seeing people being supportive of their SO =) reply mjburgess 1 hour agoprevThe \"math\" used in ML/AI papers is usually just a sort of 'whiteboard math' which is a domain-specific mishmash of linear algebra, calculus, set theory and statistics. If you could find a book just going through the relevant bits you wouldnt really have to \"learn math again\", it can be translated into english straightforwardly -- very very few ML papers relevant to industry have extended proofs, etc. that require eg., even being able to differentiate anything yourself. 90% of it is: here's the domain (ie., type) of our variables, here's the formula of our functions, we're taking a weighted average with some inner products involved. It might sound like a lot of math, but it's really all doable in semester-1 of an undergrad course, were it focused enough. reply sjducb 32 minutes agoparentI think you donâ€™t realise how much math you know. Iâ€™ve heard of set theory, but never studied it. reply mjburgess 17 minutes agorootparentsure, but you dont need to understand actual set theory -- it's just notation for mostly obvious programming stuff, R means float, Z means int R^2 is actually notation from linear algebra, but here it means a point is 2 floats with a measure of distance between points etc. A lot of this could just be given in a \"crib sheet\" for tech people, and you'd get 80% of it straightaway. It's years of work to understand this notation as used by the professional domains it was invented by, but it's a couple weeks for most \"good, technical, software engineers\" -- since they arent really using notation in much more than superficial ways. Of course there are hard mathematical papers, etc. but they're rare in ML/AI mainstream papers; and not something most would read. If you need to be able to read, eg., some sort of adv. statistical time series research in economic modelling, you'd already have the background to do that. If all you want is to be able to read 90% of the popular papers, the notation in them is just syntax sugar for things you could state easily in english or python reply programjames 47 minutes agoparentprevNormalizing flows and neural ODEs are becoming a bigger thing, and they do involve some more heavy maths. reply jorgesborges 7 hours agoprevIâ€™m a thirty-something with an arts degree who decided to learn math. Basically I was tired of reading popular science and being fed metaphors to understand concepts. I wanted to â€œseeâ€ it for myself. I spent time online at Khan Academy and friends for a year or so on and off. It was fine but meandering? So I enrolled in community college! Itâ€™s great. I have a clearer path, immediate feedback, teachers, and an obligation to do work that keeps me on it. Ultimately my plan is to get enough transfer credits for university and spend this decade slowly working toward a bachelor of science in physics. reply jambutters 5 hours agoparentI actually find the immediate feedback from khan academy exercises better than school actually. The feedback loop is much more tighter instead of waiting an entire week later for results and not really getting another go at it. I also tend to zone out or miss something in the lecture, and that missed thing is what builds the entire foundation for everything else and then the entire lecture is pointless. With video based lectures, I can pause, go back, play 2x speed, look at multiple well produced explanations, etc. Ultimately I don't find face to face all that valuable a various amount of subjects. reply andrepd 1 hour agorootparentReplacing lectures with video lectures is fine, even an improvement. But not such much for exercises/problem-solving/practical classes. reply javchz 7 hours agoparentprev100% Agree. Im a big proponent of developing self-thought skills and making the best of e-learning, but I think math (alongside languages and other) are one of those areas where the real time feedback makes traditional education still worthwhile. It's hard to replace it with just books and online courses. Not impossible but harder. reply jacobolus 6 hours agorootparentFunny. As a college student I found face-to-face interaction was much more important to studying social sciences and humanities than to studying math or theoretical physics or computing which could pretty effectively be studied in a book. reply jamestimmins 4 hours agoparentprevThat's awesome that you're working towards this goal! Side note: community colleges are an incredible deal, and since starting a woodworking class at one, I could easily see myself taking one or two classes at a time basically for decades. reply wodenokoto 3 hours agoparentprevKhan used to have something called \"world of math\", which would take you through the entirety of Khan academy \"backwards\". Eg., you would do problems, and only take lessons when you couldn't complete a problem. While the first 1 or 2 weeks felt more like a case study on how to teach number literacy to children (\"how many elephants are there in the picture?\") it soon became real calculations and later on all the branches of math. I did it for a few month leading up to my masters, and it was great. reply tayo42 3 hours agoparentprev> working toward a bachelor of science in physics. Thats cool, I kind of want to do that. But also Im stuck with wondering, I put all this work into that, what do I do at the end? reply whatshisface 3 hours agorootparentYou could get a PhD in physics, and if you time it right, you will die right after graduation, the moment when all of your classmates realize they're staring down 40 years of software engineering. The tombstone could read, \"I figured it out.\" reply blowski 1 hour agorootparentprevSome things are enjoyable in themselves, without needing a â€œso thatâ€. reply paulpauper 3 hours agoparentprevVideos are good to get some barebone knowledge, but are too superficial or unstructured to replace classroom settings, with graded exams and homework. reply burrish 1 hour agoprevNice Ad post, there are A LOT of free resources to learn math on the web, why go through $49/month ? People are citing Khan Academy which I warmly recommend, there are a lot of good Math teachers teaching math on YouTube, and there is also OpenStax.org [1] which releases free public books on different subjects including... you guessed it... math ! Go check it out ! But maybe for some people, spending money is a necessity because it motivates them to finish the courses. It happens. [1] - https://openstax.org/subjects/math reply dcw303 8 hours agoprevI've been doing similar for about a year. My target is to learn the math needed to make 3d games, so basically algebra, geometry, calculus and linear algebra. I started with brilliant.org, and while I liked the level of polish in the interactive lessons, I found the lesson structure to be out of sequence, often referring to things that haven't been covered yet. They didn't seem to have put as much thought into pedagogy as Math Academy as described in TFA. So I gave up on that and instead have been shipping several kilograms of dead tree across the pacific in the form of The Art Of Problem Solving series of textbooks. They are great, the lesson structure and building up of complex ideas from first principles is outstanding. They will humble you though, as the exercises are tough. They're also quite expensive but IMHO worth it. Math Academy does look interesting, If I was not halfway through my series I would probably take a look. But I do enjoy having reference books on hand. Many times I've jumped back to brush up on a topic that has slipped from memory. I solve my exercises with the most low tech solution possible, but I like the freedom it gives me to try new approaches, and nothing beats the latency between idea to ink on paper. edit: also wanted to add that I've enrolled Chat GPT4 as my tutor. Contrary to many other's experiences that I've read, I find it to generally be very good at reasoning in this level of mathematics. It's helped me many times when I've gotten stuck. And on the occasions where it bullshitted its way to an incorrect answer, I always challenge it if I don't understand, and we ultimately find out if it hallucinated something (rare, can usually be fixed by restating the problem), or I gave it the wrong input to start with (unfortunately more common than I'd like) reply pvg 7 hours agoparentAre you using any of the stuff you're learning for whatever practical 3d game-making things you're working on? Just curious how it's working out, you've picked a pretty broad foundation as a starting point. reply dcw303 6 hours agorootparentI took a brief detour late last year to study \"Linear Algebra: Theory, Intuition, Code\", and to my surprise it stuck pretty well. The author said the pre-reqs were just \"basic high school math\", but I'm glad I had recently done lots of algebra and geometry, as the difference between that and some vague memories of stuff I did 30 years ago in school is pretty wide. I haven't started any 3d game projects yet. For that, my plan is to do the webgpufundamentals.org course first. Scanning the TOC, I think I would be able to attempt it from what I learned from the linear algebra book. That said, I'm doing AOPS Intermediate Algebra at the moment, and the Precalc text covers more advanced trig and matrix stuff, so I'm thinking it would be good to finish at least to there before starting to apply the knowledge. reply pvg 3 hours agorootparentYeah, it sounds like you're not far from the point where you can start jumping ahead and working backwards to fill in the bits that you're missing - that's what many people naturally and instinctively try and it can work but can also be frustrating if one misjudges one's degree of proficiency. You don't often see 'I'm just going to give myself a full secondary school maths refresher' which is more demanding on time and self-discipline but at least we know it's pretty reliable given those things. reply AlchemistCamp 7 hours agoparentprevI totally agree with you on the value in using Chat GTP when stuck. What's the scope of The Art of Problem Solving? How far does the series go? reply dcw303 7 hours agorootparentAOPS audience is gifted high school kids, so it doesn't get up to the college level. The core texts are: - Prealgebra - Intro to Algebra - Intro to Counting & Probability - Intro to Geometry - Intro to Number Theory - Intermediate Algebra - Intermediate Counting & Probability - Precalculus - Calculus reply lordnacho 1 hour agorootparentI bought the whole set for my kid. He's also doing Brilliant. It starts at somewhere that the kids are at the end of primary school (at least in the UK) and ends somewhere in high school. My kid could already do all the pre-algebra stuff, so that book went fast. The way I see it, the kids waste a lot of time in the middle years when they already know the arithmetic and pre-algebra, but might as well be doing a bunch of more interesting things. reply AlchemistCamp 7 hours agorootparentprevAh, okay. I actually took calculus in 8th grade. I studied another two years past that, dropped out, and then later did a complete 180 and graduated with a literature degree. I'm now over 40 and interested in relearning the math I learned long ago and pushing a bit further than I had before. reply aoki 6 hours agorootparentThereâ€™s also an intermediate number theory class thatâ€™s basically at the level of a college elementary NT course (one that does not assume abstract algebra), an Olympiad geometry class, and a group theory class. The first two do not have a text, the third has a text but you canâ€™t get it without enrolling. reply MrVitaliy 4 hours agorootparentprevI think it's a weird way to learn math, and I learned it this way in school. Most of these courses just teach information memorization and recall. sin(x)^2 + cos(x)^2 = 1, etc. I would start with something like Elementary Analysis: The Theory of Calculus, and work from there. You'll eventually arrive at the same place -- Calculus but from a much stronger mathematical foundation. reply dcw303 3 hours agorootparentI have not found that to be the case, the books I have read have gone into deep foundational detail to build up knowledge. Perhaps you're referring to Vol 1 & 2 of \"The Art Of Problem Solving\"? I haven't read them but from what I know they are a distillation of core concepts for students looking to do competitive maths. It's confusing because that title is also the name of the publisher / website of the series of the books I'm reading. reply ammasant 4 hours agorootparentprevYou learned using the AOPS books? Don't be fooled by the titles, these books exclusively use a proof-based approach to construct a pretty wide foundation around these topics. reply elteto 7 hours agorootparentprevAre you doing the online classes or only the books? I wanted to register for the online classes but they seem to be heavily oriented towards interactive learning. reply aoki 6 hours agorootparentThe ones that have â€œinstructorsâ€ and class times have chat-based sessions that you can skip if you prefer. Part of the homework is based on an adaptive problem system (Alcumus, which you can actually use for free) and part is weekly problem sets mostly based on the textbook. Writing (proof) problems are graded by a human so it is a useful way to get feedback on your proof-writing skills (if you know you are worse at it than a college math major). reply dcw303 7 hours agorootparentprevJust self study with the (physical) books. I did also try the ebook combo for the Prealgebra book, but I found typing latex in the answers to the exercises was cumbersome. I think the online classes with interactive lessons is a separate thing, but I don't have any experience with that. reply ginbazinga 4 hours agoprevIf OP still wants to learn the mathematical foundation of transformers, I built a free alternative learning tool: https://afaik.io/nebula?mode=nebula&category=blueprint&id=ed... It's also based on an underlying knowledge graph, connecting concepts across various subjects like maths, machine learning, physics, etc. You can check the graph for transformer here: https://afaik.io/nebula?category=brickset&id=VLlOnZLl&mode=d... (only available on desktop... Basically, it frees you from learning maths from scratch and just learning the prerequisites required to grasp the concept, and there are free resources attached. Don't get me wrong, I can totally relate to the desire to relearn maths. One of the reasons that I'm building this tool is for me to relearn physics and know how to get there with my maths and cs background. I just feel in this specific scenario there might be more effective ways to learn in depth and have fun at the same time. reply galaxyLogic 3 hours agoparentI find the concept of \"underlying knowledge graph\" interesting. What does it mean? I assume it means such a graph connects the topics together as \"pre-requisites\". To understand A you need to already understand B and C, and to understand B you need to understand D and ... etc. But the thing about such a graph is that really it must be a tree, not just a directed graph. Why? Because there cannot be cycles in it. If to understand A you need to understand B, and to understand B you would need to understand A, you could never understand either of them. Right? reply ginnungagap 2 hours agorootparentIf to understand D you need to know both B and C, each of which requires familiarity with A, the graph is not a tree reply viraptor 39 minutes agorootparentprev> it must be a tree, not just a directed graph It may be a tree. But it must be a DAG (directed acyclic graph). reply boxfire 8 hours agoprevI may be biased as I am a trained Mathematician, but I always feel when someone says \"Math is Hard\", that is because they had bad teachers. Math is easy if you build up from fundamentals, not like physics education where you say \"but lets delete everything before because it had an oversimplifying assumption\", rather if you build your knowledge entirely sequentially from things you know or assume, you build up a toolbag that applies literally everywhere. So math isnt hard. Learning random bits of math out of context is hard. Climb the ladder once, you have it for life. Hopefully for this person that sticks. reply MrDresden 1 hour agoparent> ... it is because they had bad teachers. > Math is easy if... The one constant I observed in most parts of my mathamatics journey (math major in college, software engineering & computer science at university) was the lack of understanding by the person doing the math teaching that not everyone will be able to follow along if steps in the ladder are missing. Words and sentences like 'it is obvious', 'clearly', 'as can be seen' should be avoided when teaching someone a subject as abstract as mathematics as inevitably you are not fully realising the size of the gap in knowledge between you and your students and how such statements can leave them feeling frustrated. reply hiAndrewQuinn 17 minutes agoparentprevI'll bite, I think this is mostly bias. Strong evidence against this is that the average IQ of a mathematics undergraduate is, like, 125 or so, compared to ~115 for the average college graduate - that is just way too sizeable a difference to be explained by chance. Math really does seem just plain hard for a great many people. It seems to me from having done some math on the inside like it also would get harder with each point downward in IQ than at a faster rate than most other valuable things in life. reply baq 27 minutes agoparentprevIMHO when people say 'math is hard' they mean 'it takes more work than other subjects to be good at' - you're either a prodigy or you grind problems until you get the intuition. The easier subjects you can usually talk everyone and yourself into thinking you know them, or perhaps the ratio of memoization to practice is skewed more towards memoization. Maths is practice, practice, practice and then some more practice - blood, sweat and tears. reply hintymad 8 hours agoparentprev> Math is easy if you build up from fundamentals To a certain point, I guess. Most people hit a wall of abstraction at some point, either because the abstraction is too hard or because the abstraction stops being relevant so the person loses drive to learn. For me, the wall is model theory and the second course of abstract algebra. They are both too hard and too abstract for me to push through. reply ChainOfFools 6 hours agorootparent> abstraction stops being relevant I found this to be the points where abstractions being learned today are only precursors for abstractions that will be learned tomorrow. Another way to put it is at the stage where you're learning to make tools that are themselves only used to make other tools, not used to get results outside of the domain of tool making. These stages have no apparent relevance outside of math, and if your style of memory formation depends on making many inferential links to laterally associated concepts, moreso than making a few direct links between vertically associated concepts, it can be rough going. A lot of what feels like following memorized pirate treasure map directions in the dark, with no sense of what obstacles you're working around or even the general direction where the treasure lies to give you a sense of bearing and progress. reply galaxyLogic 3 hours agorootparentI remember memorizing multiplication tables in school. I learned that 3 x 9 = 27. You just had to memorize that, right? Well then I realized that if 3 x 10 = 30, then 3 x 9 must be one fewer '3' added together by the multiplication, which means take out one '3' from the set of 3s you are adding together by multiplication when doing 3 x 10, which comes to 30 - 3 = 27. That means I didn't really need to memorize 3 x 9, I needed the above simple rule in addition to the fact that n x 10 is always what you get when you take the digit 'n' and add a 0 after it. So learning multiplication tables was hard, until I learned the rule of looking for an easier-to-remember result and then adding or subtracting something to it. Of course I also had to understand that multiplication is really just repeated addition. My teacher never taught me this trick, just told us to recite the multiplication tables in out heads again and again. But after doing that for some time I figured out the above trick myself. Learning math beyond multiplication is hard if you cannot multiply numbers in your head, because lots of math presentations assume that of course you know that 3 x 9 = 27. Or something similar. It is not just about understanding the concepts, it's about being able to perform calculations, in your head. Else you cannot understand the explanations of new concepts. Even though we have pocket-calculators, we still need to be able to do calculations in our heads to understand new topics. in math. So, learning what is 3 x 9 is not hard AFTER you have learned n * 10, and this trick. I assume something like that happens in the minds of mathematicians. They know a lot of math already which makes it easier to understand new results when they already know a lot. To learn what is n * 10, you had to learn 1 x 10, 2 x 10, 3 x 10 etc. and then understand the pattern in there. Learning something is easy if you already know lots of related stuff. So it's not about learning more and more difficult things, it is about just learning more and more, related things. It is about having more and more (learned) data in your head. I assume that is also why LLMs work so well: They have lots of data. In summary: Learning math is not \"difficult\", it is tedious. reply trws 8 hours agoparentprevI probably had crummy teachers in some places, but my experience was that math up through linear algebra made sense and wasnâ€™t all that bad, but that calculus was a huge bag of â€œif it looks kinda like this try this thing, and if the result looks kinda right it probably worked, if not try this other thingâ€ such that I could never form a framework for it in my head. Also didnâ€™t help when teachers in some things would say â€œoh this is much easier and more straightforward with calculusâ€, even without a prerequisite for it, and proceed to only explain concepts with calculus half or more of the class had never learned. One of these days I need to find a way to get it the right way. reply tnecniv 8 hours agorootparentIn hindsight, thatâ€™s because high school calculus doesnâ€™t teach you how things work and just teaches you a bag of tricks so you can grind through problems. Thereâ€™s a certain number of tricks you should know, I.e., you should be able to take some simple integrals and derivatives, but for higher math, you run into complicated things where the tricks donâ€™t work or donâ€™t exist. Some of the tricks are actually really useful, but you have to fully internalize where they come from, e.g., integration by parts just comes from rearranging the chain rule, and, if you know that, you can apply it to more exotic derivatives. I did well in HS calculus but struggled in college math because the bag of tricks approach doesnâ€™t work there. It took a lot of effort for me to undo the bad habits I learned from K-12 math and learn the good stuff, but it paid off. Also, itâ€™s well known that eventually professional mathematicians hate certain kinds of math. Thereâ€™s the classic divide between analysists (those that do calculus-type stuff) and algebrists (those that do things like group theory, and linear algebra goes here). You donâ€™t have to like it all, and something you donâ€™t appreciate the first time you see it, you may enjoy later reply cloogshicer 8 hours agoparentprevThis assumes that climbing the ladder comes easy. To me at least, it doesn't. It requires tedious labor, and lots of repetition for every single step. That's the main difference I keep noticing between me and people who say they like math or find it easy. They just look at each step of the ladder once, and immediately \"get\" it, sometimes even skipping steps. In contrast, I need to repeatedly step up and down the ladder multiple times, until I can take the next step. reply dcw303 7 hours agorootparentMy theory is that people who like math have a reward system that responds well to gaining an understanding on empirical concepts. I have that, and it does drive me to keep studying math. Not that I find it easy though, I don't think I'm able to skip steps, and I often have to repeat things I've already done before they sink in. The difference is that I find this process enjoyable, so I don't mind spending the time. If I can compare to another activity, I've always wanted to be an artist as well, and have spend quite a bit of time trying to build up the skills. The problem is that, if I'm honest with myself, is I just don't enjoy the process of creative expression, it doesn't trigger any reward system that means anything for me. I wish it did but there's just nothing there. It was a hard pill to swallow, but I realized I like the idea of being an artist, but I don't enjoy the process. Hence my ultimately crummy artwork! Sorry, I realized I'm talking about myself more than you, but I hope it's some help. The point I hope it makes is that everyone has a different personality, and from that different reward systems. It sounds to me like yours doesn't align with math, and that's fine. I wouldn't try to force yourself to study something which you don't love, at least if it's optional self study. Find subjects that you love learning, and the results will come naturally. reply davorak 7 hours agorootparent> The difference is that I find this process enjoyable, so I don't mind spending the time. This is definitely the difference for at least some of the people out there, however... Imagine however that you do enjoy it at the start so you move on from topic Y to topic Y+1, then to to Y+2. However you find that you no longer understand Y and you need Y when you are doing trying to learn Y+3 so you study Y+3 and Y, now your progress in Y+3 has been slowed down. Really your goal was to get o Y+7 though that is where you can start breaking new ground and contributing but as you try Y+4 and Y+5 the gains stop and maybe even reverse. You are now on a learning treadmill(perhaps sometimes falling off and having to restart too) redoing Y-1,2,3,4,5 not moving forward. Often it is possible to find a trick/skill/simplification/etc to continue moving forward to get to Y+6,7. How long would you find the process fun on that treadmill though? I think it is common to not find covering the same ground over and over fun or never being able to make it to the point where you are part of peer group where you can contribute. An understandable result is when those people invest elsewhere, where they see better returns. reply jacquesm 7 hours agoparentprev> I may be biased as I am a trained Mathematician, but I always feel when someone says \"Math is Hard\", that is because they had bad teachers. You're biased. I've had excellent teachers, math was - and still is - hard. Especially when you get into the more complex stuff. Not everybody is as gifted at math as you are. reply nextlevelwizard 2 hours agorootparentCompletely disagree. Problem with (at least) math is that you want a teacher is not super good at math, but still knows what they are teaching. When you get taught by a brilliant match wiz teacher they skip over the stuff that is obvious to them, but what is probably crucial for mere mortals. I have had teachers who just blew over the simple stuff because they didnt care about it and focused on the interesting hard stuff, which felt a lot of people behind and also with actually good teachers who focused on the \"easy stuff\" to build a strong foundation before moving to the harder stuff. reply jacquesm 2 hours agorootparentI wrote \"I had excellent teachers\", not that they were super good at math. reply nextlevelwizard 2 hours agorootparentyou also wrote other stuff......... reply instaheat 4 hours agoprevThis post couldn't be any more timely. I dropped out of school years ago (16 years ago to be exact) to take care of my sick mother when she was dying. I never went back. I just started working. I am happy to report I am back in school and will be FINALLY finishing my Computer Science degree but I have a very long 4 years ahead of me. Math is going to be hard. What is encouraging is the thrill of when I get the answer right and most importantly knowing HOW I got there. It's (almost) better than sex. reply nicholasbraker 1 hour agoprevI work in IT as a network architect and when I tell people I graduated high school with one F on my final list being math they frown a bit. In my high- schooldays (90'ies era) they made a distinction between \"math-A\" which was more statistics and \"math-B\" which was more algebra and calculus. I really sucked at math-A which was considered by some as not even real math. I will definitely check this one out and hope to improve this even now in my 40'ies.. reply sarchertech 7 hours agoprevWhen I went back to school for CS, I used this book https://a.co/d/7hlRdnK to relearn math. I couldnâ€™t recommend it more. It starts with algebra and works through calculus. There is a pretest before every section, so you know what you need to focus on and what you can skip. reply rtpg 3 hours agoprevSelf-learning is the sort of thing where you really want to be pointed to the right books. Some books are really good if you have people you can ask questions too, but those might not work at all without that. Meanwhile, others truly are a \"lock yourself in a room for a couple of weeks and process it\" thing. One side thing I've been thinking of to try and tackle this is an autodictact's version of letterboxd: have people talk about books and resources they're using, offer help to one another, and maybe help people discover interesting things to poke at. At the very least it would help me track my own in-progress material reply jb3689 1 hour agoprevLearning grade school math wonâ€™t really help you understand these things. Yes, you will learn to think numerically and practice applying opaque algorithms, but youâ€™d be better off starting with basic set theory and logic and learning â€œrealâ€ math. Book of Proof is one of my personal favorites. Then you can move onto some Real Analysis while brushing up on Calculus, then maybe consider formal probability starting to learn the foundations reply hintymad 8 hours agoprevIt looks how do do proofs is at university level in the US. I wonder why other countries start to teach kids how to do proofs from grade 7. They start with rigorous proofs in Euclidean geometry, the move to solid geometry, then to proofs in elementary functions, sets, number theories, and etc, then to polynomials and simple discrete maths and analytic geometry. By the time a kid graduates high school. using things like proof by induction or by contradiction is like a second nature. And no, I'm not talking about elite kids, but curriculum requirements for all the STEM students. reply redcobra762 8 hours agoparentWe did proofs in 7th grade as part of geometry, in a semi-rural United States middle school. reply hintymad 8 hours agorootparentGood to know. I guess education in the US has local standards? I have this impression of the US not teaching proof because in a number of introductory math classes in my college, the profs dedicated chapters to teach basics of induction, how to write proofs, and etc. reply Jtsummers 8 hours agorootparentEvery state sets its own curriculum, with varying degrees of freedom for the districts and schools within the states. The federal level has standards, which students are generally tested against in various standardized tests, that are tied to federal funding. Multiple curricula can satisfy the same standards, at least on paper if not in practice. So states are, more or less, free to teach things how they want. However, they're also strongly driven by the textbook industry, which turns on the two biggest textbook purchasers: Texas and California. So a lot of the textbooks (and associated curriculum material) available for purchase in the rest of the states are driven by whatever those two states are pushing. reply redcobra762 7 hours agorootparentprevI would have still appreciated that refresher in a college class on content I learned 7-8 years prior. reply AlchemistCamp 6 hours agorootparentprev> I guess education in the US has local standards? Very much so! The US didnâ€™t have a Department of Education until the 90s. reply Jtsummers 6 hours agorootparent90s? You're off by a bit. The current Department of Education started in 1980, but it came out of the Department of Health, Education, and Welfare, founded in 1953. That, in turn, came out of the FSA which included an Office of Education (1939). Prior to that, the Office of Education had been part of the Department of the Interior. Before that it was its own Department, starting in 1867. Though \"90s\" is delightfully vague. You're either off by nearly 1800 years, you're very old and meant 1890s and were only off by a few years, or you really meant the 1990s and were off by nearly 130 years. reply aoki 6 hours agorootparentprevThe â€œstandardâ€ place for geometry is 10th grade (after algebra 1 in 9th grade). A few geometric ideas have been moved from geometry to algebra 1 so that slope can be explained using similar triangles but this is just about memorizing explanations instead of doing proofs. Today, if you arenâ€™t in an honors geometry section, you likely learn a handwavy version of two-column proofs and do some pretty linear proofs that way. No symbolic logic, no mathematical writing. reply mech422 7 hours agorootparentprevCan't say I remember 7th grade ... but we were doing proofs in Geometry in High School. I also lived in a semi-rural US neighborhood. reply aoki 6 hours agorootparent10th grade is the â€œon levelâ€ time to take geometry. reply ajmurmann 4 hours agorootparentSo US school kids don't encounter any geometry in school till they are ~16? reply wharvle 2 hours agorootparentShapes, areas of simple polygons and circles, Pythagorean theorem, volume of solids, graphing, translation, all that stuff and more that one might call â€œgeometryâ€, is scattered between roughly ages 6 and 12. I think the high school level â€œgeometryâ€ classâ€”which may be the only one named such, but primary school math is full of geometryâ€”is an atrophied organ left over from when it was still common to teach directly from Euclid, which is why it tends be about introducing proofs more than covering new abilities and techniques in geometry (though it may cover some of that, too) reply Jtsummers 3 hours agorootparentprevNo. The formal geometry class is usually age 14/15 (first or second year of high school). They should have seen a less formal treatment of geometry before then, though they may not know it. reply Tainnor 7 hours agoparentprevwhich other countries? that's certainly not the case in Germany. you might see some proofs in geometry, and maybe some informal derivations of things later on, but \"induction\" is a university level thing (it's possible that some kids that focus more on maths in school see this kind of stuff earlier, but it's definitely not a universal experience). reply UncleOxidant 7 hours agoprevSo... basically an ad for Math Academy? How about some free resources like Khan Academy? reply juunpp 7 hours agoparentThat's basically what it is. There is nothing to learn from this post other than \"smash that beta sign-up button\". Has anyone tried that course? Is it any good? reply bambataa 21 minutes agorootparentI have been doing the Math for ML course and would recommend. I have UK A level math but not Further Math, so up to basic calculus. But I forgot most of it and so Math Academy has me going through a lot of the Math Foundation units along the way. I was initially put off by the monthly price, as it is quite steep. The clincher is that about a year before starting Math Academy I had gone through the Open Universityâ€™s MST124/125 textbooks (covering the same stuff as Foundations). Except even after a year Iâ€™d already forgotten most of it. Math Academy learning feels much more robust, since it includes spaced reviews and regular tests. I record things in Anki but itâ€™s useful to have regular practice questions too. I also use ChatGPT to spell out things and find it works well at this level. Some things Iâ€™d like Math Academy to have: - ability to skip lessons (I donâ€™t want to spend ages going over symbolic integration again) - a reference page to track unlocked material, maybe with Anki integration - fewer multiple choice questions and more in depth problems - proof-based math. Iâ€™m told this is coming but the degree-level courses have missed their estimated due dates. I will definitely finish Math for ML and then do linear algebra and multivariate calculus. Youâ€™d still need a good textbook to do them rigorously, but I think Math Academy sets you up well. reply eps 46 minutes agorootparentprevYes, it's very good. Math Academy is much more dense and on-point that Khan's. You don't have to sit through 15 minutes of video when 2 minutes worth of text explanation does it. It uses spaced repetition for topics that you aren't good at, and for recently learned subjects. The topic dependency tree and automatic progressing to \"unlocked\" topics is obvious in retrospect, but here it's done very cleanly and unobtrusively. The initial evaluation test is worth its weight in gold. It eliminates the need to grind through things that you already know, but still covers any gaps. I had kids on Khan for few weeks and it was a hassle. The pace was too slow, too much time sunk into trivialities and they were bored most of the time. With Math Academy they sit down, they do their 20-30 min of focused hands-on effort and they are done for the day. reply AlchemistCamp 7 hours agorootparentprevI did a year and a half ago before getting too busy with work. I found it to be a bit spartan, but still the most efficient tool for math study I've used. I was a math major long ago, so it was more a case of relearning than initial learning for me but the built-in SRS helped a lot and so did the granularity of the lessons. It's head and shoulders above Brilliant, IMO. If it didn't exist or I couldn't afford it, I'd probably go the OpenCourseWare approach. https://ocw.mit.edu/ reply viraptor 7 hours agorootparentprevIt's really good for its goals. I've used it for a few months and was really happy with the results. The spaced repetition aspect worked perfectly. The courses are still being worked on - already 99% there with quality, but you can report any issues and they get fixed. Just keep in mind that the target is largely students, (at least at the moment) so the aim is mastery of the subject - if you're interested in learning the concept but not actually doing a lot of practice of using it, then it may not be the right service. And there are magic internet points / leaderboards if gamification is something that works for you. The exercise sizes are also very small almost all the time. That means instead of a whole topic at the time and figuring out where you left the last time, you can do as much as you want at a time and not be restricted by artificial \"chapters\". reply mabedan 1 hour agoprevI tried math academy for this exact purpose, but I had to give up because it didn't let me test out of lessons that I was already good at (Similar to how duolingo would allow you to do). So I ended up wasting a lot of time sitting through all the exercises which I didn't need. reply eps 54 minutes agoparentYou could've asked them to add this option. They are very responsive and reasonable. reply mabedan 34 minutes agorootparentI did. They replied a generic corporate answer that we do the best for our customers and they said Iâ€™m free to cancel my subscription reply jacquesm 7 hours agoprevBefore you look into paid options for your tuition needs I'd look into the Khan Academy first. It's free, very high quality and it's more than just math if you want it. Sal Khan is one of the greats and the Khan Academy, together with WikiPedia is one of the best things to come out of the internet. reply eps 35 minutes agoparentKhan Academy is good and free, but it is inferior to Math Academy in many aspects. It's more tedious, takes more time and, most importantly, it's not as streamlined, as guided and as fuss-free as the MA. The latter got the process and the UX absolutely nailed down. All the praises you read and hear are 100% deserved. reply gsdgsdfg 3 hours agoprevPeople here mention KhanAcademy and AOPS series for self learning. I've used both when relearning Math as an adult. But there is one more resource which is absolutely terrific: Henry Sinclair Hall's books. Not only they are good (way better than the aforementioned ones), but being published in the 19th century, they are in public domain now and can be downloaded from the Internet Archive free of charge: https://archive.org/search?query=creator%3A%22Hall%2C+H.+S.+... And, also, How to Prove it by Velleman is a must read. reply rck 7 hours agoprevTangential, but: the notes that this post refers to are probably not the best way to learn how transformers work. If you want mathematical precision, those notes are based on this paper from DeepMind: https://arxiv.org/abs/2207.09238 The paper provides mathematically precise definitions of all the parts of a transformers, though it's showing its age (ha!) in that it doesn't include some formalizations that are common in, for example, Llama. reply jasfi 3 hours agoprevSome years ago I got back into math basics, so I could do mental math as a hobby. I'm still doing it today, nearly daily. I've also added crosswords. I've found that this helps to keep me sharp (I'm in my 40s), and should help me even more as the years go by. reply fiforpg 8 hours agoprev> but I needed a good reason that would justify the time investment It should be understood though that there are cases when math(-like) language is abused, leading to overcomplication and obscurantism [1]. In mathematics, there is always the temptation of formalizing for formalization's sake. Indeed, 99% of pure math is non-constructive (\"there exists a group such that\", \"the algorithm converges in O(N) steps\"), as opposed to the practical CS and applied math (\"here are the runtimes on real world data\") which are likely the primary concerns of the HN crowd. None of this can diminish the sheer impractical appeal of pure math and pure CS, not unlike that of poetry, but I would rather not oversell either of the two. [1] A good illustration is a rant by Cosma Shalizi at http://bactra.org/notebooks/nn-attention-and-transformers.ht..., recently posted on HN. reply Tainnor 7 hours agoparentTo this day, I fail to understand why some people cannot enjoy constructive mathematics or practical engineering without shitting on traditional maths or CS. The \"runtime on real data\" thing is a trope by now, an algorithm that is exponential is in general not going to miraculously be very fast on \"real-world\" data, and even if it is, chances are, it won't be anymore once you change your data (with some few exceptions like the Simplex algorithm). reply bsdpufferfish 7 hours agoparentprev> leading to overcomplication and obscurantism Mathematicians attempt to express ideas in the most readable and clear way possible. It's actually code that must be obfuscated by the constraints of the language and computer. Mathematicians have no constraints preventing them from presenting something in the way that makes the most sense. The part that can be called \"Obscurantism\" is when they use a high-level abstraction you are unfamiliar with. This is mostly driven by the audience. > Indeed, 99% of pure math is non-constructive Citation needed? > the algorithm converges in O(N) steps That doesn't sound non-constructive. Even the group example is usually done by constructing such a group. Also the best part about math is you can use it to approach the problems you want with constraints you want. Knuth uses math to solve real CS problems. reply davorak 7 hours agorootparent> Mathematicians attempt to express ideas in the most readable and clear way possible. I buy this from the mathematicians and scientists that I know and have interacted with. I also think mathematicians spend more time trying to discover/play with new math than optimizing the communication of what already exists and is communicable. My speculation is that this naturally leads cruft that needs to be worked through by people entering the field. The cruft can not get too big or people don't enter the field so people are motivated to keep the cruft below a certain level but not the minimum. The cruft makes it harder to enter the field and once you have over come that hurdle you move on to do things in the field not reduce the cruft. Other things that make it hard to reduce cruft 1. not everyone is going to agree what is cruft 2. Person X spend time on reducing cruft in sub field Y may find out that Y is no longer hot topic so while there is less cruft there are not many people taking advantage of the reduced cruft in Y. 3. Mathematicians and scientists are reward more for new and interesting things than better pedagogical practice/techniques. 4. Optimizing for communication/pedagogy is mostly a different skill than science/mathematics so you have to split your focus or not dive as deeply into one or both. 5. I am sure there are others. This seems reasonable to me. It is s system where most everyone is well meaning and want to improve things and where things do improve over time, but where it is still easy to find areas that would benefit from substantial from improvement. reply nyssos 4 hours agoparentprev> Indeed, 99% of pure math is non-constructive (\"there exists a group such that\", \"the algorithm converges in O(N) steps\") Almost all mathematicians work with classical logic, but that doesn't mean that they always use all of its power. On the contrary, most of what you would see in an undergrad math program goes through constructively with at most a few minor modifications. reply raincole 7 hours agoparentprevMan, this article is an ad for Math Academy. I'm 100% sure that at the level of what Math Academy teaches, you don't need to worry about \"non-constructive\" or \"pure math\". reply pmdulaney 12 hours agoprevThis is inspiring! I think your realistic, keep-plugging-away attitude will lead to continued success. The cost is $49/month/student. reply maroonblazer 7 hours agoprev>> The â€˜Foundation Seriesâ€˜ is what Iâ€™m starting with. Itâ€™s for adults to help streamline learning (it skips the stuff that kids need, but adults donâ€™t) and work back up through college-level math relatively quickly (emphasis on relatively ). I'm curious to know what 'stuff' he's referring to. And what about it makes it such that kids need it but adults don't. And if that's true, are we SURE kids need it? I had horrible math teachers growing up and always thought \"I just don't have the 'math gene'.\" I eventually disabused myself of that thought and set out on my own (re)learning journey. Could it have been less arduous had I skipped the stuff I didn't need to know because I was an adult? reply JustinSkycak 7 hours agoparentHi there, my name is Justin Skycak, I'm the Director of Analytics & Algorithms at Math Academy. I can speak a bit as to the stuff that's skipped in the Foundation Series. After developing a curriculum that covers all the standards for 4th grade through AP Calculus BC, as well as plenty of advanced university courses (many of which are still under construction, but the structure is mapped out pretty comprehensively), we found that roughly a third of 4th grade through AP Calculus BC topics were not actually prerequisites for university math. So, we created a streamlined Mathematical Foundations course sequence that cuts out those topics. Those topics are necessary to check the box on grade-level / common core standards, but they're not really necessary for adult learners who want to pursue advanced university courses as soon as possible but lack the necessary foundational knowledge. I'll also send your question to my colleague Alex Smith, our Director of Content, who designed the Mathematical Foundations courses himself and can elaborate more on the specifics. reply ramblenode 5 hours agorootparentThanks for responding. What are some examples of topics that you cut out from the high school math curricula? I have seen modern Algebra II courses remove conic sections in order to make more room for probability and statistics. reply Math-Ninja 1 hour agorootparentHi, I'm Alex, curriculum director at Math Academy. As Justin mentioned, there are several criteria that we must meet in our high-school pathway that aren't needed for studying higher-level (e.g., undergraduate) math, or they can be postponed. We decided to remove some of these in the Foundations series. The idea behind the foundations series is to provide adult learners with the most efficient path possible to get onto the higher-level material. Examples of topics that were removed from the high-school series to create the foundations series include some of the following: * Various Geometry topics: All of the _essential_ geometry is covered. However, we removed topics on inscribed angles, Thales' Theorem, Triangle congruence, and similarity criteria (apart from the AA, which is the only one that seems to come up in practice), midpoint and triangle proportionality theorems, a fair amount of solid geometry, except what's fairly standard for calculus (volumes and surface areas of spheres, volumes of cones), lots of stuff on different types of quadrilaterals. * Conic sections: The essentials are covered in both pathways. But in the high-school path, we go into a little more detail about foci, directrices, eccentricity, and utilizing their geometric definitions (e.g., focus-directrix properties). * Trig identities and Equations: Covered in both pathways, but the high-school versions go into more detail and consider more cases. * Some word problem/modeling topics. * Other arbitrary Prealgebra topics: Divisibility rules, going into more detail about ratios in contextual settings, scientific notation, and some basic data representation topics that one would normally meet in Prealgebra. * Slope fields. This will be covered in our upcoming differential equations course. * Some analytical applications of differentiation that are quite specific to the BC Calculus exam: Identifying and removing point, jump, and infinite discontinuities and analyzing graphs of first and second derivatives. * There are also fewer topics on related rates and optimization, though these topics are still covered. * Some contextual applications of integration, like volumes of revolution and volumes of known cross-sections. * Convergence tests for infinite series. When we get to that, these will be covered in real analysis, but other than infinite geometric series (which _is_ covered in Foundations), these tests don't show up too often anywhere else. * Some ODE models, such as exponential and logistic growth and decay. We cover ODE basics in the foundations course, but particular models will be covered in the differential equations course. * Taylor series. Again, this can be covered in the differential equations course for anyone wishing to take that course when it's ready. Happy to answer any further questions you may have. reply BOOSTERHIDROGEN 7 hours agoprevCan OP now understand the decoder architecture? I would be interested in a follow-up post. reply gmays 5 hours agoparentNot likely yet, I'm still working through the Mathematical Foundations courses before I earn my way up to the Mathematics for Machine Learning course. I would love to do a follow-up post at some point. reply moi2388 2 hours agoprev50 a month for what Khan academy does for free? Ads do be getting smarter, albeit more annoying reply corethree 43 minutes agoprevUse chatgpt. The math isn't actually hard, it's just the person who wrote it wants to look smart so he makes it hard by writing it in a mishmash of formal notation. There's a lot of domain specific stuff too that a straight up math major won't understand. reply jrnichols 5 hours agoprevKhan Academy worked for me and has a bunch of other fun classes too. reply thefz 25 minutes agoprevAd in disguise. reply TotoHorner 8 hours agoprevCan anyone help me with some questions about this program? (I assume the founders will see this thread once they notice the HN hug of death) 1. How exactly is AI being used here? Is there an AI chat-bot that I can ask for help? Do you generate problem-sets with AI? Check answers with AI? Is it GPT-4? 2. Do you utilize Spaced-Repetition in any way? Have you found that to be useful? Thank you reply JustinSkycak 7 hours agoparentHi there, my name is Justin Skycak, I'm the Director of Analytics & Algorithms at Math Academy, I developed all of our quantitative software, and I'd be happy to answer your questions. 1. The AI is more like an expert system that emulates the decisions of an expert tutor with regard to what tasks a student should work on at any given point in time (what should the student learn next, what do they need to review). There's a knowledge graph that encodes structural relationships between thousands of math topics (such as prerequisite relationships, but also other types). And then there's an algorithmic reasoning system that looks at a student's answers, overlays them on the knowledge graph, figures out what the student knows (and how well they know it), and decides what learning tasks are going to move the needle most given their personal knowledge profile. The decision-making is inspired by cognitive learning strategies such as mastery learning, spaced repetition, interleaving, minimizing associative interference. 2. Yes, spaced repetition is a core part of the system. Each student has a personalized spaced repetition schedule that adapts to their performance on each topic, and when choosing what topics a student should review or learn next, we're always trying to implicitly \"knock out\" as many due reviews as possible to maximize learning efficiency. (For instance, if a student is due for a review on one-step ax=b equations, we can implicitly \"knock out\" that review by having them learn two-step ax+b=c equations instead.) From a quantitative standpoint, the spaced repetition model was one of the more challenging (but equally fun) parts to build. You normally think of spaced repetition in the context of independent flashcards, but in a hierarchical body of knowledge like mathematics, it gets really complicated because repetitions on advanced topics should \"trickle down\" to update the repetition schedules of simpler topics that are implicitly practiced (while being discounted appropriately since these repetitions are often too early to count for full credit towards the next repetition). Our spaced repetition model not only accounts for implicit \"trickle-down\" repetitions but also minimizes the number of reviews by choosing reviews whose implicit repetitions \"knock out\" other due reviews (like dominos), and calibrates the speed of the spaced repetition process to each individual student on each individual topic (student ability and topic difficulty are competing factors). reply jacquesm 7 hours agorootparentWhy am I not surprised that a marketeer shows up in an 'organic' posting about a company. reply gmays 5 hours agorootparentFYI this is the guy that wrote the comment you replied to: https://www.justinmath.com He's true math nerd, and definitely not a marketer. In fact, I don't think a single marketer works at the company. It's a bootstrapped labor of love and I've been following their journey for almost a decade. I get the skepticism, but some things are legit. reply jacquesm 3 hours agorootparentI'm sure there are math nerds that work in marketing. Your whole blog post comes across as an advert, that may not have been your intention but that's what it looks like to me, legit or not. reply eps 33 minutes agorootparentprevDon't be nasty. Especially ridiculing a tech person giving detailed and interesting answers as a \"marketeer\". reply TotoHorner 2 hours agorootparentprevVery cool! Thanks for the reply. It would be awesome if you could also add GPT-4 as a kind of helpful tutor. Not sure if you're already experimenting with that. > Our spaced repetition model not only accounts for implicit \"trickle-down\" repetitions but also minimizes the number of reviews by choosing reviews whose implicit repetitions \"knock out\" other due reviews (like dominos), and calibrates the speed of the spaced repetition process to each individual student on each individual topic (student ability and topic difficulty are competing factors). That's super interesting and definitely one of the issues I faced while building anki cards for math classes I took in undergrad. Thanks again! reply __loam 6 hours agoprevI've got an engineering degree but I've been thinking about trying to relearn this stuff. Sometimes it felt like I was just surviving rather than getting any of the skills to stick. reply paulpauper 3 hours agoprevThere is so much interest in self-learning math or physics. We're in something of an autodidacticism boom. The amount of work to even have any hope of being proficient at this is substantial. For some reason it's always self-learning math or physics, which are among the two most difficult subjects. You got your work cut out. Even if you understand the basic concepts, understanding papers is another level above that. reply 6d6b73 8 hours agoprev$49/student/month? That's excessive. reply AlchemistCamp 7 hours agoparentCompared to what? They have a track-record of students not even old enough to be in high school yet passing AP Calculus BC exams. Here in Taiwan, where I live, it's not that uncommon for people to pay 5x that price per month on supplementary math courses for their kids. https://twitter.com/_MathAcademy_/status/1708542077695574292 reply KallDrexx 7 hours agorootparentCompared to Kahn Academy, which also has a proven track record, is free, and has been around for a long while. reply mhss 7 hours agorootparentprevThe tool might be good but thereâ€™s also strong selection bias due to its price. reply viraptor 7 hours agoparentprevThis is cheaper than lessons with a teacher, so it's hardly excessive. (Even if higher than other learning services) reply paulpauper 3 hours agoparentprevIf it works, it is a bargain reply hnbad 8 hours agoparentprevIt's not cheap. Given that it sounds like this is something you want to deliberately spend time on rather than just an app to use when you're bored it might be worth it but probably not so much if you can't use the knowledge professionally somehow. reply juunpp 7 hours agoprevThis is basically an unsolicited ad post. It communicates nothing of substance and the entire thing amounts to \"click the sign-up button\". It doesn't even cover the course contents. How this makes it to the HN front page is mind-boggling. Goatse would at least be more entertaining. reply xupybd 7 hours agoparentThank you for bringing that visual memory back. Why do I struggle to remember my anniversary date but have that image burned into my brain. reply ChainOfFools 6 hours agorootparentGoatse set up shop on a plot of mental real estate nothing else would go near. its in a bad part of town, but acts as a kind of landmark being the only object anything like its kind for miles in all directions. edit: removed the unintentional reference to the url; I did not expect it would still be active! reply kirubakaran 7 hours agorootparentprevYou need an AI art of your anniversary date in the form of a goatse reply lebean 6 hours agorootparentAdding this to my arsenal of memorization tricks. reply juunpp 6 hours agorootparentThey don't teach that in schools. reply ngneer 6 hours agoparentprevOn a very apt topic for HN readers, though, who likely enjoy math to some degree and have heard of LLMs. What if the post inspires someone to look into revisiting actively learning math as an adult? Is that so bad? reply jcpst 4 hours agorootparentYes, I agree, it reads like an ad. But I did in fact find it inspiring. For all I know, maybe it is a targeted ad. I am a software engineer at a large company. I was selected and flown to HQ for training on integrating LLMs into applications. I am currently building systems that support our data scientists. Iâ€™ve tried picking up more math skills a few times. But Iâ€™ve never taken trig or calc. Iâ€™d like to understand ML and LLMs better, but I feel like Iâ€™m not even sure where to start with trying to learn math. For I have a family and a job as well. So the adult track of that Math Academy site does seem like something I would try. reply SuperNinKenDo 8 hours agoprevWell, it's essentially an ad/shout-out for the mate's product, but if the value is there, the value is there. I can't afford the subscription price and don't care much for subscriptions these days anyway, but I'd love to found my own education company in the future, so wishing nothing but the best, and happy to see someone hopefully being able to make some money in the spacez even when free alternatives like Khan Academy are already established. Edit: The original post has no value in explaining how the author is learning maths other than to say that they're using the Math Academy platform, and taking notes. Useless to anybody not interested in a $49/month subscription to a semi-open beta. I would almost characterise the title of the post as a bait and switch after further consideration. reply j7ake 4 hours agoprev [â€“] I'm curious how many days before author can read a mathematical description of an algorithm (let's say expectation-maximization algorithm) into code? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author shares their experience of relearning math as an adult and the motivation behind it, driven by their work with AI products and a desire for a better understanding of large language models.",
      "They found Math Academy, a startup founded by a friend, to be an amazing and effective tool for learning math, emphasizing its convenience, consistency, authenticity, and hands-on approach.",
      "The author recognizes that learning math requires hard work but believes that Math Academy makes it easier and more accessible, setting a long-term goal of understanding LLMs and transformers with consistent learning over several years."
    ],
    "commentSummary": [
      "The discussion covers a range of topics related to learning math, including personal experiences and recommended resources.",
      "Individuals share success stories using online platforms like Khan Academy and Math Academy, while others advocate for traditional education methods and textbooks.",
      "The conversation also explores differences in math education between countries, the importance of a strong math foundation, and the role of AI and machine learning in math education."
    ],
    "points": 205,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1705612374
  }
]
