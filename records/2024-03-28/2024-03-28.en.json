[
  {
    "id": 39844936,
    "title": "Developing GNOME Apps Made Easier with Swift",
    "originLink": "https://www.swift.org/blog/adwaita-swift/",
    "originBody": "Writing GNOME Apps with Swift March 25, 2024 david-swift David is a student interested in Swift and the GNOME Project. Swift is well-suited for creating user interfaces thanks to the clean syntax, static typing, and special features making code easier to write. Result builders, combined with Swiftâ€™s closure expression syntax, can significantly enhance code readability. Adwaita for Swift leverages these Swift features to provide an intuitive interface for developing applications for the GNOME platform. GNOME is a popular, open source desktop environment for Linux, known for its emphasis on simplicity and accessibility. It offers an intuitive user interface, with a vast app ecosystem built using its modern Adwaita design language. Explore a collection of great apps under Apps for GNOME. Letâ€™s look at a code example of using Adwaita for Swift. The following code snippet defines a view, which represents a part of the user interface inside a window. struct Counter: View { @State private var count = 0 var view: Body { HStack { Button(icon: .default(icon: .goPrevious)) { count -= 1 } Text(\"\\(count)\") .style(\"title-1\") .frame(minWidth: 100) Button(icon: .default(icon: .goNext)) { count += 1 } } } } A view can be nested within other views or added as the child of a window. Its content can be modified from outside that view and is influenced by its position in the view hierarchy. This makes it easier to compose views to produce different results. The screenshot shows one simple possibility. Motivation The primary motivation for this package is to enable the use of Swift when writing GNOME apps, for all the reasons outlined above. But there are a few additional reasons: Declarative While there are already libadwaita and GTK bindings for numerous modern programming languages, including Rust, Python, and JavaScript, all official bindings follow an imperative coding style. This can be verbose and harder to follow than a declarative style as user interfaces are constructed using a series of commands. The following Python code serves as an illustration of this. class Counter(Gtk.Box): def __init__(self): Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL, spacing=6) self.count = 0 button_prev = Gtk.Button.new_from_icon_name(\"go-previous\", Gtk.IconSize.BUTTON) button_prev.connect(\"clicked\", self.on_prev_clicked) self.pack_start(button_prev, True, True, 0) self.label = Gtk.Label(label=str(self.count)) self.label.set_name(\"title-1\") self.pack_start(self.label, True, True, 0) button_next = Gtk.Button.new_from_icon_name(\"go-next\", Gtk.IconSize.BUTTON) button_next.connect(\"clicked\", self.on_next_clicked) self.pack_start(button_next, True, True, 0) def on_prev_clicked(self, button): self.count -= 1 self.label.set_text(str(self.count)) def on_next_clicked(self, button): self.count += 1 self.label.set_text(str(self.count)) This Python code uses the PyGObject library and produces the same user interface as the Swift code above. Ease of Use As you can see, Adwaita for Swift is built around data. For example, changing the variable count when pressing one of the buttons in the sample app will automatically update the user interface. Traditional bindings require you to call a function on the object holding a widget that should update its content once a value changes. If you decide to store the value on the disk so that it persists between startups of the app, you would have to add a lot of complexity to your code using traditional bindings. Adwaita for Swift enables you to simply add a unique identifier to the variable that should be stored, and will take care of the rest. @State(\"count\") private var count = 0 There is also a simple and safe approach for localization with the Localized package. Readability The simplicity coming with the data-centric approach has a positive impact on readability. Another point is the declarative definition of the user interface itself. You can focus on what the app should look like and how it should behave rather than how to achieve those results. While there are other solutions available, such as defining the UI with XML and Blueprint, they require the user interface and actual code to be written in different files. Also, updating the user interface has to be done manually whenever data changes. This makes it more difficult to follow the logic as a reader. As the user interface is written in Swift, you can use convenient Swift syntax directly in your user interface definition. var view: Body { if count == 0 { Text(\"ðŸ˜\") } else { Text(\"\\(count)\") } } Cross-Platform App Development Adwaita for Swift is useful in a number of ways: You can write apps that run on Linux, macOS and Windows with a single codebase. You can share backend Swift code between SwiftUI apps and GNOME apps. You can create entirely new GNOME apps using Swift, achieving great code readability and memory safety. Publish Apps In addition to traditional distribution packages, Adwaita for Swift works great with Flathub. Flathub is an app store powered by Flatpak which simplifies the installation and publishing of apps for desktop Linux. There is the Freedesktop SDK Extension for Swift 5 which adds support for Swift, and a tool to convert Swift Package Manager dependencies into Flatpak sources. Learn how to publish your apps in the Adwaita for Swift documentation. Get Involved Each contribution to this project is highly appreciated. You can: Create an app! Use the template repository as a starting point and refer to the tutorial. Feel free to showcase your project in the discussions. Note that libadwaita works best on Linux. If youâ€™re on a newer Mac and interested in Linux, check out Asahi Linux. Open issues if you find any problems or if you have an idea, or participate in the dicussions by asking questions, dicussing ideas, or informing others about your work. Write documentation to help others understand Adwaita for Swift. Simply star the repository to improve its discoverability. Take a look at the Memorize app. It is the first app on Flathub built using Adwaita for Swift. Thanks for your participation â¤ Introducing the Benchmark Package: Complementing Unit Tests with Performance Checks",
    "commentLink": "https://news.ycombinator.com/item?id=39844936",
    "commentBody": "Writing Gnome Apps with Swift (swift.org)530 points by msk-lywenn 23 hours agohidepastfavorite263 comments w10-1 19 hours agoFor another SwiftUI-like wrapper, see also https://github.com/stackotter/swift-cross-ui (used by Adawaita to generate widgets, and mentioned in other comments). The key premise of this approach is to provide a SwiftUI-like declarative wrapper around Gnome functionality. It's unclear what it adds over swift-cross-ui. SwiftUI itself has growing pains mainly around being on the right thread for processing/updates and getting data binding right. Blog entries on swift.org or from Apple tend to be little demos that show the happy path, but when discussing new frameworks (like a Gnome wrapper) or platforms (like the recent embedded), I'd like more demonstration that the authors understand and address key issues and will sustain development. Cross-platform UI frameworks get complicated quickly and have a long tail of issues (cf Flutter, Java/Eclipse, et al) that can be blockers for clients/users. For Swift it doesn't help to have multiple concurrency models and obviously different behaviors on apple platforms and Linux (where UI is not officially tested). reply azinman2 17 hours agoparentIâ€™ve never struggled with being on the right thread. Itâ€™s always main to update UI. Grand dispatch makes this trivial, and the recent actors work also extends this. Iâ€™m also not sure how this is SwiftUI specific as UIKit and most other UI frameworks are the same. What are the growing pains here? reply brailsafe 1 hour agorootparentWell, I've been fighting with an extremely simple Navigationsplitview for ages. Put a list in the sidebar, put 100 items in it, and render almost anything else in the detail on macos (one version back). Then select an item in the nav and hit the down arrow. Depending on implementation, scrolling will get clipped to the visible area, it'll hold onto multiple selections if the first has been scrolled off screen, or the main thread will get thrashed and performance will be about what the current settings menu is. I haven't found something that I don't have to accept a really mediocre experience with, but next I'm going to try rewriting it with NSTable reply w10-1 17 hours agorootparentprevAside from UI updates, processing includes view-model derivations (e.g., calculating errors), persistence, and loading, all of which are offloaded to dispatch queues or actors and then brought back to the UI/main thread. wrt granularity, there's @State, @StateObject, and @Observable, with different binding reaches. So understandably a lot of choices reflecting legacy and new API's, integration with UIKit and web/media services -- and probably AI recognizers in the background. To me the pains are that the approach taken needs to be consistent application-wide (async is pretty viral, queues are designed to be shared e.g., per subsystem, etc.), making it hard to manage or migrate a code base. Also many features build on macros which can make builds almost intolerable. Also saving on macOS vs integrating with update manager on iOS. It can be hard even to find documentation on stdlib feature support e.g., Regex. It's good they maintain both the legacy support and go full-steam-ahead on new features, but developers (i.e., I) need more guidance on tip-toeing around pitfalls and managing platform differences. reply nickwarren 8 hours agoprevSwift is such a delightful language to use, well suited for general application development. It's awesome to see it gaining traction outside of the cocoa ecosystem. If you haven't given it a fair chance yet, I would highly recommend you do! reply zengid 5 hours agoprevI feel like a cross platform Swift GUI would be a great thing for the world. Swift strikes a great balance between ergonomics and performance, and seems to be the only other mainstream language to have absorbed some of Rust's key features around borrowing references. reply georgelyon 3 hours agoparentFor the record, borrowed references are only going to be really usable in Swift 6 which isn't released yet. That said, Swift's implementation of borrowing seems significantly more user-friendly than Rust's. While this is very much an advanced feature, I'd expect it to be actually used in many cases where in Rust folks would resort to working around the borrow checking (via things like indexing into arrays and such). As a result I expect it to be significantly more useful. reply jrsj 3 hours agoparentprevBrowser Company sort of built this themselves for Arc, but its really a separate SwiftUI-like Windows implementation (Windows UI is separate code written in a similar style). It still feels like a technical preview though unfortunately. reply lukeh 20 hours agoprevOther things worth checking: https://github.com/stackotter/swift-cross-ui https://github.com/TokamakUI/Tokamak Iâ€™m also working (slowly) on native Flutter channels: https://github.com/PADL/FlutterSwift But this is really targeted at embedded use cases. reply dkh 19 hours agoparentTIL Sony maintains a Flutter eLinux embedder project[0] [0] https://github.com/sony/flutter-embedded-linux reply marcprux 18 hours agoparentprevAnd there's also SwiftUI for Android: https://skip.tools/blog/bringing-swift-to-android/ reply jwells89 16 hours agorootparentWill have to try it to see how well it works in practice, but very cool. I can see this being popular for side project apps written by iOS devs that otherwise wouldnâ€™t have an Android port. reply wahnfrieden 17 hours agorootparentprevVery nice Do any of these have a good wkwebview equivalent reply marcprux 16 hours agorootparentYes, web views (backed by WKWebView on iOS and android.webkit.WebView on Android) are one of the Skip modules under active development: https://github.com/skiptools/skip-web reply wahnfrieden 3 hours agorootparentLooks amazing. As an indie dev who quit my job to try to make it solo, I'll either need to wait until I have more revenue to afford this, or hopefully you add some indie-friendly tier for bootstrapped pricing (such as a discount on team size, or ARR like Apple does with its small business program). reply timo555 3 hours agorootparentLooks like it is free for your use case. Pricing page[0] shows $0 annual cost for small businesses, which is defined as > Educational institution, nonprofit, or business/individual with less than 250K USD annual revenue [0] https://skip.tools/pricing/ reply wahnfrieden 2 hours agorootparentThank you! It is temporarily free with application reply wahnfrieden 18 hours agoparentprevarc released a windows ui for swift lib but it's imperative reply kybernetyk 7 hours agorootparentdo you have a link? my google-fu failed me reply wahnfrieden 7 hours agorootparenthttps://github.com/thebrowsercompany/swift-build reply treprinum 12 hours agoprevWriting UI code layouts is suboptimal in any language. Delphi had it right - place whatever controls you like in a GUI, set up basic behavior via properties, then just quickly write handlers in code. reply ptx 8 hours agoparentPerhaps, but as a counterexample, the SerenityOS people implemented the Delphi approach with Visual Builder but then realized that they preferred working with text, so they replaced it with a declarative DSL and live preview (GML Playground). Here's Andreas Kling briefly demoing both and talking a bit about it: https://www.youtube.com/watch?v=1QYBvTy9QKE&t=519s reply badsectoracula 8 hours agorootparentI don't know about Visual Builder, but judging from this screenshot[0] it doesn't look like the Delphi approach, but the \"Windows resource editor\" approach. Yes, both allow you to place things visually, but one works with live instances of serialized objects in an IDE that also understands the edited source code and can modify the code to -e.g.- introduce a new event handler for the OnClick event when you doubleclick the button (even with the cursor placed just right where you can start writing the actual logic of the event handling code), while the other has you draw the UI, assign some IDs and then expects you to do all the plumbing of loading the UI, associating it with code and handlers by hand. The difference might sound trivial but in practice it is like trying to dismiss editing text with Emacs by experiencing editing text in Notepad. [0] https://adkaster.github.io/images/build/VisualBuilder.png reply fleabitdev 11 hours agoparentprevI also admire the simplicity of this approach, but it has several downsides: - Code-based UIs tend to work better with existing tooling, like comments and source control. You can freely customise your development environment, rather than being at the mercy of a single GUI app. - Most serious UIs need code-like features, such as \"for-each\" to render a list of objects, or \"if\" to reveal a form when a checkbox is ticked. The easiest way to access code-like features is to write your UIs in code. - You'll need to write some backing code in any case. Defining the UI tree and its \"code-behind\" in the same file could be considered more DRY. - Live preview (or alternatively, hot reloading) will give you very quick iteration when writing a UI in code. It's not quite as good as drag-to-resize, but it's close. - Automatic layout (which is non-optional nowadays) isn't necessarily a great fit for WYSIWYG editing. - As React has demonstrated, the ability to quickly throw together custom components is extremely useful. Visual editors tend to make it more complicated and bureaucratic to define custom components. reply jwells89 5 hours agorootparentIn addition: - WYSIWYG editors are bad about making small unintended changes that can easily slip by undetected (Interface Builder in Xcode for example often changes XIBs/storyboards just by viewing them) - WYSIWYG editors bury bits of configuration in inspectors that are only visible in certain conditions, e.g. a control being selected, making them less evident and more difficult to find There are circumstances where I think they still work alright â€” for instance I still enjoy building Mac apps with XIBs in Cocoa, but thereâ€™s a reason for that: traditional desktop UI has much less of a need for flexibility and generally speaking, has far fewer moving parts since it doesnâ€™t have to hide things as a result of limited screen real estate. Additionally, these apps will only ever run on Macs which further reduces need for flexibility/adaptivity. For mobile and multiplatform on the other hand, I strongly prefer code. It just works better. reply berkes 12 hours agoparentprevMy immediate though of the Swift Example Code was \"but where does the business logic go\". This trivial example lacks it, and places it simple logic inside the UI code. But what if we want to protect against negative numbers? Or want to increase the number with larger increments if we hold the button pressed? Etc. Your Delphi setup isolates business logic from UI. Which may seem \"overly complex\" in trivial demoes, but will help you the very moment you write the first test or add some business logic. It's also why I see so many React apps spiral into an unmaintainable mess within days after their \"git init\". reply NiteOwl066 11 hours agorootparentYou would just use some architecture pattern. I would say the most natural one for SwiftUI is MVVM so the logic would go to viewModel. reply berkes 5 hours agorootparentDo I understand it correct when the UI then calls methods or functions on a model layer? reply Wytwwww 11 hours agorootparentprev> Your Delphi setup isolates business logic from UI. Which may seem \"overly complex\" in trivial demoes, but will help you the very moment you write the first test or add some business logic. So basically, the same as Cocoa/obj-C? reply diggan 11 hours agorootparentprev> It's also why I see so many React apps spiral into an unmaintainable mess within days after their \"git init\". This is true for any library/framework/architecture, and the same problem is very prominent in Svelte/Vue/React/Backbone/Angular and everything else. reply berkes 8 hours agorootparent> and everything else. No. It's true for any library or framework that lack isolation or decoupling concepts. In react (and many of the ones you mention) there is nothing on place that guides you into decoupling. It has nothing, not even conventions, that help a junior to put stuff in the right place (or to prohibit or make it difficult to put stuff in the wrong place). Part of that is due to how in TS/JS everything can grope around in everything else. But the bigger part is lacking conventions, primitives and structure in the libs and frameworks. Sure, a library (which react is) doesn't provide structure (it's a distinguishing trait from frameworks). But the many frameworks on top of React don't do a good job either. They either become some Enterprise Ready amalgamation of saga's, redux, message-bus, setups, or they offer too little guidance. And in all situations, it's still possible to just fire a fetch() or put data transforms or business logic within the UI. Only discipline keeps people from taking this \"much easier\" route. And when only discipline stands between us and \"the easier way for now\", that \"easier way for now\" will be chosen, and pain in future will be felt. reply imbnwa 6 hours agorootparent>They either become some Enterprise Ready amalgamation of saga's, redux, message-bus, setups, or they offer too little guidance At least Redux provides a semblance of immediately grokable data flow, this all gets worse with mobx which gives you all the flour you need to make spaghetti for the whole village. Worked on a codebase where you might have to chase down references across all sorts of files you wouldn't expect because everything is 'observable' so people, working 2-week sprints, just stop thinking about any kind of coherent structure cause it works anyway. reply teekert 11 hours agoparentprevBut then what if the UI changes dimensions? Then you'd need an underlying set of rules, and isn't it best if you can set those rules yourself? How would that work graphically? And then how about version control? Sure there could be (and is) underlying machine code, and you could try hard to make it human readable. But... IDK seems like a lot of effort to me for some small benefits. Disclaimer: I have only very little experience with UI programming. reply badsectoracula 11 hours agorootparent> But then what if the UI changes dimensions? Then you'd need an underlying set of rules, and isn't it best if you can set those rules yourself? How would that work graphically? I don't know about current Delphi, but in Lazarus (which is kind of an open source and crossplatform Delphi) you set those rules visually. For example you can \"draw\" the UI by drag-and-dropping controls in a window/containers/etc and then you can add rules like \"this button's left side will be 5 pixels from that label's left side and will be placed vertically so that it is centered relatively to the label\". You can also set things like \"this control (or container or whatever) will always be at the top/left/right/bottom edge of its window/container\". This is done in the visual editor with immediate feedback (you can even resize the window/container while you are editing its layout to see how it behaves). This allows you to make UIs that work not only across dimensions, but also handle different fonts, texts (for localization), scaling (for DPI) and themes. Especially important for Lazarus since its GUI framework has various backends that often look very different from each other. > And then how about version control? Lazarus (and Delphi - with the exception of some earlier versions - and really most GUI designers) save UIs in a text based format with a tree-like structure of key/value pairs, e.g. (i edited it a bit for brevity): object Main: TMain Left = 625 Height = 505 Top = 393 Width = 903 Caption = 'World Editor' Menu = MainMenu1 Position = poScreenCenter object plRenderContainer: TPanel Align = alClient BorderStyle = bsSingle object plRenderWindow: TPanel Align = alClient BevelOuter = bvNone end end end This can easily be stored in version control and diffed to see changes (in fact in my own projects before committing something to VCS i check both the code and the UI files to see what exactly i changed). reply hgs3 4 hours agorootparentprevYou solve this by using a layout control (a UI control specifically for managing the size/position of its child controls). For example using a visual form builder you could drag-n-drop a \"vertical layout control\" and then drag-n-drop controls inside it to be resized/positioned in a vertical stack. The window itself can have a layout control that stretches to fill the window regardless of resizing. Layout changes would cascade down through the tree of UI controls and everything would resize/reposition accordingly. reply diggan 11 hours agorootparentprev> But then what if the UI changes dimensions? Then you'd need an underlying set of rules, and isn't it best if you can set those rules yourself? How would that work graphically? Look into how various design tools handle flexible layouts. Usually a combination of flexbox/something similar to flexbox or slightly more old-school; constraints. Here is an example with Figma: https://gdwn.medium.com/how-you-can-create-really-flexible-a... reply boxed 11 hours agoparentprevThat's what mac/iOS development has had since before it was even mac, back in the NeXTStep days... But it doesn't work very well for very custom stuff. reply sgt 11 hours agorootparentMy thoughts exactly. Generally writing UI code in Xcode (and presumably before that on NeXT as well) is a breeze and a joy. Work with your delegates, connections, outlets etc. reply izacus 11 hours agorootparentprevAnd that's a good thing, because it discourages \"very custom stuff\" that made mobile apps such a usability disaster. reply atlasduo 11 hours agoparentprevIt is the same approach as declarative UI programming like SwiftUI or QML, but with an extra GUI abstraction on top of it. An artifact of this GUI-driven development process (like Xcode or Glade) is still a file with some declarative markup (sometimes even human-readable). reply steve1977 4 hours agorootparent> An artifact of this GUI-driven development process (like Xcode or Glade) is still a file with some declarative markup Not really in the case of Cocoa's Interface Builder (nib/xib files). There the artifact is basically a marshalled object tree of the actual UI objects, not declarative markup. reply treprinum 8 hours agorootparentprevThere is a big qualitative jump when one can arrange and play with UI without writing a single line of code, even if the user's decisions about component placement are recorded in a declarative file. reply datascienced 9 hours agoparentprevThe old fashioned screwdriver has it right. Why fiddle with charging batteries, using a chuck and selecting direction when you can just pick up a olâ€™ screwdriver and get going! â€¦ assembles an appartments worth of new Ikea furnitureâ€¦ Oh! reply treprinum 8 hours agorootparentTry Delphi/Lazarus for just 10 minutes, then come back with a better metaphor. The productivity difference in comparison to React, Qt, GTK etc. is enormous. When was the last time you built the whole UI of a large app in 1 day? reply rimliu 7 hours agoparentprevIt is not. macOS/iOS had it for a long time with AppKit, UIKit. But the progression is usually this: you start with Interface Builder and storyboards or .xibs, then you see the problem with that and gradually move to code-only UI and then start looking at SwiftUI with it's declarative UI like a guy in that meme. GUI for layout just does not cut it, especially when your app runs in very different environments - it can be macOS, it can be a phone or just a smartwatch/widget. reply steve1977 4 hours agorootparent> especially when your app runs in very different environments - it can be macOS, it can be a phone or just a smartwatch/widget. But the question here is also if it makes sense to basically have the same UI or even UI paradigms for such different types of environments. reply treprinum 6 hours agorootparentprevAlternate take: macOS/Qt/MFC/React etc. got it wrong, Delphi got it right. reply etaioinshrdlu 20 hours agoprevI'm having Deja Vu from about 20 years ago of writing Gnome apps in C# using Mono. reply pjmlp 13 hours agoparentWhich ended up having such a community backslash that Miguel de Icaza decided to focus his efforts on Xamarin instead, followed by Microsoft's acquisition, and nowadays he is focused on Apple's ecosystem, Swift and Godot on Apple platforms. \"Miguel de Icaza and his ostracization from FOSS\" https://www.linux-magazine.com/Online/Blogs/Off-the-Beat-Bru... \"What killed the Linux Desktop\" https://tirania.org/blog/archive/2012/Aug-29.html \"How I ended up with a Mac\" https://tirania.org/blog/archive/2013/Mar-05.html One might wonder how things would have turned out instead if the community had been more welcoming of his efforts on GNU/Linux. reply masfoobar 12 hours agorootparentWhile I found the MonoProject interesting, I was skeptical using it. Sure, it is an Open Source .NET framework but .NET is Microsoft at the end of the day. I do not (and still do not) want their fingerprints inside my GNU/Linux machine. What I mean by this is the legalities behind it. Remember, my comment above is based on views 20 years ago. My perspective is that Microsoft cannot \"beat\" Linux purely as competition. It isn't going anywhere. While it may not be a concern in the Desktop market, it certainly dominates on servers! Microsfot are not stupid and see CONTROL through other means. Imagine if most programs that come default in Linux distributions being C#? If more and more programs are written in C# (whether Mono or not) gives them power over the Linux user. Today, Microsoft has .NET core (recent release .NET 8) and also replaces Mono. We still have Xamarin of course but that is getting replaced with MAUI. A lot of Microsofts software is now cross platform, like Powershell, SQL Server, etc. This \"concern\" I was having 20 years ago is still just as big of an issue today. Imagine Microsoft getting the marketing right and SQL Server starts gaining momentum on Linux boxes. This means less using MySQL or Postgres. Imagine is Powershell starts gaining more traction in Linux land rather than Bash. Now -- I think this is EXTREMELY UNLIKELY to happen but you can garantuee this is a strategy. They have the money and manipulation skills to help make it happen. Big companies can easily eat this up and it starts with \"but we can support you!\" Think about it -- WSL is easy to setup on Windows machines! More and more C# applications can easily be tested for Linux. Microsoft just gave you the tools, and letting developers/companies do the rest for them. Soon it is sheep follow sheep. Bit of a long winded comment/reply - and while I do not share targeting hate towards anyone (I do not know Miguel personally but he seems like a cool guy) -- I just think efforts should have been elsewhere. Dlang could have been a really, really good replacement. My guess as to why Dlang didn't take off back them was the compiler was not open source. Who knows? reply devjab 11 hours agorootparentI think that most of what Microsoft does today on the developer front is focused on getting enterprise developers ever more integrated into azure. I live in a very Microsoft heavy part of Denmark, and the result is that virtually everyone uses azure and so do we. Take SQLServer as an example, a lot of FOSS database frameworks and orms donâ€™t support it, even though there are some pretty decent Microsoft drivers for most languages. The result of this, when you use azure, is that youâ€™re going to be using a different SQL server, or a different set of tools. Itâ€™ll often be the latter because on many enterprise subscriptions running SQLServer is quite a bit cheaper than running any other SQL DB in Azure. Thatâ€™s the developer side of things, then on the more operations side of things itâ€™s hard to justify not using Powershell if youâ€™re running a lot of Microsoft products. It integrates very well with everything your IT operations department does anyway from EntraID to Azure Automation, where you may be able to use Python as well, but Python is often not what Microsoft IT operations people â€œgrew up withâ€. So unless other cloud providers have a strong Powershell presence on their IT operations side of things, using them, instead of using Azure, because a huge change management issueâ€¦ Often one you canâ€™t really solve, because a lot of IT operations people will rather find a different job than switch away from their Microsoft focused talents, and why wouldnâ€™t they? Good cloud operations people are harder to find than basically anyone else in IT. reply robertlagrant 9 hours agorootparentGiven Azure's support for Postgres is pretty good, I would push hard for this in any new projects. Makes you more portable in future, and you can spin up local environments more easily. reply pjmlp 12 hours agorootparentprevWell, many folks on the FOSS space are to blame, Microsoft has learned by the hordes buying Apple hardware, that what a large majority cares about is POSIX experience and very little about GNU/Linux itself. As usual, while Microsoft has its own actions to answer for, it isn't alone in making everything happen. The Year of Desktop Linux comes packaged in desktop VMs, regardless if it is on Apple, Microsoft or Google's hardware. reply tamrix 6 hours agoparentprevYou may have started with Vala. An object oriented language inspired by C# complied in straight C. reply jddj 20 hours agoparentprevOh wow, I forgot all about that little detour. I remember making some rudimentary accounting software for which I'm sure now the source is long gone. reply neonsunset 20 hours agoparentprevYou still can! (even easier now since it will run on CoreCLR instead) https://www.nuget.org/packages/GtkSharp reply przmk 13 hours agorootparentThis only targets Gtk3 and not Gtk4 or libadwaita though. Seems a little end-of-life. reply l72 22 hours agoprevI recently wrote a small side project using vala + gtk4. I tried blueprint, and while I liked the format, I struggled with a lack of documentation on how to do some more advanced things. Gtk's .ui files are ok, but you still end up writing a lot of code to hook everything up. While I really like vala as a language, I think it'd be great to write all my logic and models in vala, then use this swift library for the UI. reply RussianCow 20 hours agoparent> While I really like vala as a language, I think it'd be great to write all my logic and models in vala, then use this swift library for the UI. At that point, why not just do everything in Swift? What does Vala give you that Swift doesn't? reply dkh 19 hours agorootparentIn the context of Gnome/GTK development, there's almost nothing more stable and comprehensive than Vala, as it's been around a very long time and was created specifically to occupy that space. Can't speak for OP about why to combine it with Swift handling the UI, but certainly Vala still has far better support for the Gnome data model and APIs outside of those specific to the GUI. reply RussianCow 15 hours agorootparentI get that, but if you're going to deal with the impedance mismatch anyway, I would just go all in and use Swift for everything. But I guess that's assuming that GTK/GLib is fairly easy to wrap in a language like Swift, which I assume is true given all the different language bindings out there. reply badsectoracula 13 hours agorootparentI think a difference between Vala and everything else is that Vala has been written with gobject as its \"native\" object system whereas everything else uses the glib bindings. Kinda like using COM from Visual Basic 6 vs using it from plain C. reply pona-a 10 hours agoprevThat looks really nice! A healthy balance of reactive UI, expressiveness, and sanity. I wonder if there's a similar Swift binding for Qt... Ubuntu Touch and KDE could really benefit from that, as QML proved to be a total typing nightmare from my experience, often even slightly worse than regular JS thanks to its quirks... reply koito17 23 hours agoprevSomething like SwiftUI but open source and targeting GTK4 would be pretty close to my \"dream framework\" for cross-platform desktop UI. I will admit, Swift syntax is an acquired taste, but once you're familiar with all of the concepts (and understand that some design decisions were made for Objective-C interoperability), then it's a very usable language. To be frank, the only thing that stops me from using Swift is the fact that Linux support isn't as good as on Apple platforms. But if I am targeting nothing but Apple platforms, then Swift is probably the best choice, just for SwiftUI and SPM alone. reply firecall 20 hours agoparentFWIW I very much enjoyed using SwiftUI once I got the hang of it! I'd been out of iOS dev for a good long while, and was still thinking in UIKit and Obj-C. Overall I've found SwiftUI to be the most productive and enjoyable declarative framework and developer experience I've used! To be fair my experience is limited to React and Flutter, but still, Apple have done a rather excellent job IMHO! YMMV :-) reply mojuba 14 hours agorootparentRewriting an app from UIKit to SwiftUI not only eliminates storyboards but also reduces the code base. So once again: you have code plus storyboard XML vs. just code that is smaller! My jaw dropped when I first discovered this while rewriting something. Unfortunately though SwiftUI hasn't completely matured yet. Especially if you are targeting iOS versions prior to 16, you will encounter many of SwiftUI's shortcomings. Some (many?) UI components are still UIKit under the hood, scroll view and its derivatives are still not as flexible as you sometimes want them to be etc. For some custom UI tricks that would be a piece of cake in UIKit are impossible in SwiftUI and you often resort to wrapping the old components in your custom ones. Oh and don't get me started on resorting to the main thread (because of the underlying UIKit code) in the age of structured concurrency. All in all, the concept of SwiftUI coupled with structured concurrency is beyond amazing but its maturing process is still underway. reply dkh 22 hours agoparentprevI remember a few years ago, a few really cool cross-platform UI libraries were starting to emerge such as libui [0] that got me excited. I've kind of lost track of them since then (libui itself went dormant for a while before this fork) so I am not sure how mature/useful they are now, but the potential for writing native desktop UIs in basically any language seemed like an absolute dream. Perhaps it's feasible for very basic things? [0] https://github.com/libui-ng/libui-ng reply pojntfx 22 hours agoparentprev> Linux support isn't as good as on Apple platforms That's definitely still a problem for libraries etc., but thanks to very recent developments (see the article) at least getting your app to users is super simple thanks to the new Swift Flatpak runtime: https://flathub.org/apps/org.freedesktop.Sdk.Extension.swift... reply cglong 22 hours agorootparentIt says the runtime is under GPL3. Does the copyleft apply to all Flatpak apps written using Swift? reply flexagoon 17 hours agorootparentNo, it is the runtime, it's not a part of your app, it just runs it. You can basically think of it as a Docker container (but specifically for desktop apps). You don't have to make your app GPL, the same way as you can run a proprietary app on Linux even though the Linux kernel is GPL reply badsectoracula 13 hours agorootparentIt isn't that simple. If your application links against the runtime, be it dynamically or statically, then it is a derivative work and thus must be distributed under the GPL. This is why Java, also being under GPL, has an explicit exception for the runtime library despite even being a VM. The Linux kernel allows you to run proprietary apps because the kernel code and the userland code exist in two separate \"planes\" connected by the syscall interface. The kernel even has an explicit exception for any code that may need to be shared between the kernel and the userland to make clear that this code is excluded from GPL. As another similar case, the Free Pascal compiler is licensed under GPL including the runtime and almost all libraries/units that come with it but it also has an exception to allow linking without having the GPL extend to the programs the users write. AFAIK the GNU C library also has a similar GPL-with-linking-exception license. reply nextaccountic 20 hours agorootparentprevI thought that Apple actively avoided GPLv3 reply cglong 15 hours agorootparentIt looks like the runtime is owned by the author of this article, who (from his bio) doesn't seem to be affiliated with Apple. Either way, I agree it seems like an odd choice. reply rock_artist 10 hours agorootparentpreva. It's the author using something which is GPL b. GPL is allowed as long as complied. c. GPL mostly limits ability for use within iOS / AppStore. reply nicoburns 20 hours agoparentprevThere is Relm (https://relm4.org/). Which is in Rust is just GTK (through it's Rust bindings) with a nice reactivity layer on top. reply p10r 22 hours agoparentprevSounds like Compose and Kotlin, although multiplatform still being more in a beta stage. reply dkh 21 hours agorootparentIf I had a nickel for every time I got excited about something with experimental multiplatform support... The Kotlin platform looks good and I've kept an eye on it, but the problem is, if I have to start working on an app now, it's still kind of scary, as you're basically just placing a bet on a horse race of which one will mature the fastest down the road. At a previous job, I decided to adopt React Native in its early stages for a project. By some miracle (and with a lot of rolling-our-own) it managed to not hold us back and seemed to mature about as fast as we needed it to, but boy, even then it was still stressful, and I feel like we got a little lucky. (Just to be clear, I also knew this going into it and the choice was mine, I may just have a deathwish) reply marcprux 16 hours agorootparentTake a look at skip.tools. It's pure SwiftUI on iOS and Jetpack Compose on Android, with the tool automatically handling the translation from Swift to Kotlin as part of the Xcode build process. reply travisgriggs 18 hours agorootparentprevWe had a Kotlin app written with view bindings and the various other bits and pieces of Android app stack â€œno now this thingâ€ detritus over the years. I hated it. I cut my teeth on 20 years of smalltalk, so it wasnâ€™t even the â€œletâ€™s hate on OO nowâ€ thing. It was just so much unfinished/inconstant things. We have been porting to Jetpack Compose, and I really like it. Itâ€™s still got some growing pains. We donâ€™t use ViewModels, hardly any Flow stuff, just mutable states and render trees and Iâ€™ve been pretty pleased. What makes me happiest is that itâ€™s much more consistent. I donâ€™t feel like Iâ€™m in a line at the DMV anymore; â€œoh you need that, go stand in that line and learn that stack, then come backâ€. Like you, Iâ€™m extremely skeptical about the multiplatform siren. We tried it in Smalltalk land. The Java guys tried it and failed. I tried Flutter for a couple of apps, early testing iOS users were totally turned off (so fine for internal simple utility apps only). I would love it if someone really succeeded. We have 2 Swift UIKit apps Iâ€™ll have to convert to SwiftUI someday. So I will wish all that try well, but Iâ€™m not holding my breath at all. Having a â€œwrite once run everywhereâ€ pitch is about the same as politicians who run on â€œchangeâ€. It always sells; it never really delivers. reply jwells89 17 hours agorootparentThe first two paragraphs has been my experience on Android too. Android Framework is an incredibly disjointed mess that leaves you neck-deep in half-baked APIs. Compose is better for sure. Iâ€™m still figuring it all out but itâ€™s a marked improvement. reply jwells89 21 hours agorootparentprevKotlin is probably the most similar in syntax to Swift out of the languages Iâ€™ve written, but itâ€™s somewhat quirky and opinionated and Iâ€™m not sure I agree with its opinions (lack of guard statement, no ternary ifs, etc). Also it involves Java ecosystem stuff like Gradle which can drive a person mad sometimes. reply pjmlp 14 hours agorootparentThere is only one reason to use Gradle instead of Maven, being stuck on Android. reply fuzztester 20 hours agorootparentprev>Also it involves Java ecosystem stuff like Gradle which can drive a person mad sometimes. Interesting. Why is that? I've been out of the Java loop for some years (although I did a fair amount of work with it earlier), so not up to date with this stuff. reply dhosek 20 hours agorootparentGradle combines the inscrutable magic of Maven with the unpredictable structurelessness of Ant in one bundle of pain. reply thfuran 19 hours agorootparentWhat really irritates me about gradle is that they have significant API churn but there's still five ways to do everything. reply naruhodo 18 hours agorootparentI will never pass up an opportunity to heap scorn on Gradle. I agree with everything said so far, except I would argue Ant was easier to use. Every single Gradle build system I have encountered in the wilds of GitHub has been broken on Fedora. I eventually realised it works if I run it in an Ubuntu container (using \"toolbox\"). So it's only portable if you bundle up the OS with your build system. Now it should be portable. It's written in a JVM language and every Gradle project I have seen commits a copy of the Gradle JAR to its GitHub repo, which gives me those arbitrary code execution heebie-jeebies. reply e3bc54b2 13 hours agorootparentprevooh where do I start... Let's see: 1. Every single gradle script is a unique snowflake of mishmashed plugins and custom functions 2. Gradle likes to pretend it is declarative, but as people very quickly learn it really isn't. 3. The one thing a build system is expected to do is be reliable in face of changing platform version, libraries and plugins. But gradle, being built on top a language on top of JDK itself has a Compatibility Matrix[0] that one has to be aware of. Often when upgrading a project you have to update JDK and gradle in explicit order, sometimes multiple times. 4. Speaking of which, did you know that gradle, being designed to build java projects does not even manage multiple JDK versions?! 5. untyped groovy means you're forever left wondering whether what you wrote is actually correct until you run it, at which point it fails with excellent errors that tell you nothing. Granted, this situation has improved in recent days, but a jump from 90th floor compared to 100th is still painful. 6. Every single fkin thing that gradle offers can be done in half dozen ways and nothing tells you which way is better or why. Ex.A: is it providedCompile or implementation? Yes, one is intended to be a replacement for another, and no, they are /not/ same. 7. The 'One Nice Thing' gradle had going for is that it bootstraps itself. But look, if want to add gradle to a 'new' project, you have to install it to your system first and use it to add the wrapper. But after that, you are expected to use the wrapper. Nobody tells you that, you just have to figure it out. Oh and when it comes time to upgrade the wrapper version, you're to use the wrapper itself, not the system gradle, again mentioned nowhere, and if you try updating the wrapper using system gradle, the error helps exactly not. 8. Gradle takes free reign in breaking APIs /between minor versions/. WTF! 9. gradle starts a daemon to cache stuff, which is nice I guess. Except when you don't want it to run a daemon, so you tell it with `--no-daemon`. Do you know what that does? It starts a daemon, runs the build and shuts it down. This may not sound like a big deal, but it is just cherry on top of this shitcacke that tells you just how thoughtfully and well designed gradle is. /s /endrant [0]: https://docs.gradle.org/current/userguide/compatibility.html reply thfuran 6 hours agorootparent>4. Speaking of which, did you know that gradle, being designed to build java projects does not even manage multiple JDK versions?! What about toolchains? reply newZWhoDis 18 hours agorootparentprevMy dealbreaker for kotlin is that itâ€™s possible to call a throwing function with no indication it will throw. In swift, the compiler forces every throwing function do be inside a try/catch block or be called by another throwing function. I also am extremely unhappy that those functions can be 16 layers deep somewhere in a lib and cause your app to blowup. reply jwells89 18 hours agorootparentYep, this is a problem Iâ€™ve encountered several times. Even if none of your own code has unhandled throws, youâ€™ll inevitably get crash reports coming in from fooLib throwing an exception somewhere because the moon was in the wrong phase. reply rockyj 12 hours agorootparentprevThere are entire languages built with unchecked exceptions, Python, Ruby, Nodejs and most recent ones. Even with checked exceptions you can write code and miss to throw or declare an exception somewhere so ultimately the developer has to deal with exceptions somehow. reply rubymamis 22 hours agoparentprevWhy not go with Qt's QML? reply wizzledonker 20 hours agorootparentAs someone who works with QML daily, I had the same question. The work is already done. Why write a common UI backend in swift when you can have the whole thing common using QML/Qt. Itâ€™s the best way to write native Multiplatform apps at the moment. It just is. reply pona-a 10 hours agorootparentFor me, QML, while expressive, had a lot of rough edges. If most of your logic is inside the C++ backend, its JS engine is just useless overhead. If you do something like lite data wrangling in QML, or worse, try to adapt existing JS libraries for it, it quickly becomes a nightmare of standard JS weirdness, non-compliance with normal JS, and just outright ridiculous and difficult to diagnose issues like data getting passed by reference from the previous page and that page getting popped off the stack, resulting in error. And besides that, QML tooling is virtually non-existent. Major code editors don't even ship basic syntax highlighting for it out-of-the-box, the linter doesn't catch anything useful forcing you back into manual testing, and recently added language-server is at best a little useless and at worst impossible to get working correctly because your components live inside the build container and cannot be installed on the host without risk to system stability (Ubuntu Touch Clickable and Lomiri.Components). If something like that was possible for Qt, I'd probably switch in a heartbeat. If our modern programing languages are finally expressive enough to write sane reactive UI and statically verify parts of your logic, why keep relying on the unverifiable and slow DSL? reply rubymamis 9 hours agorootparent> If most of your logic is inside the C++ backend, its JS engine is just useless overhead. Well, if most of your logic in C++, what's the problem then? For my app[1] most of the logic in C++ but there's still a good amount of logic in JS (out of laziness or ease). BTW, much of QML code is compiled to C++ these days[2] > difficult to diagnose issues like data getting passed by reference from the previous page and that page getting popped off the stack, resulting in error. This is very true, it's quite difficult to diagnose issues in QML, and it doesn't seem to me like Qt ships debugger tools for errors as available for C++ when a program crashes. I relate to your issues with syntax highlighting (although the linter is good imo). Also auto-complete is pretty bad in Qt Creator for QML. I wonder how feasible it is to integrate Typescript into QML rather than JS. But I think that while all these issues should be addressed, developing with C++ and QML is the most joyful combination I've experienced so far for GUI development (I also developed in React and React Native). [1] https://www.get-plume.com/ [2] https://www.qt.io/blog/the-new-qtquick-compiler-technology reply dhosek 20 hours agorootparentprevIâ€™m not entirely convinced that multiplatform UI is a good idea for anything other than the simplest of applications. It always ends up looking out of place on at least one platform and sometimes all of them. reply rubymamis 15 hours agorootparentIt just takes an effort to make Qt apps look and behave native. This has been one of the goals with my new note-taking app, and I think it looks pretty native (at least on macOS): https://www.get-plume.com/ reply ezst 13 hours agorootparentHey, I don't use your app because it's too limited for my \"PKMS\" needs (I use trilium notes instead), but I appreciate that you make being \"native and fast\" a distinguishing feature (vs all the other electron based alternatives boiling the oceans). reply rubymamis 13 hours agorootparentThanks for the feedback, although the app isnâ€™t released yet so you should at least give it a shot once itâ€™s out. I do try to strike a balance between flexibility and ease of use. I think Notion is too complicated (yet very flexible/powerful). With Plume, the focus is to be able to organize your thoughts in a powerful way, effortlessly. Sign up to the waitlist and try it once itâ€™s out. Much more is coming soon. reply ezst 4 hours agorootparent> I think Notion is too complicated I wrote about the problem space extensively on this site before, tl;dr, to me the issue lies in the fact that most of the contenders aim to manage data/knowledge/notes as \"types\" (for categorization, templating and derivation/re-purposing), but, to my knowledge, only trilium is enabling that with a \"sound\" design. Notion is exposing a lot of incidental complexity due to its \"unsoundness\". reply rubymamis 4 hours agorootparentJust read this comment of yours[1]. Plume is aimed to be much simpler than Trilium, I want a non-tech-savvy 40-year-old mom that doesn't know what Kanban is to be able to happily use it as someone that is tech-savvy that knows all about Kanbans. Something that just works for many people, like Apple Notes but with a more advanced editor and features. [1] https://news.ycombinator.com/item?id=39034749 reply mike_ivanov 13 hours agorootparentprevLooks gorgeous. Is it QML or pure Qt? reply rubymamis 13 hours agorootparentThanks! Itâ€™s both. The model side and logic is written in C++ while the view is written in QML. That way I get the best of both worlds, the performance of C++ with the ease of use, flexibility, animations, etc of QML. Itâ€™s worth noting that most Qt Quick components and much of QML code is compiled to C++, so even code on that side is performant. reply mike_ivanov 4 hours agorootparentAmazing. This is very inspiring, thanks. reply aplummer 15 hours agorootparentprevIt just is is a relative term, for example - I already know SwiftUI. reply dheera 20 hours agorootparentprevI hate Qt, the apps look non-native and don't obey Ubuntu's appearance settings and fonts. reply ezst 13 hours agorootparentQt apps arguably look more \"native\" on average than anything else I've seen, considering that it mimics the native look and feel of the target platform for a wide range of them. Now compare that to Gtk, which just leaves you with gnome-style shortcuts and controls on Windows/Mac, and nothing in the area of desktop integration if that's a feature gnome doesn't have (e.g. tray). reply dartharva 14 hours agorootparentprevNobody bats an eye when apps built for Windows don't adhere to its design patterns. Some goes to a large extent for MacOS. I swear Linux users have the strangest obsessions.. reply tcmart14 5 hours agorootparentTo be fair, even Microsoft isn't consistent on what people feel like native should look like. I'm primary a linux/mac user as home, but at work I have to use Windows 11. It is surprising that Microsoft gets paid the Windows given that the control panel has a new updated UI that meshes with Windows 11 fairly well, but then you open up something in control panel and need to access more advanced features and your greeted by a UI that I am pretty sure is from Vista or 7. A standard winforms UI looks totally different from a WinUI. Yes, technically they are all native, but they all look completely different. reply eitland 12 hours agorootparentprevMac users are worse than ordinary Linux users I think (writing this as a Linux user who right now uses a Mac :-) As an ordinary Linux user I at least welcome all applications with bonus points if they are well integrated into KDE. Maybe the Gnome crowd is more picky? reply jwells89 5 hours agorootparentLongtime mac users definitely have a preference for apps that are not only native, but designed to be good citizens of the mac desktop by abiding by its UI conventions, feature progressive disclosure of power user features, etc. reply dheera 2 hours agorootparentprevI mean, most Windows UIs look like shit, they look like something that would be at a DMV. We Linux users do like our desktops to be sleek, badass, and sci-fi ... reply dartharva 14 hours agoparentprev> targeting GTK4 > cross-platform ?? Do you know of any GTK4 app that runs well on non-Unix platforms? reply loic-sharma 22 hours agoparentprevFlutter Linux targets GTK3 and is currently investigating a GTK4 migration. Flutter also supports Windows and macOS. reply PlutoIsAPlanet 22 hours agorootparentBut it doesn't use GTK widgets, it just uses GTK to make a window. That said GTK on Windows and macOS is very meh. You don't choose GTK for making a cross platform app. reply treyd 22 hours agorootparentDeluge and Transmission are good cross platform GTK apps. reply dpassens 22 hours agorootparentTransmission uses Qt on Windows, either GTK or Qt on Linux, and something AppKit on macOS. reply chungy 22 hours agorootparentprevTransmission has Qt and Win32-native GUI clients as an alternative to its GTK client. I don't think Transmission is a good example. reply IshKebab 22 hours agorootparentprevEvidentially it is possible to make GTK apps work at least somewhat nicely on Windows and Mac since there are a few out there. But it's clearly a ton of work. If you just make a standard GTK app it will be terrible. Most toolkits (e.g. Qt or even Flutter) work much nicer without having to fix them. reply sirwhinesalot 22 hours agorootparentprevTransmission only uses GTK on linux. reply abrouwers 22 hours agorootparentThere is a Qt and CLI client, too. reply seabrookmx 17 hours agorootparentAnd a web UI! (My preferred method as I run it on my home server) reply rokkitmensch 20 hours agorootparentprevAnd it's a Google project, which means as soon as the low-hanging promo fruit is harvested it will immediately go EOL. reply seabrookmx 17 hours agorootparentLike golang? Dart? Or Angular? They kill consumer products not programming languages or major frameworks.. reply krasin 16 hours agorootparent> Angular Well, Angular is kind of dead now (or rather - will be). See https://twitter.com/sarah_edo/status/1770478763253379488 > Today we have some exciting news! We're merging frameworks! Angular and Wiz! Wiz is awful and it's my read that a Wiz manager \"won\" a corporate battle and Angular (as it was) is dead. reply seabrookmx 5 hours agorootparentIsn't Wiz internal only at Google? How can it replace Angular (honest question)? reply rokkitmensch 1 hour agorootparentprevSometimes there's a lot of low hanging promo fruit! Generics were a Significant Engineering Challenge! reply wiseowise 14 hours agorootparentprevThese folks built their whole business on DartAngular only to be dropped when some manager decided that itâ€™s time to push Flutter. https://medium.com/wriketechclub/wrike-is-sunsetting-its-ang... reply seabrookmx 5 hours agorootparentHardly anyone used the Dart Angular bindings so it was not surprising they got dropped. They were an early adopter and got bit.. this happens everywhere especially in frontend web development, and is certainly not specific to Google's frameworks. reply YmiYugy 21 hours agoprevHas anyone been able to get this running on Mac. Followed the instructions, but I always get a missing adwaita.h in some shim.h reply axoltl 18 hours agoparentAdwaita is - I believe - closely tied to Gnome. SwiftUI (obviously) already has bindings for macOSâ€™ window server. Not sure what this project gets you on macOS that you donâ€™t already have? reply ankurdhama 18 hours agoparentprevYou will need to install libadwaita. Try \"brew install libadwaita\" reply FireInsight 11 hours agoprevThis is really cool! I love the JSX-like approach to UI and it's a shame it's not so common on desktop. https://github.com/can-lehmann/owlkettle is the only thing I find comparable. reply elcritch 8 hours agoparentAnd Nim is pretty handy for DSL approaches like that! I've never got to try SwiftUI stuff, but it looks great for desktop UIs. reply tripdout 7 hours agoprevIs this the only declarative way to write desktop app UI? (Maybe Kaitlin multiplatform, but not sure how that works on Linux). I mean GTK/Qt reply tschumacher 12 hours agoprevI wonder where the pulse is with current GTK app development. I've noticed some of the newer core apps are in Rust like the new camera app and the image viewer, also the public transport app railway (not a core app afaik). reply imbnwa 23 hours agoprevIâ€™ve recently noticed Swift sneakily becoming an interesting option for desktop dev. On top of this example Iâ€™d add Arc for macOS and Windows. reply diggan 9 hours agoparentWill be interesting to see where it ends up, yeah :) > On top of this example Iâ€™d add Arc for macOS and Windows. Didn't development of Arc stop like a really long time ago? Anarki seems to be where development is at nowadays. reply tunaoftheland 6 hours agorootparentI believe the references to â€œarcâ€ here and elsewhere in the thread is referring to the new web browser and not the Lisp-family language. Thereâ€™s a GitHub link to a Swift ui bindings for Windows elsewhere by another poster here. reply imbnwa 6 hours agorootparentThis is correct reply imbnwa 6 hours agorootparentprevOh, I meant the Arc Browser[0]. Wraps Chromium with a Swift GUI layer [0]https://arc.net/ reply diggan 2 hours agorootparentOh yeah, in hindsight that makes perfect sense. Guess I've spent too much time on HN... reply jamilbk 21 hours agoprevThat's neat! But how is everyone testing their Swift codebases? We've found the story around testing to be... lacking. The [docs](https://developer.apple.com/documentation/xctest) on the subject are pretty bare and don't offer strategies for mocks, stubs, reporting, code coverage, etc. And good luck if your app uses a Network Extension... those must be tested on a live physical device due to the signing restrictions! On that note, does anyone know of a good physical device CI service that supports both iOS and macOS devices? reply suraj 21 hours agoparentTake a look at https://github.com/apple/swift-testing It is under active development as Swift first replacement for xctest. For CI service, Xcode cloud does support running tests on mac and iOS hardware. https://developer.apple.com/xcode-cloud/ reply plorkyeran 14 hours agorootparentXcode Cloud doesnâ€™t actually support running tests on devices. Some of the marketing tries to imply that it does, but itâ€™s simulators only. reply accurrent 16 hours agoprevHow is the 3D story on gtk4 am I still stuck to opengl contexts? reply msie 22 hours agoprevI always thought that introducing keys in function parameters was a mistake. reply yen223 21 hours agoparentNot having keys in function parameters is a mistake. Swift does have an unconventional approach to function keys though, wherein you can specify an \"external\" label and an \"internal\" label: func greeting(for person: String) -> String { \"Hello, \" + person + \"!\" // the argument is \"person\" inside the function body... } print(greeting(for: \"Dave\")) // ... but it's \"for\" when calling the function I'm not sure if I like it or hate it, but it is cool. reply jwells89 21 hours agorootparentI love the internal/external labeling. With a little thought it can make for code that reads more nicely than is possible otherwise. reply dorianmariefr 20 hours agorootparentJavaScript has that with: const hello = ({ for: person }) => `Hello ${person}` hello({ for: \"Dorian\" }) 'Hello Dorian' reply yen223 20 hours agorootparentJavascript's one is a little bit different in that you are renaming the destructured variable - it's not a function-specific thing - whereas Swift's version is a property of the function. e.g. const user = {id: \"123\"}; const { id } = user; // This extracts the `id` field const { id: userId } = user; // This also extracts the `id` field, but renames it to userId console.log(userId) reply jahewson 17 hours agorootparentprevIt does indeed, but the cost is an object allocation for every function call. reply airstrike 20 hours agorootparentprevit's one of those small things that are also brilliant in hindsight reply MBCook 17 hours agorootparentObjective-C sort of had it unofficially through how methods tended to be named. Iâ€™m glad they found a nice way to do it in Swift. reply zem 16 hours agorootparentprevcrystal has it too, and i agree, it's a very nice feature reply tcmart14 5 hours agorootparentprevFor me, I felt the same way initially, but I found it depends on the case. The case you gave is probably now one I would do, I would probably have the external be 'for' if I expected the caller to pass in a list that I was gonna iterate over inside of the method. An example I like to use to show when and how I used it. I have been playing with Metal. If I write a function called translate, I will have it's external parameter as 'by' with the internal parameter being 'vector'. As a simple example: func translate(_ origin: simd_float3, by vector: simd_float3) -> simd_float3 { // do some stuff } let newVector = translate(originalVector, by: translatingVector) reply travisgriggs 18 hours agorootparentprevItâ€™s one of the things I miss most in Kotlin. reply cherryteastain 9 hours agorootparentprevEven C/C++ have the internal/external mismatch: // in greeting.h void greeting(char* for); // in greeting.c void greeting(char* person) { ... } reply seanalltogether 21 hours agoparentprevI disagree, I think the more self documenting the code is, the better. It's also nice with code completion because when I start typing a function, I'm given a list of all the overloads for that function, and when I pick one I get all the arguments sitting there ready for me to fill in. reply msie 20 hours agorootparentYou still get that with traditional languages that donâ€™t use keywords like java. With Swift you have to read a lot more to get the right function since many vary in the number and type of parameters. reply frizlab 22 hours agoparentprevI disagree. It makes the code readable. reply makeitdouble 21 hours agorootparentIt's still a tradeoff: in a previous team switching languages it openned the door to function with 5+ parameters, when that was highly throwned upon otherwise. It's a tool to help better manage complexity, and that naturally invites more complexity as well. reply bigyikes 19 hours agorootparentis that an issue of the language or of the team? adding additional names does not add additional complexity. complexity arises in interactions between components. reply makeitdouble 18 hours agorootparentI see it as mostly influenced by the language and tooling. From there, some people will be more attracted by one side or the other, but when moving stack you tend to follow the stack's natural incline. For instance ruby helps to have shorter, less verbose code, but with more hidden components. Rails rose from there, tooling tends to support that style. I've seen java devs moving to ruby and naturally writing less verbose code. In contract Java tooling makes it a lot more manageable to write 40 character long classes, deeper dependency trees and injections and potentially auto-generate half of the needed methods. The cost is low, and there's less incentive to fight that trend when tools help you abstract part of it. reply bigyikes 18 hours agorootparenti agree but you discuss verbosity and not complexity reply makeitdouble 17 hours agorootparentFair point. You're right that total complexity across the system fundamentally doesn't change (it's up to the devs and the problems at hand). Local complexity in each part of the system can vary, but the whole will probably always be least as complex as it needs to be. reply astrange 15 hours agoparentprevThe best function calling syntax I've ever used is the video scripting language AVISynth, which is mostly key based. It's basically Swift but more flexible and informal. http://avisynth.nl/index.php/Grammar#Functions.2C_Filters_an... reply nurettin 8 hours agoprevYou could say \"writing Gtk code in X language where I implemented a DSL for this special case is easy!\" in any PR piece. You could do it in Python using contextmanager which packs after adding the widget to HBox to save a line, you could do it in Ruby using do/end blocks, you could do it in C with the help of some pretty macros. reply throw_m239339 20 hours agoprevSo, the elephant in room, what's the best way/framework today to write desktop apps for linux (no electron)? reply dzogchen 20 hours agoparentQt of course, hands down. reply earthnail 12 hours agoparentprevQt (without QML). Has been around for ages and works beautifully. GTK is more complicated. I have no experience with libadwaita, but if in doubt I'd always go for Qt on Linux. It's stable, has great tooling and good documentation. And it hasn't changed much over the years, so most information you find - even on Qt 3 - is still mostly accurate today. reply rubymamis 12 hours agorootparentI would argue that Qt with QML is the best combo. See: https://news.ycombinator.com/item?id=39848069 reply earthnail 11 hours agorootparentLove the idea of Plume; signed up to the mailing list. Btw the website layout breaks on very wide browsers (images in the .features-section overlap text). Maybe consider some max-width for the page. And I also have to say that my days with Qt are quite some time ago. I never really got into QML, so if you say that QML is a great choice I'd put more weight on your word than on mine. reply rubymamis 10 hours agorootparentThanks for letting me know! I'll fix that. Qt Quick (The Qt Company's library that is exposed in QML) is very advanced today. I'm able to do things that would be considered very difficult with Qt Widgets. For example: true drag and drop between items in a virtualized list: https://twitter.com/plumenotes/status/1772599295243440137 Also, they started to work well on native widgets (at least on macOS), for example they support native dialogs, context menus, etc. Very helpful. I'll probably write a blog post about the development and architecture (some said they'd be interested). reply FireInsight 13 hours agoparentprevImo libadwaita apps are the best, but I haven't found a perfect solution for writing them. reply tkubacki 17 hours agoparentprevFlutter reply codedokode 11 hours agoprevI don't understand why there are so many negative comments. Writing GUI in C looks like a stone age programming, and people are simply wasting their time to do routine work that can be diminished by using another language. One might use Python, but it is slow and memory-hungry. Isn't it good that now there is an alternative to C? reply amon22 9 hours agoparentI used common lisp in the past to interface with GTK via the cl-cffi-gtk library. Performance was good I think (I did not benchmark but the UI was responsive and did not consume much resources) and dev experience was great because of the REPL. But it did take quite a bit of suffering to get the resulting artifact working on Windows which was a definite requirement sadly. It can be done though. reply diggan 11 hours agoparentprev> Isn't it good that now there is an alternative to C? It's not exactly the first alternative, GJS (Gnome JavaScript) have existed for a long time and is also a C-like language, so doesn't seem this would give too much value compared to just using GJS, unless you know Swift a lot better than JavaScript but the languages are similar enough that even that doesn't provide much value. AFAIK, GJS is an official Gnome project too, so there will be a vast difference in ecosystem support compared to Gnome apps written in Swift, which I'm not sure is so popular outside of Apple circles. reply codedokode 11 hours agorootparentJavaScript is non static-typed and you'll spend time fixing bugs that can be prevented by static typing. Also, GJS is not well documented, as far as I remember. reply diggan 11 hours agorootparent> JavaScript is non static-typed and you'll spend time fixing bugs that can be prevented by static typing. Use TypeScript if types are so important for you. Others find their own way of handling those issues without getting tripped up on it. Hardly a reason to completely switch between two languages in my mind, but of course it's alright if it's reason enough for you. Luckily there are acceptable workarounds for both groups of people :) > Also, GJS is not well documented, as far as I remember. What exactly is missing here? There are guides for the basics, API reference exists and there is a ton of apps you can look into for inspiration and/or figure out specific implementations. Is that really worse than what exists for writing Gnome apps with Swift? Seems like a really weak argument for using Swift instead of GJS. reply codedokode 11 hours agorootparentSwift is compiled, static-typed language and without tons of legacy like JS (for example, it has real objects, not dictionaries). Doesn't require an interpreter. It seems to be better than JS in every aspect. reply diggan 11 hours agorootparentOne mans gold is another mans trash :) Static typing seems to be a neat addition for lots of people, that's great! Doesn't mean it's a silver bullet that improves development for everyone, and that's OK. I still don't see how a language (GJS) with an already existing ecosystem of writing Gnome apps, lots of examples, API references and more is worse for writing Gnome apps than Swift, that seems to have been launched just some days ago? Edit: I realize now that the \"Adwaita for Swift\" this blogpost is about isn't even an official Swift project, is the output of a student interested in Swift and Gnome. reply sph 8 hours agorootparentI think you are vastly overestimating how good and current the GJS documentation and examples are. Without touching the fact that it is NOT a stable API and breaking changes are very common. Even the gold standard of GTK coding in C is still very undocumented outside of the happy path and confusing due to the Gtk 3->4 migration, and the only approach to learning it is by reading what other Gtk apps do. reply Betelgeuse90 9 hours agorootparentprevHonestly I used to think the same way about JS, because not having types allowed for very concise code sometimes. But the more I used Swift I realized how powerful type inference can be, and the difference in conciseness shrunk to basically nothing. reply diggan 9 hours agorootparentHeh, yeah, everyone's journey is different :) I started out being a big fan of static typing but eventually found that I'm usually hit by different issues than \"this was a int but I expected a string\" that were more important to be solved, so I'm mostly using dynamic languages nowadays. But that's what so great with programming languages, there are so many that work so differently, so there is at least one language for everyone, no matter how different your brain works :) By the way, if you're a fan of \"conciseness\" you should give a lisp-type languages a try if you haven't before, will show you a completely different level of conciseness! Clojure is a great introduction to lisps. And if you still need validation of data somehow, clojure.spec et al works great and will introduce you to some cool new things you probably haven't come across before :) reply knallfrosch 7 hours agorootparentprevDoesn't TypeScript â€“ as mentioned above â€“ solve all JavaScript type problems? I have, in 6 years, never encountered a single type error originating from a TS file. reply jwells89 4 hours agorootparentBiggest problems with TypeScript IMO are that itâ€™s a layer rather than a language proper and that untyped JS problems can too easily worm their way in if youâ€™re using any libraries at all. Also depending on the group of developers involved, the ease at which one can pull the escape hatch and opt out of TS is a liability and can render much of its benefit moot. reply SkiFire13 9 hours agorootparentprev> I still don't see how a language (GJS) with an already existing ecosystem of writing Gnome apps, lots of examples, API references and more is worse for writing Gnome apps than Swift, that seems to have been launched just some days ago? I mean, you said it yourself: > One mans gold is another mans trash :) Static typing seems to be a neat addition for lots of people, that's great! For those people it is definitely better than GJS! reply diggan 9 hours agorootparentWell, I mean if the difference was only about static typing, I definitively see what you're talking about. But the difference between GJS and Swift for Gnome app development is greater than that, so personally just that one \"feature\" wouldn't push me towards Swift. But yeah, probably for some it's worth it, so that's pretty cool :) reply azangru 9 hours agorootparentprev> legacy like JS (for example, it has real objects, not dictionaries) Could you explain the nature of problems that occur due to javascrript's treatment of objects? What makes it a big and important issue? reply codedokode 5 hours agorootparentIn JS you can delete properties, assign anything to them (no typing), cannot add comments to them, cannot restrict access from outside. Also you can access non-existing properties and no error will be thrown. reply mahkoh 10 hours agoparentprev>Isn't it good that now there is an alternative to C? Rust has had endorsed language bindings for GTK for a long time: https://www.gtk.org/docs/language-bindings/rust Some official Gnome applications are written in Rust. Swift only supports a small number of linux systems (Ubuntu, CentOS, Amazon Linux) which makes unsuitable for general linux application development. reply machinekob 9 hours agorootparentSwift run on almost every linux desktop (Arch, Debian, Ubuntu etc. have even their own packages) I hate when people are writing false information with such a confidence. reply mahkoh 9 hours agorootparentSee https://www.swift.org/platform-support/ for a list of supported distributions. You seem to have hallucinated that I said that swift cannot be made to run on other systems. You can even make windows-only games run on linux so that is not a surprise. What distinguishes swift from gcc, clang, python, bash, go, rust, and so on is that languages other that swift aim to support linux in general. reply machinekob 9 hours agorootparentSwift only supports a small number of linux systems. which is at most half-truth cause this is just official installers and most likely you'll use some sort of rustup (rust wasn't working on every system few years ago if you use official installer not some sort of rustenv installer or building from source etc.) you can use https://github.com/kylef/swiftenv you can use community packages https://wiki.archlinux.org/title/Swift etc. \"and so on is that languages other that swift aim to support linux in general.\" -> again not true linux distro dosen't change swift usage it is just official build is run for few most popular distros and you can use prebuild swift-bin on any linux repo. (arch, debina, ubuntu, centos etc. etc.) You can say the same stuff about rust/nim/go every other language that didn't have official release for some niche linux distro. reply rsynnott 6 hours agorootparentprevI don't think that, say, rust, offers any explicit support for any particular linux distro? Swift here are basically saying they'll endeavour to make sure it works on those particular distros, but in general you're probably going to install Swift on Linux the same way you install rust; via your distro's package manager, and supported by your distro, not the Swift or Rust project. reply cocoto 9 hours agorootparentprevIt might run but support and packaging is missing, compared to gtk oficially supported for other languages and packaged on distributions that matter (e.g. Debian). reply machinekob 9 hours agorootparenthttps://forums.swift.org/t/new-swift-package-repository-for-... reply diggan 9 hours agorootparentprev\"runs\" would be different than \"supports\". AFAIK, there still isn't an official package for Swift in the Arch package registry, so to say Swift is supported by Arch sounds like \"writing false information with such a confidence\". reply machinekob 9 hours agorootparenthttps://wiki.archlinux.org/title/Swift reply diggan 9 hours agorootparent> Install swift-bin [AUR] Notice the [AUR] tag, that means it's in the Arch User Repository, not in the official repository. https://wiki.archlinux.org/title/Arch_User_Repository https://wiki.archlinux.org/title/Official_repositories Slightly ironic given the whole \"confidence\" side-note you made earlier... reply machinekob 8 hours agorootparentalmost no smaller/newer language is added to official repo so i don't know what are you taking about it is kinda expected? (even if this languages are fully supported on linux) https://wiki.archlinux.org/title/MATLAB https://wiki.archlinux.org/title/Scala etc. reply diggan 8 hours agorootparentBe that as it may, the initial claim was \"Swift only supports a small number of linux systems\" which you tried to refute but moved the goal post from \"supports\" to \"runs\". One of them are true for Swift + Arch, yes. reply machinekob 8 hours agorootparentSupporting languages isn't the arch maintainers job I srsly don't understand your argument if all language stuff (LSP, language, debbuger etc.) work on every linux distro without any modifications is this distro \"supported\"? If rustup will be removed from official repo we can argue that rust isn't supported in arch? reply jeroenhd 10 hours agorootparentprevWhy doesn't Swift run on other Linux distributions? reply machinekob 9 hours agorootparentIt runs just fine comment above is lying if you can run llvm/clang you can run Swift. reply tcmart14 4 hours agorootparentI don't know if I would say, 'just fine.' Technically yes. The issue comes in with that not everything in Foundation is quiet yet there on the Linux platform. But it is getting better and better and probably good enough for 90% of stuff. It seems more of a problem of just getting the last bit done to push Foundation over the finish line. reply poulpy123 9 hours agoparentprevto be fair and looking at how closed is the apple ecosystem, I would not put my open source eggs in swift reply tiny_ouch 8 hours agorootparentMy feelings exactly! It's frustrating the lack of viable alternatives though. Just typing on my japanese flip phone is a pain and i think the T9 could be improved. That said i don't think adopting apple tech would help much as far as fixing any deficiencies in ui imho. reply t888 6 hours agorootparentprevHow does the App Store affect Swift? reply sgjohnson 6 hours agorootparentprevSwift is open source. reply kevincox 7 hours agoparentprevYeah, I'll happily take GUIs written in a fairly fast and memory efficient language that are using a full GUI toolkit. It beats Electron, Python, Java or Go programs any day. reply pjmlp 6 hours agoparentprevGtkmm exists since GNOME 1.0 days. As do bindings for Python, C#, Lisp, Scheme, Vala, JavaScript (since GNOME 3)... reply steve1977 8 hours agoparentprev> Isn't it good that now there is an alternative to C? Thereâ€™s this new kid in town, IIRC itâ€™s called C++ reply vi4m 11 hours agoprevReally something we needed. Swift has such low memory usage, that it's an order of magnitude easier on resources, than those Electron wrappers. At the same time, it gives what you loved about React - expressiveness for UI. I wrote a lot of apps in SwiftUI, and it strikes a good balance between type safety and expressiveness, it's cool that we have something similar for GKT/Gnome now. reply coldtea 22 hours agoprev>The primary motivation for this package is to enable the use of Swift when writing GNOME apps, for all the reasons outlined above The only problem I have with such projects is when they are unmaintained, in various stages of immaturity, and have little adoption (vicious circle). You find them, they promise exactly what you need, and then you fell into issue after issue in practical use (*). It would be amazing if there was (perhaps this is or will be) well maintained bindings for Swift/Rust/Go and co for Gnome. * Yes, it's open source and you can fix some of the issues yourself. Doesn't mean you have the know-how or time to fix all of them, especially when there are lots of things to fix or features missing. Ideally a big community must exist, so that each can just work on or fix a small part and the problem still get lots of fixes/improvements incoming, as opposed to \"fully replace the single overworked maintainer yourself\". reply dkh 22 hours agoparentThis. Over the years I've seen so many cool projects aiming to ease native desktop UI development, but most became unmaintained at some point, for what I am guessing is due to the difficulty and complexity associated with actually making this work in practice. It is less sexy, but a solid language binding to the existing libraries is likely the more practical and maintainable way to go reply MBCook 17 hours agorootparentAfter so many years of seeing cross platform stuff come and go I canâ€™t help but think it canâ€™t be done well enough for mass adoption. It just has too many gotchas that make things feel out of place on every platform in different ways. At least outside my first demo app territory. The only thing that really seems to be succeeding is web stuff like Electron, which usually throws the baby out with the bathwater and does its own thing of emulating the web (itself, basically) instead of trying to feel perfectly native. reply jcelerier 16 hours agorootparentIdk I've been developing with Qt for idk, 15 years now, it's stable and keeps chugging along with constant improvements. And is used in more than enough mass-adopted apps, e.g. Telegram reply georgelyon 22 hours agoparentprevThis is spot-on. Though I think the interesting thing here is just demonstrating that you _can_ build this kind of thing at all and a cross-platform-SwiftUI-like framework isn't a pipe dream. For production use-cases at this moment in time, I'd probably lean towards using Swift's pretty-good C++ interop functionality to thinly wrap a more battle-tested C++ library. reply Razengan 22 hours agoparentprevI donâ€™t get these kinds of complaints about open source projects.. Seems like you guys want either 0% or 100% ..that something either not exist at all or perfectly does everything you ever wanted without any effort or cost on your part. reply dkh 21 hours agorootparentIt doesn't have to be 100%, but nobody wants to invest a ton of time/energy into a project just to hit a wall a little ways down the road when something at the very core of it breaks or becomes unmaintained. Of course it would be nice for users of such projects to help and contribute, but this isn't always practical. Not because the users are being entitled assholes, but often times they aren't even the same skillsets, and I think this is especially true of some of this complicated, low-level UI stuff. If I'm a user of PyGObject writing GTK apps in Python, I'm not necessarily capable of contributing to the underlying C bindings, even if I wanted to be helpful. This dynamic presents a legitimate problem for pretty much any open source project that aims to abstract away something very complex to enable more developers to use it. Any project that does this is going to have more developers relying on it than are capable of contributing to it. You should never feel entitled to continued development of a project you don't contribute to, and you should always assess the community around tools you want to use in order to make good decisions. But this doesn't mean you can't be super frustrated if something you rely on goes dormant. I personally avoid using any library/package that doesn't appear to be very active, but nothing is foolproof. Even a seemingly healthy project die can fairly quickly in certain circumstances. reply lmm 22 hours agorootparentprevYou want a process and commitment, a clear distinction between which things are first-class and which things aren't. If this is just an experimental project that may not go anywhere, fine. If this is meant to be the new way of writing Gnome apps, displacing Vala, and they're going to support it in LTS releases for at least the next n years, fine. But it should be clear which it is. reply balder1991 21 hours agorootparentprevI think the discussion is valid, I donâ€™t see it as complaining. People can create cool things, but you have to weight whether that can actually be used in practice. After all, until AI start writing software for us, maintaining a project takes time and effort. No one wants to see it go to waste. reply coldtea 21 hours agorootparentprev>Seems like you guys want either 0% or 100% ..that something either not exist at all or perfectly does everything you ever wanted without any effort or cost on your part. Or, you know, that's a strawman, and we just want something that exists and is mature, like hundreds of other FOSS people are fine with, as opposed to basing our code on something that is immature, has little community, and will probably be abandoned when the authors get bored with it. Which has nothing to do with it being \"100%\" or \"perfectly doing everything we ever wanted\". reply eptcyka 22 hours agoprevIs there a language server for Swift that does not suck? I believe swift is a good language, however its ecosystem being steered by apple is a massive red flag. It also suffers a bit from being a commercially developed language in that its developers are clearly incentivized to add more features. reply dcgudeman 20 hours agoparent> a commercially developed language in that its developers are clearly incentivized to add more features. Do you have any evidence this is true? Most programming languages are developed either by a company (C#, Java, Swift, Go) or heavily influenced by many companies (Python, JavaScript, C++). Java had been criticized forever (until very recently) for it's slow pace of development and it was 100% controlled by either Sun or Oracle. Comments like these show just how little developers investigate the reasons why features they personally dislike were introduced to a language. reply MBCook 16 hours agorootparentAs a professional Java developer its new feature pace is still slow. Itâ€™s a little better but it hasnâ€™t been fast in a VERY long time. But thatâ€™s OK. They do an amazing job of maintaining backwards compatibility and making things fit in the language well as well as trying to get it right the first time. Some languages are more willing to remove things that donâ€™t work. Others are willing to have multiple different attempts that all work completely differently every few years. In many ways thatâ€™s just not Javaâ€™s style. And thatâ€™s OK. reply tkubacki 8 hours agorootparentIf you want to move faster in JVM world use Kotlin. There is no alternative in .NET world- thatâ€™s why JVM ecosystem is much better (and bigger) reply MBCook 6 hours agorootparentIâ€™m actually quite happy with how itâ€™s done, but I know many others arenâ€™t. reply pjmlp 5 hours agorootparentprevF# would be the alternative. reply tkubacki 3 hours agorootparentF# is not mainstream lang - itâ€™s more like Clojure for .NET. My point was - you donâ€™t have that variety in .NET as in JVM (Scala, Kotlin, Groovy are all relatively mainstream) reply pjmlp 3 hours agorootparentKotlin is only mainstream on Android because Google says so, Groovy is barely kept alive thanks Gradle, and if it wasn't for Kafka and Spark, Scala would have been long gone. Hardly any better than F#. reply tkubacki 1 hour agorootparentWell you are clearly out of JVM world. See supported langs here https://start.spring.io/ (most popular JVM framework) Kotlin is especially popular on backend if you canâ€™t jump out of JDK8 F# is functional - by definition not mainstream reply georgelyon 22 hours agoparentprevsourcekit-lsp works really well, VSCode integration is solid[1]. I've been using VSCode+dev-containers+sourcekit-lsp for a couple years now for Linux development on macOS and it has been really nice. I agree that this is a must-have for idiomatic Swift. It is really hard to write the long-named-functions and get all the variable names correct without reasonable autocomplete. [1]: https://www.swift.org/blog/vscode-extension/ reply jwells89 21 hours agorootparentVS Code isnâ€™t too bad, it after ~20 years of Xcode/Project Builder, muscle memory for keybinds and UI in general is strong. Hoping that someone uses the LSP to write a cross platform â€œXcode Liteâ€ or something along those lines. reply georgelyon 20 hours agorootparentIt wasn't too bad to switch for me, but the problem is going back and forth. I don't love over-customizing my IDE but I've created my own keybindings for the commands I mis-type most (Command-R to run being the main culprit). Both Xcode and VSCode support custom key bindings and this isn't something that the LSP is responsible. UI is a different matter. Xcode is still miles ahead in performance tooling. reply cmrdporcupine 19 hours agorootparentprevI was curious and noticed that this looks reasonable: https://github.com/emacs-lsp/lsp-sourcekit Emacs + lsp-mode + sourcekit + company-mode etc looks reasonably close to what I get with Rust in Emacs. If I were doing application development I'd maybe consider Swift. reply zapzupnz 17 hours agoparentprevItâ€™s not a commercially developed language; itâ€™s open source and many of its features have been developed outside of Apple. reply Apocryphon 22 hours agoprevFlutter desktop app support has been on Ubuntu since 2021, but not sure if that ever got anywhere. reply robertlagrant 22 hours agoparentI quite enjoyed following a Flutter/Dart tutorial[0] a couple of years ago. Quite enjoyed the combo. If anyone fancies trying it, it's probably also the best tutorial I've ever seen. Really well structured and just the right amount of detail based on the place in the tutorial. [0] https://www.youtube.com/watch?v=1ukSR1GRtMU (video) reply bcye 22 hours agorootparentTop comment: \"don't follow this tutorial [because it's outdated]\" :( reply robertlagrant 22 hours agorootparentI don't see that one. There's one from 3 weeks ago that liked the course. I did do it years ago though, so it could be outdated now. reply zogrodea 13 hours agorootparentprevI had to use Flutter and Dart for a job a couple of years back and found this video series an excellent guide when learning about them too. Would recommend to anyone looking to learn either too. reply fngjdflmdflg 22 hours agoparentprevYes flutter works on Linux. In fact the Ubuntu installer/OOBE is written in Flutter.[0] Not sure how this is related to the OP though. [0] https://ubuntu.com/blog/how-we-designed-the-new-ubuntu-deskt... reply QuantumG 21 hours agoprevThe article doesn't summarise the differences between developing these cross-platform apps vs only targetting Apple and that is the most important information really. Did I miss it? reply worik 22 hours agoprevI spent 3-years with Swift recently Makes me want to ask: Why? Why do this? It is a decent language for 2005. But it has some serious shortcomings (reference counting garbage collector? Really?) The worst thing IMO is its dreadful support for threads. The \"DispatchQueue\" seems to be a wrapper around \"fork/renice\". There is no attempt at memory protection. But it is full of little niggles that get very irritating in this day and age. I never used Objective-C so it may be a vast improvement on that. It is no longer 2005, and we deserve, and we have, better languages. My time as an Apple developer left me with the overwhelming sensation that Apple hates its developers. So much cool looking stuff that mostly worked... reply frizlab 21 hours agoparentARC is for classes, structs use donâ€™t have that and classes are heavily discouraged. DispatchQueue is anything but fork/renice. Also there is async/await now. GCD should be used for concurrent work only now, not async work. Memory protection is fully implemented in Swift 5.10, but compilation only warns, enabled by default as errors in Swift 6. reply cageface 20 hours agorootparentI really like the struct-based method of modeling data in Swift. The language makes this very convenient. Unfortunately the new Observation framework which is at the center of SwiftUI requires classes. https://forums.swift.org/t/any-future-directions-for-support... reply amomchilov 4 hours agorootparentThis makes sense, observation requires a durable identity, which structs donâ€™t have. Two struct might be the same, but when I observe for changes in one, but not another, a distinction arises which is best captured by object-based identity reply stevepotter 21 hours agoparentprevI did obj-c on a popular consumer app about 10 years ago. Recently had to make an app. I used async/await and SwiftUI heavily. Used observableobject and actors as well. Itâ€™s very nice, much like a React/typescript app. UIs used to be torture I did have to build some things that I felt should have come standard. For example, I had to build a class that provides a thread-safe way to enqueue objects and process them in a background task, which used DispatchQueue internally. By and large, itâ€™s a world of difference from what it was and my experience has been joyful. Xcode cloud just worked so thatâ€™s cool. Profiling is wonderful (signposts etc). Could there be improvements? Sure. Are there other languages with better features? I think so. But I havenâ€™t found myself longing much for something provided by other languages and platforms Point is, I no longer dread iOS development. In fact, itâ€™s quite fun. reply cageface 20 hours agorootparentI'm coming back to iOS development after years of doing web stuff. SwiftUI will feel very familiar to anyone that's done React and massively reduces the amount of boilerplate and ceremony it takes to build for Apple platforms. It has some rough edges but overall feels like the most modern mainstream UI toolkit now. reply astrange 15 hours agorootparentprev> I did have to build some things that I felt should have come standard. For example, I had to build a class that provides a thread-safe way to enqueue objects and process them in a background task, which used DispatchQueue internally. That is DispatchQueue. Or NSOperationQueue. Or preferablly Swift concurrency. Most wrappers around dispatch queues are unnecessary and use it incorrectly. (I would say this is true of operation queues themselves.) Swift concurrency is better than dispatch, though. reply saagarjha 6 hours agorootparent> Swift concurrency is better than dispatch, though. For some things, sure. reply jumhyn 21 hours agoparentprevFWIW the concurrency story has been getting substantially more attention over the past couple of years with first-class language support. Swift 6 aims to be data-race-safe by default. reply zapzupnz 17 hours agoparentprev2005? Swift is from 2014. reply keyle 21 hours agoparentprevI'm not sure where you get your references from but Swift is one of the most modern and advanced languages out there. The documentation of Apple is worse than hot garbage though. As in, at least with hot garbage you have something. reply tcmart14 4 hours agorootparentI've gotten better at navigating the Apple docs, but yea, they are not the best. The one thing I will say, when they give code snippets in their docs, the code snippets are really good. But you just need to read the API of a framework or see the functions tied to a type, it could be a lot better. reply developerDan 21 hours agorootparentprevWhat do you mean? Apple has lots and lots of documentation saying that function signatures exist! (/s just in case) reply 3 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article explores utilizing Swift for developing GNOME apps, emphasizing the Adwaita for Swift package.",
      "Benefits of Swift include cleaner syntax and enhanced code readability when compared to languages like Python.",
      "Adwaita for Swift streamlines GNOME app development by facilitating data-centric UI design, supporting cross-platform development, and integrating with Flathub for app distribution."
    ],
    "commentSummary": [
      "The post delves into the hurdles of developing Gnome apps using Swift, emphasizing a SwiftUI-like wrapper for Gnome features, addressing challenges such as concurrency, data binding, cross-platform support, and long-term project maintenance.",
      "Users share their encounters with UI updates and difficulties in handling navigation split views specifically on macOS, shedding light on architecture patterns like MVVM and the significance of establishing guidelines for UI development.",
      "Discussions extend to the potential influence of Microsoft's technologies on Linux, exploring various languages and frameworks for GUI development, while outlining the pros and cons of code-centric UI programming."
    ],
    "points": 530,
    "commentCount": 263,
    "retryCount": 0,
    "time": 1711575659
  },
  {
    "id": 39848847,
    "title": "Uncovering Unheard Machine Learning Breakthroughs",
    "originLink": "https://news.ycombinator.com/item?id=39848847",
    "originBody": "What are some exciting things that are happening in the #ML #DataScience world that we are not able to hear over the din of LLMs?I notice that Cynthia rudin is continuing to produce great stuff on explainable AI.What else is going on that is not GPT&#x2F;Diffusion&#x2F;MultiModal?",
    "commentLink": "https://news.ycombinator.com/item?id=39848847",
    "commentBody": "What things are happening in ML that we can't hear over the din of LLMs?319 points by aflip 12 hours agohidepastfavorite85 comments What are some exciting things that are happening in the #ML #DataScience world that we are not able to hear over the din of LLMs? I notice that Cynthia rudin is continuing to produce great stuff on explainable AI. What else is going on that is not GPT/Diffusion/MultiModal? lelag 10 hours agoSome exciting projects from the last months: - 3d scene reconstruction from a few images: https://dust3r.europe.naverlabs.com/ - gaussian avatars: https://shenhanqian.github.io/gaussian-avatars - relightable gaussian codec: https://shunsukesaito.github.io/rgca/ - track anything: https://co-tracker.github.io/ https://omnimotion.github.io/ - segment anything: https://github.com/facebookresearch/segment-anything - good human pose estimate models: (Yolov8, Google's mediapipe models) - realistic TTS: https://huggingface.co/coqui/XTTS-v2, bark TTS (hit or miss) - open great STT (mostly whisper based) - machine translation (ex: seamlessm4t from meta) It's crazy to see how much is coming out of Meta's R&D alone. reply nicce 10 hours agoparent> It's crazy to see how much is coming out of Meta's R&D alone. They have the money... reply logtempo 10 hours agorootparentand data reply joshspankit 6 hours agorootparentand (rumours say) engineers who will bail if Meta doesnâ€™t let them open source reply teaearlgraycold 8 hours agorootparentprevHundreds of thousands of H100sâ€¦ reply FLT8 8 hours agorootparentAnd a dystopian vision for the future that can make profitable use of the above ... reply AYBABTME 8 hours agorootparentOn the plus side, people make up the organization and when they eventually grow fed up with the dystopia, they leave with their acquired knowledge and make their own thing. So dystopias aren't stable in the long term. reply falcor84 8 hours agorootparentThat seems to rely on the assumption that human input is required to keep the dystopia going. Maybe I watched too much sci-fi, but the more pessimistic view is that the AI dystopia will be self-sustaining and couldn't be overcome without the concerted use of force by humans. But we humans aren't that good in even agreeing on common goals, let alone exerting continuous effort to achieve them. And most likely, by the time we start to even think of organizing, the AI dystopia will be conducting effective psychological warfare (using social media bots etc.) to pit us against each other even more. reply dmd 8 hours agorootparentprevThe Ones Who Walk Away From O-Meta-s reply randrus 8 hours agorootparentA very apt reference to the story The ones who walk away from Omelas Dunno how pasting a link works but here it is: https://shsdavisapes.pbworks.com/f/Omelas.pdf reply refulgentis 7 hours agorootparentI feel vaguely annoyed, I think it's because it took a lot of time to read through that, and it amounts to \"bad to put child in solitary confinement to keep whole society happy.\" What does a simplistic moral set piece about the abhorrence of sacrificing the good of one for the good of many have to do with (check notes) Facebook? Even as vague hand-wavey criticism, wouldn't Facebook would be the inverse? reply tga_d 1 hour agorootparentYou have every right to take what you like from it, but I'd suggest that perhaps you're not seeing what others are if all you get is a morality play. As one example, maybe spend some time thinking about why you apparently missed that it's intentionally left ambiguous as to whether the child is even real in the story's world. reply refulgentis 56 minutes agorootparentA condescending lecture starting with \"you just don't get it\" ending with \"I read your mind and know you missed the 'but was it even real?'\" part isnt imparting anything useful. Re: \"actually you should just ponder why you are a simpleton who doesn't get it, given other people derived value from how it relates to Facebook\": There arent people here running around praising it. The comment 4 up was, and still is downvoted well below 0, there's barely anyone reading all the way down here. Only one other person even bothered replying. I don't think me mentioning this is useful or fair, but I don't know how to drive home how little contribution there is from a condescending \"think harder, didn't you notice the crowd loves it and understands how it's just like Facebook\" reply HPsquared 7 hours agorootparentprevSo the dystopia spreads out... Metastasis reply karaterobot 7 hours agorootparentprev> So dystopias aren't stable in the long term. Unless they think to hire new people. reply teaearlgraycold 8 hours agorootparentprevFor some people this is a stable dystopia. reply JL-Akrasia 3 hours agoparentprev- streaming and rendering 3d movies in real-time using 4d gaussian splatting https://guanjunwu.github.io/4dgs/ reply jusgu 3 hours agoparentprevNot sure how relevant this is but note that Coqui TTS (the realistic TTS) has already shut down https://coqui.ai reply turnsout 7 hours agoparentprevWhoa, Bark got a major update recently. Thanks for the link as a reminder to check in on that project! reply lelag 5 hours agorootparentCan you share what update you are referring to ? I've played with Bark quite extensively a few month ago and I'm on the fence regarding that model: when it works, it's the best, but I found it to be pretty useless for most use-case I want to use TTS for because of the high rate of bad or weird output. I'm pretty happy with XTTv2 though. It's reliable and output quality is still pretty good. reply mike_hearn 11 hours agoprevNeRFS. It's a rethink of 3D graphics from the ground up, oriented around positioning glowing translucent orbs instead of textured polygons. The positioning and color of the orbs is learned by a NN given accurate multi-angle camera shots and poses, then you can render them on GPUs by ray tracing. The resulting scenes are entirely photo-realistic, as they were generated from photos, but they can also be explored. In theory you can also animate such scenes but how to actually do that is still a research problem. Whether this will end up being better than really well optimized polygon based systems like Nanite+photogrammetry is also an open question. The existing poly pipes are pretty damn good already. reply baxuz 11 hours agoparentWhat you're talking about is I think gaussian splats. NeRFS are exclusively radiance fields without any sort of regular 3d representation. reply lelag 11 hours agorootparentYes, I think Gaussian Splats are were all the rage is. My limited understanding is that Nerfs are compute-heavy because each cloud point is essentially a small neural network that can compute its value from a specific camera angle. Gaussian splats are interesting since they achieve almost the same effect using a much simpler mechanism of using gaussian values at each cloud points and can be efficiently computed in real-time on GPU. While a Nerf could be used to render a novel view of a scene, it could not do so in real-time, while gaussian splats can which opens up lots of use-cases. reply Mandelmus 8 hours agorootparent> My limited understanding is that Nerfs are compute-heavy because each cloud point is essentially a small neural network There's no point cloud in NeRFs. A NeRF scene is a continuous representation in a neural network, i.e. the scene is represented by neural network weights, but (unlike with 3D Gaussian Splatting) there's no explicit representation of any points. Nobody can tell you what any of the network weights represent, and there's no part of it that explicitly tells you \"we have a point at location (x, y, z)\". That's why 3D Gaussian Splatting is much easier to work with and create editing tools for. reply lelag 6 hours agorootparentInteresting. Thanks for the clarification. reply phireal 9 hours agoparentprevThere's a couple of computerphile videos on this: nerfs: https://youtu.be/wKsoGiENBHU Gaussian platting: https://youtu.be/VkIJbpdTujE reply unwind 11 hours agoparentprevVery cool, thanks! NeRFs = Neural Radiance Fields, here [1] is the first hit I got that provides some example images. [1]: https://www.matthewtancik.com/nerf reply sigmoid10 11 hours agoparentprev>Whether this will end up being better than really well optimized polygon based systems like Nanite+photogrammetry is also an open question I think this is pretty much settled unless we encounter any fundamental new theory roadblocks on the path of scaling ML compute. Polygon based systems like Nanite took 40+ years to develop. With Moore's law finally out of the way and Huang's law replacing it for ML, hardware development is no longer the issue. Neural visual computing today is where polygons where in the 80s. I have no doubt that it will revolutionize the industry, if only because it is so much easier to work with for artists and designers in principle. As a near-term intermediate we will probably see a lot of polygon renderers with neural generated stuff inbetween, like DLSS or just artificially generated models/textures. But this stuff we have today is like the Wright brother's first flight compared to the moon landing. I think in 40 years we'll have comprehensive real time neural rendering engines. Possibly even rendering output directly to your visual cortex, if medical science can keep up. reply WithinReason 9 hours agorootparentIt's easier to just turn NeRFs/splats into polygons for faster rendering. reply sigmoid10 3 hours agorootparentThat's only true today. And it's quite difficult for artists by comparison. I don't think people will bother with the complexities of polygon based graphics once they no longer have to. reply ron0c 5 hours agoprevUW-Madison's ML+X community is hosting Machine Learning Marathon that will be featured as a competition on Kaggle (https://www.kaggle.com/c/about/host) \"What is the 2024 Machine Learning Marathon (MLM24)? This approximately 12-week summer event (exact dates TBA) is an opportunity for machine learning (ML) practitioners to learn and apply ML tools together and come up with innovative solutions to real-world datasets. There will be different challenges to select from â€” some suited for beginners and some suited for advanced practitioners. All participants, project advisors, and event organizers will gather on a weekly or biweekly basis to share tips with one another and present short demos/discussions (e.g., how to load and finetune a pretrained model, getting started with GitHub, how to select a model, etc.). Beyond the intrinsic rewards of skill enhancement and community building, the stakes are heightened by the prospect of a cash prize for the winning team.\" More information here: https://datascience.wisc.edu/2024/03/19/crowdsourced-ml-for-... reply ok_dad 10 hours agoprevAnyone know anything I can use to take video of a road from my car (a phone) and create a 3D scene from it? More focused on the scenery around the road as I can put a road surface in there myself later. Iâ€™m talking about several miles or perhaps more, but I donâ€™t mind if it takes a lot of processing time or I need multiple angles, I can drive it several times from several directions. Iâ€™m trying to create a local road or two for driving on in racing simulators. reply Jedd 9 hours agoparentphotogrammetry - is the key word you're looking to search on. There's quite a few advanced solutions already (predating LLM/ML) reply 0_____0 8 hours agorootparentSLAM from monoscopic video. I imagine without an IMU or other high quality pose estimator you'll need to do a fair bit of manual cleanup. reply WhatIsDukkha 8 hours agoparentprevGaussian splatting, there is quite a bit of youtube about it and there are commercial packages that are trying to make a polished experience. https://www.youtube.com/@OlliHuttunen78 edit - I just realized you want a mesh :) for which Gaussian splatting is not there yet! BUT there are multiple papers which are exploring adding gaussians to a mesh thats progressively refined, I think its inevitable based on what's needed for editing and usecases just like yours. You could start exploring and compiling footage and testing and maybe it will work out but ... Here is a news site focused on the field - https://radiancefields.com/ reply chpatrick 7 hours agoparentprevYou can do this for free now with RealityCapture, not ML though. reply sp332 8 hours agoparentprevMicrosoft's PhotoSynth did this years ago, but they cancelled it. reply beklein 11 hours agoprevMore like a cousin of LLMs are Vision-Language-Action (VLA) models like RT-2 [1]. Additionally to text and vision data they also include data from robot actions as \"another language\" as tokens to output movement actions for robots. [1]: https://robotics-transformer2.github.io reply angusturner 11 hours agoprevOne area that I would dive into (if I had more time) is \"geometric deep learning\". i.e) How to design models in a principled way to respect known symmetries in the data. ConvNets are the famous/obvious example for their translation equivariance, but there are many recent examples that extend the same logic to other symmetry groups. And then there is also a question of whether certain symmetries can be discovered or identified automatically. reply mrdmnd 8 hours agoparentI've been doing some reading on LLMs for protein/RNA structure prediction and I think there's a decent amount of work on SO3 invariant transformer architectures now reply mjhay 7 hours agorootparentThere's also been some work on more general Lie-group equivariant transformer models. http://proceedings.mlr.press/v139/hutchinson21a/hutchinson21... reply postatic 9 hours agoprevI launched https://app.scholars.io to get latest research from arxiv on specific topics Iâ€™m interested in so I can filter out ones that Iâ€™m not interested. Hopefully it will help someone find research activities other than LLM. reply 4b11b4 5 hours agoparentjust signed up for computer vision and image processing related topics as this is what I'm specializing in for my Master's The interface to sign up was very painless and straightforward I signed up for a 2-week periodic digest The first digest comes instantly and scanning through the titles alone was inspirational and I'm sure will provide me with more than a few great papers to read over upcoming years reply kookamamie 11 hours agoprevThe SAM-family of computer-vision models have made many of the human annotation services and tools somewhat redundant, as it's possible to achieve relatively high-quality auto-labeling of vision data. reply joshvm 10 hours agoparentThis is probably true for simple objects, but there is almost certainly a market for hiring people who use SAM-based tools (or similar) to label with some level of QA. I've tried a few implementations and they struggle with complex objects and can be quite slow (due to GPU overhead). Some platforms have had some variant of \"click guided\" labelling for a while (eg V7) but they're not cheap to use. Prompt guided labelling is also pretty cool, but still in infancy (eg you can tell the model \"label all the shadows\"). Seg GPT for example. But now we're right back to LLMs... On labelling, there is still a dearth of high quality niche datasets ($$$). Everyone tests on MS-COCO and the same 5-6 segmentation datasets. Very few papers provide solid instructions for fine tuning on bespoke data. reply kookamamie 7 hours agorootparentThat's basically what we are able to do now: showing models an image (or images, from video) and prompting for labels, such as with \"person, soccer player\". reply wara23arish 8 hours agoprevI was just going to ask a similar question recently. Ive been working on a side project involving xgboost and was wondering if ML is still worth learning in 2024. My intuition says yes but what do I know. reply danieldk 8 hours agoparentI recently attended an interesting talk at a local conference. It was from someone that works at a company that makes heating systems. They want to optimize heating given the conditions of the day (building properties, outside temperature, amount of sunshine, humidity, past patterns, etc.). They have certain hard constraints wrt. model size, training/update compute, etc. Turns out that for their use case a small (weights fit in tens of KiB IIRC) multilayer perceptron works the best. There is a lot of machine learning out in the world like that, but it doesn't grab the headlines. reply krapht 7 hours agorootparentI have doubts that a simple adaptive building model-based controller wouldn't be better, and interpretable. I wonder why you'd go with a perceptron... those are so limited. reply rkwz 6 hours agorootparentprevSounds interesting, can you share a link to video if available? reply mjhay 7 hours agoparentprevxgboost will still work better for most problems people encounter in industry (which usually involve tabular data). reply anshumankmr 11 hours agoprev+1 to this, but one might be hard pressed to find anything nowadays that isn't involving a transfomer model somehow. reply TheDudeMan 11 hours agoparentSame sentiment here. Love the question, but transformers are still so new and so effective that they will probably dominate for a while. We (humans) are following the last thing that worked (imagine if we could do true gradient decent on the algorithm space). Good question, and I'm interested to hear the other responses. reply antegamisou 9 hours agorootparent> but transformers are still so new and so effective that they will probably dominate for a while. They're mostly easy grant money and are being gamed by entire research groups worldwide to be seen as effective on the published papers. State of academia... reply sdenton4 9 hours agoparentprevIn the area in working in (bioacoustics), embeddings from supervised learning are still consistently beating self supervised transformer embeddings. The transformers win on held out training data (in-domain) but greatly underperform on novel data (generalization). I suspect that this is because we've actually got a much more complex supervised training task than average (10k classes, multilabel), leading to much better supervised embeddings, and rather more intense needs for generalization (new species, new microphones, new geographic areas) than 'yet more humans on the internet.' reply PaulHoule 6 hours agorootparentIn text analysis people usually get better results in many-shot scenarios (supervised training on data) vs zero-shot (give a prompt) and the various one-shot and few-shot approaches. reply tkulim 8 hours agorootparentprevHey, that is a field that I am interested in (mostly inspired by a recent museum exhibition). Do you have recent papers on this topic, or labs/researchers to follow? reply sdenton4 8 hours agorootparentIt's a really fun area to work in, but beware that it's very easy to underestimate the complexity. And also very easy to do things which look helpful but actually are not (eg, improving classification on xeno canto, but degrading performance on real soundscapes). Here's some recent-ish work: https://www.nature.com/articles/s41598-023-49989-z We also run a yearly kaggle competition on birdsong recognition, called birdclef. Should be launching this year's edition this week, in fact! Here's this year's competition, which will be a dead link for now: https://www.kaggle.com/competitions/birdclef-2024 And last year's: https://www.kaggle.com/competitions/birdclef-2023 reply antegamisou 9 hours agoprevI wager the better question is What things are happening in fields of, or other than, CS that we don't hear over the din of ML/AI reply babel_ 7 hours agoprevSo, from the perspective I have within the subfield I work in, explainable AI (XAI), we're seeing a bunch of fascinating developments. First, as you mentioned, Rudin continues to prove that the reason for using AI/ML is that we don't understand the problem well enough; otherwise we wouldn't even think to use it! So, pushing our focus to better understand the problem, and then levy ML concepts and techniques (including \"classical AI\" and statistical learning), we're able to make something that not only outperforms some state-of-the-art in most metrics, but often even is much less resource intensive to create and deploy (in compute, data, energy, and human labour), with added benefits from direct interpretability and post-hoc explanations. One example has been the continued primacy of tree ensembles on tabular datasets [0], even for the larger datasets, though they truly shine on the small to medium datasets that actually show up in practice, which from Tigani's observations [1] would include most of those who think they have big data. Second, we're seeing practical examples of exactly this outside Rudin! In particular, people are using ML more to do live parameter fine-tuning that outwise would need more exhaustive searches or human labour that are difficult for real-time feedback, or copious human ingenuity to resolve in a closed-form solution. Opus 1.5 is introducing some experimental work here, as are a few approaches in video and image encoding. These are domains where, as in the first, we understand the problem, but also understand well enough that there's search spaces we simply don't know enough about to be able to dramatically reduce. Approaches like this have been bubbling out of other sciences (physics, complexity theory, bioinformatics, etc) that lead to some interesting work in distillation and extraction of new models from ML, or \"physically aware\" operators that dramatically improve neural nets, such as Fourier Neural Operators (FNO) [2], which embeds FFTs rather than forcing it to be relearned (as has been found to often happen) for remarkable speed-ups with PDEs such as for fluid dynamics, and has already shown promise with climate modelling [3], material science [4]. There are also many more operators, which all work completely differently, yet bring human insight back to the problem, and sometimes lead to extracting a new model for us to use without the ML! Understanding begets understanding, so the \"shifting goalposts\" of techniques considered \"AI\" is a good thing! Third, specifically to improvements in explainability, we've seen the Neural Tangent Kernel (NTK) [5] rapidly go from strength to strength since its introduction. While rooted in core explainability vis a vis making neural nets more mathematically tractable to analysis, not only inspiring other approaches [6] and behavioural understanding of neural nets [7, 8], but novel ML itself [9] with ways to transfer the benefits of neural networks to far less resource intensive techniques; which [9]'s RFM kernel machine proves competitive with the best tree ensembles from [0], and even has advantage on numerical data (plus outperforms prior NTK based kernel machines). An added benefit is the approach used to underpin [9] itself leads to new interpretation and explanation techniques, similar to integrated gradients [10, 11] but perhaps more reminiscent of the idea in [6]. Finally, specific to XAI, we're seeing people actually deal with the problem that, well, people aren't really using this stuff! XAI in particular, yes, but also the myriad of interpretable models a la Rudin or the significant improvements found in hybrid approaches and reinforcement learning. Cicero [12], for example, does have an LLM component, but uses it in a radically different way compared to most people's current conception of LLMs (though, again, ironically closer to the \"classic\" LLMs for semantic markup), much like the AlphaGo series altered the way the deep learning component was utilised by embedding and hybridising it [13] (its successors obviating even the traditional supervised approach through self-play [14], and beyond Go). This is all without even mentioning the neurosymbolic and other approaches to embed \"classical AI\" in deep learning (such as RETRO [15]). Despite these successes, adoption of these approaches is still very far behind, especially compared to the zeitgeist of ChatGPT style LLMs (and general hype around transformers), and arguably much worse for XAI due to the barrier between adoption and deeper usage [16]. This is still early days, however, and again to harken Rudin, we don't understand the problem anywhere near well enough, and that extends to XAI and ML as problem domains themselves. Things we can actually understand seem a far better approach to me, but without getting too Monkey's Paw about it, I'd posit that we should really consider if some GPT-N or whatever is actually what we want, even if it did achieve what we thought we wanted. Constructing ML with useful and efficient inductive bias is a much harder challenge than we ever anticipated, hence the eternal 20 years away problem, so I just think it would perhaps be a better use of our time to make stuff like this, where we know what is actually going on, instead of just theoretically. It'll have a part, no doubt, Cicero showed that there's clear potential, but people seem to be realising \"... is all you need\" and \"scaling laws\" were just a myth (or worse, marketing). Plus, all those delays to the 20 years weren't for nothing, and there's a lot of really capable, understandable techniques just waiting to be used, with more being developed and refined every year. After all, look at the other comments! So many different areas, particularly within deep learning (such as NeRFs or NAS [17]), which really show we have so much left to learn. Exciting! [0]: LÃ©o Grinsztajn et al. \"Why do tree-based models still outperform deep learning on tabular data?\" https://arxiv.org/abs/2207.08815 [1]: Jordan Tigani \"Big Data is Dead\" https://motherduck.com/blog/big-data-is-dead/ [2]: Zongyi Li et al. \"Fourier Neural Operator for Parametric Partial Differential Equations\" https://arxiv.org/abs/2010.08895 [3]: Jaideep Pathak et al. \"FourCastNet: A Global Data-driven High-resolution Weather Model using Adaptive Fourier Neural Operators\" https://arxiv.org/abs/2202.11214 [4]: Huaiqian You et al. \"Learning Deep Implicit Fourier Neural Operators with Applications to Heterogeneous Material Modeling\" https://arxiv.org/abs/2203.08205 [5]: Arthur Jacot et al. \"Neural Tangent Kernel: Convergence and Generalization in Neural Networks\" https://arxiv.org/abs/1806.07572 [6]: Pedro Domingos \"Every Model Learned by Gradient Descent Is Approximately a Kernel Machine\" https://arxiv.org/abs/2012.00152 [7]: Alexander Atanasov et al. \"Neural Networks as Kernel Learners: The Silent Alignment Effect\" https://arxiv.org/abs/2111.00034 [8]: Yilan Chen et al. \"On the Equivalence between Neural Network and Support Vector Machine\" https://arxiv.org/abs/2111.06063 [9]: Adityanarayanan Radhakrishnan et al. \"Mechanism of feature learning in deep fully connected networks and kernel machines that recursively learn features\" https://arxiv.org/abs/2212.13881 [10]: Mukund Sundararajan et al. \"Axiomatic Attribution for Deep Networks\" https://arxiv.org/abs/1703.01365 [11]: Pramod Mudrakarta \"Did the model understand the questions?\" https://arxiv.org/abs/1805.05492 [12]: META FAIR Diplomacy Team et al. \"Human-level play in the game of Diplomacy by combining language models with strategic reasoning\" https://www.science.org/doi/10.1126/science.ade9097 [13]: DeepMind et al. \"Mastering the game of Go with deep neural networks and tree search\" https://www.nature.com/articles/nature16961 [14]: DeepMind et al. \"Mastering the game of Go without human knowledge\" https://www.nature.com/articles/nature24270 [15]: Sebastian Borgeaud et al. \"Improving language models by retrieving from trillions of tokens\" https://arxiv.org/abs/2112.04426 [16]: Umang Bhatt et al. \"Explainable Machine Learning in Deployment\" https://dl.acm.org/doi/10.1145/3351095.3375624 [17]: M. F. Kasim et al. \"Building high accuracy emulators for scientific simulations with deep neural architecture search\" https://arxiv.org/abs/2001.08055 reply touisteur 1 hour agoparentThanks a lot. I love the whole XAI movement, as it often forced you think of cliff and limits and non-linearity of the methods. Makes you circle back to an engineering process of thinking about specification and qualification of your black box. reply strangecasts 4 hours agoparentprevThank you for providing an exhaustive list of references :) > Finally, specific to XAI, we're seeing people actually deal with the problem that, well, people aren't really using this stuff! I am very curious to see which practical interpretability/explainability requirements enter into regulations - on one hand it's hard to imagine a one-size fits all approach, especially for applications incorporating LLMs, but Bordt et al. [1] demonstrate that you can provoke arbitrary feature attributions for a prediction if you can choose post-hoc explanations and parameters freely, making a case that it can't _just_ be left to the model developers either [1] \"Post-Hoc Explanations Fail to Achieve their Purpose in Adversarial Contexts\", Bordt et al. 2022, https://dl.acm.org/doi/10.1145/3531146.3533153 reply dartos 9 hours agoprevAlpha fold seems like a major medical breakthrough reply svdr 8 hours agoprevThis is a nice daily newsletter with AI news: https://tldr.tech/ai reply hiddencost 10 hours agoprevKeep in mind that LLMs are basically just sequence to sequence models that can scan 1 million tokens and do inference affordably. The underlying advances (attention, transformers, masking, scale) that made this possible are fungible to other settings. We have a recipe for learning similar models on a huge variety of other tasks and data types. reply HarHarVeryFunny 6 hours agoparentTransformers are really more general than seq-to-seq, maybe more like set-to-set or graph-to-graph. The key insight (Jakob Uszkoreit) to using self-attention for language was that language is really more hierarchical than sequential, as indicated by linguist's tree diagrams for describing sentence structure. The leaves of one branch of a tree (or sub-tree) are independent of those in another sub-tree, allowing them to be processed in parallel (not in sequence). The idea of a multi-layer transformer is therefore to process this language hierarchy one level at a time, working from leaves on upwards through the layers of the transformer (processing smaller neighborhoods into increasingly larger neighborhoods). reply chronosift 9 hours agoprevA novel SNN framework I'm working on. Newest post has been taking me a while. metalmind.substack.com reply PaulHoule 6 hours agoprevI'm just a touch disappointed that this thread is still dominated by neural-network methods, often that apply similar architectures as LLMs to other domains such as vision transformers. I'd like to see something about other ML methods such as SVM, XGBoost, etc. reply dmarchand90 11 hours agoprevTo plug my own field a bit, in material science and chemistry there is a lot of excitement in using machine learning to get better simulations of atomic behavior. This can open up exciting areas in drug and alloy design, maybe find new CO2 capturing material's or better cladding for fusion reactors, to name just a few. The idea is that to solve these problems you need to solve the schrodinger equation (1). But the schrodinger equation scales really badly with the number of electrons and can't get computed directly for more than a few sample cases. Even Density Functional Theory (DFT), the most popular approximation that still is reasonably accurate scales N^3 with the number of electrons, with a pretty big pre factor. A reasonable rule of thumb would be 12 hours on 12 nodes (each node being 160 cpu cores) for 256 atoms. You can play with settings and increase your budget to maybe get 2000 (and only for a few timesteps) but good luck beyond that. Machine learning seems to be really useful here. In my own work on aluminium alloys I was able to get the same simulations that would have needed hours on the supercomputer to run in seconds on a laptop. Or, do simulations with tens of thousands of atoms for long periods of time on the supercomputer. The most famous application is probably alphafold from deep mind. There are a lot of interesting questions people are still working on: What are the best input features? We don't have any nice equivalent to CNNs that are universally applicable, though some have tried 3d convnets. One of the best methods right now involves taking spherical harmonic based approximates of the local environment in some complex way I've never fully understood, but is closer to the underlying physics. Can we put physics into these models? Almost all these models fail in dumb ways sometimes. For example if I begin to squish two atoms together they should eventually repel each other and that repulsion force should scale really fast (ok maybe they fuse into a black hole or something but we're not dealing with that kind of esoteric physics here). But, all machine learning potentials will by default fail to learn this and will only learn the repulsion to the closest distance of any two atoms in their training set. Beyond that and the guess wildly. Some people are able to put this physics into the model directly but I don't think we have it totally solved yet. How do we know which atomic environments to simulate? These models can really only interpolate they can't extrapolate. But while I can get an intuition of interpolation in low dimensions once your training set consists of many features over many atoms in 3d space this becomes a high dimensional problem. In my own experience, I can get really good energies for shearing behavior of strengthening precipitates in aluminum without directly putting the structures in. But was this extrapolated or interpolated from the other structures. Not always clear. (1) sometimes also the relativistic Dirac equation. E.g. fast moving moving atoms in some of the heavier elements move at relativistic speeds. reply rsfern 8 hours agoparentMore physical ML force fields is a super interesting topic that I feel like blurs the line between ML and actually just doing physics. My favorite topic lately is parametrizing tight binding models with neural nets, which hopefully would lead to more transferable potentials, but also let you predict electronic properties directly since youâ€™re explicitly modeling the valence electrons Context for the non-mat-sci crowd - numerically solving Schrodinger essentially means constructing a large matrix that describes all the electron interactions and computing its eigenvalues (iterated to convergence because the electron interactions are interdependent on the solutions). Density functional theory (for solids) uses a Fourier expansion for each electron (these are the one-electron wave functions), so the complexity of each eigensolve is cubic in the number of valence electrons times the number of Fourier components The tight binding approximation is cool because it uses a small spherical harmonic basis set to represent the wavefunctions in real space - you still have the cubic complexity of the eigensolve, and you can model detailed electronic behavior, but the interaction matrix youâ€™re building is much smaller. Back to the ML variant: itâ€™s a hard problem because ultimately youâ€™re trying to predict a matrix that has the same eigenvalues as your training data, but there are tons of degeneracies that lead to loads of unphysical local minima (in my experience anyway, this is where I got stuck with it). The papers Iâ€™ve seen deal with it by basically only modeling deviations from an existing tight binding model, which in my opinion only kind of moves to problem upstream reply occamschainsaw 8 hours agoparentprevI am currently working on physics-informed ML models for accelerating DFT calculations and am broadly interested in ML PDE solvers. Overall, I think physics-informed ML (not just PINNs) will be very impactful for computationally heavy science and engineering simulations. Nvidia and Ansys already have \"AI\" acceleration for their sims. https://developer.nvidia.com/modulus https://www.ansys.com/ai reply mynameismon 9 hours agoparentprev> In my own work on aluminium alloys I was able to get the same simulations that would have needed hours on the supercomputer to run in seconds on a laptop. Could you elaborate on this further? How exactly were the simulations sped up? From what I could understand, were the ML models able to effectively approximate the Schrodinger's equation for larger systems? reply dmarchand90 9 hours agorootparentWhat you do is you compute a lot of simulations with the expensive method. Then you train using neural neural networks (well any regression method you like). Then you can use the trained method on new arbitrary structures. If you've done everything right you get good, or good enough results, but much much faster. At a high level It's the same pipeline as in all ML. But some aspects are different, e.g. unlike image recognition you can generate training data on the fly by running more DFT simulations reply fennecfoxy 9 hours agorootparentThat's pretty cool! It seems like most of ML is just creating a higher dimensional representation of the problem space during training and then exploring that during inference. I suppose your process would be using ML to get pointed in the \"right direction\" and then confirming the models theories using the expensive method? reply dmarchand90 1 hour agorootparentYeah exactly like this. It is a subtle art of validating in small scale a method you would later use at large scale. reply aflip 9 hours agoparentprevibh i didn't understand most of that but sounds exciting. reply dmarchand90 6 hours agorootparentWe want to do computer experiments instead of real life experiments to discover or improve chemicals and materials. The current way of doing computer experiments is really really slow and takes a lot of computers. We now have much faster ways of doing the same computer experiments by first doing it the slow way a bunch of time to train an machine learning model. Then, with the trained model, we can do the same simulations but way way faster. Along the way there are tons of technical challenges that don't show up in LLMs or Visual machine learning. If there is anything unclear you're interested in just let know. In my heart I feel I'm still just a McDonald's fry cook and feel like none of this is as scary as it might seem :) reply FrustratedMonky 11 hours agoprevSeems like there is always push back on LLM's that they don't learn to do proofs and reasoning. Deepmind just placed pretty high at International Mathematical Olympiad . Here it does have to present reasoning. https://arstechnica.com/ai/2024/01/deepmind-ai-rivals-the-wo... And it's couple years old, but AlphaFold was pretty impressive. EDIT: Sorry, I said LLM. But meant AI/ML/NN generally, people say a computer can't reason, but DeepMind is doing it. reply imtringued 10 hours agoparent>To overcome this difficulty, DeepMind paired a language model with a more traditional symbolic deduction engine that performs algebraic and geometric reasoning. I couldn't think of a better way to demonstrate that LLMs are poor at reasoning than using this crutch. reply fennecfoxy 9 hours agorootparentI suppose it's because LLM training data uses text that can contain reasoning within it, but without any specific context to specifically learn reasoning. I feel like the little reasoning an LLM can do is a byproduct of the training data. Does seem more realistic to train something not on text but on actual reasoning/logic concepts and use that along with other models for something more general purpose. LLMs should really only be used to turn \"thoughts\" into text and to receive instructions, not to do the actual reasoning. reply FrustratedMonky 6 hours agorootparentprevI wouldn't say 'crutch' but component. Eventually LLMs will be plugged into Vision Systems, and Symbolic Systems, and Motion Systems, etc... etc... The LLM wont be the main 'thing'. But the text interface. Even human brain is bit segmented with different faculties being 'processed' in different areas with different architectures. reply king_magic 9 hours agoprevfeatup reply publius_0xf3 10 hours agoprev [â€“] Is there anything cool going on in animation? Seems like an industry that relies on a lot of rote, repetitive work and is a prime candidate for using AI to interpolate movement. reply soulofmischief 10 hours agoparent [â€“] 3D animation is seeing tools like https://me.meshcapade.com/ crop up reply xrd 7 hours agorootparent [â€“] That is a really creepy demo. It is cool for sure, but creepy for sure. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Work by Cynthia Rudin on explainable AI is making exciting developments in the machine learning and data science world.",
      "Models like GPT, Diffusion, and MultiModal are currently popular, overshadowing other important advancements in the field.",
      "Despite the attention on certain models, there are other significant advancements in machine learning and data science deserving of recognition."
    ],
    "commentSummary": [
      "The post discusses new advancements in machine learning and data science, including 3D scene reconstruction, Gaussian avatars, text-to-speech technology, and explainable AI, amidst the buzz around models like GPT.",
      "It highlights progress in neural rendering and deep learning, along with possible industry applications, while also delving into the hurdles faced in adopting and interpreting AI models, mentioning technologies such as NeRFs and NAS.",
      "Other areas explored are the integration of AI in material science, chemistry, and 3D animation, offering a broad view of AI's expanding influence across diverse fields."
    ],
    "points": 319,
    "commentCount": 85,
    "retryCount": 0,
    "time": 1711614358
  },
  {
    "id": 39854182,
    "title": "NotepadNext: Cross-Platform Notepad++ Reimplementation",
    "originLink": "https://github.com/dail8859/NotepadNext",
    "originBody": "Notepad Next A cross-platform, reimplementation of Notepad++. Though the application overall is stable and usable, it should not be considered safe for critically important work. There are numerous bugs and half working implementations. Pull requests are greatly appreciated. Installation Packages are available for Windows, Linux, and MacOS. Windows packages are available as an installer or a stand-alone zip file on the release page. The installer provides additional components such as an auto-updater and Windows context menu integration. You can easily install it with Winget: winget install dail8859.NotepadNext Linux packages can be obtained by downloading the stand-alone AppImage on the release page or by installing the flatpak by executing: flatpak install flathub com.github.dail8859.NotepadNext MacOS disk images can be downloaded from the release page. MacOS Tweaks By default, MacOS enables font smoothing which causes text to appear quite differently from the Windows version. This can be disabled system-wide using the following command: defaults -currentHost write -g AppleFontSmoothing -int 0 A restart is required for this to take effect. Development Current development is done using Visual Studio 2022 and Qt v6.2+ on Windows. This is also known to build successfully on various Linux distributions and macOS. Other platforms/compilers should be usable with minor modifications. If you are familiar with building C++ Qt desktop applications with Qt Creator, then this should be as simple as opening src/NotepadNext.pro and build/run the project. If you are new to building C++ Qt desktop applications, there is a more detailed guide here. License This code is released under the GNU General Public License version 3.",
    "commentLink": "https://news.ycombinator.com/item?id=39854182",
    "commentBody": "NotepadNext â€“ a cross-platform reimplementation of Notepad++ (github.com/dail8859)286 points by Brajeshwar 4 hours agohidepastfavorite178 comments qwertox 3 hours agoNotepad++ (and this one here) are based on Scintilla [0]. It's worth pointing it out because it is a high-quality open source code editor component. SciTE [1] is the \"official\" demo-editor for Scintilla and was last updated on March 9th 2024. The history reaches back to 1999. [0] https://www.scintilla.org/ [1] https://www.scintilla.org/SciTE.html reply kiney 2 hours agoparentI really like geany, which is also based on scintilla reply speps 3 hours agoparentprevI wrote a custom mod more than 15 years ago for SciTE that exposed its plugin API to Ruby and wrote some of my own plugins. It didn't support multiple cursors and I instantly switched to Sublime as soon as I discovered that feature, never looked back. reply jmole 2 hours agorootparentWhat are multiple cursors used for? reply rezonant 9 minutes agorootparentAny time you need to make the same edits in multiple places. I use it to mass edit array items for example by using the highlight / add cursor to identical text feature in VS Code (Ctrl+D). I even use it to copy data out of the browser and mass edit it into data structures-- often there will be some pattern to the pasted data even if it's garbage, so being able to quickly set up multicursors around the patterns in the text makes this sort of task much easier, if you are luckily on how the data pastes out. Multicursors are the number one editor innovation of the last ten years that developers should get comfortable with-- once you start to use them you won't want to use an editor without them. reply twodave 1 hour agorootparentprevI use it to: * transform a list of field names into different formats (class properties, sql select list, etc.) * quick and dirty convert delimited text into insert statements or graphql queries or json objects * really anything I need to change in column mode but with better tracking of words via mod+arrow keys reply nolongerthere 1 hour agorootparentprevI use it daily in vscode to clean up small data sets where wrangling regex will take more time, and the data set isnâ€™t something that Iâ€™m gonna see again so itâ€™s not worth generalizing a solution. reply blacksmith_tb 1 hour agorootparentprevI use it all the time to mangle small amounts of data, like selecting all the newlines in a file with cntrl-d and making them into \",\" to make it into values for an array or something (obv. search+replace could do that, still it's quicker for a small number this way, or feels like it). It was pretty slick in the early TextMate / Sublime days to see people editing html and making a big bunch of tags all write themselves out simultaneously. reply input_sh 2 hours agorootparentprevIf you're using the same variable name across the file, but want to change only a couple of references to something else, it fills that \"I need to do this more than once, but in a bit of an easier to reach, fancier way than with find and replace\" niche. reply AeroNotix 28 minutes agorootparentMost editors these days should have \"rename\" functionality which is very aware of how that symbol is used across a codebase. M-x lsp-rename in emacs, for example works great, if you're using lsp. reply rezonant 6 minutes agorootparentYes but this is more general, allowing you to use it in more cases. For instance, I use it heavily when converting old JavaScript to modern ES/TS. Using \"var\" everywhere? Replace them all with let. Using anonymous functions instead of lambdas, easy to change those all over (provided there's no \"this\" dependencies) Have two thousand strings which all need the same edits? No need to do a find/replace operation, you can do it directly in the editor. reply neoromantique 6 minutes agorootparentprevIt helps when it is a bit more interactive, i.e when I only need to replace some of the occurrences versus everything. Also when working with lists it is useful, you spawn cursors on , or The only way for one person to even attempt cross-platform app is to use a UI abstraction layer like Qt, WxWidgets or Gtk. >The problem is that Gtk is ugly, Qt is extremely bloated and WxWidgets barely works.[0] To be fair, a PDF reader and a notepad editor are two different things, and startup speed is only one metric which is the only one I tested. But I always assumed npp was also using win32 APIs only for similar reasons. (I don't actualy know what GUI toolkit npp uses.) And \"bloated\" could perhaps mean a lot of things. Perhaps QT takes more memory or something. But I always assumed npp's unbeatable speed was due to native APIs. [0] https://blog.kowalczyk.info/article/2f72237a4230410a888acbfc... reply chrystalkey 1 hour agoparentSumatra is such an awesome piece of software, small, fast, almost entirely bug-free, incredible load speeds for large pdfs... my Linux alternative is Evince, which does about the same reply zozbot234 1 hour agoparentprevGTK+ 3 and 4 are quite visually ugly, but you can get Windows classic-styled themes for both (from Chicago95 and B00merang project respectively) that will make them far more usable. reply criddell 11 minutes agorootparentDo those themes mimic the Windows look or do they ask Win32 to draw butons, windows, menus, etc...? reply xcv123 1 hour agoparentprevPerformance is not an issue with Qt. He probably means the framework is too large and complicated from a developer perspective. The compiled code is fast. reply umpalumpaaa 48 minutes agorootparentCame here to say the same thing. Qt is a C++ library and is widely used (for example in KDE) and is also used in embedded environments a lot. And its pretty mature. reply tentacleuno 3 hours agoprevI very much miss Notepad++ for making quick notes, and then being able to close the window without being asked whether I'd like to save the document. This, and auto-save (so not losing documents if you forget to save) is one of the main reasons I replaced Notepad with ++. Rather quickly, I found that I had to completely remove Notepad so muscle memory would stop guiding me to it. Good times (and sad ones; I lost a lot of lecture notes) -- nevertheless, Notepad++ is an excellent piece of software. I'm curious if the same \"write and close the window\" workflow is achievable with Kate, as I haven't been able to find the option; and, of course, the obvious question: what about this one? reply publius_0xf3 2 hours agoparentOccasionally, someone will submit their new text editor to Hacker News and the first thing I do is check if it quietly saves sessions upon closure. It's amazing how many people don't bother implementing this indispensable feature. reply jraph 2 hours agorootparentKate can restore sessions, not sure it can auto save on close. Ctrl+L saves all but Kate will ask for still unnamed files. reply tentacleuno 2 hours agorootparentI haven't been able to get it to act like Notepad++, wherein it doesn't ask you to save on quit. Perhaps there's a configuration option I've missed? reply jraph 1 hour agorootparentI'll look for it but I'm not sure I've ever seen it despite having seen the settings countless times. If it doesn't exist it could be an easy and useful contribution :-) reply tentacleuno 2 hours agorootparentprevI'm very glad others have come to expect this feature, too; I assumed it was another of my weird, niche workflows :-) reply nullindividual 3 hours agoparentprevNotepad will now restore open files, like Notepad++ does. TextEdit on macOS does the same. reply MBCook 2 hours agorootparentIt has been a suggested/encouraged default behavior on the Mac for many years at this point. reply adamomada 1 hour agorootparentItâ€™s just yet another thing Apple gets right: why would the default be to NOT keep what you just put into the computer? reply card_zero 1 hour agorootparentIt seems to be the modern way, and normal on mobile apps, and I can't stand it. Why would I want the computer to save what I wrote without asking? I like being asked. I dislike computers trying to be clever. reply NekkoDroid 1 hour agorootparentprev> why would the default be to NOT keep what you just put into the computer? Because you didn't ask it to save and closed the app? reply mxuribe 1 hour agoparentprevI don't think the core/default Kate editor does the same \"write and close the window\" like Notepad++. Kate does have pretty cool options for session handling - which helps keep files open that you had been working on, etc...which i understand is not the same thing. But, now that you asked, i wonder if there is a plugin or extenson for Kate that might provide such a feature? I myself am a fan of Notepad++, and install it on any corporate-issued Windows machine that i am given by dayjobs...but at home, its all linux all the time, so Kate comes closest for me. I did see someone else mentioned that there is something named NotepadQQ or something which is like Notepad++ but works cross-platform...so that sounds interesting if true. And, i wonder if NotepaddQQ has that auto \"write and close the window\" workflow? reply dailykoder 32 minutes agoparentprevHave you tried neovim? It just works and is blazing fast (respectively plain vim, if you don't need plugins) reply kayodelycaon 1 hour agoparentprevYou probably already know this. VSCode has both autosave and hot exit features. If you quit the application when hot exit is enabled, it will restore all windows the next time you start it. I don't see any way to close individual windows without prompting but you can do command+w and then command+d to \"Don't Save\". reply tentacleuno 1 hour agorootparentOh yeah, VSCode's autosave has saved me hours in otherwise-lost code. I do make frequent use of its hot-exit functionality, too. While that's great, I wish the same thing existed for a lightweight Notepad-esque app, too: I used ++ a lot for quickly jotting down information while it was being read to me (so, on the phone); having to start a full-blown IDE for this seems wasteful, and not the right tool for the job. Perhaps the solution is just to leave VSCode open all the time, but that wouldn't work either: whenever I switch workspaces, I'm asked whether I'd like to save the unsaved files (so, just like Kate), and it can be quite resource intensive. Grr. reply teekert 1 hour agoparentprevFwiw, I do this in Obsidian (it just saves every keystroke), really enjoying it. reply thrdbndndn 3 hours agoparentprevit's achievable with default notepad.exe in Win11. reply SpartanJ 1 hour agoprevShameless plug: I'm working on a multi-platform code editor similar to NP++ and some new editors like Zed called ecode, that tries to be a fresh take on code editors using some modern tools and technologies like LSPs. I started working on it after using Geany for many years but finding Geany lacking some essential features for my needs. ecode is developed with speed in mind and has a very fast startup time. [1] https://github.com/SpartanJ/ecode/ reply hoyd 19 minutes agoparentNice work. Does it have auto-save, like npp? reply user3939382 3 hours agoprevJust to provide a diversity of opinion: I've heard basically nothing but positive feedback about Notepad++ over the years. However, I tried it out for about 10 seconds before closing it and never looked back. The, what I call \"millions of tiny buttons\" interface is ugly and distracting. I've never liked IDEs or other apps with this UI style. I use a JetBrains IDE now that has just as many features but the UI is not cluttered with millions of tiny buttons and tool ribbons. reply gamepsys 3 hours agoparentI greatly miss those tool bars. I think it's ironic that modern UI strives to be less cluttered than ever before while computer monitors are larger than ever before. * They encourage curiosity about previously undiscovered functionality. It improves feature discoverability. * It's way easier to find the correct tool bar icon than trying to hunt for a feature inside the menus. * If some toolbars are highlighted or disabled can tell you information about the state of the document you are editing. reply funnybeam 2 hours agorootparentâ€œless cluttered than ever before while computer monitors are larger than ever before.â€ Less cluttered but with more white space, especially in the vertical direction which is particularly cramped since the change in monitor aspect ratios so the toolbars have less functionality but take up more of the usable screen space. Progress is greatâ€¦ reply nine_k 3 hours agorootparentprevThere is no \"One size fits all\" UI, sadly. Absolute beginners should be shown a basic interface front and center, with a clear way to access more advanced features. More advanced users may benefit from a plethora of rich controls, all shown together. Experts may want to remove the visual clutter because they access features from keyboard without looking. Good software offers a way to achieve all of these, and often more customization. reply jvanderbot 3 hours agorootparentJust give me a view->toolbars-> checklist and I'll sort it out. FreeCAD does this well. reply giancarlostoro 3 hours agorootparentprevVisual Studio (not Code) lets you move it all around, remove pieces, and add things. It's one of the reasons I love Visual Studio. I otherwise use JetBrains for other languages, or when on other OS' it was a shame VS for Mac went away, but I assume adoption was not very high. reply jwells89 2 hours agorootparentprevI think an argument can be made for toolbars if theyâ€™re customizable with no holes barred on customizability (looking at you, Firefox, with your non-optional hamburger menu) and can be hidden entirely, should the user choose to do so. For me, toolbars as they were commonly implemented in Cocoa apps for the first half of OS Xâ€™s history are the model example here, which offer all the above. Itâ€™s when theyâ€™re not fully customizable and arenâ€™t optional when they grate on me. reply darby_eight 3 hours agorootparentprev> It's way easier to find the correct tool bar icon than trying to hunt for a feature inside the menus. What? I am just completely confused by thisâ€”menu items are labeled in clear textual language, sorted roughly by functionality. icons greatly depend on cultural context. Looking at a screenshot of notepad++ I could would understand maybe a third of the icons and could guess at another third at best. That said, it's not that big of a dealâ€”I'd probably just disable the toolbar rather than figure it out. I don't really use the mouse outside of selecting regions of text anyway. reply jwells89 2 hours agorootparentI find it depends on how many things are in the toolbar, and if the icons are actually icons or monochromatic glyphs. A toolbar thatâ€™s populated only with the most frequently used functions and employs full color, uniquely shaped icons can be visually grokked in an instant, whereas a densely packed toolbar full of glyphs is inscrutable at a glance. reply Dalewyn 3 hours agorootparentprevOnce you learn a toolbar, it just becomes visual and muscle memory. Not unlike using hotkeys to access something hidden under a couple layers of menus. reply darby_eight 3 hours agorootparentSure, but that's very different from \"feature discovery\". I totally get this with the floppy-disk icon (which is, ironically enough, now a terrible visual metaphor for persisting to local storage outside of cultural context), but I have no clue what \"up arrow on top of down arrow\" means, nor what the Â¶ icon would doâ€”start a new paragraph? Select the current paragraph? Open some kind of paragraph outline? Granted, I don't use windows so it's entirely possible I'm just showing my ass here. reply Dalewyn 2 hours agorootparentThe toolbar buttons all have hover text to ease the learning, Â¶ is \"Show All Characters\" where \"characters\" mean stuff like Carriage Return and whitespace. Microsoft Word users are probably familiar with this meaning. I have no idea what \"up arrow on top of down arrow\" is though, because I don't have that button. reply codedokode 2 hours agorootparentprevThe problem with tool bars is that usually you cannot guess what 80% of the icons mean. reply jprd 2 hours agorootparentIf you hover over the icon, a tooltip pops up to help remind/train you on what the icons represent. reply codexb 33 minutes agoparentprevNotepad++ originated at a time when there weren't many code editors for most of the new, growing languages (perl, python, js), or for editing xml and json, especially on windows. Many of the \"good\" code editors were expensive and enterprisey, or they were limited to linux, or they had an extremely steep learning curve (vim, emacs). Notepad++ worked on everything, was free, installed quickly, and it was fast. I've used it to replace hardcoded values in binary files before. I think most of the people who are praising it are remembering how valuable it was 20 years ago. I don't know anyone that still uses Notepad++. reply AdrianB1 2 minutes agorootparentI have it on a few thousand servers in my department, mostly as a Notepad that can do more, like comment color or editing small config files of all sorts. It is far from the days I used to write entire small apps in Notepad ++, but we still use it and there is no plan to replace it unless they do something that puts us in danger (ex: stop fixing bugs/security issues). reply soupbowl 2 hours agoparentprevTakes one second to disable all that. I've used notepad++ forever and not once have I used those buttons, indeed they are useless. Your opinion is valid but I never understand using a tool with options and acting like the defaults are the only option. reply lukan 1 hour agorootparentThat is true, but it takes more than 1 second to find out about it. reply CraigJPerry 3 hours agoparentprevThe new Jetbrains ui is hard to like. Itâ€™s form over function. The old ui (thankfully still available). Having to hover over a hamburger button just to cause it to draw the menu bar options then slide the mouse across to what you want is annoying. The new commit window alt+0 is better, the old modal always felt tacked on when everything else is a docked panel. reply hyperman1 3 hours agorootparentI tried it. The first week I shared your opinion. But then something flipped. I configured and learned hotkeys to hide the file/services/... pane and ended up with something I can only describe as 'calm'. Only 1 or 2 panes of code visible, and all functions hidden but available. The main detractor is indeed the hamburger menu. Vscode had ctrl-p, emacs has alt-x, and both provide a way to search for some function to execude. I hope Jetbrains is hiding something similar in its innnards, but haven't found it yet. Ctrl ctrl isn't it, at least for me. I went all-in on Jetbrains Ultimate last year without regrets. The thing is great and powerfull, but it is hard to find what you need in there, and hard to find out what is the purpose of some functionality. I've actually lost usefull functionality: Something usefull but I don't remember the name and can't find it in the menus. I should spend some time spellunking in there. Even so, I hope they find something better than the hamburger or the zillion hotkeys. reply abhinavk 3 hours agorootparentJetbrains has Double Shift and Ctrl+Shift+A. reply hyperman1 35 minutes agorootparentThanks, all of you. reply michaelcampbell 1 hour agorootparentprevInterestingly in the JetBrains emacs keybindings set, alt-x does exactly what you want. So, it's bindable, and you can use it in ANY keybinding, emacs or not. reply ydant 2 hours agorootparentprevI like the new UI as well. There's always a learning curve, but after using it for months I haven't found any reason to switch back. ctrl+ctrl is \"run anything\" (I tend to use ctrl+alt+r for the different but similar run menu instead). I think what you want is \"Actions\" - which is default to \"shift shift\" and then click on a tab, or (ctrl/cmd)+shift+a to jump directly to that tab. reply indymike 3 hours agorootparentprev> The new Jetbrains ui is hard to like. Itâ€™s form over function. I'd like my JetBrains IDEs better with a 10x speedup. The new redesign isn't bad if you memorize keyboard shortcuts :-) reply bboygravity 3 hours agorootparent> The new redesign isn't bad if you memorize keyboard shortcuts :-) Contradictio in terminis reply nine_k 3 hours agorootparentprevWith time, you start using the menu very rarely, because keyboard shortcuts are so much faster. No menu bar means more screen space when working on a laptop. I usually switch off the menu bar in Emacs, and I don't even know if it can be turned on in Vim. reply SlackingOff123 2 hours agorootparentprevFYI, it's possible to make the menu bar always visible in settings. reply porphyra 3 hours agoparentprevTiny buttons toolbars were the norm for decades in, say, Windows Explorer and Microsoft Word, before Microsoft transitioned to the \"Ribbon\" style in 2007. Personally I think that people who enjoy those buttons do so for nostalgia reasons, but they are not the worst to use once you remember where each tool is and what each tool's icon looks like. reply j1elo 3 hours agorootparent> Tiny buttons toolbars were the norm for decades (...) before Microsoft transitioned to the \"Ribbon\" style in 2007. The Ribbon still feels to me like that \"new thing\" Microsoft did since some version of Office... and you're telling me it was 2007?!! Oh my... A bit before that time I already moved to Open/LibreOffice, and never really used any Windows past 7, so I've missed a whole UI paradigm transition that now makes Windows feel like a complete stranger to me. reply StuffMaster 2 hours agorootparentPull-down menus are so obtrusive! You SHOULD prefer to hunt and hunt and hunt for the button you want. The future is now and it sucks. reply porphyra 2 hours agorootparentprevThere's now a whole generation of 20 year old programmers who have never used the toolbars of the 1990s and early 2000s. reply mysterydip 3 hours agoparentprevWhat you find ugly and distracting I find essential to functioning in the app. I can't stand it when I'm trying to find some feature that was hidden so the UI would look cleaner. reply Grazester 3 hours agoparentprevI have used Notepad++ for more than 10 years and I don't think I have ever tried replacing my IDE with it. I don't think it should be use as an IDE replacement but a file editor. reply AdrianB1 0 minutes agorootparentIt is the other way around: 10 yeas ago I was using Notepad++ for writing small apps and I replaced it with IDE (VS Code). It makes no sense to replace a decent IDE with Notepad++. reply yndoendo 3 hours agoparentprevTo me it is a tool for select jobs. Mainly use it for parsing log files. Handles gigabyte files ease unlike Windows notepad. It also is great with regex searching to filter useful log content with cascading results. Temporary scratch pad, for constructing SQL statements, that retains unsaved files upon OS or user closing. Not my go-to for coding and project maintenance. Still a great tool. reply roland35 3 hours agorootparentNotepad++ is what I have for any random file format I need to right click and open quickly! reply HumblyTossed 2 hours agoparentprevI hate cluttered flat surfaces as much as the next guy, but I don't put my toaster away when I'm not using it. It's stays right on the counter because it's convenient for it to be there. reply user3939382 1 hour agorootparent> I don't put my toaster away when I'm not using it I actually do lol reply AdamH12113 3 hours agoparentprevMy advice is to just turn the toolbar off (Settings -> Preferences -> General -> Toolbar -> Hide). I find it easier to skim through menus. You can turn off almost all of the extra UI elements if you want, which makes the interface very clean. reply j1elo 3 hours agorootparentFunny that something as simple as hiding a toolbar requires diving through 5 steps. Doesn't it just offer that option upon right-click? It sounds natural and expected to me for a toolbar to do so. reply AdamH12113 3 hours agorootparentIt's really two or three steps -- select menu item, dialogue box page is already selected by default, click on checkbox. I was giving the full navigation. Personally, I find that making every part of the UI an active control makes it easy to do things by mistake, especially hiding elements, which often doesn't have an obvious way to reverse the process. For one-time UI setup, I don't mind going through a dialogue box. reply wolpoli 2 hours agorootparentprevI just tried it and was surprised that it doesn't offer Right-Click option to customize/turn off the toolbar. There was a period in Windows software when that level of customizability was expected. reply Topgamer7 3 hours agoparentprevnotepad++ was really great for simple syntax highlighting on windows, when good clients were either slow or costed money. It supported a lot of languages. reply nine_k 3 hours agorootparentAlso, the original Notepad++ is unabashedly native to Windows, with none of the limitations or expense of cross-platform toolkits like Qt. So it's lightweight and responsive even on lowest-specced boxes. reply circusfly 3 hours agorootparentI use Notepad++ on Linux, ran the installer, works, it auto updates just like it did on Windows, WINE enables it to run just fine. I use it every day for small files like my TODO, Notes and Scrap files. reply lukan 1 hour agorootparentBut that is a recent developement? Some years ago the experience under WINE with npp was not great. (might be also 10 years, since I tried it the last time) reply aveao 3 hours agoparentprevNpp is a code editor, and you're comparing it to an IDE. Apples and oranges. reply jraph 2 hours agorootparentBoth are fruits. The comparison applies here I think :-) reply jccalhoun 3 hours agoparentprevIt depends on what you use it for, I guess. I'm not a programmer so I use it as a replacement for windows notepad. I don't know what most of the buttons do and I just ignore them. reply publius_0xf3 2 hours agoparentprevAs a longtime Notepad++ user, I hate those buttons as well. Fortunately, the settings contain the option to hide the menu, the icons, the buttons on the tabs, the status bar, etc. resulting in a very minimalistic experience, which is how I use it. I recommend giving it another look. reply circusfly 3 hours agoparentprevRe-training propaganda: [only the JetBrains products should be used, repeat after me...]. reply Dalewyn 3 hours agoparentprev>The, what I call \"millions of tiny buttons\" interface is ugly and distracting. That's a feature. It's a GUI harkening back to Windows Explorer Classic, aka the interface style used from Windows 95 through Windows XP. reply simion314 3 hours agoparentprevMaybe you can customize it. I am not a user but you will avoid good programs because of this instant reaction. IMO, I would check if the toolbar and key shortcuts can be customized. reply rembicilious 2 hours agoprevNpp (Notepad++) is my go to text editor for windows. It has been actively maintained for 20 years. Itâ€™s lightweight with a super responsive UI. I love the text search/replace interface. I keep a copy of the portable version on my keychain thumb drive because I never know when a friend or family member will have me muck around with their pc. Npp Version 7 runs splendidly on wine. I prefer it over the linux desktop text editors like Kate (which is a great editor in its own right). I donâ€™t think NotepadNext appimage or flatpak will be able to match Npp in regards to memory footprint and ui responsiveness. But, I am excited to use it and it may find itâ€™s way onto my thumbdrive because it runs natively on Linux so it doesnâ€™t depend on wine. reply butz 2 hours agoparentI was not expecting much, but AppImage startup time and responsiveness looks promising. Memory usage in GNOME System Monitor looks decent (AppRun.wrapped - 13.9MB, NotepadNext - 876.5 kB). Typing feels much faster than Linux version of VSCode, maybe even reaching levels of SublimeText? Need to test with much bigger documents with complicated syntax highlighting to make sure. Overall, the major Notepad++ selling point - autosave on exit - is not implemented here, so until then I'll be going back to Geany, but will keep my eye on this. And forgot to mention that it decently integrates into GNOME desktop as well, no issues with decorations and missing app in Alt+Tab list. reply jtriangle 2 hours agoparentprevNotepadqq on linux is basically 1:1 with notepad++ reply StuffMaster 2 hours agoparentprevI also love Notepad2. Both are awesome. reply gen3 3 hours agoprevAwesome. When I moved to linux a few years ago notepad++ was one of the harder apps to find a replacement for. I ended up sticking with Kate Edit: Kate is great, give it a shot! reply techmindmaster 3 hours agoparentThere is https://www.geany.org reply mxuribe 1 hour agorootparentLike @fngjdflmdflg noted, years ago when i moved to linux (for personal use), I also had trouble finding a decent/similar replacement to Notepad++. I started down the Geany route, and liked it alot. It is cross-platform, not slow, has lots of themes, customization options, etc. But eventually I stopped using it, and landed on Kate. For the life of me can't recall why i moved away from Geany? I have been a user of KDE Plasma for many years, but that's not the reason why i moved to Kate, because i actually was still a user of Geany for quite a while during my use of KDE Plasma. In any case, Geany is a really solid option. Not sure that Geany is a feature-for-feature, perfect alternative for Notepad++ (but neither is my favorite Kate editor either!)...nevertheless, the rare times when people ask me for recommendation of text editors on linux (or cross-platform with the intent of using the same editor on all their OSes), I often stick to suggesting Geany or Kate. And, then of course, if they're exclusively Windows users i then suggest either Notepad++ or Geany Kate - not necessarily in any order. (For the Windows machines that my dayjobs issue me, I still use Notepad++ since funny enough that is easier to allow then requesting to install Kate! Corporate world be getting all strict on software installations nowadays - yikes!) reply nsteel 3 hours agorootparentprevExactly this. It's already cross platform (windows and Linux, at least), extendable, looks very similar and has many of the same features. I'm not sure what killer feature is missing that would make someone reimplement the whole thing. The readme weirdly doesn't mention it. reply AlienRobot 1 hour agorootparentprevYeah, but Notepad++ is a Windows app, that is a GTK app. As someone coming from Windows, it's crazy how bad GTK apps look for desktop. Crazy. Like I can't comprehend how did it get to this point. Just compare the screenshots https://www.geany.org/media/uploads/screenshots/geany_light_... https://notepad.plus/wp-content/uploads/2023/03/screen.gif Notepad has 16 toolbar buttons in the same amount of width that GTK can only fit 10 toolbar buttons. The height of the tabs and status bars are also MUCH shorter. It's completely ridiculous and makes every GTK app look bad to me. Not just Geany, but Xed, Pluma, Gedit, the image viewers, the file managers, the system settings dialogs, etc. I have a mouse. I can point at things. I'm not using my thumbs or toes to operate a desktop app. Qt's licensing sounded a bit weird. At first I thought your app HAD to be open source to use it. But once it was clear to me that you can sell apps made with Qt so long as you dynamically link without having to pay royalties or anything, the choice was clear. If I have to program an app for Linux, I'm using Qt. And so far the only problem I found in Qt is that it uses the system's \"native\" GUI by default (i.e. it uses Gtk on Linux). This means that the Ok-Cancel buttons are Cancel-Ok instead of the correct order. Who puts Ok buttons at the right side? Now if I want to quickly close something, I'm clicking at the corner of the window which is the easiest point to click at, and on the top right I have close (which cancels) and at the bottom right I don't have cancel but Ok which COMMITS which is the opposite of what a thoughtless rash speedy click is supposed to do. Ok should be at the left so you can't commit things by accident. The only reason to put it on the right is if you're designing for tablets so the ok button is closer for right-handed users. This isn't how a decision for a desktop-oriented design. reply ramon156 3 hours agoparentprevI never needed a replacement but I tried Kate for quick edits and honestly it's a very lovely implementation reply ww520 3 hours agoparentprevI have run Notepad++ with Wine on Linux before and it works well. Kate is awesome. Itâ€™s cross platform as well. reply circusfly 3 hours agorootparentI use Notepad++ every day, that WINE runs it is implicit, it's like running any other app. I love KDE but I'm not a fan of the Kate editor. Notepad++ even automatically checks for updates like it did on Windows, downloads it, installs it, etc. Works exactly the same. It's great. reply sixthDot 3 hours agoparentprevHave you ever heard of https://cudatext.github.io/. It's certainly faster than Kate. reply jraph 2 hours agorootparentFaster than Kate is a feat. Speed is one aspect, I have been using Kate for more than 10 years. What, in your opinion, should make me check out this editor? reply wildzzz 3 hours agoparentprevI used Sublime as my npp replacement on Linux. It's a little more coding focused so it lacks some of the nice editing features but was good enough. Luckily npp is pre installed on my work PC so I don't use anything else now. reply Piraty 3 hours agoparentprevthere is https://notepadqq.com reply summermusic 3 hours agorootparentSadly this project is not actively maintained anymore reply nurettin 3 hours agoparentprevThere is vs code if you like browsers. reply rubymamis 1 hour agoprevDamn this app is so fast. It handles 24x War and Peace without sweating a bit. Much faster than Sublime as well. The only thing with equivalent performance (on macOS) is BBEdit. Does anyone know how they are able to load such large files so fast? I guess they lazy load from disk as well? I'm writing a block editor in Qt C++ (Npp is also written in Qt) and QML[1], so I'm very curious. I load the entire text and then render it using a virtualized list (ListView). My app is currently the fastest block editor that I've tested. But I always want to take it up a notch and even compete in performance with Sublime and BBEdit, and now NotepadNext. [1] https://www.get-plume.com/ EDIT: It's REALLY fast and very efficient (consumes low amount of memory). Seems to be faster than BBEdit (unscientific). If anyone has a clue about the architecture or can share a link, it will be appreciated. reply extragood 25 minutes agoparentThanks for the comparison to Sublime. That's been my preferred editor for a decade, but massive files have always been a pain point. reply binary132 47 minutes agoparentprevmmap? reply pyrophane 2 hours agoprevI love that this is a made with C++/Qt and isn't an electron app. reply bregma 3 hours agoprevWhy would I choose notepad++ over something like vim or emacs? Is there a compelling differentiator? reply tredre3 3 hours agoparentThe compelling differentiator is that all the features are easily discoverable, you don't need to read a manual before you know how to save/quit/search/replace/use tabs/undo/redo/macros/etc. reply aveao 3 hours agoparentprevIs there a point in comparing CLI-based, primarily-*nix-userbase editors with a GUI-based primarily-windows-userbase editor? reply bongodongobob 2 hours agorootparentOf course, to signal your leetness. reply orthoxerox 3 hours agoparentprevStandard Windows hotkeys, fast, buttons. reply mardifoufs 2 hours agoparentprevFrom what I've seen it's mostly baby duck syndrome and that's totally ok. I am also fully \"baby ducked\" into vscode, so I get it reply kstrauser 2 hours agorootparent> baby duck syndrome Today I learned something new. reply ivanjermakov 3 hours agoparentprevNotepad++ is literally a better version of notepad.exe. I would not consider using it for anything serious though. reply sgc 2 hours agorootparentIt depends what your \"serious\" work is. I have used it to edit well over 300 million words of text, reformatting scripts to add tagging etc, large scripts of complex regex to data clean (although nothing I know of beats TextCrawler for that task), even writing code in several languages - though of course a proper ide is more useful for many coding tasks. VS Code for example absolutely chokes on large files. Sublime does an ok job - but not one I can rely on for larger batch jobs. NPP excels, and I can quickly do thousands of changes on thousands of large files quickly. NPP also has many plugins (like Sublime etc), and its utility depends on them as much as the other text editors do. reply Brian_K_White 1 hour agoparentprevI use vim and geany and code::blocks and np++ for different things at different times. geany, codeblocks, and np++ are all scintilla, so what I am really saying is I use both \"something like vim or emacs\" AND scintilla, and there is no dichotomy. And what is \"something like vim or emacs\"? The two are nothing like each other. Anyone who used either vim or emacs already knows why they do so, and already knows that none of the reasons anyone will say they like any normal editor will apply. Everything anyone says will either be something vim or emacs already has their own answer for, or will be things they actively don't want. Question seems somewhere between disingenuous to inexplicable. I would say rather than an actual request for information, it was just to say \"I like vim or emacs\", except \"I like vim or emacs\" makes no sense because they are not substitutions for each other. reply bregma 1 hour agorootparentUnless you're looking for a compelling reason to switch. For example, I use VS Code sometimes because of its markdown preview pane. That's not available in emacs or vim (to my knowledge). reply nurettin 3 hours agoparentprevDoes emacs work as well as notepad++ on windows? reply rbancroft 3 hours agorootparentemacs works great on windows. I'm not sure if there are things notepad++ does that emacs can't but I've never had any windows-specific issues with emacs. reply michaelcampbell 1 hour agoparentprevNot really, if you already know vim or emacs well enough. You don't need to worry about modes or plugins for language syntax highlighting for most file types as it's built in. reply tombert 2 hours agoprevNotepad++, as the name suggests for me, was actually the next editor I learned how to use after Windows Notepad. I saw all this pretty syntax highlighting, and the ability to use tabs, and I decided to use it. I got pretty good with it, even making custom macros and the like, and as I was learning C and C++ on Windows it was still the text editor I used. The reason I stopped using it really did just come down to the fact that it didn't work on Linux. I had already been dual-booting Windows by 2011, and when Windows 8 got announced I utterly hated it so much that I decided to just do Linux full-time. While I was aware that Notepad++ worked on Wine, I didn't really want to muck with anything emulator or emulator-adjacent, so I just picked up Emacs and Vim (went back and forth for multiple years until finally settling on Vim). I will need to look at NotepadNext. NeoVim is great, but sometimes I want a simple, non-IDE, GUI text editor as a place to just dump notes down. reply constantcrying 3 hours agoprevA colleague of mine, who certainly was an extremely experienced and knowledgeable programmer, used Notepad++ for everything. Certainly was interesting to see how good you can be even with relatively simple tools. reply jhwhite 3 hours agoprevNotepad++ has a place in my heart. When I was learning HTML back in the late 90s early 00s I was using MS Frontpage or Adobe Dreamweaver GUI. I read that those would spit out sub-optimal HTML and you should use a text editor. So I downloaded Notepad++ and I learned real HTML using it. reply dang 1 hour agoprevRelated: NotepadNext: A cross-platform reimplementation of Notepad++ - https://news.ycombinator.com/item?id=30959025 - April 2022 (273 comments) reply binary132 45 minutes agoprevI think I missed what was wrong with npp that needed superseding. Is it just that itâ€™s not portable? Perhaps a portability layer could be contributed? reply SuperNinKenDo 13 minutes agoparentBased off looks and speed, I've always assumed Npp was pure win32. So the only portability layer is Wine. That said, from memory, it actually works well in Wine, but plugins can be iffy. reply shnkr 3 hours agoprevhonest question - why was there a need to start a new repo? Would you be ok to merge yours with notepad++'s official repo[0] (both are in c++). Did this cross your mind before and what happened? Not saying that they would allow but it'd help the community as a whole with less duplication of work and deliver more features. https://github.com/notepad-plus-plus/notepad-plus-plus reply tredre3 3 hours agoparentI can't answer for the author, but keep in mind that Notepad++ is good because it uses the win32 API directly. I don't see any future where they'd just accept to replace everything with Qt. reply circusfly 3 hours agorootparentThere's no need to. It installs, updates and runs exactly as it did on Windows, I use it every day. reply nicolas_17 3 hours agoparentprevIt's a complete re-implementation from scratch, they don't share code, using the same programming language is not particularly relevant. reply knighthack 2 hours agoprevWhile I love the plethora of text editors, I'm sticking to Sublime Text for pure text editing work, and Vim / Vim-mode with Jetbrains' IDE for code-related work. Power and love be to all the alternative text editors out there though. reply throwaway918274 48 minutes agoprevI worked with a guy who used Ubuntu and his main editor was Notepad++ running in Wine. reply account-5 3 hours agoprevI hope this is better than other offerings on Linux. I've tried a few and none of them come close. Fingers crossed. I hope this will be compatible with np++ plugins which makes np++ even better. reply thehias 3 hours agoprevNotepad++ for Linux & MacOS?? Very awesome!! :) reply israrkhan 2 hours agoprevI am primarily a nevim users. Occasionally I use vs code and dislike it for its slowness. Recently discovered `Zed`[1] on Mac. it is quite fast and really good GUI editor (vs code replacement in some ways). I think NotePadNext will still remain primarily a choice for windows users. [1] https://zed.dev/ reply rightbyte 58 minutes agoprevNice I'll try it. About the only app I miss on Linux is Notepad++. reply NetOpWibby 3 hours agoprevMan, what a throwback. I absolutely LOVED Notepad++. Then I transitioned to macOS and Brackets, then Atom, then Sublime Text. Thanks for the trip down Memory Lane. reply ed_elliott_asc 3 hours agoprevI used to love notepad++â€™s macros but that is pretty much been replaced with vscode multi caret and copilot. Iâ€™d still use it for more complicated things but very rarely.. reply indigodaddy 2 hours agoprevI like this a LOT. Any plugins eg diff type things or vim mode etc on the roadmap? reply slig 3 hours agoprevI really loved TextMate for quick, simple and ultra-fast note taking / quick pasting stuff on macOS. Is there anything like that for Windows (except Notepad++)? reply ahdsr 3 hours agoparentNotepadNext reply slig 3 hours agorootparentWill try, thanks! reply bluenose69 2 hours agoprevFor the macOS version, the docs suggest turning off font smoothing. This might not be something users want to do. reply mig39 3 hours agoprevIs there a homebrew package for macOS ? reply Tagbert 1 hour agoparentIt looks like they are supplying a DMG so you would just drag the executable to Applications reply indigodaddy 2 hours agoparentpreva brew search for notepad only returns \"notedup\" so I don't think so currently reply Sweepi 3 hours agoprevsometimes I am still sad that I switched to VS Code 6 years ago. The multi-language-spell check feature (plugin) is still better implemented than in any other editor or smartphone I have seen. Same for multi-line editing (native to npp). reply jeroen79 2 hours agoprevnever really been a fan of Npp, i used to use geany, and now vscode as most people do these days. reply ulrischa 3 hours agoprevI always wanted this. Notepad++ is an excellent editor but was always Windows only reply RDaneel0livaw 3 hours agoprevHOLY CRAP!!! This is wonderful news. This is probably my most missed app on Linux/Macos. Installing immediately! edit: flatpak support is just chefs kiss. reply VHRanger 3 hours agoparentWhy do you prefer it to sublime text in particular? I also like Micro a lot - it uses the command line as a GUI reply margalabargala 3 hours agorootparentSublime is not FOSS, for one. I use Geany on Linux, it is the closest replacement I have found. Until now. reply RDaneel0livaw 3 hours agorootparentprevSublime text for me takes too long to load. It's also too heavy for what my use case is. I just want a simple text editor, not an entire development app. reply wewtyflakes 2 hours agorootparentI've always known Sublime text to load and run instantaneously unless working with enormous files that do not have newline characters. reply wildzzz 3 hours agorootparentprevNpp is great for editing text, no matter what kind of text file it is. It has a bunch of crazy plugins that are just mean for editing and converting text in files. For example, you can edit a column of text (rather than just a row). It's great for working on log files or anything computer generated that needs reformatting. Works ok as a code editor too but it's not an IDE (although it does come in handy when an IDE is not available). It's just another tool to have in your quiver. reply wigster 2 hours agoprevhappy days. at last reply dumdumdum_tada 3 hours agoprevIs there a way to disable the save prompt? reply detinho 3 hours agoparentSettings -> Preferences. [x] Restore previous sessions [x] Unsaved changes [x] Temporary files reply walteweiss 2 hours agoprevNot really willing to explore after this. >By default, MacOS enables font smoothing which causes text to appear quite differently from the Windows version. This can be disabled system-wide using the following command: Does any sane person on a Mac want to have a Windows look, especially when it comes to fonts? Looks crazy to me. reply emestifs 3 hours agoprev [â€“] Missed opportunity to write it in a Memory-Safe, White House approved language and call it Rustpad or something...I joke of course. After reading the title I was 99% sure it would've been an Electron app, nice to see it's actually native. Good work. reply j1elo 3 hours agoparentThe GUI is made with Qt, for which the preferred programming language is C++. So that could be one reason already. There are a lot of bindings listed for Rust in the Qt docs [1] though, but they will always be a subpar experience compared to the first-class support for C++ in Qt. [1]: https://wiki.qt.io/Language_Bindings reply arsome 2 hours agorootparentYeah and the main editing component is Scintilla, also C++. reply collegeburner 3 hours agoparentprevan electron implementation would sorta kill the point of npp :) reply sharken 3 hours agorootparentAbsolutely, the startup speed of npp is addictive. If only VS Code could be half as fast. reply denimnerd42 2 hours agorootparentthat's the main reason I stuck with sublimetext for soooo long. It's so fast and it can handle insanely huge files plus it can do column operations on text on insanely huge files. VS Code does seem to have been optimized since the first few years though and its not hardware related. reply DonnyV 3 hours agoparentprev [â€“] I was thinking the same thing. Why didn't they do it in Rust? But probably because the GUI story with Rust is still evolving. Only recently have I started to see UI frameworks popping up for Rust. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Notepad Next is a cross-platform alternative to Notepad++, compatible with Windows, Linux, and MacOS.",
      "Although stable, it is advised against using it for essential tasks due to bugs and unfinished features.",
      "Development is active and open for contributions, offering installation packages for all platforms, with extra components for Windows and the option for MacOS users to disable font smoothing."
    ],
    "commentSummary": [
      "Users discuss text editors like Notepad++, Geany, and Kate, highlighting features, usability, and cross-platform compatibility.",
      "Notepad++ is commended for its fast and minimalistic UI, contrasting with concerns about other editors with cluttered interfaces.",
      "Opinions vary on the ideal text editor for coding, with Notepad++ standing out for its adaptability and ease of use."
    ],
    "points": 286,
    "commentCount": 178,
    "retryCount": 0,
    "time": 1711644659
  },
  {
    "id": 39844960,
    "title": "Demystifying Digital Wallet Security Beyond Apple Pay",
    "originLink": "https://birchtree.me/blog/digital-wallets-and-the-only-apple-pay-does-this-mythology/",
    "originBody": "Digital wallets and the â€œonly Apple Pay does thisâ€ mythology Posted by Matt Birchler 22 Mar 2024 â€” 5 min read Apple Pay is great, but I think there is some misunderstanding out there about the details of how it works. John Gruber has some choice words for Merrick Garland and crew, but this paragraph stood out as uniquely interesting to me: Apple Pay through Wallet obfuscates your actual credit card numbers, which retailers infamously use to track customers. Itâ€™s far more private than using your credit card itself. I highly doubt any banks or credit card issuers would do this themselves if given access to NFC tap-to-pay. Payments you say? My specialty! First off, this obfuscation is referring to the DPAN, which is distinct from the FPAN. Ahem, sorry for the jargon, but it's important to understand what's happening, so let me explain. The FPAN is the â€œfunding primary account numberâ€ and itâ€™s the 15-18 digit number printed on your physical card. The DPAN is your â€œdevice primary account numberâ€. Think of the DPAN as something like DNS records. When you type â€œbirchtree.meâ€ into your browser, your browser is able to determine what IP address this domain is related to and directs you there. I can keep my website physically in the same place on the same IP address, but I can change the domain to birchtree.com or wigglewobble.org and browsers will know what to do without the user needing to know what IP address is involved. This might be the nerdiest way to explain DPANs, but I know my audience, so I think this may have helped at least some of you. Your same card used through Apple Pay on your iPhone and iPad will show different DPANs, though since each device gets its own number. Itâ€™s notable that itâ€™s called a DPAN and not â€œthe Apple Pay numberâ€ â€“ itâ€™s a generic term, and thatâ€™s because this is a standard feature of digital wallets everywhere, not just Apple Pay. Google Pay and Samsung Pay are the biggest other digital wallets in the U.S. and they both do exactly the same thing. While itâ€™s not technically using a DPAN since the payment runs through different companies, Amazon Pay and Shop Pay buttons also obscure the actual FPAN (full card number) from merchants. I feel like this comes up a lot, but I can not stress enough to you how little merchants want to ever ever ever handle your actual credit card number. It adds so much risk on their end and modern payment acceptance tools make it easy to collect payment details in a way that makes sure as few people as possible have access to the real card info. Gruber mentions banks absolutely not wanting to use DPANs themselves, but we actually donâ€™t need to speculate about this, we have this info already. Numerous banks from Walls Fargo to Chase to Bank of America have (or had) digital wallets, all of which used DPANs to protect your plain text account number. Paze is what a few big U.S. banks use today and it of course uses DPANs as well. In fact the top reason they give for why you should use Paze is, â€œPaze does not share your actual card number with the merchant.â€ On tracking customers Then thereâ€™s the issue of the DPAN changing over every transaction, which wasnâ€™t called out by Gruber, but I see people floating around. This is not really true, though. A previous version of this post suggested the DPAN changes between merchants, but that was a mistake. Serves me right for cranking this post out too quickly. Seriously, my bad. The DPAN is always the same for subsequent transactions at the same merchant. So yes, while this can hinder data brokers from easily buying transaction data from a bunch of different merchants and figuring out shopping trends across those merchants, it does nothing to stop a single merchant from seeing your transaction history with just the DPAN provided by Apple Pay. If that Target story from forever ago about Target knowing a teen was pregnant based on their Target purchase history, Apple Pay doesnâ€™t stop someone like Target from being able to track that. And yes, itâ€™s the same with the other digital wallets out there. A final thing to note about DPANs is that they are much better for you as a customer in the event of a data breach. No merchant should be handling your credit card number directly in 2024, but letâ€™s say the payment gateway gets hacked and leaks the DPAN and expiration date for a transaction you ran at a shop. In that case, the attacker wouldnâ€™t be able to do anything with your DPAN they acquired because DPANs only work when submitted as a part of an encrypted bundle thatâ€™s unique to each transaction. There is a way to run recurring transactions on a card collected via Apple Pay, but that should not be possible for a hacker and now weâ€™re a bit in the weeds, so letâ€™s just say that your FPAN being in a data breach is way worse than your DPAN which is collected by all digital wallets. Personal info in Apple Pay Thereâ€™s also an idea I see sometimes (again, not in Gruberâ€™s linked post, but that I want to clear up anyway) that Apple Pay obscures your personal information. Thatâ€™s simply not true. Because Iâ€™m a very dedicated blogger, I actually ran a real Apple Pay transaction on one of my test merchant accounts (but that run very real transactions) and looked at the merchant-level reporting for it. Hereâ€™s what I see as the merchant for this Apple Pay transaction: Iâ€™ve blurred out a good amount of it because thatâ€™s my real billing and home address as well as my full name and email address. And if you think about it, of course that info would be there! In this example, my checkout page was for a physical item so I needed the customerâ€™s shipping info. Apple Payâ€™s SDK allows me to choose what personal info I want to get from the customer, and itâ€™s for this exact sort of situation. Oh, and product info can be passed into Apple Pay to show you what youâ€™re buying, and that info is sent to the merchant as well. Again, of course it is since the merchant needs to know what you bought. Basically, when that Apple Pay card pops up when youâ€™re checking out, expect everything on that card to be sent to the merchant. In that way itâ€™s just like all other payment forms; the merchant chooses how much personal info they want or need to collect, and Apple Pay doesnâ€™t prevent them from asking you for that at checkout. And yes, this is how other digital wallets work. Takeaway I hope what you take away from this post is that while Apple Pay is a great way to pay for things and that Apple did a great job mainstreaming digital wallets like this, what they do is not unique in the industry. DPANs are great for making it harder to track one personâ€™s purchases across multiple merchants and they make customers less at risk in the event of a data breach of payment card info. None of us can know everything about everything, and I donâ€™t think itâ€™s reasonable to expect everyone to know about all the details of how digital wallets work. Thatâ€™s why I find opportunities like this to be so useful; I can share more info than most in this Apple niche, and I hope itâ€™s informative.",
    "commentLink": "https://news.ycombinator.com/item?id=39844960",
    "commentBody": "Misunderstanding about the details of how Apply Pay works (birchtree.me)267 points by CharlesW 23 hours agohidepastfavorite253 comments codethief 21 hours agoCan anyone ELI5 how Apple & Google Pay work in detail? I used to think they simply pass on my CC details to the merchant or the merchant's chosen payment gateway in one way or another (obfuscated or not), and the OP suggests the same. Moreover, I noticed that some merchants refuse my payment when I use e.g. Google Pay with my Amex instead of my MasterCard. However, I'm sometimes under the impression that Apple/Google take on the role of a payment gateway or a payment method themselves. After all, they collect all my transaction data, and it also seems payment terminals at the grocery store needed special support for the Apple/Google Pay apps. Interestingly, this comment[0] is saying the opposite, namely that at least Apple Pay is very much rooted in standards. But what is Apple and Google's special proprietary sauce then? Why are these apps so hard/impossible to replace by open-source alternatives? Is it because only Apple/Google get full access to the NFC chips on iOS/Android? [0]: https://news.ycombinator.com/item?id=39845805 reply lxgr 17 hours agoparent> But what is Apple and Google's special proprietary sauce then? There isn't any. Many banks across the world offer their own HCE wallets, but these only run on Android (Apple simply doesn't offer the necessary APIs, although that's now changing in the EU). What does matter a lot are defaults: You can only have one default Visa, Mastercard etc. wallet per device (that you don't need to specifically need to open before tapping your phone), so Google Pay has a huge advantage there, since it supports cards by many banks and not just one as would be the case for an issuer HCE wallet. > However, I'm sometimes under the impression that Apple/Google take on the role of a payment gateway or a payment method themselves. They don't. They're involved in mediating the initial setup of a new card on a given device, but aren't part of the actual transaction flow at all (at the POS, in any case). > Moreover, I noticed that some merchants refuse my payment when I use e.g. Google Pay with my Amex instead of my MasterCard. The underlying card brand still needs to be accepted by the merchant. Unlike e.g. early Google Pay (or what it was called back then; I lost track) and some other solutions, modern-day Google Pay and Apple Pay aren't \"proxy cards\" (which can sometimes change the card brand, e.g. from Visa to Mastercard; an example of that would be Curve). > it also seems payment terminals at the grocery store needed special support for the Apple/Google Pay apps. They don't. Unless a given POS terminal is buggy, it'll work anywhere that otherwise accepts the underlying card scheme. The physical and logical protocols are exactly the same as for actual plastic cards and mostly indistinguishable to the terminal; actually breaking Apple Pay/Google Pay support needs a lot of destructive energy on the merchant's/PSP's side. On the web it's a different story; explicit support by both the store website and payment service provider is needed there. reply andylynch 9 hours agorootparentThis is underrated. Eg I have Garmin Pay on my watch. It works anywhere Apple/google etc works, even though the merchants and quite possibly whoever set up their terminals have never heard of it. reply codethief 12 hours agorootparentprev> Google Pay has a huge advantage there, since it supports cards by many banks and not just one as would be the case for an issuer HCE wallet. Ah, so it's the integration with issuer banks in the background that requires a lot of effort. That makes sense! Thanks so much for enlightening me! :) reply p_l 12 hours agorootparentAndroid essentially provided bunch of interfaces over time to either load a complete payment infrastructure through hw means (usually it involved telco cooperating with banks to provide EMV secure element on the SIM card, and the NFC chip has hardware connection to the SIM card), and later and more popular there's both complete Host Card Emulation capability (so you can run EMV protocol in your app) plus Google Pay integration making it easier on issuer because now they don't have to implement EMV themselves on HCE, and also provide more convenience to users vs forcing you to open specific app when you have more than one card connected. reply nox101 11 hours agorootparentprev> > it also seems payment terminals at the grocery store needed special support for the Apple/Google Pay apps. > They don't. Unless a given POS terminal is buggy, it'll work anywhere that otherwise accepts the underlying card scheme. The physical and logical protocols are exactly the same as for actual plastic cards and mostly indistinguishable to the terminal; actually breaking Apple Pay/Google Pay support needs a lot of destructive energy on the merchant's/PSP's side. this doesn't fit my experience. For example, Home Depot doesn't accept apple pay but their chip readers work with other cards. If there's no difference then it would seem impossible for the machines to distinguish apple pay from any other card. I've had similar issues at many other merchants reply jon-wood 11 hours agorootparentDo their readers do contactless payment at all? Apple/Google Pay are just presenting your phone as a contactless payment card so it should work anywhere a physical card can be used that way. reply alistairSH 8 hours agorootparentDo their readers do contactless payment at all? US-based here... My local HD does NOT do contactless of any variety. It's chip or swipe. Same for my local Thai food carry-out. I would have sworn my local bicycle shop did contactless for cards only (but not devices) - I'll have to test that next time I'm there. It could just be that the pub/cafe side has a contactless reader but the retail side is chip/swipe-only (effectily two businesses in the same space and owned by the same person). reply noodlesUK 10 hours agorootparentprevI believe they don't have NFC enabled on the terminals at all. Same with Walmart (allegedly, I haven't been there in a while). I've heard rumours that the reason for this is so they can do customer tracking more reliably, but I'm not sure how much more valuable an actual card PAN is than a DPAN if the DPAN isn't getting rotated. reply joshstrange 10 hours agorootparentIâ€™ve seen the data the reader gives us from a dip vs a tap (inserting your card vs NFC) and there is a difference. IIRC we would get the name on the card from a dip but not from a tap. In both cases we get the last 4 digits though. reply phil21 9 hours agorootparentAt Home Depot at least they do this due (in part, if not in whole) to returns. Your virtual card number may change, since itâ€™s generated every time you add it to a device. This breaks their easy return lookup where you simply present the item and your card, no receipt needed. I actually ran into exactly this when I tried to make a return to Target after losing my receipt. I had replaced my phone and the card number changed. Luckily for random reasons I had my old phone laying around still and was able to come back and return with that. Having done a receipt based return vs. dozens of card based returns at Home Depot, the staff time involved is orders of magnitude more so I understand why they would turn NFC off. Tracking may be part of this consideration too, but Iâ€™d speculate itâ€™s secondary. reply Reason077 10 hours agorootparentprev> \"this doesn't fit my experience. For example, Home Depot doesn't accept apple pay but their chip readers work with other cards.\" It must be different in the US, then. In Europe, Canada, and elsewhere, any terminal that accepts standard contactless cards (ie: pretty much 100% of them now days) will accept Apple Pay/Google Pay. When Apple Pay first launched, there was an issue where some older terminals would apply the unauthenticated contactless payment transaction limit (Â£50 or whatever), instead of recognising that device-authenticated payments should have no limit. But that's long since been fixed. reply rimunroe 8 hours agorootparentI donâ€™t know much about the underlying tech, but some large retailers (Target sprints to mind) resisted adding contactless payments and push users to use their own app. Some quick searching indicates they may have added support in 2018 or 2019. It sounds like Walmart still doesnâ€™t support them. reply worewood 10 hours agorootparentprevHe saying there's no difference between a standard contactless plastic card and using the phone. reply oefnak 10 hours agorootparentI can pay contactlessly with my card, but my bank doesn't support paying with my phone. reply lxgr 8 hours agorootparentMy point is that Apple Pay works wherever contactless cards are accepted, but yes, not all card issuers offer Apple Pay in the first place. reply anticensor 7 hours agorootparentprev> actually breaking Apple Pay/Google Pay support needs a lot of destructive energy on the merchant's/PSP's side. They do bank whitelisting, not protocol breakage. reply amatecha 12 hours agorootparentprevYeah, recently my Apple Watch stopped being usable with the tap terminals at a certain gas station chain here. I have to use the physical card. I use the Apple Watch tap at basically all vendors that accept tap, except this one gas station brand. Weird, right? Especially strange is that I paid with the same Apple Watch and Apple Pay setup for a long time (like years) and one day they just stopped accepting it. reply kalleboo 9 hours agorootparentFor some reason, recently Apple Pay on my phone stopped working on the local trams. It works everywhere else, and Apple Pay on my Apple Watch, using the exact same card, works fine. No idea what weird technical glitch is going on there. The tram company says Apple Pay is supported. reply pjerem 11 hours agorootparentprevIn general, when you have this kind of bugs, it have to do with transaction amount limits which looks like they are a mixed bag of rules from the terminal and the card itself. In the early days of mobile payments, I remember that some terminals were configured to enforce the legal limit for contactless cards (which was 30â‚¬ IIRC) even if you paid with mobile. I havenâ€™t encountered this issue for the last few years though, I even forgot my card PIN. reply amatecha 1 hour agorootparentOh, yeah no in this case you tap ahead of making the transaction. Maybe it preauths a certain amount? But.. I've made purchases of like $350 with Apple Pay, maybe more. reply my123 11 hours agorootparentprevGoogle Pay still supports proxy cards today through PayPal. Only applicable to the US and Germany though. reply lxgr 9 hours agorootparentThatâ€™s Paypal providing proxy cards for use in Google Pay though, not the other way around. Curve does that too. reply sitharus 15 hours agoparentprevThe only â€œsecret sauceâ€ is the liability shift. Traditional online and contactless payments are classed as â€œcardholder not presentâ€ transactions which place more liability for fraud on the merchant. Apple and Google Pay (and other bank-provided payment apps) use biometrics to confirm cardholder authorisation, switching a subset of payment types to cardholder present. This means some chargeback types are instantly declined, and others have a lower requirement for merchant proof. This is all part of the card network standards, which are freely available if youâ€™re interested from https://www.emvco.com/ The reason thereâ€™s no open source option is the requirement to certify the implementationâ€™s security, so you need a commercial entity to work with the banks. Oh, and every bank has to integrate separately - thatâ€™s a lot of banks to talk to. reply Nursie 11 hours agorootparentContactless card transactions are not â€œCardholder not presentâ€ transactions! They are usually â€œNo Cardholder Verification Methodâ€ transactions, though they can do ask for PIN entry in some circumstances. And no, the liability is not with the merchant for contactless, or they never would have accepted it! Itâ€™s firmly with the banks, which is why the limits were initially so low - to limit potential fraud. When it transpired that fraud was more than acceptably low, they raised the limits a bit. The liability is only with the merchant if the merchant chooses to accept a magnetic swipe transaction, or keyed card details. Not contactless EMV. reply anticensor 7 hours agorootparent> They are usually â€œNo Cardholder Verification Methodâ€ transactions, though they can do ask for PIN entry in some circumstances. In Turkey, contactless transactions are \"Special Cardholder Verification Required, no PIN\" or \"Cardholder Present, PIN required\" depending on the amount. And they are legally required to be performed online with immediate confirmation. reply mainde 19 hours agoparentprev>Moreover, I noticed that some merchants refuse my payment when I use e.g. Google Pay with my Amex instead of my MasterCard. In my experience this is normally due to either how the card machine provider has set up the device or due to the lack of certification of the mobile wallet functionality on the \"acquirer\" backend (\"host\") that speaks to the card schemes. It's annoyingly tricky to get the end-to-end transaction working properly across all schemes, all payment methods and devices. Different card schemes support different \"payment kernel\" parameters and have different certification requirements. It could also be an attempt to save money on transaction fees, amex is generally significantly more expensive for merchants. reply EricE 5 hours agorootparentWhen I briefly had my own store I blocked amex because of their ridiculous fees. And they are pretty merchant hostile re: chargebacks too. The overhead and headache wasn't worth dealing with them. That was a while ago so maybe they have improved, but I still occasionally run into places that don't take them so I guess not. reply Nursie 18 hours agorootparentprevHistorically, Amex always required a separate retailer relationship and to act as its own acquirer. I don't know how true that is any more. They've just always been the awkward one, with higher fees and special relationships. Also they used to use ANSI standards on some stuff where everyone else used ISO... but that's going back 20 years! reply inkyoto 17 hours agorootparentYes, that is still true â€“ AmEx own their own payment processing network, and they do not allow outsiders into it, even banks they have the brand sharing agreements with, hence a separate retailer relationship. reply devmor 18 hours agorootparentprev>Different card schemes support different \"payment kernel\" parameters and have different certification requirements. Those certification requirements are one of the biggest hurdles because they can change quite often, and unless you are a high-volume gateway, there may be no leniency for you, making simply refusing the transactions cheaper than processing them and being fined. The digital cryptogram requirements for visa caused some major engineering expenditures for a few payment processors I'm aware of. reply criddell 11 hours agoparentprevThis is not an ELI5, but it is all the details: https://www.emvco.com/emv-technologies/payment-tokenisation/ EMVCo is American Express, Discover, JCB, Mastercard, UnionPay and Visa. Itâ€™s basically a credit card standardization group. reply Reason077 10 hours agoparentprev> \"But what is Apple and Google's special proprietary sauce then? Why are these apps so hard/impossible to replace by open-source alternatives?\" Google Pay and Apple Pay aren't unique. There's Garmin Pay and Samsung Pay, too, for example. The EMV standards are maintained by EMVCo (www.emvco.com), and the specification documents seem to be out there and googleable. I'm sure anyone sufficiently qualified in NFC tech could have a go at implementing them on their own device. The only tricky part is that you have to interface with each card issuer (bank) to generate DPANs? reply tekno45 21 hours agoparentprevGood info here https://blog.bytebytego.com/p/ep25-how-applegoogle-pay-handl... reply mundays 20 hours agoparentprevThe biggest difference is that no internet connection is required for the authentication because the bank trusts the user's device. CC number is randomized per transaction so that the merchant does not receive the real CC number. I've seen cases contactless payment is not supported only for a particular brand and I believe it's because of missing software update on the payment terminal. reply 1ncorrect 20 hours agorootparentItâ€™s randomised in a similar way to how iOS creates privacy MAC addresses for each WiFi SSID. The merchant receives the same â€˜randomâ€™ card number for transactions from the same device. reply lxgr 18 hours agorootparentThe device card number (DPAN) is static after adding a card to a given device. It doesnâ€™t change between transactions or merchants. reply ffsm8 20 hours agorootparentprevHonestly apples approach is pure security theater, as they're not an acquirer that process the transaction at the end. Instead the real acquirer now reverses apples masking. The merchants themselves aren't allowed to store the credit card information anyway, otherwise they'd lose their PCI certificate, losing the ability to process credit cards. And if they use a payment processor, then they didn't ever get in contact with the credit card information either. No clue how/if Google does anything. I was just involved in implementing apple pay at a payment processor that was also an acquirer a few years ago. Ultimately, we've had the same information on the consumer, wherever they used Apple pay or just a regular credit card reply lathiat 18 hours agorootparentI am not an expert in this so I can't explain it in any truly deep detail, and you might be right in terms of \"Masking\" the identity of the card number if you think this is a privacy feature, but there is much more to it than security theater of a per-device DAN. Both when using EMV Contactless and when using Apple Pay on the web, some kind of dynamic and/or encrypted data is signed by the secure element of the device. EMV Contactless definitely signs the whole transaction, with Apple Pay on the web in at least some cases it will use either a dynamic CVV code and/or \"cryptogram\" containing the transaction data similar to the contactless protocol that verifies that specific payment request was signed by the secure device/card. The payment processors can use this to know the transaction is freshly authorised and is not a replay of a skimmed credit card number/CVV (whether skimmed from another apple pay transaction, or skimmed from entering the static physical card details). On the merchant/processor side, I believe in some cases you may get a better rate or different fraud protection for such transactions (especially at a large scale), or, it will also factor into the fraud control and the bank/payment network/etc are less likely to reject such a payment as fraud where as it may be more likely to reject the static physical card details as fraud, etc. If someone knows better or different then please do share. Some references: https://support.apple.com/en-au/HT203027 https://developer.apple.com/documentation/passkit_apple_pay_... https://support.apple.com/en-au/guide/security/secc1f57e189/... reply lxgr 18 hours agorootparent> EMV Contactless definitely signs the whole transaction, with Apple Pay on the web in at least some cases it will use either a dynamic CVV code and/or \"cryptogram\" containing the transaction data similar to the contactless protocol that verifies that specific payment request was signed by the secure device/card. The same is true for chip card payments. What makes Apple Pay significantly more secure in practice is that issuers can limit the device-specific card number to be only usable with a chip cryptogram, and not e.g. by manually typing it in on a website. For POS and online payments, the idea was the same (eventually depreciate cryptogram-less use entirely and use 3DS online and chip/EMV at the POS), but alas, it never quite happened that way. > On the merchant/processor side, I believe in some cases you may get a better rate or different fraud protection for such transactions (especially at a large scale) Apple Pay usually shifts the liability for fraud to the issuer, yes. This is a huge advantage for merchants that would otherwise usually be on the hook for most types of fraud. reply the_mitsuhiko 12 hours agorootparent> What makes Apple Pay significantly more secure in practice is that issuers can limit the device-specific card number to be only usable with a chip cryptogram, and not e.g. by manually typing it in on a website. That's sort of true for non 3DS enabled cards. For 3DS enabled cards, you need a second factor for most transactions on the internet. reply lmz 12 hours agorootparentFor 3DS enabled cards, 3DS is optional. Unless you mean 3DS-mandatory cards. reply agos 13 hours agorootparentprev> For POS and online payments, the idea was the same (eventually depreciate cryptogram-less use entirely and use 3DS online and chip/EMV at the POS), but alas, it never quite happened that way. where I live it happened exactly this way since a few years. Online is 3DS only and in person is chip/EMV only reply lxgr 8 hours agorootparentCan you not use your card in US online stores? These mostly donâ€™t support 3DS, so there is still a large fraud vector for compromised cards that work internationally. reply astrange 15 hours agorootparentprevApple Pay is also somewhat different from contactless/chip payments on a card because it's authenticated, whereas (US at least) cards are not authenticated since we don't use PINs. IIRC in some countries this means it's accepted more or has higher payment limits. reply caf 17 hours agorootparentprevDo the chip / paywave payments with the physical card also use a DPAN generated for that card, or do they use the FPAN that's embossed on the plastic? reply lxgr 16 hours agorootparentA physical card usually uses the number embossed on the plastic on all other channels (i.e. magnetic stripe, chip, contactless) as well. That's not a hard rule â€“ some cards have no number embossed/printed at all (e.g. the Apple Card), and it's technically possible to use different numbers. But I haven't really seen it done since it could cause quite some confusion, as e.g. some airlines use the card number to look up your online booking at self-check-in machines, which wouldn't work if the two differ. There are also some special cases of things that are technically regular old smartcards but that do (I believe) use tokenization/DPANs, like wearable form factor contactless payment devices by Swatch or Fidesmo. reply caf 16 hours agorootparentAhh, that makes sense - in fact I just used a credit card to pick up linked online Shinkansen bookings from the JR-West ticket machines. (Those systems all seem to use either magstripe or chip though, so maybe the wireless transaction could still use a different one, in theory). reply shp0ngle 12 hours agorootparentprevhave you read the actual article? reply mundays 4 hours agorootparentMy bad. I read the article but I must have skimmed past the section about DPAN being randomized because I don't remember seeing it. The majority of my attention went the last part about personal details where I thought it was pretty obvious. Short attention span. reply numpad0 17 hours agoparentprevI suspect there are more than just one combination of frontend and backend for Apple/Google Pay depending on how you're paying, masked behind that act of you presenting the device and store presenting the reader. So I think there can be cases where \"payments\" (or promises thereof) can be made, while money withdrawn from banks notwithstanding, e.g. queued in an intermediary entity and manually resolved on request, in which cases the payment gateway might want to pattern detect and shut down such cases. reply Nursie 18 hours agoparentprevThey work using contactless EMV, which is the same way contactless credit cards work, and is the standard behind Visa/MC's Paywave and Paypass products. This is why wireless terminals in general just work with apple and google pay and actually didn't need much in thw way of special support. From what I recall one of the few things that did change was raising of payment limits for these devices over contactless cards, because they are deemed more secure (can't be used by just anyone that happens to have stolen it). > Why are these apps so hard/impossible to replace by open-source alternatives? EMV implementations are non-trivial and need a lot of testing and validation using specialised equipment. There need to be secure enclaves on the device to hold private keys in a way that can't easily be compromised. The app needs to interact with the phone in such a way as it can tell that biometric or PIN-based unlocks have been used so that it can vouch for user security. And the app needs to interface with card-issuing banks on the back end during setup, to get the keys and details it needs issued. An open source implementation would need to jump through a lot of hoops and set up agreements with the banks and pay for all sorts of lab verification (probably through UL). reply lxgr 17 hours agorootparent> From what I recall one of the few things that did change was raising of payment limits for these devices over contactless cards, because they are deemed more secure (can't be used by just anyone that happens to have stolen it). The limits are the same, but what these wallets added is on-device cardholder verification. In a nutshell, it lets Apple Pay tell the terminal \"the cardholder already did Face ID/Touch ID/entered their passcode; it's fine\", which can then skip PIN entry or signature collection. Other wallets do it differently and only prompt for that on-device authentication if the amount exceeds that where a PIN or signature would normally be required; yet others don't support it at all and just make you enter the PIN on the terminal (if there is any). reply karlshea 17 hours agorootparentA couple of times that lack of signature verification tripped up a cashier, theyâ€™re obviously used to always needing it with however their terminal was configured, but with Apple Pay the receipt got printed with no signature line and after looking at it funny theyâ€™re like, â€œoh, well hereâ€™s youâ€™re receipt I guess you donâ€™t need to sign!â€ reply lxgr 17 hours agorootparentI'm glad the cashiers in your country took it that well! I've heard of a few cases of surprised employees getting suspicious or outright hostile in the early Apple Pay days (when it wasn't available to domestic cardholders yet and only tourists would use it) This might be largely due to a strong culture of cashiers expecting to be handed over your card and them being the ones to insert it into the terminal (which is quite ridiculous â€“ it causes the terminal to be pivoted between cashier and customer twice for each transaction for the mandatory PIN entry). reply 998244353 10 hours agorootparent> cashiers expecting to be handed over your card This is quite frustrating. I used to have a rather low limit for contactless payments. Back then, some terminals would not prompt for a PIN when the limit was exceeded and would simply decline the transaction. Abroad, I had several incidents where a cashier would take my card, see the \"contactless\" icon on the card and tap the terminal. It was usually difficult to explain with limited English that they needed to insert the card because the limit was exceeded. I ended up crossing the contactless icon out with a marker. reply worthless-trash 16 hours agorootparentprevI got this experience first hand in Boston in 2008ish, \"Tap and Go\" had been introduced to Australia for what seemed to be years before and the cashier expected me to \"pass my card\" after I had already tapped to pay. Fortunately she took my explanation well and wanted me to demo it in front of a co-worker. reply 4rt 16 hours agorootparentprevI thought apple/google only verified payments up to a limit (ever increasing) of e.g. Â£500/Â£1000 based on the biometrics? Is that right? reply Nursie 16 hours agorootparentprevFair enough, tÌ¶hÌ¶eÌ¶ Ì¶tÌ¶eÌ¶rÌ¶mÌ¶iÌ¶nÌ¶aÌ¶lÌ¶sÌ¶ Ì¶oÌ¶rÌ¶ Ì¶bÌ¶aÌ¶nÌ¶kÌ¶sÌ¶ Ì¶mÌ¶uÌ¶sÌ¶tÌ¶ Ì¶hÌ¶aÌ¶vÌ¶eÌ¶ Ì¶lÌ¶iÌ¶mÌ¶iÌ¶tÌ¶sÌ¶ Ì¶tÌ¶hÌ¶aÌ¶tÌ¶ Ì¶dÌ¶eÌ¶pÌ¶eÌ¶nÌ¶dÌ¶ Ì¶oÌ¶nÌ¶ Ì¶tÌ¶hÌ¶eÌ¶ Ì¶CÌ¶VÌ¶MÌ¶ Ì¶tÌ¶hÌ¶eÌ¶nÌ¶,Ì¶ Ì¶bÌ¶eÌ¶cÌ¶aÌ¶uÌ¶sÌ¶eÌ¶ Ì¶tÌ¶hÌ¶eÌ¶rÌ¶eÌ¶ Ì¶aÌ¶rÌ¶eÌ¶ Ì¶dÌ¶eÌ¶fÌ¶iÌ¶nÌ¶iÌ¶tÌ¶eÌ¶lÌ¶yÌ¶ Ì¶hÌ¶iÌ¶gÌ¶hÌ¶eÌ¶rÌ¶ Ì¶lÌ¶iÌ¶mÌ¶iÌ¶tÌ¶sÌ¶ Ì¶fÌ¶oÌ¶rÌ¶ Ì¶pÌ¶hÌ¶oÌ¶nÌ¶eÌ¶ Ì¶pÌ¶aÌ¶yÌ¶mÌ¶eÌ¶nÌ¶tÌ¶ Ì¶cÌ¶oÌ¶mÌ¶pÌ¶aÌ¶rÌ¶eÌ¶dÌ¶ Ì¶tÌ¶oÌ¶ Ì¶cÌ¶oÌ¶nÌ¶tÌ¶aÌ¶cÌ¶tÌ¶lÌ¶eÌ¶sÌ¶sÌ¶ Ì¶cÌ¶aÌ¶rÌ¶dÌ¶sÌ¶ (edit: forgot cards and devices can have their own limits, best ignore this comment) reply codethief 12 hours agorootparentprevThanks so much! reply Nursie 16 hours agoparentprev> Can anyone ELI5 how Apple & Google Pay work in detail? Oh, in case this was not really answered in other responses ... When you add a card to an Apple or Google wallet, the wallet softwares goes off to your card issuer and asks for permission to include it in the wallet. Your card issuer may then ask you directly if it's OK and please confirm. When you have confirmed, they provide some details to your phone including some private keys (likely derived from a master) and other bits and pieces like the PAN to use, supported transaction types etc. OK, now it's set up in your phone. What happens when you tap? The terminal first goes through a sort of rapid handshake - hey, I'm a terminal, please select your default card application, let's go! Then it asks for a bunch of data - can I have your PAN, expiry, velocity data, hard and soft limits etc, please? Then it sends a bunch of data to your card - transaction type (payment, cash, refund(?)), amount, date and time, terminal type, some other bits. Your phone or card will then check these fit in with its internal rules (do I allow cash? etc), add some information (user unlocked biometrically/with PIN) arrange the data in a canonical order, hash and sign it and send back the resulting signature as a cryptogram. Part of this cryptogram will tell the terminal Yes/No to proceed and whether it needs to ask for a PIN or go online to the acquiring bank for approval. The terminal applies its own rules to the transaction as well, and can optionally downgrade the transaction from approved to online or denied, or from online to denied. If it needs to go online, it will transmit the transaction details to the acquiring (merchant's) bank, which may approve the transaction immediately or itself refer the transaction to the issuing (your) bank. It's at this point, for Apple Pay, that Apple steps into the picture - as the PAN is not the 'real' PAN, the acquiring bank refers to apple, and they then refer to the issuer. Then the approved message pops up :) Apart from the issuer-proxying, the process is basically identical if you use a phone or your physical card. I've probably glossed over quite a lot and got a couple of details wrong, but hey, that's the nature of ELI5. reply codethief 12 hours agorootparentThanks so much! reply refulgentis 20 hours agoparentprevCorrect. Though it's not the same on Android, you can be not-Google and do payments just fine, provided you have the same business relationships with the CC companies as a big merchant processor (good luck) Not a huge fan of Android, but Android's pretty damn open, the open advocacy orgs unfortunately tend to conflate \"you have to say \"yes\" to a dialog about untrusted apps in Android! intentionally difficult!\" with the debacle the years-long Apple stuff has turned into. I suspect we'll see less of that equivocation now that the petulance is nakedly visible, and gratefully, there's no longer billions spent on things like the \"Privacyâ„¢\" ad campaign, rushed after 100s of celebs had their nudes leaked from iCloud due to bad customer support. reply hoistbypetard 21 hours agoprevWhen Apple Pay first started to become common, I looked hard at it through the lens of my own retail payment processing experience. One of the things that impressed me most about it at the time was just how rooted in industry standards it was. None of it from the radio back was Apple-specific at all at the time, and by my read of this piece, that has held up through the present. At the time, I recall a few merchants who were intentionally accepting card-based tap-to-pay needing to alter their systems because they found themselves accidentally accepting the very standards-based Apple tap-to-pay, and they didn't want to. (CVS comes specifically to mind... IIRC they were part of a competing scheme, and they wanted the fact that their competing scheme was accepted at their retail locations to help differentiate that scheme from Apple Pay.) I'm goad the author took the time to do a more current review in this context, because when the \"only Apple Pay does this\" mythology started to emerge recently, I was scratching my head, wondering if something had changed since I had last gotten to look. reply jjcm 21 hours agoparentSharing a personal anecdote - when Apple Pay first launched, it only worked in the US. A more accurate statement though was it could only be set up in the US. I very shortly after moved to Australia, where tap-to-pay is the standard. It was kind of crazy because despite not officially being supported, Apple Pay worked everywhere in Australia. Whereas only a small handful of merchants supported it in the US, 99% of point of sales in Australia supported it because it was based off the standard. reply JimDabell 12 hours agorootparentThis also worked in reverse. When I was visiting the USA, when I tapped my credit card to pay on terminals that were seemingly set up for Apple Pay, it was mind-blowing for some people. I didnâ€™t realise contactless cards were so rare over there at the time. reply patch_cable 18 hours agorootparentprevI had a similar experience. After it was released in the US, I took a trip to the Netherlands. I had a lot of â€œhow did you do that?â€ reactions from merchants when I paid for things with my phone. reply p_l 12 hours agorootparentDepends on country, and how contactless cards being the norm in many places meant there was less push among people for payment with phones, compared to USA where it seems it no modern bits for card payments happened between introduction of magnetic strip and phone-based EMV2 NFC payments. I remember changing card ~2012, in Poland, because my ancient Visa Electron with magstripe-only was confusing to new cashiers who thought lack of chip meant it's contactless. Around that time phone-based \"cards\" were also widely promoted though the tech wasn't exactly ready yet so you needed cooperation between banks and telcos to provide secure element. reply kenny11 18 hours agorootparentprevI had the same experience as you on a trip to the Netherlands. Ironically, the only place where it didn't work was the Apple store in Amsterdam. I don't know if that was an actual technical limitation, or they were aware that it was not yet available in the Netherlands and so didn't even let me try with my phone and its US credit card. reply Schiendelman 18 hours agorootparentprevI had a similar experience traveling in Europe! More than one merchant thought I had â€œhackedâ€ them initially. reply stefandesu 10 hours agorootparentprevSame, I used Apple Pay in Germany before it was officially launched there and people were very surprised that I could just pay with my Watch. Contactless payment was already becoming more prevalent, so it worked in a lot of places. reply e_y_ 3 hours agoparentprevIt was standards based, but the way Apple ran the launch and marketing (kind of genius, actually), they gave the impression that Apple Pay was the only phone-based tap-to-pay around. Merchants would have signs saying \"Apple Pay accepted\" but not mention Google, leading to confusion over whether non-Apple payments would work. Part of that is definitely the confusing state of payments on Android. Samsung Pay could refer to either NFC or magstripe-emulation. Google, of course, is terrible at branding stuff, and between Wallet and the many iterations of Google Pay it's still difficult to figure out what's what. reply tentacleuno 3 hours agorootparent> Samsung Pay could refer to either NFC or magstripe-emulation Last time I checked, you've got to swipe a magnetic-stripe card (we mainly use C&P/contactless). Unless there's some really cool sci-fi pop-up plastic tab inside the phone / case / a separate re-programmable card, I'm really curious as to how this could work? reply e_y_ 57 minutes agorootparentI haven't been able to find a detailed explanation of how it works. Somehow it emits a magnetic pulse that simulates the card being swiped, without having to physically swipe the card. Best guess is that it uses some kind of magnetic induction to induce a current in the reader the same way that a swipe would. I never had a Samsung phone so I can't comment on how it worked in practice or the reliability. Can't find any mention of having to hold your phone a particular way so presumably it's direction-independent, although apparently sometimes it might not be possible to hold your phone close enough for the reader to pick it up. https://en.wikipedia.org/wiki/Magnetic_secure_transmission reply p_l 12 hours agoparentprevThe funniest thing to me is how people forget that Apple Pay was late addition to mobile payment game. Practically the last one to enter the market. reply lxgr 18 hours agoprevSomething that's missing from all of these discussions is that transactions on Apple Pay (and all similar wallets like Google Pay, Samsung Pay etc.) are now just as trackable as those done using the underlying card number. While the DPAN is unique to a given device, the merchant's payment service provider these days can receive a unique identifier called PAR in the authorization response from the card network. That identifier is consistent across all DPANs for the same card (and aspirationally even across card number changes on the same underlying account). The PAR can't be charged by any merchant, so this is not a security problem, but don't expect your digital wallet payments to be any more private than those done using your regular card or card number. https://wcapra.com/payment-account-reference-capraplus-your-... https://www.securetechalliance.org/wp-content/uploads/EMVCo-... reply mattmaroon 18 hours agoparentI would never expect anything to get more private ever again short of acts of government. reply ljlolel 17 hours agorootparentTry reading the book Seeing like a State reply astrange 15 hours agoparentprevNot true in Japan, Apple Pay uses anonymous ICOCA (aka Suica) cards which you can delete and recreate if you want. reply klausa 13 hours agorootparentThis is a very weird understanding of what IC cards are in Japan. Yes, Apple Pay supports them, and they're ephemeral and easily recreated, and semi-anonymous; but Apple Pay over here absolutely still supports \"regular\" cards here. And you can't use your IC card for online purchases, which is most of the article was about anyway. reply astrange 12 hours agorootparent> Yes, Apple Pay supports them, and they're ephemeral and easily recreated, and semi-anonymous â€¦so what I said, yes. > but Apple Pay over here absolutely still supports \"regular\" cards here But you don't have to use em. Strange interaction here: you can refill Suica with a foreign credit card, there is no transaction fee for it, and it means you can turn anything you can purchase via IC card into 5x travel spending with the right card. reply klausa 11 hours agorootparentMaybe it's a non-native speaker thing; but for me when you says \"Apple Pay uses XYZ here\"; it implies exclusivity, that it underpins the whole system; not that it's one of the available option. I can see now that's not what you meant. > But you don't have to use em. You do, if you want to use it over the internet. You and I might have a good grasp of what IC cards here are; but your comment without that knowledge can be misleading. > it means you can turn anything you can purchase via IC card into 5x travel spending with the right card. As long as nothing you buy costs more than 20000 JPY ;) reply lxgr 8 hours agorootparentprevSure, you can also add some anonymous prepaid/gift cards to Apple Pay, but my point is that Apple Pay does not add any privacy/anonymity beyond that of the underlying card, contrary to what some people seem to still believe. The PAR was introduced after Apple Pay (and in a way in response to it and other wallets), and some people might have missed it. reply worthless-trash 17 hours agoparentprev> (and aspirationally even across card number changes on the same underlying account). My local Australian bank (NAB) does this. I imagine it's pretty normal across most credit cards here. reply praseodym 21 hours agoprevThe post by Matt Birchler has been amended with the paragraph \"A previous version of this post suggested the DPAN changes between merchants, but that was a mistake. Serves me right for cranking this post out too quickly. Seriously, my bad.\". However, the rest of the post still suggests that there is a unique DPAN per merchant, but I can't find any basis for that. Even Apple's own documentation at https://support.apple.com/en-us/HT203027 says that the DPAN (called Device Account Number here) is only unique per device. When a card is added to Apple Pay a DPAN is created for that device, and it never gets changed afterwards unless the card is removed and re-added. So whereas you can't be tracked by using the same card on two devices (e.g. iPhone and Apple Watch) because they will have two different DPANs, I'm pretty sure data brokers can track you when using the same card on the same device across different merchants. reply arcticbull 21 hours agoparent> hen a card is added to Apple Pay a DPAN is created for that device, and it never gets changed afterwards unless the card is removed and re-added. They're not generally considered stable in the payments world. They can get rolled periodically, even outside of card addition and removal. reply MBCook 20 hours agorootparentIn Apple Pay they are sort of static. Not per merchant, but they donâ€™t cycle by default for any reason. I believe there is a button you can press to have the number changed. I think Iâ€™ve seen it before but Iâ€™ve never used it. And of course you could always just remove your card and then re-add it. That would give you a new DPAN. reply lxgr 17 hours agorootparent> I believe there is a button you can press to have the number changed. That's for the Apple Card's virtual card number, which is just a regular old PAN. There is no such button for the DPAN, to my knowledge. reply MBCook 17 hours agorootparentAh youâ€™re right, I got those confused. Thanks. reply adrr 21 hours agoparentprevDifferent PANS doesnâ€™t make a difference when your bank is selling your credit card data anyway. reply MBCook 20 hours agorootparentIt makes a difference for credit card thieves. Not for transaction list privacy. As long as your bank is involved youâ€™re just going to have to put up with them and trust them. reply adrr 15 hours agorootparentCredit theft affects the banks and merchants. They are out of the money not me. Its for their benefit. I just suffer the inconvenience of getting a new card. reply mightytravels 19 hours agoparentprevI noticed that the last 4 digits of the card used with Apple Pay is different every time I pay (I use my Apple Watch mostly). Not use between merchants but also with the same merchant. reply lxgr 17 hours agorootparentAre you sure you're not mixing up phone and watch payments? And is this with a Mastercard or Visa card, or something region-specific? The DPAN has always been constant in many years of using Apple Pay for me, which is useful to e.g. check which card I've actually used on by comparing the last four digits printed on a receipt to those I can see on my phone or watch (the card details show both the funding and the DPAN last four digits). reply adam_arthur 20 hours agoprevWhy are SSO and mobile pay not standard interfaces that anybody can build a provider for? Why is there \"Login with Google\" or \"Login with Apple\" instead of \"Login with [my default configured SSO provider]\". Or \"Pay with [my default configured pay provider]\" Even worse, many times vendors/sites only support a subset of these providers, making SSO not really SSO at all. I'm sure the reasons are out there, but I haven't researched it in-depth. It seems to me there should be a common agreed upon spec that all vendors adhere to. If not, it will probably be legislated to this standard sometime in the future reply ndriscoll 20 hours agoparentI believe what you're looking for for SSO is RFC 7591[0], which describes how to register with an oauth IdP on the fly. RFC 8414[1] describes well-known locations to get metadata about the registration process. So the standards are there, and in theory you could have a login form where e.g. someone types their email (or the browser autofills it), and that kicks off an oauth login to that domain, doing client registration on the fly if the server has never talked to that domain before. I've never seen it in the wild though. Would be nice. [0] https://datatracker.ietf.org/doc/html/rfc7591 [1] https://datatracker.ietf.org/doc/html/rfc8414 reply hashworks 12 hours agorootparentI think tailscale supports exactly that? You give them your email address and they check the web finger endpoint of the domain for your configured SSO provider. https://tailscale.com/kb/1240/sso-custom-oidc reply Nextgrid 19 hours agoparentprevBecause of \"growth & engagement\". Somewhere around 2010, technology shifted from being a tool to empower the user to a tool to waste the user's time with spam. Things shifted from offering a service and collecting a fair fee to spamming the user or collecting their data (so it can be used to further spam the user down the line). An open standard isn't something any of the current providers want since otherwise users can easily substitute them with different alternatives and no longer \"engage\" with them. reply soared 20 hours agoparentprevBecause user verification varies significantly between businesses, and so they need to vet and trust SSO vendors to uphold the standards they require. If there are a million sso vendors, who knows what standards each upholds. reply ndriscoll 19 hours agorootparentYou could say the same thing about email registration, but people generally don't restrict email-identified accounts to one of 3 providers. reply tadfisher 18 hours agorootparentThe difference is that you can be reasonably sure that an email will be delivered to the user's address that they specified, and there is a common understanding that sharing your email credentials will result in immediate financial loss. The communication is out-of-band, as SMTP is not an authentication protocol, so the user must perform some affirmative action (such as clicking a link in the email) to authenticate the request. With SSO, the claim that a user is authentic lies completely with the provider. If there is a bug in the implementation, a user could be authenticated when they should not be, and the actual account owner may never even be notified that such an authentication occurred. reply ndriscoll 16 hours agorootparentWith oauth/oidc, the service that's requesting the token doesn't even specify the username. What would the IdP send back if the user is not authenticated? The concern is it will just issue a token for a random user? Or that someone will break into another account on the IdP's login form? I don't see any difference with email besides convenience. If an email provider has a bug, they might allow someone else to read your email and click the link without any notification to the actual account owner that such an authentication occurred. In fact, if a provider has oauth and webmail, the two probably use the same authentication system (e.g. they use the same session cookie and login form, or the webmail might use the oauth service as its auth). Even native email clients are using oauth these days. This is a good thing. It lets you store a token with limited permission in your email client instead of storing a password for SMTP that also gives you full permissions to everything the account can do. Also most oauth implementations I've seen actually do have a dashboard in your user settings where they record which services you've provided tokens to, and what scopes those tokens have. If you're worried about CSRF, that's what the state parameter is for, and it's the consuming service that needs to use it appropriately, so you don't need to worry about whether the IdP did it right. If the IdP gives the wrong state back, the login will fail when your service checks it. reply Scarblac 20 hours agoparentprevTo support \"Login with Google\" you have to do some config on the Google side. You have to tell them, this ils my app, this is the URL you have to redirect back to after authenticating, and do on. Otherwise there would be security problems. reply Spooky23 19 hours agoparentprevBecause itâ€™s both a pain in the ass and a magnet for fraud. Stackoverflow encouraged openid from anywhere and it created problems. reply MBCook 20 hours agoparentprevWhy do we need SSO? Passkeys seems perfect to me. Easy sign on anywhere I sign up. No central whoever that knows every time I log in anywhere. reply lxgr 18 hours agorootparentPasskeys are great(-ish) for authentication, but don't offer identification at all. It's just not in scope (and I think that's a good thing; the two problems are pretty different, and WebAuthN is already extremely overloaded with features serving conflicting goals). reply grpt 19 hours agoprev> the merchant chooses how much personal info they want or need to collect, and Apple Pay doesnâ€™t prevent them from asking you for that at checkout. Does this happen when shopping in-person? > of course that info would be there! In this example, my checkout page was for a physical item so I needed the customerâ€™s shipping info. They don't need my name and address if I'm buying eggs in a grocery store. Does Apple/Google require my consent to share that info when it's obviously not required? Is it similar to a terms & conditions, or shrink-wrapped EULA? (ie take it or leave it) I've never used these payment systems. reply lxgr 18 hours agoparentFor POS payments, usually only the device account number (DPAN) is shared with the merchant. Even the name is usually redacted, similar to contactless and as opposed to chip or magstripe payments. All of the additional details mentioned in the article are only shared when you pay \"online\" â€“ but that includes scanning a QR code on your phone and paying in Safari or an App Clip, which is something I've seen in a few restaurants these days. That way, the restaurant gets as much as they ask for, which can include your name, your address, and your email address. I think this is usually displayed on the payment sheet, but it didn't really register for me the first time I used it in some restaurant. Now I make sure to ask the waiter for an actual terminal to tap or just give them my physical card. reply troad 21 hours agoprevFunnily enough, Apple Pay launched in Australia following a multi-year push by local big banks to increase the use of contactless payments. So all the infrastructure was already there, built out by the banks themselves, when Apple came in demanding a US-style cut, as though they built the thing. The local big banks held out for years on supporting Apple Pay, before the customer pressure became too overwhelming and they relented. They're all still very upset about this, and would drop Apple Pay in a second if the NFC chip were forced open by a regulator, but to date they've found it hard to find anyone too sympathetic to a sob story from - well - the nation's biggest banks. reply madeofpalk 19 hours agoparentAmusingly, all the Australian banks asked the ACCC for permission to form a cartel and collectively bargain with Apple on Apple Pay terms. They were denied. https://www.accc.gov.au/media-release/accc-denies-authorisat... reply amadeuspagel 9 hours agorootparentAntitrust usually makes it impossible for smaller companies to combine their market power against the market power of a bigger company. reply joshl32532 20 hours agoparentprev> They're all still very upset about this, and would drop Apple Pay in a second if the NFC chip were forced open by a regulator Not if the users have anything to say about that. Canadian banks tried to do their own contactless payment on Android (TD Pay, lol), but nobody wants it. In the end they caved and finally offered Google Pay. I predict it's gonna be similar. Even if Apple opens up NFC payment, nobody will use them and prefer 1st party support like Apple Pay or Google Pay. Just see how many people actually use Samsung pay vs Google Pay. reply troad 19 hours agorootparentTo be part of Apple Pay, banks have to enter into an agreement with Apple. Though the details of this agreement are generally confidential, it's fairly well known that there is an Apple cut, and that that cut is rather high. (It's Apple!) The moment a bank has the option to extract itself from this arrangement, it will. Not just because there's absolutely no reason to give Apple a cut of the bank's own business if the bank doesn't need to, but also because the bad blood between Aus banks and Apple is very real at this point. > Even if Apple opens up NFC payment, nobody will use them and prefer 1st party support like Apple Pay or Google Pay. And since that costs the bank money, it won't be an option. Also, I think the bank would think of itself as a first party in a payment made using their card, and Apple as a parasitic third party. I'm not saying people won't grumble, but there is no way - unless Apple actually makes Apple Pay somewhat attractive to banks - that the banks will continue to support it if they don't absolutely have to. (I'm not siding with the banks on this, I'm just trying to lay out their logic.) reply dwaite 17 hours agorootparentI think it's just different math. The 15 basis points Apple supposedly charges for with card payments from Apple Pay is meant to come from the fraud budget; that a biometric-based authentication is consider both more secure and easier to counter payment disputes. The rest comes from the convenience and hope that actually results in more card payments. In the US where there's no PIN, fraud is high. Parts of the country are still heavily cash based, so there's a good margin to gain if added convenience results in more card payments. For heavily credit card based markets with chip-and-pin, you have less fraud concerns and less to gain from convenience. My take though is that even if apple opens up the NFC chip, they aren't opening up the Secure Enclave. So even if a bank app can take over the NFC chip, they still will have secrets in memory at some point without a new P-256 based payment protocol. Unless this is a new app backed by a bank cartel, you'll also go from being able to use multiple cards to just one first-party card. This all leads to my opinion of a pretty wonky situation - opening NFC up probably increases the value of Apple Pay, since it can now be compared to other software-based wallets by users, and Apple Pay support again becomes a differentiator for the payment card. reply astrange 15 hours agorootparent> My take though is that even if apple opens up the NFC chip, they aren't opening up the Secure Enclave. So even if a bank app can take over the NFC chip, they still will have secrets in memory at some point without a new P-256 based payment protocol. The NFC chip is itself a secure enclave. (It's called a \"secure element\" but same thing.) It does its own key storage, which is why it can work when the phone is turned off. reply troad 16 hours agorootparentprev> Unless this is a new app backed by a bank cartel Good news - they've already got the cartel ready to go, and it's conveniently already in bed with the regulators! See https://en.wikipedia.org/wiki/BPAY & https://en.wikipedia.org/wiki/New_Payments_Platform > This all leads to my opinion of a pretty wonky situation Yep, that's sadly accurate for all the banks' other tech, so I see no reason they'd shy away from it here either. I feel like you're coming at this from the wrong angle. No one is saying Apple Pay is bad, or that the banks' solutions will be better. The question is: will banks voluntarily give up a cut to a third party intermediary, when they can roll a slightly-less-convenient-but-good-enough tech stack and keep all the money for themselves? One doesn't exactly become a top 4 bank by handing out a cut to intermediaries willy nilly. Even if the Apple cut were eliminated (unrealistic), the banks would need a very good reason to allow an intermediary between themselves and their customers at all. reply rswail 7 hours agorootparentThe NPP is about removing the Visa/MC networks from the equation. It would also remove the EMV requirements, if I'm identified by my mobile phone number + biometrics linked to a bank account, which can have it's own credit line associated with it, why does the bank need to support Visa/MC? The new payment platforms with instant settlement effectively remove the branding and merchant agreements that Visa/MC offer. Person A can transfer money to Merchant M immediately, no intermediaries except the two banks/account provider and the payment platform usually run by the central bank. reply bigyikes 19 hours agorootparentprevApple should buy a bank and compete on their own turf reply astrange 15 hours agorootparentOwning a bank is an extreme regulatory headache. You always want someone else to be the bank. Or even better multiple someone elses - in the US, small banks are allowed to do things large ones aren't, so you sometimes gather up a bunch of them and become a single proxy for them. reply gessha 18 hours agorootparentprevThey probably wonâ€™t do that in the current antitrust climate. I hope the DOJ and the EU continue probing the big companies because Iâ€™m sick and tired of my non-ecosystem device choices not working well together. reply rswail 7 hours agorootparentprevWhy would they want to be involved in a highly competitive and low margin business like consumer credit? reply m463 19 hours agorootparentprevWhat if an alternative is cheaper? customers end up paying in the end. edit: in the end. I guess the place I notice it is paying for gas - see the cash vs credit price always shown on the sign. It is pretty easy to add up when you're spending $100+ on gasoline. but this affects everything we buy, just hidden. reply tonyarkles 19 hours agorootparent> customers end up paying in the end. Not in a transparent way, generally speaking. And at least in Canada you couldn't even (as a business) add a credit card surcharge to a purchase price. Now you can, so long as you're simultaneously complying with the legislation (https://www.canada.ca/en/financial-consumer-agency/services/...) and your contract with your payment processor (e.g. https://www.visa.ca/content/dam/VCOM/regional/na/canada/Supp...). Apparently, too, merchants aren't actually charged for Apple Pay, it's the banks themselves that are. Merchants apparently pay the regular charge to their payment processor whether I use my Visa-through-Apple Pay or my Visa as a physical card. https://paymentdepot.com/blog/apple-pay-fees-for-merchants/ At any rate, Apple Pay is ridiculously convenient compared to anything my bank has ever come up with. The last time there was a Pay With Bank $X thing on a website that I tried, I ended up getting directed through some kind of Verified by Visa thing where they were asking for some kind of security code that I don't recall ever setting up. Or... I can double-tap the power button on my phone to verify a payment I'm making on my laptop. If the banks are unhappy about giving a cut to Apple, my recommendation to them would be: Suck Less. reply stale2002 16 hours agorootparent> Not in a transparent way, generally speaking There are ways to get around that. For example, a bank could offer partial rewards for using their payment system, over Apple's. The effect would be the same as passing on the savings to the consumer. reply tonyarkles 16 hours agorootparentGiven the software that banks generally produce, itâ€™d have to be a sufficiently good reward. If Iâ€™m buying a $10 sandwich at a deli counter, Iâ€™m going to double tap my power button and tap my phone on the debit machine. A $0.03 cash back isnâ€™t worth the hassle to fish around to find my bankâ€™s app, enter a secure password, and then enter a 2FA code. I had another comment elsewhere in this thread: want me to use the bank app instead of Apple Pay? Make the bank app suck less. reply FridgeSeal 19 hours agorootparentprevI donâ€™t get charged for using Apple Pay, I get charged for the processing fee for the card I used (which is an entirely separate discussion), and given the option between â€œjust continue using Apple Payâ€ or â€œdownload several janky apps just because the bank wants its own wallet implâ€, Iâ€™m going to stick with Apple Pay. reply jdminhbg 19 hours agorootparentprevThe Apple Pay take is 15 bps, which is not a difference customers care about enough to change behavior even slightly. reply icehawk 19 hours agorootparentprevI don't pay anything extra for using Apple Pay, as a customer, how could it be cheaper? reply toast0 19 hours agorootparentIf Apple is getting 0.15% as stated in a sibling, it's coming from somewhere. Maybe it's added on top of the fees the merchant pays, and like other payment fees gets kind of mixed into the price of everything you buy. Maybe it comes out of the fees your bank gets on purchases, which will reduce their income and then they'll need to increase fees, reduce benefits for depositors, or reduce dividends to investors. reply jwells89 19 hours agorootparentprevYeah, I have no interest in keeping 15 digital wallet apps, even if they offer incentives, for the same reason I donâ€™t carry a physical wallet for each physical card. Now I could see an argument for wallet apps being generic so e.g. the apps for Chase, BofA, SoFi, etc could carry all the userâ€™s cards like Apple/Google wallet should the user want that, but I doubt banks would have much interest in that (at least if itâ€™s privacy respecting and not skimming transaction history) because itâ€™s not prying mindspace away like per-provider apps do. reply jpgvm 20 hours agorootparentprevEh, maybe not in Australia. Remember Australia doesn't have like 5 million banks, we have essentially 4 big ones and they already are pretty cutting edge vs US/Canadian banks. i.e instant transfers are normalized, NFC is the norm, apps and Internet banking have been very good for about 10 years. If the NFC chips were opened up through regulation I have zero doubt Australian banks would just say \"we support contactless with our first party app\" and that would be the end of that until Apple asked for a more reasonable cut. When all your banks suck and Apple seems to be the only people with their shit together, sure but Australia doesn't live in that world. reply xvaier 20 hours agorootparentCanada has essentially 6 big banks, instant transfers using Interac has been the most common way of transferring money for years (it launched in 2003) and payment using NFC has been the norm for a decade. reply jpgvm 20 hours agorootparentHeh ok, sorry for assuming Canada would be as bad as the US. reply tonyarkles 19 hours agorootparentThe mobile phone apps are probably just as bad, but e-transfers (Interac, EMT, whatever you want to call it) generally work pretty well. And they're still somewhat of a hassle compared to I guess Venmo or Cashapp or... I've never used those but they seem pretty slick in comparison to having to go into a banking app, set up an EMT Payee using email/phone number, set a password on the transaction, hope that they remember to cash the EMT before it expires, etc. reply FridgeSeal 19 hours agorootparentprev> When all your banks suck and Apple seems to be the only people with their shit together, sure but Australia doesn't live in that world. ANZ was too busy charging dead people to bother implementing it. God only knows what westpac was up too, NAB had an implementation on Android, and having used it a bunch, it was _awful_ and I was glad when they gave up and just accepted the alternative. Combank did their own thing, and seemed the furthest along, but support seemed patchy and they ended up junking their solution anyways and going to Android/Apple pay anyways IIRC. These places can hardly manage to maintain their own apps, I have about zero confidence in them deciding to wander off into the wilderness and trying again. Not to mention, all the non-big-4, and all the smaller banks probably wonâ€™t bother with reimplementing NFC pay as they either donâ€™t have the resources, or canâ€™t rely on institutional-inertia to foist useless changes onto their customers. reply caf 16 hours agorootparentThe CBA Android app supports contactless, or you can add your card to the Google wallet. It seems to work equivalently well (although the enrolling bit has less friction in CBAs own app). reply inkyoto 19 hours agorootparentprev> [â€¦] we have essentially 4 big ones and they already are pretty cutting edge [â€¦] The Big Four are not the cutting edge, it is a delusion. Out of four, only the Commonwealth Wank has transitioned onto a modern core banking platform for retail banking. Business accounts still run on the legacy core banking platform, if my understanding is current and accurate. The remaining ones are as backward (from the technology POV) as they have always been. Westpac acquired St George Bank in 2008 trumpeting their core banking platform as the reason for the acquisition and the intention to transition onto it. To the best of my knowledge, that has not happened as of 2024, and Westpac contunues to use its own legacy core banking platform disjointly from that of St George's. Moreover, banking is not even integrated between the two even today, and the St George core banking has fell into a state of disrepair â€“ EFT's can take a few days to reach the receipient's account depending on the receipient's bank. The actual â€“ pretty much only â€“ innovator is Macquarie Bank that has invested a lot into revamping their banking platform from the ground up, plus neo-banks â€“ newcomers to the banking market albeit niche ones. The Big Four (or, most banks in general) loathe technology and IT as they see both as a liability, not a competitive advantage, due to tech not being their core business and due to being run by old farts with ossified brains. And that was the reason why they started rapidly losing millenials, Gen Z and other young customers to neobanks. It was a wake-up call for them. > [â€¦] instant transfers are normalized [â€¦] â€¦ and it has nothing to do with the Big Four. The Big Four, in fact, sabotaged instant payments for many years due to a lack of interest to advance the payment technology, and the instant payments in Australia only succeeded at the third (or at the fourth â€“ I have lost the count) attempt after the Reserve Bank held the Big Four at a gunpoint and threatened them with severe penalties if they pull out again, as they had done every single time before. Instant payments in Australia are done via NPP/Osco, an independent company set up by the RBA, a BPAY subsidiary, and the Big Four as well as other local banks are mere users of it. None of the four control NPP/Osco payments, and that is a very good thing. > If the NFC chips were opened up through regulation I have zero doubt Australian banks would just say \"we support contactless with our first party app\" [â€¦] â€¦ and users would be left with the atrocious quality banking apps and with banks tracking the users all the way down into the customer's colons. User tracking was the actual reason behind the spat between the Big Four and Apple â€“ the former wanted to get a way into users' smartphones and all sorts of device and chip ID's â€“ to track the user behaviour to which Apple said no. As a customer, Apple's stance suits me way more. Of course, banks have found other ways to track the iPhone users courtesy of advances in the big data science, although the attempt has been somewhat hampered. The Big Four are the largest employers of data scientists and for a reason. You can't be naive and look at the Big Four through the rose tinted glasses â€“ they are in the business of making very big money and treat their customers as acquisition assets and cows to milk. Commonwealth Wank has been onselling the transaction information to Equifax (other than reporting the credit history), and Equifax has been onselling that transaction information to some pretty shady loan shark companies. reply robertlagrant 11 hours agorootparent> and Westpac contunues to use its own legacy core banking platform disjointly from that of St George's It's so difficult to do this stuff. I firmly believe they should just start a new tech-focused bank from the ground up, and transition customer to it gradually over the subsequent 10 years. Maintain 2 apps; shift to a new backend gradually. But I think it has to be in-house, and built with this in mind. Mergers don't work with banking tech. Maybe they're already quietly doing this. reply jamesfinlayson 14 hours agorootparentprevWestpac has been saying just this week that their big transformation will be done in the next few years. I've never worked in banking but having seen some other big transformation projects in my career, I'm not optimistic. reply Xeamek 20 hours agorootparentprevTo be fair, samsung pay is only avaible in like 10(?) countries. But yeah, point still stands reply tadfisher 18 hours agorootparentSamsung isn't even interested in Samsung Pay. I work at an FI, and have submitted an application repeatedly to integrate the SDK. We have yet to receive a response. reply wkat4242 20 hours agorootparentprevI use Samsung Pay in Spain. I like it because it's better integrated on my phone and more importantly I don't need a Google account for it. I don't even have one set up on my phone. Of course Samsung does see my data this way but they have less info to correlate with. Also I don't use many of their services. I do wish there was a truly open payment solution though that doesn't require me to trust a big tech party. reply lstamour 19 hours agorootparent> I do wish there was a truly open payment solution though that doesn't require me to trust a big tech party. Cash? Everything else needs a relying party of some kind in order to facilitate the transaction. If it's a credit card or digital wallet, the transaction passes through the credit card or debit card networks, and your info is logged and, depending on laws, potentially re-sold. Don't get me wrong, I sometimes feel like Google shouldn't know my location either, but if my cell carrier already knows my location, I actually trust Google to not resell my location more than my cell carrier - it's worth more to Google if they're the only ones with that information and the same applies to Apple. Another way of putting it, rules and regulations, strictly enforced and updated, is probably the only way to prevent tracking and abuse by legitimate big actors. reply wkat4242 18 hours agorootparent> If it's a credit card or digital wallet, the transaction passes through the credit card or debit card networks, and your info is logged and, depending on laws, potentially re-sold. The reliance on credit card networks is part of the problem. There's no way to avoid them. And they're all from the US. This causes privacy issues but also moral problems because they tend to block sexually oriented products and services. In Europe a lot of countries are way more progressive than the US. I was hoping bitcoin would become this system but obviously it's been completely hijacked by speculators and its original purpose of control of ones own money has been perverted. There really should be a digital alternative for cash though. It's really silly that we still have to drag around pieces of linen and metal. And no, I don't trust Google for anything at all. I don't want them making money off of me. I also block a lot of ads of course. reply toast0 15 hours agorootparent> The reliance on credit card networks is part of the problem. There's no way to avoid them. And they're all from the US. JCB is Japanese, not sure what countries it has issuing banks in; it no longer issues in the US, and US acceptance is through Discover. There's also a lot of country specific debit/atm networks (including several in the US), if you are ok with debit over credit. reply astrange 15 hours agorootparentprevDebit cards don't all have to be processed through credit card networks, it's easier to do it that way. Websites could also take direct bank transfer payments if they felt like it, but it would hard internationally. reply ThePowerOfFuet 11 hours agorootparentprevYou should read Samsung's privacy policy. reply simondotau 20 hours agorootparentprevIt should be assumed that if the banks get an opportunity to implement their own NFC payment system on iPhone, theyâ€™ll switch off Apple Pay. Otherwise no customer would have any incentive to migrate over. And the incremental cost of Apple Pay is too little to be redirected towards some customer incentive program. (Of course that doesnâ€™t preclude a bank from making an irrational decision.) reply zilti 19 hours agorootparentprevIn Switzerland, the banks' own system, Twint, has been and still is a massive success. reply newsclues 18 hours agorootparentprevBanks want another Interact. reply pbh101 19 hours agoparentprevApple didnâ€™t create contactless payment infra in the US either. The contactless interface was already there, had its own logo, usable by tap cards, etc. Some retailers eg CVS turned off tap payments when Apple Pay was introduced. reply CharlesW 20 hours agoparentprevhttps://www.apple.com/newsroom/2024/01/apple-announces-chang.... reply knallfrosch 8 hours agoparentprevApple strangling the payment API and the App store at the same time is anti-competitive, but as long as noone cares.. reply sunnybeetroot 19 hours agoparentprevI remember pre-Apple pay when banks like NAB offered an NFC sticker you attached to the back of your phone as a â€œlook, just as good as Apple Payâ€ reply FridgeSeal 19 hours agoparentprevAh yes, the Australian bank impls. Where each bank had their own janky implementation inside their own specific app, which was both slower and had a worse UX. Had a credit (a la Amex) that wasnâ€™t from a major bank? Well womp womp no wireless pay for you. I for one welcome the Australian banks getting put out to the curb on this. The Apple Pay/Wallet experience is genuinely better in just about every single way. I also enjoy the virtualised card number I get with Apple Pay, which I donâ€™t believe any of the Australian banks bothered implementing, presumably because they were all too busy illegally charging dead people, and hiring corrupt ex state PMâ€™s to build anything good. reply ragazzina 3 hours agorootparent> Where each bank had their own janky implementation inside their own specific app, which was both slower and had a worse UX. You obviously understand this is by (Apple's) design. reply FridgeSeal 11 minutes agorootparentI had an Android when the banks were doing this before Google pay took off. The banks are capable of jankiness all by themselves. reply cam_l 19 hours agorootparentprevWhile I don't exactly disagree, for my own personal selfish reasons, I would prefer to not use the \"Big 2\" apps. Mainly because my bank doesn't lock me out just because I chose to ~root~ own my device. reply troad 19 hours agorootparentprevThe apps are bad, sure, but it was the banks who heavily pushed contactless EFTPOS terminals out to merchants in Australia. Without those, Apple Pay is a very cute curiosity on your phone, but I hope you remember your PIN because here comes the restaurant's dinosaur card machine. (Or worse, a click-clack card imprinter.) reply MBCook 20 hours agoparentprevSimilarly a ton of retailers in the US hated what Apple did. They came in right as EMV was starting to be mandated and contactless was being installed everywhere, even if it often wasnâ€™t on or working. The banks and retailers all try to make their own thing that they work that way. CurrenC was one, it failed horribly and relied on people taking pictures of QR codes to transfer debit payments, thus avoiding card fees. ApplePay can do debit also. But they didnâ€™t push that. More â€œwe donâ€™t control it so itâ€™s badâ€ nonsense. reply threeseed 20 hours agoparentprevEveryone along the payment food chain takes a cut so was always surprised that people thought Apple wouldn't. Especially when they are adding a value add on top. And banks are free to drop Apple Pay. Customers will simply move their business to those who do support it. Just like happened when Apple Pay first launched in Australia and banks like Commonwealth Bank held out. reply lolive 18 hours agoprevOff-topic, but I still donâ€™t understand why Apple Pay cannot display on the screen the sum currently to be paid before I validate the transaction. I suppose it is not a UX issue, but I suppose that sum is simply not known by the Apple device. Any idea? reply jen729w 18 hours agoparentJust think of your phone like a plastic card. It's listening for the request from an NFT reader, at which point it beams out your 'card number', and that is that. This took me a while to grok. I couldn't understand how Apple Pay could work when my phone was in Airplane mode. But of course it does! Your existing Visa card works just fine without an internet connection. Fundamentally, they're the same thing. That's why, if everyone is playing by the standards, there's nothing extra to 'support'. See jjcm's sibling comment here. https://news.ycombinator.com/item?id=39846117 So I dare say the NFT reader isn't 'broadcasting' the amount to pay. Why would it be? Your plastic card had no way of dealing with that information. And so your iPhone has no way of receiving it, and telling the NFT reader to hold on a second while you swipe-to-accept. reply lxgr 18 hours agorootparentIt actually is most of the time, but itâ€™s often a placeholder amount (some POSes let you tap before the check is finalized), so itâ€™s too unreliable to display in the wallet directly. The phone would also not have any way to verify if the terminal actually sent the payment online, causing confusion in case of having to tap again (that would then look like a double booking). > Your plastic card had no way of dealing with that information. You'd be surprised! Plastic cards can do all kinds of elaborate things, like deduct that amount from an offline transaction balance, replenishing that balance the next time it gets to talk to the issuer during a chip-dipped payment (assuming the card is still in good standing), update currency conversion rate tables used abroad, maybe even play doom â€“ but probably not all of them. reply kristjansson 16 hours agorootparent> like deduct that amount from an offline transaction balance, replenishing that balance the next time it gets to talk to the issuer during a chip-dipped payment (assuming the card is still in good standing) That deserves its own article. Where/why in the world would you need that!? reply etoulas 2 hours agorootparentHereâ€™s that article youâ€™re asking for. Smart Cards originated from pay phones https://computer.rip/2023-09-03-plastic-money.html reply lxgr 16 hours agorootparentprevFor offline support! Chip cards were introduced before internet connections were ubiquitous. Some cards were even explicitly offline-preferring as long as there was any offline balance remaining to save on data transmission and processing bills. There are even some fully offline chip systems around (where both terminal and card are mostly offline) that take the â€œoffline purseâ€ idea even further, but these are usually separate from the mostly account-based debit and credit schemes popular today, and are often getting phased out. These days, cards are mostly online-preferring or even online only, with some merchants taking on the risk of accepting cards while offline. reply saagarjha 6 hours agorootparentprevSome transit cards (such as the Bay Area Clipper card) do this. They are actually quite interesting in how they settle balances! reply kccqzy 15 hours agorootparentprevIsn't it mostly obvious? Offline transactions are needed whenever a transaction is made without access to the internet. Like a train in the middle of nowhere or a flight. Typically the POS just accepts the card, and then when Internet access is restored, sends them all out. So the merchant takes the risk of a customer using a bad card. But with smart functionality in the card, the card itself could make a determination of whether the payment should be approved. reply Nursie 16 hours agorootparentprev> So I dare say the NFT reader isn't 'broadcasting' the amount to pay. Why would it be? Your plastic card had no way of dealing with that information. Ah but it is, and it does :) You see those four lights that are on contactless readers? I know they're mostly meaningless to laypeople and they more or less just flash in unison to the naked eye, but they show stages of the transaction progress, left to right. There's a bunch of two-way comms going on there, including the transmission of the transaction amount, date/time, various transaction details, maybe a cryptographic challenge (nonce), and a bunch of other stuff I can't remember, from the terminal to your card. Your plastic card has an active chip on it, it's not just a dumb NFC tag, it is powered by the field the NFC reader is giving off. It does send a bunch of data to the terminal on request as an early part of the process, then receives transaction data back, arranges it with some internal bits of its own, pads, hashes and encrypts it using a key (usually a session key derived from a stored private key) and sends back the resulting cryptogram to the terminal. In fact your card makes important decisions about whether to allow the transaction to proceed, based on the transaction data, various counters and limits it maintains, etc etc. If the card doesn't approve the transaction (and show that approval in its cryptogram), the terminal cannot approve. You phone does the same stuff, but obviously without needing to use the power the reader puts out. The problem with displaying the amount before you validate, is that it would interrupt the process and require running the transaction in two halves, and it would kill the \"tap'n'go\" aspect of the transaction. But the phone can immediately display the amount afterwards. Incidentally, this sort of thing is why we have rules that the terminal must display the amount in a way that's visible to the customer, to be compliant. > It's listening for the request from an NFT reader, at which point it beams out your 'card number', and that is that. This is definitely not the case, and if it were the case, contactless cards would be trivial to clone! reply astrange 15 hours agorootparentprev> I couldn't understand how Apple Pay could work when my phone was in Airplane mode. But of course it does! Your existing Visa card works just fine without an internet connection. If you set it as an express card, it also works if the phone is shut off or has a dead battery. (As long as it's not too dead.) reply gruez 16 hours agorootparentprev>NFT reader NFC reader reply mikestew 22 hours agoprevWhere did Gruber say that â€œonly Apple Pay does thisâ€? The writer goes on to point out a few mistakes (or rather, didnâ€™t quite get the details right) Gruber made, and thatâ€™s seems to be it. reply lnxg33k1 22 hours agoparenthttps://daringfireball.net/linked/2024/03/21/garland-monopol... [Update: Whoops, I was wrong about that. Matt Birchler, who works in the payments industry, has a great explainer about how this works, and it turns out major banks and credit cards do generate per-merchant â€œDPANâ€ numbers for tap-to-pay transactions. I stand by my argument that Apple Wallet is at least as, if not more secure than, any digital payment app provided by a card issuer.] --- From the original author (Gruber) reply ryukoposting 21 hours agorootparentThe DOJ doesn't have a case, but WOW the last paragraph of that blog is an extraordinary wall of brand fellatio. reply internetter 18 hours agorootparentGruber has always been an Apple fanboy, but in the past few months it's taken a turn into ragebait territory, and i'm this close to stopping reading it reply ksec 5 hours agorootparentHow many things that most people ( within Apple Fans circle ) commonly believes that are plain wrong was started by him? Apple invented USB-C and turned it over to USB-IF The original AirPod was sold at cost. These are the two I remember well, others including Modem, CPU, Unified Memory, and now Payment. Although arguably Payment doesn't count because he did admit he is wrong. Basically Gruber and Daniel Eran Dilger from AppleInsider have similar traits, they have made their own conclusion and they derived their explanation backwards. reply newsform 3 hours agorootparentGruber also lies about having invented markdown, which was actually invented by Aaron Swartz in 2002 (http://www.aaronsw.com/2002/atx/intro.html). Gruber just wrote a little perl script called Markdown.pl in 2004, but after Swartz's suicide in 2013, he pretended that he had come up with the whole thing, and has been using it to market himself ever since. Truly repugnant behavior. reply ragazzina 3 hours agorootparentprevI guess the latest message he is putting out is \"Apple can't compete in Europe without anti-competitive practices, so they should get out of there\". reply lnxg33k1 5 hours agorootparentprevApple has killed the theft industry and the app store is safe reply lnxg33k1 21 hours agorootparentprevBrand fellatio has just become my new favorite concept :D reply notatoad 20 hours agorootparentprev>any digital payment app provided by a card issuer from this line, it seems like the author here and gruber are kind of arguing beside each other. Birchler says that google and samsung pay work the same way. gruber says bank's own apps don't work this way. they can both be right. does anybody here know if the payment apps operated by card issuers work this way? (or else, do card issuers actually have payment apps? my bank doesn't) reply lxgr 18 hours agorootparentGruber is wrong. Many bank-specific wallets also use device account numbers. Storing full credit card numbers and the associated cryptographic keys on a device's application processor (like many wallets on Android do, both Google Pay and others) is a big no-go, and even for secure element based solutions like e.g. Apple Pay it's a big advantage being able to lock the number for a lost/stolen device server side without having to reissue the associated physical card and vice versa. > do card issuers actually have payment apps? my bank doesn't They've been somewhat popular regionally, especially in countries where Google took their time with rolling out Google Pay support in, or for regional payment schemes that aren't supported in Google Pay. (They're only possible on Android; iOS hasn't traditionally supported the necessary APIs, until very recently when the EU forced them, and still only offers them there). I don't think they ever were a big thing in the US. reply addicted 22 hours agoparentprev> I highly doubt any banks or credit card issuers would do this themselves if given access to NFC tap-to-pay. Birchler points out that the banks did do this. And Gruber has acknowledged his mistake. Gruber is an open fanboi but for the most part he would at least get his facts straight and would be open about what he didnâ€™t understand and would link to experts in the field. However, since the EU DMA actions on Apple he seems to have completely lost his objectivity. First by pretending to understand the legalese better than apparently the EC does, then by applying American lawmaking approaches to European ones which are very different and then finally by taking Appleâ€™s bad faith statements at face value (Gruberâ€™s turn has coincided with Appleâ€™s very weird bad faith approach to the EU so maybe the fundamental issue is his trust in Apple). And he seems to be carrying over that to the U.S. govtâ€™s antitrust action as well. Also, to be fair, social media is absolutely filled with Apple people pretending to be legal experts but being completely wrong about almost everything. So it might be hard for him to even see opposing viewpoints from legitimate folks. reply scarface_74 21 hours agorootparentHave you actually looked into the claims of the US case? Some of their statements are completely incorrect and they donâ€™t even try to address what most commenters on HN seem to care about He and Ben Thompson are very consistent. If the government wants changes in the way that Apple and other tech companies operate - pass laws - like they did in the EU instead of trying to make up definitions and facts based on a law that was passed almost 100 years ago reply addicted 20 hours agorootparentYes I have. But thatâ€™s completely irrelevant because Iâ€™m not a lawyer. Ben Thompson and Gruber are not lawyers. Lawyers Iâ€™ve followed have not found any mistakes though they do think some stuff is pushing it, but thatâ€™s completely normal and how all such cases work. You have a core case on which you add a bunch of stuff. Because, one, you expect stuff to get thrown out, but more importantly these cases are rarely litigated to the end. Theyâ€™re settled. So you put more in, even the slightly weaker stuff, so you can compromise on it during negotiations. I wouldnâ€™t have know this stuff, which is why I donâ€™t pretend to know this stuff. Unlike Gruber and Thomson. Instead I follow lawyers online and speak to friends who are lawyers who have a better idea of whatâ€™s going on. The ridiculous part of Gruberâ€™s assertions is because he hears about these things only when Apple is involved he seems to think they are unique or new. Thatâ€™s why his insinuations in a couple of posts that the EU actions were to punish American companies and protect European ones. If he had half a clue about this area he would have known that the EU has fined way more European companies than it has companies from the rest of the world put together. reply scarface_74 20 hours agorootparentHowever, Andrew Sharp, Benâ€™s cohost on SharpTech was a lawyer and he also says that the judicial system is not the way to go and they should pass laws. But you donâ€™t have to be a lawyer to know the statements of fact are in correct as far as the technology. They also condemned EUs ruling against Facebook where Facebook canâ€™t even give users a choice of having an ad free experience by paying. I have no problem paying money for stuff I want. I think thatâ€™s an honest transaction. On Dithering, Gruber commended the EU for actually passing a simple law forcing Apple to open up NFC and the USB C mandate for iPhones instead of dragging it through some arcane legal doctrine. He didnâ€™t necessarily agree with the law. But it was at least straightforward and honest. But even if you arenâ€™t a lawyer - the things that most HN users care about were not addressed at all in the lawsuit. For instance there is no mention of the App Store at all except concerning NFC, cloud gaming (that Apple has already addressed) and whatever apps are called with other embedded apps. And no one in the Apple commentary community thinks the anti steering provision for Spotify and Kindle and Netflix etc is legitimate nor the former ban on cloud gaming. Right now Iâ€™m listening to the Talk Show podcast with Gruber and Jason Snell (former editor in chief of Macworld) and they arenâ€™t giving Apple a pass at all for the three items I mentioned reply MBCook 20 hours agorootparentExcellent points. > For instance there is no mention of the App Store In fact the DOJ would have likely had issues doing that given Appleâ€™s recent victory in that point against Epic (whatever you think of it). reply MBCook 20 hours agorootparentprevThe fact that the DOJ may be able to win the case does not make an antitrust case like this the correct way to legislate how we want companies to operate. It would be SO MUCH SIMPLER to just pass a law that says â€œsideloading has to be legal, easy, and freeâ€. Thatâ€™s all it would take. Or maybe â€œall cell phones must support RCS.â€ But not only have we not done that, the lawsuit against Apple for being a monopoly on the App Store was won by Apple. A court said they are legally in the clear. Apple already said they were adding RCS before this whole thing started. So the DOJ has come up with a bunch of issues, some of which that donâ€™t even seem relevant anymore, in an attempt to draw out concessions from Apple in a settlement to get what they couldnâ€™t get through previous court cases. Or perhaps win a verdict and charge them a whole bunch of money for stuff that doesnâ€™t matter all that much because again, some of the stuff they seem to be really mad about Apple already won on in another trial. The DOJ is supposed to be about enforcement, not creating the laws. This is not how this process should be working. And as Gruber and others have pointed out, if you have to twist a bunch of hundred plus year-old laws to try to come up with a case to do something that couldâ€™ve been done with a single stroke of a penâ€¦ maybe thatâ€™s what you shouldâ€™ve done instead. I havenâ€™t seen anyone saying who is arguing that Apple should 100% get out of all of this and theyâ€™re not doing anything wrong. Gruber and many others in the app world have been saying for years that Appleâ€™s blatant greed is going to get them a smack down, and theyâ€™ll lose some of their good policies along with the bad. People are arguing that the lawsuit doesnâ€™t seem well-made and that it shouldnâ€™t how the government accomplishes its goals in the first place anyway. reply hedora 18 hours agorootparentLaws like you propose tend to age poorly. RCS is incredibly consumer-hostile (e.g., there is no end to end encryption unless you use Googleâ€™s data-harvesting stack on both sides). Similarly, requiring side loading could preclude new classes of devices. Usually, the laws are written more vaguely for this reason. I think the big change we need to make is to say that anti-trust laws apply whenever N or fewer organizations control over X% of the market. I think N=3 and 75% would be good starting points. Among other things, this would open up licensing and cell plans on 5G modems. It would also mean that the google app store and apple app store both have monopolies over cell phone software resale and distribution. (Googleâ€™s â€œandroid is open source and supports side loadingâ€ argument wouldnâ€™t matter in such a regime, unless that meant that consumers and device manufacturers could reasonably expect degoogled android to actually run android apps and stuff, and that over a quarter of the market actually did so). reply scarface_74 16 hours agorootparent> Laws like you propose tend to age poorly. And court cases donâ€™t? There was a court case against IBM over anti trust that started in 1969 and it was finally dropped in 1982 because the world has moved on. One of the issues in the current case is already irrelevant - Cloud gaming that Apple has addressed. Another issue was whatever you call the mega apps. Apple has allowed that for years and Microsoft, Google and Facebook all moved away from the mega app into smaller apps. reply madeofpalk 21 hours agorootparentprevGruber never pretends to be objective - he likes what he likes, and he dislikes what he dislikes. Notably, he has a pretty strong \"pro-business\" streak in him that objects to anything resembeling workers rights or unions, and government regulation/interference in businesses. The EU tends to do a lot of that, so overall he's very critical of it. And at the moment there's a lot of governments telling Apple what to do, so it's the perfect storm of getting his knickers in a twist constantly. reply kemayo 21 hours agorootparentI don't think I've seen him do opposition to workers rights / unions? He hasn't been constantly yelling about supporting them either, but that's different. E.g. a quick google for \"daring fireball unions\" turned up mostly articles like this one which were pro union-demands: https://daringfireball.net/linked/2021/11/24/wirecutter-unio... Closest to a negative I found in that quick search was him making fun of the Maryland Apple Store union that was asking to be allowed to request tips from Apple Store customers... while also saying that the rest of their demands sounded like good things to ask for. reply MBCook 20 hours agorootparentOh man I had forgotten about that. reply ineedaj0b 21 hours agorootparentprevI think you should reconsider your judgement on the EU ruling being good. If you canâ€™t argue the EU ruling is bad (and not because Apple is greedy or shortsighted etc), you are missing something. Apple has a vision - the EU has a vision and they do not align. The EU is poor. It has been mismanaging itself for years: they should be doing better than they are. Is this caused by outside vectors or the leadership, or maybe the structure (too many cooks in EU kitchen)? Is the vision of the world the EU wants 15-25 years out strong? Is the world the EU would create good for the EU - 30 years out? Iâ€™d argue itâ€™d be a comfortable one. But a poor and weaker one. Iâ€™m not trying to defend Apple. Iâ€™m trying to say that the EU leadership is likely bad - my hunch is anyone truly good would work in the state department of the respective nation. Kinda like how UN ambassadors for the US are never our best - our best maybe might once in a blue moon take the post like a retirement phase. Now take the ruling, are you sure they made a smart long term move? reply TillE 21 hours agorootparentI don't know what \"ruling\" you're talking about. The DMA is a law, and it will be enforced despite Apple pretending to comply with it. There's nothing like a judicial proceeding as yet, much less a ruling. This really underscores the point, and it's not just Gruber and random internet commenters opining on EU law while having zero clue about it, it's also Apple fans I respect like John Siracusa and Jason Snell who have a lot of opinions without familiarizing themselves with the facts. reply chrisfinazzo 19 hours agorootparentGruber had Jason as his guest on the last episode of The Talk Show, just to give some context to both of their arguments. At the very least, they seem to agree that issues with the DMA - and the US DOJ case - stem from the idea that these lawmakers fundamentally misunderstand Apple's approach and why customers choose iOS, macOS, etc. Tl;dr, the integration is the point and these legal challenges pose the idea that this approach doesn't comport with the law as written and should be disallowed. reply p_l 12 hours agorootparentThat sounds like critical understanding failure on what DMA is about, what law is about, what EU is and is about. reply wkat4242 20 hours agorootparentprev> The EU is poor. It has been mismanaging itself for years: they should be doing better than they are. Is this caused by outside vectors or the leadership, or maybe the structure (too many cooks in EU kitchen)? > Is the vision of the world the EU wants 15-25 years out strong? > Is the world the EU would create good for the EU - 30 years out? Iâ€™d argue itâ€™d be a comfortable one. But a poor and weaker one. The EU vision isn't just about economy and making money. This is something that the US will never understand because money and",
    "originSummary": [
      "Matt Birchler debunks the myth that only Apple Pay safeguards credit card details, pointing out that Google Pay and Samsung Pay also protect card numbers.",
      "He distinguishes between FPAN and DPAN, underscoring the security advantages of DPANs, especially during data breaches.",
      "Birchler clarifies that Apple Pay doesn't conceal essential personal information from merchants, stressing that other digital wallets provide comparable security measures."
    ],
    "commentSummary": [
      "Hacker News discussion delves into Apple Pay and Google Pay, emphasizing their compatibility with physical payment terminals, security measures, and constraints, including the adoption of NFC technology.",
      "It outlines challenges banks encounter negotiating with Apple, regulatory concerns about digital wallets, transaction fees, and the legal consequences of antitrust lawsuits against Apple.",
      "The dialogue also covers offline transactions, smart card usage, and how EU regulations affect Apple's operations."
    ],
    "points": 267,
    "commentCount": 253,
    "retryCount": 0,
    "time": 1711575839
  },
  {
    "id": 39852167,
    "title": "Dioxus 0.5: Next-Gen App Development in Rust",
    "originLink": "https://dioxuslabs.com/blog/release-050/",
    "originBody": "Dioxus 0.5: Signal Rewrite, Remove lifetimes, CSS Hotreloading, and more! March 28, 2024 @jkelleyrtp, @ealmloff The story Here at Dioxus Labs, we have an unofficial rule: only one rewrite per year. Our last rewrite brought some amazing features: templates, hotreloading, and insane performance. However, donâ€™t be mistaken, rewrites are scary, time consuming, and a huge gamble. We started this new rewrite on January 1st of 2024, completed it by Feburary 1st, and then spent another month and a half writing tests, squashing bugs, and polishing documentation. Rewrites are absolutely not for the faint of heart. If youâ€™re new here, Dioxus (dyeâ€¢oxâ€¢us) is a library for building GUIs in Rust. Originally, I built Dioxus as a rewrite of Yew with the intention of supporting proper server-side-rendering. Eventually, Dioxus got popular, we got some amazing sponsors, and I went full time. Weâ€™ve grown from a team of 1 (me) to a team of 4(!) - pulled entirely from the wonderful dioxus community. Now, Dioxus is something a little different. Real life, actual companies are shipping web apps, desktop apps, and mobile apps with Dioxus. What was once just a fun little side project powers a small fraction of apps out in the wild. We now have lofty goals of simplifying the entire app development ecosystem. Web, Desktop, Mobile, all end-to-end typesafe, blazing fast, living under one codebase. The dream! With 0.5 we took a hard look at how Dioxus would need to change to achieve those goals. The request we got from the community was clear: make it simpler, make it robust, make it polished. Whatâ€™s new? This is probably the biggest release of Dioxus ever, with so many new features, bug fixes, and improvements that I canâ€™t list them all. We churned over 100,000 lines of code (yes, 100,000+) with over 1,400 commits between 0.4.3 and 0.5.0. Hereâ€™s a quick overview: Complete rewrite of dioxus-core, removing all unsafe code Abandoning use_state and use_ref for a clone-free Signal-based API Removal of all lifetimes and the cx: Scope state A single, unified launch function that starts your app for any platform Asset hotreloading that supports Tailwind and Vanilla CSS Rewrite of events, allowing access to the native WebSys event types Extension of components with element properties (IE a Link now takes all ofproperties) Integrated Error Boundaries and Server Futures with Suspense integration 5x faster desktop reconciliation and custom asset handlers for streaming bytes Streaming server functions and fullstack hotreloading Tons of QoL improvements, bug fixes, and more! ðŸ’¡ If you are updating from DIoxus 0.4, a migration guide is available Lifetime Problems To make Dioxus simpler, we wanted to remove lifetimes entirely. Newcomers to rust are easily scared off by lifetime issues, and even experienced Rustaceans find wading through obtuse error messages exhausting. In dioxus 0.1-0.4, every value in a component lives for a 'bump lifetime. This lifetime lets you easily use hooks, props and the scope within event listeners without cloning anything. It was the chief innovation that made Dioxus so much easier to use than Yew when it was released. // Scope and Element have the lifetime 'bump fn OldDioxusComponent(cx: Scope) -> Element { // hook has the lifetime 'bump let mut state = use_state(cx, || 0); cx.render(rsx! { button { // The closure has the lifetime 'bump which means you don't // need to clone hook before you move it into the closure onclick: move |_event| *state += 1, } }) } Rust Copy This works great for hooks most of the time. The lifetime lets you omit a bunch of manual clones every time you want to use a value inside an EventHandler (onclick, oninput, etc). However, the lifetime doesnâ€™t work for futures. Futures in dioxus need to be 'static which means you always need to clone values before you use them in the future. Since a future might need to run while the component is rendering, it canâ€™t share the componentâ€™s lifetime. // Scope and Element have the lifetime 'bump fn OldDioxusComponent(cx: Scope) -> Element { // state has the lifetime 'bump let state = use_state(cx, || 0); cx.spawn({ // Because state has the lifetime 'bump, we need to clone it to make it // 'static before we move it into the 'static future let state = state.clone(); async move { println!(\"{state}\"); } }); // ... } Rust Copy If you donâ€™t clone the value, you will run into an error like this: 4fn OldDioxusComponent(cx: Scope) -> Element {--|`cx` is a reference that is only valid in the function bodyhas type `&'1 Scoped` ... 8/ cx.spawn(async move { 9| println!(\"{state}\"); 10| });| ^|| |______`cx` escapes the function body hereargument requires that `'1` must outlive `'static` Rust Copy The error complains that cx must outlive 'static without mentioning the hook at all which can be very confusing. Dioxus 0.5 fixes this issue by first removing scopes and the 'bump lifetime and then introducing a new Copy state management solution called signals. Here is what the component looks like in dioxus 0.5: // Element has no lifetime, and you don't need a Scope fn NewComponent() -> Element { // state is 'static and Copy, even if the inner value you store is not Copy let mut state = use_signal(|| 0); // State is already 'static and Copy, so it is copied into the future automatically spawn(async move { println!(\"{state}\"); }); rsx! { button { // The closure has the lifetime 'static, but state is copy so you don't need to clone into the closure onclick: move |_event| state += 1, } } } Rust Copy While this might seem like a rather innocuous change, it has an impressively huge impact on how easy it is to write new components. Iâ€™d say building a new Dioxus app is about 2-5x easier with this change alone. Goodbye scopes and lifetimes! In the new version of dioxus, scopes and the 'bump lifetime have been removed! This makes declaring a component and using runtime functions within that component much easier: You can now declare a component by just accepting your props directly instead of a scope parameter #[component] fn MyComponent(name: String) -> Element { rsx! { \"Hello {name}!\" } } Rust Copy And inside that component, you can use runtime functions directly spawn(async move { tokio::time::sleep(Duration::from_millis(100)).await; // You can even use runtime functions inside futures and event handlers! let context: i32 = consume_context(); }); Rust Copy Now that lifetimes are gone, Elements are 'static which means you can use them in hooks or even provide them through the context API. This makes some APIs like virtual lists in dioxus significantly easier. We expect more interesting APIs to emerge from the community now that you donâ€™t need to be a Rust wizard to implement things like virtualization and offscreen rendering. Removal of all Unsafe in Core Removing the 'bump lifetime along with the scope gave us a chance to remove a lot of unsafe from dioxus. dioxus-core 0.5 contains no unsafe code ðŸŽ‰ Thereâ€™s still a tiny bit of unsafe floating around various dependencies that we plan to remove throughout the 0.5 release cycle, but way less: all quite simple to cut or unfortunately necessary due to FFI. Signals! Dioxus 0.5 introduces Signals as the core state primitive for components. Signals have two key advantages over the existing use_state and use_ref hooks: They are always Copy and they donâ€™t require manual subscriptions. Copy state Signal is Copy, even if the inner T values is not. This is enabled by our new generational-box crate (implemented with zero unsafe). Signals can even optionally be Send+Sync if you need to move them between threads, removing the need for a whole class of specialized state management solutions. The combination of Copy + Send + Sync Signals, and static components makes it incredibly easy to move state to anywhere you need it: fn Parent() -> Element { // We use a sync signal here so that we can use it in other threads, // but you could use a normal signal if you have !Send data let mut state = use_signal_sync(|| 0); spawn(async move { // Signals have a ton of helper methods that make them easy to work with. // You can call a signal like a function to get the current value let value: i32: state(); }); // Because signals can be sync, we can copy them into threads easily std::thread::spawn(move || { loop { std::thread::sleep(Duration::from_millis(100)); println!(\"{state}\"); } }); rsx! { button { // You can easily move it into an event handler just like use_state onclick: move |_| state += 1 } } } Rust Copy With Copy state, weâ€™ve essentially bolted on a light form of garbage collection into Rust that uses component lifecycles as the triggers for dropping state. From a memory perspective, this is basically the same as 0.4, but with the added benefit of not needing to explicitly Clone anything. Smarter subscriptions Signals are smarter about what components rerun when they are changed. A component will only rerun if you read the value of the signal in the component (not in an async task or event handler). In this example, only the child will re-render when the button is clicked because only the child component is reading the signal: fn Parent() -> Element { let mut state = use_signal(|| 0); rsx! { button { onclick: move |_| state += 1, \"increment\" } Child { state } } } #[component] fn Child(state: Signal) -> Element { rsx! { \"{state}\" } } Rust Copy Smarter subscriptions let us merge several different hooks into signals. For example, we were able to remove an entire crate dedicated to state management: Fermi. Fermi provided what was essentially a use_state API where statics were used as keys. This meant you could declare some global state, and then read it in your components: static COUNT: Atom = Atom::new(|| 0); fn Demo(cx: Scope) -> Element { let mut count = use_read_atom(cx, &COUNT); rsx! { \"{count}\" } } Rust Copy Since fermi didnâ€™t support smart subscriptions, you had to explicitly declare use the right use_read/ use_write hooks to subscribe to the value. In Dioxus 0.5, we just use signals, eliminating the need for any sort of external state management solution altogether. // You can use a lazily initialized signal called // GlobalSignal in static instead of special Fermi atoms static COUNT: GlobalSignal = Signal::global(|| 0); // Using the GlobalSignal is just the same as any other signal! // No need for use_read or use_write fn Demo() -> Element { rsx! { \"{COUNT}\" } } Rust Copy Signals even work with the context API, so you can quickly share state between components in your app: fn Parent() -> Element { // Create a new signal and provide it to the context API // without a special use_shared_state hook let mut state = use_context_provider(|| Signal::new(0)); rsx! { button { onclick: move |_| state += 1, \"Increment\" } Child {} } } fn Child() -> Element { // Get the state from the context API let state = use_context::>(); rsx! { \"{state}\" } } Rust Copy Smart subscriptions also apply to hooks. Hooks like use_future and use_memo will now automatically add signals you read inside the hook to the dependencies of the hook: // You can use a lazily initialized signal called GlobalSignal in static instead of special Fermi atoms static COUNT: GlobalSignal = Signal::global(|| 0); fn App() -> Element { // Because we read COUNT inside the memo, it is automatically added to the memo's dependencies // If we change COUNT, then the memo knows it needs to rerun let memo = use_memo(move || COUNT() / 2); rsx! { \"{memo}\" } } Rust Copy CSS Hot Reloading As part of our asset system overhaul, we implemented hotreloading of CSS files in the asset directory. If a CSS file appears in your RSX, the dx CLI will watch that file and immediately stream its updates to the running app. This works for web, desktop, and fullstack, with mobile support coming in a future mobile-centric update. When combined with the Tailwind watcher, we now support hotreloading of Tailwind CSS! On top of that, we also support IDE hinting of Tailwind classes in VSCode with a custom regex extension Whatâ€™s even niftier is that you can stream these changes to several devices at once, unlocking simultaneous hotreloading across all devices that you target: Event System Rewrite Since itâ€™s release, dioxus has used a synthetic event system to create a cross platform event API. Synthetic events can be incredibly useful to make events work across platforms and even serialize them across the network, but they do have some drawbacks. Dioxus 0.5 finally exposes the underlying event type for each platform along with a trait with a cross platform API. This has two advantages: You can get whatever information you need from the platform event type or pass that type to another library: fn Button() -> Element { rsx! { button { onclick: move |event| { let web_sys_event: web_sys::MouseEvent = event.web_event(); web_sys::console::log_1(&web_sys_event.related_target.into()); } } } } Rust Copy Dioxus can bundle split code for events apps donâ€™t use. For a hello world example, this shrinks the gzipped size ~25%! Again, this seems like a small change on the surface, but opens up dozens of new use cases and possible libraries you can build with dioxus. ðŸ’¡ The Dioxus optimization guide has tips to help you make the smallest possible bundle Cross platform launch Dioxus 0.5 introduces a new cross platform API to launch your app. This makes it easy to target multiple platforms with the same application. Instead of pulling in a separate renderer package, you can now enable a feature on the dioxus crate and call the launch function from the prelude: [dependencies] dioxus = \"0.5\" [features] default = [] desktop = [\"dioxus/desktop\"] fullstack = [\"dioxus/fullstack\"] server = [\"dioxus/axum\"] web = [\"dioxus/web\"] TOML Copy use dioxus::prelude::*; fn main() { dioxus::launch(|| rsx!{ \"hello world\" }) } Rust Copy With that single application, you can easily target: # Desktop dx serve --platform desktop # SPA web dx serve --platform web # Or a fullstack application dx serve --platform fullstack Bash Copy The CLI is now smart enough to automatically pass in the appropriate build features depending on the platform youâ€™re targeting. Asset System Beta Currently assets in dioxus (and web applications in general) can be difficult to get right. Links to your asset can easily get out of date, the link to your asset can be different between desktop and web applications, and you need to manually add assets you want to use into your bundled application. In addition to all of that, assets can be a huge performance bottleneck. Lets take a look at the dioxus mobile guide in the docsite as an example: The 0.4 mobile guide takes 7 seconds to load and transfers 9 MB of resources. The page has 6 different large image files which slows down the page loading times significantly. We could switch to a more optimized image format like avif , but manually converting every screenshot is tedious and time consuming. Lets take a look at the 0.5 mobile guide with the new asset system: The new mobile guide takes less than 1 second to load and requires only 1/3 of the resources with the exact same images! Dioxus 0.5 introduces a new asset system called manganis. Manganis integrates with the CLI to check, bundle and optimize assets in your application. The API is currently unstable so the asset system is currently published as a separate crate. In the new asset system, you can just wrap your assets in the mg! macro and they will automatically be picked up by the CLI. You can read more about the new asset system in the manganis docs. As we continue to iterate on the 0.5 release, we plan to add hot reloading to manganis assets, so you can interactively add new the features to your app like CSS, images, tailwind classes, and more without forcing a complete reload. 5x Faster Desktop Rendering Dioxus implements several optimizations to make diffing rendering fast. Templates let dioxus skip diffing on any static parts of the rsx macro. However, diffing is only one side of the story. After you create a list of changes you need to make to the DOM, you need to apply them. We developed sledgehammer for dioxus web to make applying those mutations as fast as possible. It makes manipulating the DOM from Rust almost as fast as native JavaScript. In dioxus 0.5, we apply that same technique to apply changes across the network as fast as possible. Instead of using json to communicate changes to the desktop and liveview renderers, dioxus 0.5 uses a binary protocol. For render intensive workloads, the new renderer takes only 1/5 the time to apply the changes in the browser with 1/2 the latency. Here is one of the benchmarks we developed while working on the new binary protocol. In dioxus 0.4, the renderer was constantly freezing. In dioxus 0.5, it runs smoothly: Dioxus 0.4 Dioxus 0.5 Spreading props One common pattern when creating components is providing some additional functionality to a specific element. When you wrap an element, it is often useful to provide some control over what attributes are set in the final element. Instead of manually copying over each attribute from the element, dioxus 0.5 supports extending specific elements and spreading the attributes into an element: #[derive(Props, PartialEq, Clone)] struct Props { // You can extend a specific element or global attributes #[props(extends = img)] attributes: Vec, } fn ImgPlus(props: Props) -> Element { rsx! { // You can spread those attributes into any element img { ..props.attributes } } } fn app() -> Element { rsx! { ImgPlus { // You can use any attributes you would normally use on the img element width: \"10px\", height: \"10px\", src: \"https://example.com/image.png\", } } } Rust Copy Shorthand attributes Another huge quality-of-life feature we added was the ability to use shorthand struct initialization syntax to pass attributes into elements and components. We got tired of passing class: class everywhere and decided to finally implement this long awaited feature, at the expense of some code breakage. Now, itâ€™s super simple to declare attributes from props: #[component] fn ImgPlus(class: String, id: String, src: String) -> Element { rsx! { img { class, id, src } } } Rust Copy This feature works for anything implementing IntoAttribute, meaning signals also benefit from shorthand initialization. While signals as attributes donâ€™t yet skip diffing, we plan to add this as a performance optimization throughout the 0.5 release cycle. Multi-line attribute merging Another amazing feature added this cycle was attribute merging. When working with libraries like tailwind, youâ€™ll occasionally want to make certain attributes conditional. Before, you had to format the attribute using an empty string. Now, you can simply add an extra attribute with a conditional, and the attribute will be merged using a space as a delimiter: #[component] fn Blog(enabled: bool) -> Element { rsx! { div { class: \"bg-gray-200 border rounded shadow\", class: if enabled { \"text-white\" } } } } Rust Copy This is particularly important when using libraries like tailwind where attributes need to be parsed at compile time but also dynamic at runtime. This syntax integrates with the tailwind compiler, removing the runtime overhead for libraries like tailwind-merge. Server function streaming Dioxus 0.5 supports the latest version of the server functions crate which supports streaming data. Server functions can now choose to stream data to or from the client. This makes it easier to do a whole class of tasks on the server. Creating a streaming server function is as easy as defining the output type and returning a TextStream from the server function. Streaming server functions are great for updating the client during any long running task. We built an AI text generation example here: https://github.com/ealmloff/dioxus-streaming-llm that uses Kalosm and local LLMS to serve what is essentially a clone of OpenAIâ€™s ChatGPT endpoint on commodity hardware. #[server(output = StreamingText)] pub async fn mistral(text: String) -> Result { let text_generation_stream = todo!(); Ok(TextStream::new(text_generation_stream)) } Rust Copy Side note, the AI metaframework used here - Kalosm - is maintained by the Dioxus core team member ealmloff, and his AI GUI app Floneum is built with Dioxus! Fullstack CLI platform The CLI now supports a fullstack platform with hot reloading and parallel builds for the client and sever. You can now serve your fullstack app with the dx command: dx serve # Or with an explicit platform dx serve --platform fullstack Bash Copy Liveview router support https://github.com/DioxusLabs/dioxus/pull/1505 @DonAlonzo added liveview support for the router in dioxus 0.5. The router will now work out of the box with your liveview apps! Custom Asset Handlers https://github.com/DioxusLabs/dioxus/pull/1719 @willcrichton added support for custom asset handlers to dioxus desktop. Custom asset handlers let you efficiently stream data from your rust code into the browser without going through javascript. This is great for high bandwidth communication like video streaming: Now, you can do things like work with gstreamer or webrtc and pipe data directly into the webview without needing to encode/decode frames by hand. Native File Handling This is a bit smaller of a tweak, but now we properly support file drops for desktop: Previously we just gave you the option to intercept filedrops but now itâ€™s natively integrated into the event system Error handling Error handling: You can use error boundaries and the throw trait to easily handle errors higher up in your app Dioxus provides a much easier way to handle errors: throwing them. Throwing errors combines the best parts of an error state and early return: you can easily throw an error with ?, but you keep information about the error so that you can handle it in a parent component. You can call throw on any Result type that implements Debug to turn it into an error state and then use ? to return early if you do hit an error. You can capture the error state with an ErrorBoundary component that will render the a different component if an error is thrown in any of its children. fn Parent() -> Element { rsx! { ErrorBoundary { handle_error: |error| rsx! { \"Oops, we encountered an error. Please report {error} to the developer of this application\" }, ThrowsError {} } } } fn ThrowsError() -> Element { let name: i32 = use_hook(|| \"1.234\").parse().throw()?; todo!() } Rust Copy You can even nest ErrorBoundary components to capture errors at different levels of your app. fn App() -> Element { rsx! { ErrorBoundary { handle_error: |error| rsx! { \"Hmm, something went wrong. Please report {error} to the developer\" }, Parent {} } } } fn Parent() -> Element { rsx! { ErrorBoundary { handle_error: |error| rsx! { \"The child component encountered an error: {error}\" }, ThrowsError {} } } } fn ThrowsError() -> Element { let name: i32 = use_hook(|| \"1.234\").parse().throw()?; todo!() } Rust Copy This pattern is particularly helpful whenever your code generates a non-recoverable error. You can gracefully capture these \"global\" error states without panicking or handling state for each error yourself. Hotreloading by default and â€œdevelopâ€ mode for desktop We shipped hotreloading in 0.3, added it to desktop in 0.4, and now weâ€™re finally enabling it by default in 0.5. By default, when you dx serve your app, hotreloading is enabled in development mode. Additionally, weâ€™ve drastically improved the developer experience of building desktop apps. When we canâ€™t hotreload the app and have to do a full recompile, we now preserve the state of the open windows and resume that state. This means your app wonâ€™t block your entire screen on every edit and it will maintain its size and position, leading to a more magical experience. Once youâ€™ve played with it, you can never go back - itâ€™s that good. Updates to the dioxus template With this update, our newest core team member Miles put serious work into overhauling documentation and our templates. We now have templates to create new dioxus apps for web, desktop, mobile, tui, and fullstack under one command. We also updated the default app you get when using dx new to be closer to the traditional create-react-app. The template is now seeded with assets, CSS, and some basic deploy configuration. Plus, it includes links to useful resources like dioxus-std, the VSCode Extension, docs, tutorials, and more. Dioxus-Community and Dioxus-std The Dioxus Community is something special: discord members marc and Doge have been hard at working updating important ecosystem crates for the 0.5 release. With this release, important crates like icons, charts, and the dioxus-specific standard library are ready to use right out the gate. The Dioxus Community project is a new GitHub organization that keeps important crates up-to-date even when the original maintainers step down. If you build a library for Dioxus, weâ€™ll be happy to help maintain it, keeping it at what is essentially â€œTier 2â€ support. Coming soon At a certain point we had to stop adding new features to this release. Thereâ€™s plenty of cool projects on the horizon: Stabilizing and more deeply integrating the asset system Bundle splitting the outputted .wasm directly - with lazy components Islands and resumable interactivity (serializing signals!) Server components and merging LiveView into fullstack Enhanced Devtools (potentially featuring some AI!) and testing framework Complete mobile overhaul Fullstack overhaul with websockets, SSE, progressive forms, and more Sneak Peek: Dioxus-Blitz revival using Servo Weâ€™re not going to say much about this now, but hereâ€™s a sneak peek at â€œBlitz 2.0â€â€¦ weâ€™re finally integrating servo into blitz so you can render natively with WGPU using the same CSS engine that powers Firefox. To push this effort forward, weâ€™ve brought the extremely talented Nico Burns (the wizard behind our layout library Taffy) on full time. More about this later, but hereâ€™s a little demo of google.com being rendered at 900 FPS entirely on the GPU: Admittedly the current iteration is not quite there (google.com is in fact a little wonky) but weâ€™re progressing rapidly here and are quickly approaching something quite usable. The repo is here if you want to take a look and get involved: https://github.com/jkelleyrtp/stylo-dioxus How can you contribute? Well, thatâ€™s it for the new features. We mightâ€™ve missed a few things (thereâ€™s so much new!). If you find Dioxus as exciting as we do, weâ€™d love your help to completely transform app development. Weâ€™d love contributions including: Translating docs into your native language Attempting â€œGood First Issuesâ€ Improving our documentation Contributing to the CLI Help answer questions from the discord community Thatâ€™s it! Weâ€™re super grateful for the community support and excited for the rest of 2024. Build cool things! âœŒ",
    "commentLink": "https://news.ycombinator.com/item?id=39852167",
    "commentBody": "Dioxus 0.5: Web, Desktop, Mobile Apps in Rust (dioxuslabs.com)238 points by jkelleyrtp 6 hours agohidepastfavorite84 comments terhechte 6 hours agoI build a Mastodon client with Dioxus last year [1] and it was in general a good experience, but it was also clear that lots of things were still missing (I mean, it was also at version 0.2 when I started working on it). With these 0.5 changes the Dioxus authors remove almost all the complexities that I ran into when working on Ebou. I haven't played around with it yet, but the removal of lifetimes and constant cloning will make it a much more pleasant experience. I'm looking forward to trying it out, congratulations to the team for such an awesome release! [1]: https://github.com/terhechte/Ebou reply ryukoposting 1 hour agoparent> in general a good experience, but it was also clear that lots of things were still missing I'll second that. I was working on a GUI frontend for sshfs in Dioxus about 9 months ago. My impression was that it's a really, really good GUI framework... until you run into a wall because the developers aren't finished with some feature yet. Sharing state across different contexts can also be a pain sometimes, but that's true of every GUI framework I've ever used, regardless of language or underlying technologies. Dioxus 0.5 looks like a big leap forward in this regard. My blog uses Dioxus to render a sizable portion of its HTML. In that use case, its limits aren't pushed, and it does a wonderful job. reply echelon 5 hours agoparentprevHow did you choose Dioxus? There are about a dozen Rust frameworks [1] that are trying to do the \"native, reactive UI\" you can deploy on desktop, web/wasm, mobile, etc. I'm worried about betting on the wrong horse and being stuck maintaining abandonware or being faced with a painful and pointless migration. In a similar evolutionary race, there were dozens of Rust HTTP server frameworks. Now Axum, Actix, and Rocket appear to have the lead. I'm worried I made the wrong choice as the community momentum appears to be shifting to Axum. Is there any indication Dioxus will win? It looks to have a large community, venture backing [2] (a good sign!), and more momentum than some of the others. I'd like to use one of these frameworks now, but I worry it's too early to place a bet. Are there any good indicators that now is a good time to start using it? Are Leptos and Yew the other top contenders? These are the two names I hear the most, apart from Dioxus. What would make them a better (or worse) choice? My company is heavily invested in Rust, Actix, and Bevy. We're looking at pairing Bevy with Dioxus or a similar framework to deliver native desktop and mobile clients in the future. I just want to make the right choice. Also, stupid question: is Dioxus named after the Pokemon [3]? The logo makes me think there's something to that, but there are no Pokemon references in the codebase. [1] https://github.com/flosse/rust-web-framework-comparison [2] https://www.ycombinator.com/companies/dioxus-labs [3] https://m.bulbapedia.bulbagarden.net/wiki/Deoxys_(Pok%C3%A9m... reply jkelleyrtp 4 hours agorootparentCreator here, so I'm biased... Yew has had about 10 commits in the past 6 months and the original creator has since moved on. Leptos is a good solution for web-app type stuff, but IMO there's a big usability gap. I'll let the community be the judge there, but I wrote up some differences here: https://github.com/dioxusLabs/dioxus/?tab=readme-ov-file#dio... Leptos was fortunate enough to receive a lot of attention from youtubers on its launch. The most important thing here: we raised venture money for Dioxus. We have many years of runway, are pretty lean, and exclusively focused on pouring resources into making the best GUI library for Rust (and potentially branching out to Python/JS). Getting into YC isn't easy, raising money isn't easy, and there's currently no other Rust projects with similar goals, talent, and financial backing. Biased of course. Oh, and we're committed to the bevy integration. bevy_dioxus is already updated for 0.5 and we share corporate sponsors with the bevy folks. Final point, legally, no we're not inspired by any pokemon with a similar sounding name. Even though that pokemon is awesome. reply dorian-graph 4 hours agorootparent> The most important thing here: we raised venture money for Dioxus. Important, but in a _bad_ way? What will the VC expect out of Dioxus? How will you make money? reply jkelleyrtp 4 hours agorootparentVenture doesn't necessarily mean bad. Long term the goal the goal is to dissolve the gates to Apple and Google's walled gardens, which I personally believe is a net good. As much is the idealist in me wants to do that with no venture backing, the realist in me knows we need Dioxus to be self sustaining and providing legitimate value for people to switch. Google spends 76 million dollars a year on catering alone - there's no way you can compete with Android and Flutter without huge resources. Apple and Google capture the value for their platforms via fees and lock-in. Our goal is to capture value by providing really good utilities for building and deploying apps. You can't move heaven and earth without a really big lever, and venture gives us more leverage. reply steveklabnik 4 hours agorootparentIf you don't mind me asking, what's the actual business model here? Are you going to charge for those utilities? reply jkelleyrtp 3 hours agorootparentYes, we're looking at something like a Vercel/Expo model, probably built on Fly, Cloudflare, or AWS, but designed to be self hosted. We've got a decent amount of enterprise adoption and I think there's money to be made by selling something like a self-hosted Vercel. TBD on licensing - I'd want it to be open source but we wouldn't want people reselling our deploy platform. We raised a seed to prove that people want to build with dioxus. If that hypotheses is validated, then we invest in the deploy model. If not, we have OSS grants and corporate sponsors that will keep the project alive for years even if the VC money runs out. I'm not super interested in making money at the hobbyist tier - those developers are our evangelists. Enterprise self hosting is likely harder but I think we can provide a lot of value to teams building apps in large companies. reply steveklabnik 3 hours agorootparentNeat, thank you! reply SkyMarshal 3 hours agorootparentprevSpeaking of Flutter, that and Electron seem to be the only really mature multi-platform build systems. What is Dioxus's competitive proposition vs those two? The performance and memory efficiency+safety of Rust is one, any others? reply jkelleyrtp 3 hours agorootparentI'd add React-Native / expo to your list. Flutter is written in Dart but renders to a canvas on the web making it a very, very poor choice for web apps. Especially backend/fullstack apps. Plus you can't use tailwind or whatever flavor of css library there is today. Flutter just nailed the \"get up and running\" part which we've got as well: `cargo binstall dioxus-cli`, `dx new`, `dx bundle` is literally less than 30 seconds. Hopefully `dx deploy` coming soon. Electron is... it's electron. A whole chromium instance, an IPC bridge between your frontend and the system, NodeJS, etc. If you compile for size, our desktop apps are 3mb. You can easily deploy them on an embedded/low end device. We're hoping to eat some market share in the embedded-ish land (not true embedded, but like industrial or POS). Dioxus also has mobile and desktop compatible server functions which basically no other projects have. Expo has been kinda exploring this space. One of our examples is deploying your own LLM on your own infrastructure with a dioxus mobile app UI and it fits in a single file and builds in under a minute. reply SkyMarshal 33 minutes agorootparentThanks, wasn't aware of Expo, though it seems to only do mobile+web apps but not desktop apps? > If you compile for size, our desktop apps are 3mb. I'm aware of this from familiarity with Tauri, but hearing it again still amazes me. Very cool. I have an app in mind I want to build, and really would like to have standalone versions on Android+iOS+Linux+Mac+Windows, plus a web app. But there's no way I can manage all that as a single developer. And the fact no development tool has really nailed this yet is telling how hard it is. Whoever really gets this right will save a ton of developer hours across the industry, and that's valuable. Good luck, hope you guys pull it off! PS - one feature request: a local/offline-first mode that eases development of apps that work even with poor or no internet connection. Basically I want to build something like Obsidian that is multi-platform, and does all processing and data storage locally first, then syncs with the cloud when available, with as few developer resources as possible. A tool that could enable that would be amazing. reply azemetre 4 hours agorootparentprevYeah, it's becoming more common in my group of SWEs to specifically opt to NOT use VC backed software. Everyone has stories about companies closing shop and projects failing to continue onward. Why would Dioxus be any different? If VC's cared about tearing down walled gardens of Google and Apple, why not explicitly donate the money instead? Why have strings attached at all? reply nemothekid 3 hours agorootparentFor a GUI based project, I'd actually prefer they were VC and/or corporate backed with clear governance. OSS backend libraries are easily forked, and someone is usually willing to hack on a database library, but GUIs tend to be boring to work on, and designers don't tend to have to the same gumption to work for free that developers do. reply jkelleyrtp 3 hours agorootparentprevWe have grants and corporate sponsors to keep the project alive even if the VC money runs out. This was all a side project for me at first, so I went down the \"donation\" route in the beginning. Donations are great but they're not how the system works, unfortunately. Dioxus could never compete with the two most valuable companies on earth if it wasn't a self-sustaining business. VC just lets me scale the team from 2 people to 10(?) and have some cash to iterate. We were \"profitable\" even before taking venture money. Now we're able to take on more moonshot-type projects like the blitz renderer, a deploy platform, UI fuzz tooling, and more. We're using our seed round exclusively to make dioxus as awesome as possible, so even if it doesn't work out at a venture level, there's still a really cool, polished, end-to-end app framework that you can build and ship with in Rust. reply azemetre 2 hours agorootparentThat's fair and you're welcome to chart your own path, but I like what Tauri does with their governance model: https://dracc.commonsconservancy.org/0035/ https://tauri.app/about/governance Just for me personally, I don't see the financialization of open source software as an intrinsic good thing and I reflect my technology choices to support this when applicable. reply jkelleyrtp 2 hours agorootparentWe'll probably explore that in the future but right now our team is literally just 2.5 fulltime engineers. Tauri is seeking monetization via CrabNebula, but I can see how the governance structure would secure more confidence in the OSS side. http://crabnebula.dev reply riku_iki 3 hours agorootparentprev> it's becoming more common in my group of SWEs to specifically opt to NOT use VC backed software so, what they use instead? Bugged, dead OSS dropped by creators?.. reply azemetre 2 hours agorootparentNo, normal OSS whose existence isn't tied to VC mostly. It's not like a hard/fast rule, just a heuristic. reply riku_iki 1 hour agorootparentThere are very few good quality, stable, active OSS projects which is not fed by VC/corps money. In this case (UI for rust) there is no much choice. reply fabrice_d 53 minutes agorootparentFunding by VC and funding by corps sponsors are 2 very different things. Check how linux desktop projects such as Gnome & KDE kept the lights on for >20 years without VC funding. reply wpietri 3 hours agorootparentprev\"There are more things in heaven and Earth, Horatio, / Than are dreamt of in your philosophy.\" reply riku_iki 3 hours agorootparentprev> What will the VC expect out of Dioxus? there are several ways to monetize: - consultancy - \"Pro\" extensions on top of OSS core reply yencabulator 1 hour agorootparentConsultancy is unlikely to give VC a 100x return. Enterprise extensions means the cursed land of open core and refusing to have features in the open source version, or a heavy SaaS push combined with a possible license change along the road, and these are the primary reasons to avoid VC-backed \"open source for now\". reply riku_iki 31 minutes agorootparent> Enterprise extensions means the cursed land of open core and refusing to have features in the open source version yes, there are risks in exchange of VC money. You can branch your \"Libre\" project any time, and continue building on top of infra developed using VC funds and which you get for free. But what are other choices? reply unshavedyak 3 hours agorootparentprev> Oh, and we're committed to the bevy integration. bevy_dioxus is already updated for 0.5 and we share corporate sponsors with the bevy folks. I checked out the crate and am still a bit confused. If i may, is it a goal of bevy_dioxus to allow standard bevy gamedev but with the UI portion handled by dioxus? reply jkelleyrtp 3 hours agorootparentYes, a big feature bevy is lacking is a decent editor. There's been an ongoing push to get dioxus into bevy to accelerate the editor development. Bevy's ECS model is good for games but hasn't been cleanly mapped into the traditional GUI space yet. Dioxus is composable so you can integrate it at multiple levels. The bevy folks are using our virtualdom plus state management with their own renderer. reply earthling8118 4 hours agorootparentprevAxum is certainly where it is at and where it has been for a while in terms of HTTP server frameworks. I'd say actix is in second place for sure, but it is wholly viable regardless. Rocket is no longer in the running as far as I'm concerned, and it hasn't been for quite some time. Dioxus is certainly taking the head spot in front end. I still have more concern about the venture backing than I have confidence about it, but for better or for worse, it is certainly the best attempt at this so far. I enjoyed yew as a react-style framework, but its development is slow. Dioxus has made a lot of progress, and in my experience, it is currently the best experience that can be had. It's hard to say if now is the correct time, but I'd be watching it closely if I were you. There's been major work to improve the framework with many of the interfaces changing. Now might be a good time because of the progress made here, but I wouldn't be surprised if there were more changes in store. Although I imagine that you're used to that from bevy anyway. reply cchance 5 hours agorootparentprevI'd say leptos and dioxus are the bigger ones now i feel like many people moved from ywe to those 2 reply sanity 2 hours agoprevI just picked Dioxus to build a decentralized homepage for Freenet[1], it will be the first decentralized website people see when they get Freenet set up. It reminds me a bit of my Kotlin web framework called Kweb[2] that I've been working on on-and-off for a few years now, particularly the way it handles state and the DSL that maps from code to HTML. So far I like what I see. [1] https://freenet.org/ [2] https://kweb.io/ reply jkelleyrtp 2 hours agoparentThat's awesome!! I must've ran into kweb when designing the DSL at first - they're so similar. I'm secretly a huge kotlin fan and love the kotlin DSLs and concurrency models. reply airstrike 50 minutes agoprevI kinda wish instead of RSX we got something closer to SwiftUI than to React/JSX I feel like despite the name and all the good it did for JS and the web, React is not exactly how I would envision \"reactive UI\" code to look like in 2024 if we have the choice of designing a language (or DSL) from a blank state Which is not to say SwiftUI is perfect, but whatever code I write with it feels much more neatly organized / compartmentalized than similar code using React IMHO the only real advantage of using JSX for cross-platform GUIs is... to reuse existing libraries that were built for the web, which means something like RSX has very little \"transferable value\" other than letting the developer transfer their conceptual knowledge of JSX to RSX. I'd argue that's a worse tradeoff than having the developer learn some new paradigm that is (again IMHO) objectively superior to the React/JSX one TL;DR \"SwiftUI but cross-platform\" is the project I wish existed but doesn't. I'm aware of @Tokamak/TokamakUI but that's still very much incomplete and activity seems to have waned reply prabir 7 minutes agoparentThere is https://ribir.org/. Currently it only supports native desktop apps on Linux/mac/windows but they have plans for WASM/web/mobile. reply airstrike 2 minutes agorootparentThanks for sharing that. It looks very interesting and I had not come across it even after lots of googling. It's still in 0.2 but I will definitely keep track of its development, so thank you reply skybrian 5 hours agoprevIâ€™m not a Rust programmer, but Iâ€™m curious, and Iâ€™m wondering if someone could explain how their generational-box crate works? [1] I understand that itâ€™s some kind of arena allocation, but I donâ€™t understand how they support copying without copying, or how this is safe: > Internally, generational-box creates an arena of generational RefCell's that are recycled when the owner is dropped. You can think of the cells as something like &'static RefCell> with a generational check to make recycling a cell easier to debug. Then GenerationalBox's are Copy because the &'static pointer is Copy Like okay, you can create a pointer to static data, but what if itâ€™s something that doesnâ€™t have a static lifetime? [1] https://crates.io/crates/generational-box reply Evan-Almloff 4 hours agoparentWe are copying the reference to the data, not the data itself. The reference to the data lasts for the lifetime of the program. Generational box lets you insert data that last for shorter than the lifetime of the program (as long as that data contains no references). Once you drop the data you inserted, we reuse the box for other allocations. It uses a very similar approach to a generational arena but with boxes instead of a centralized arena (to avoid locking issues). If you try to access the Copy reference to the data after it has been dropped, it will fail with a nice error message reply skybrian 4 hours agorootparentThanks. Iâ€™m wondering if this allows for non-static data at all? Maybe it has to be either static or copyable? reply Evan-Almloff 3 hours agorootparentAll data you insert into a generational box needs to be allowed to last for the 'static lifetime (have no internal temporary pointers). You cannot insert something like &'a str into a generational box reply steveklabnik 5 hours agoparentprevI am not familiar with this crate, but I am with Rust, hereâ€™s my take: Copy is a specific thing in Rust, it means that if a type implements the Copy trait, it can be copied via a memcpy, that is, itâ€™s like a â€œshallowâ€ copy as opposed to a â€œdeepâ€ copy. So theyâ€™re not â€œcopying without copyingâ€, theyâ€™re letting you treat a non-Copy type as a Copy type, in my understanding. > what if itâ€™s something that doesnâ€™t have a static lifetime? The read me says it requires static content so the answer is â€œyou canâ€™t do that.â€ reply skybrian 2 hours agorootparentCould you use position-independent internal references (relative pointers) to make data copyable? Does Rust have good support for that? reply steveklabnik 42 minutes agorootparentRust does not have native support for relative pointers, so you'd have to hack that together with unsafe. It's not generally done. reply m0meni 5 hours agoprevBeen following this for a while and super excited to see it out! I love how Dioxus captures a lot of what made React successful, but also while innovating on top of it and shipping at a super fast rate. Congrats to the team. Excited to try out the signals in this release. reply KolmogorovComp 5 hours agoprevI've been following dioxus with interest despite not having a chance to use it yet. However I'm a bit perplexed with the solution to remove lifetimes [0]. Isn't it a poor's-man GC? What was the performance impact? [0]: https://crates.io/crates/generational-box Side-note: `[generational-box](https://crates.io/crates/generational-box)` link is broken reply jkelleyrtp 5 hours agoparentIt is poor man's GC, but the memory semantics are exactly the same as the previous version. Since `use_hook` owns a value for the lifetime of the component, that value is dropped when the component drops. All signals still `use_hook` so their lifetimes are the same. No performance impact whatsoever since we generally discourage calling `GenerationalBox::new()` outside of use_hook. Now if you spammed `GenerationalBox::new()` in a loop or something, yeah, your garbage will exist until the component drops. But most of the time folks will just push/pop from a Map or a Vec and regular memory semantics apply. reply ramesh31 5 hours agoparentprev>However I'm a bit perplexed with the solution to remove lifetimes [0]. Isn't it a poor's-man GC? This is essentially just ARC: https://en.wikipedia.org/wiki/Automatic_Reference_Counting reply sirwhinesalot 1 hour agorootparentRust's Arc is like ARC, this is more like a generational pool of Box. reply osener 1 hour agoprevHow does Dioxus fare as a native GUI lib? Last time I checked the focus was on web targets and both the built in wgpu renderer and skia backend were not supported as much. reply airstrike 59 minutes agoparentYeah, that was my impression too which is why I passed on it and went with Tauri instead. Which is not to say that Tauri perfectly map to the boxes I wanted checked, but beggars can't be choosers reply swsieber 5 hours agoprev> Thereâ€™s still a tiny bit of unsafe floating around various dependencies that we plan to remove throughout the 0.5 release cycle I'd love to see what these usages are, and what motivates this. I understand that sometimes people reach for unsafe too eagerly. But the std is full of unsafe and drawing the line there sometimes seems like a line in the sand. reply jkelleyrtp 4 hours agoparentIt's mostly just needed to interact with FFI and declare some types as Send/Sync. We use it in 3 places: - fixing some FFI on iOS - enabling function-call syntax for signals (took this implementation from dtolnay) - implementing Send/Sync for an ID that uses a pointer as a hash (which honestly could be removed in lieu of a usize, now that I'm looking at it) reply swsieber 3 hours agorootparentOh, OK. That sounds more like stuff you're directly responsible for, and it looks sensible. reply n42 4 hours agoparentprevI agree, people can be a little too afraid of unsafe. but I don't think it's necessarily ill-advised for a crate author to make a goal of removing unsafe from their crate. crate authors that try to remove all unsafe often do it to relieve the burden of trust from the user. _this_, in my opinion, is the power of the `unsafe` keyword (which probably should have been split into `trust_me` blocks and `check_yourself` functions). it constrains the conversations about memory safety into very tightly defined and auditable locations in the code, AND it creates new, manageable conversations about trust. reply ashia 2 hours agoprevCongrats on the launch! Really excited to see the move to signals + curious to see how Blitz 2.0 goes. reply dasloop 5 hours agoprev\"Here at Dioxus Labs, we have an unofficial rule: only one rewrite per year.\" If you have to rewrite your code once a year, maybe it helps to plan ahead before coding. But, if you can rewrite your code once a year, you might not have too much code to worry about. reply jkelleyrtp 5 hours agoparentAgreed, but we've been doing a lot of R&D discovering new ways of doing things. Dioxus was the first Rust framework to do template-based hotreloading and we couldn't have predicted that was even possible 2 years ago. The Copy-state stuff also seemed impossible a year ago, so no way to plan ahead. Now, I think things have matured enough that there's hopefully not a major major rewrite for a long time. reply 63stack 5 hours agorootparentDid something happen in rust that made the copy state thing work? Or was it just \"huh nobody thought of this before\"? reply jkelleyrtp 4 hours agorootparentSomeone else figured it out :-) I think we had a prototype of it a long time ago but couldn't figure out how to implement drop. Leptos came out but just leaked the runtime in its initial rev. We figured we could safely recycle the runtimes and voila, problem solved. reply palmfacehn 5 hours agoprevHow does this render native apps? Is it still within a browser instance of some kind? reply jkelleyrtp 5 hours agoparentYou can choose between using the system's webview as your renderer or an experimental WGPU-based engine that pulls in stylo (the piece of servo shared with Firefox). We're hoping to move folks to the WGPU renderer in the long term, but it's still pretty raw and many companies using Dioxus are pragmatic enough to know that a webview is a good enough solution for like 90% of apps. reply littlestymaar 5 hours agorootparentI had a mixed feeling about your idea of writing your own HTML renderer (because making it so it is actually compatible with how browser engine are rendering their stuff is actually very hard, and even browser vendors don't actually agree on how everything should render) but seeing that you are leveraging work from servo, and even hired a former mozillian in that effort makes me much more confident in your ability to actually deliver. I wish you good luck! reply rtp4me 6 hours agoprevCongrats to the team! I know it has been a long process, but kudos for sticking with it! reply jkelleyrtp 5 hours agoparentIt was 3 months of work and you probably saw our alphas kicking around for a while. We had been thinking about this rewrite for like 6 months, but put it off for a while. Glad we dove into it since the finished product is so much better. reply J_Shelby_J 5 hours agoprevI'm really excited about this project because it means you can build a single app and deploy it easily anywhere. And in a single language. reply orthecreedence 1 hour agoparentAnd a good language. Flutter/Dart promises this, but I really, really hate Dart. reply skybrian 50 minutes agorootparentSwitching from Dart to Rust doesn't seem like a usability improvement, though? It's good for other things like performance and safe concurrency, but a language that has GC seems easier for web development. reply orthecreedence 25 minutes agorootparentI've tackled UI from both the web end and the rust end, and I honestly can't say which I prefer. Javascript is definitely quicker and easier, I'll give you that, but I hold my nose when writing in it and people have been building interfaces in compiled/typed languages for decades without issue. I'd say it really depends on developer preference. I've grown to appreciate working with typed interfaces, and rust's compiler eliminates so many pains of working in the low-level space that I think it hits a really good mix of usability and performance. Do UIs really need the performance that the nerds on here gripe about every time something like Electron comes up? Probably not, so maybe HTML+Javascript (or WASM) is the winning combo. I don't really care either way, as long as I don't have to learn 5 different languages, platforms, UI frameworks, etc to release an app for desktop and phones as a single developer. And I already know Rust, so another option in that regard is welcome. reply mattdmrs 46 minutes agorootparentprevHonestly curious: what makes you hate it so much? reply orthecreedence 31 minutes agorootparentI found it hit a strange position between trying to be friendly and trying to be powerful. Things felt very inconsistent. After learning a few patterns in the language, other things I would expect to follow the same patterns went off in their own direction. I wish I could conjure up more specific examples but that's about all I remember from it. It felt like a language that was built for the singular purpose of supporting Flutter (which I actually did enjoy learning) instead of something that needed to exist in its own right. I wish they'd just picked something already baked. reply zengid 5 hours agoprevHuge release, congrats! I'm most interested in Dioxus-Blitz. Congrats to Nico for joining the team (I think?). reply jkelleyrtp 3 hours agoparentYeah Nico is awesome. Between Evan and Nico, I'm sure I'm the worst programmer on the team! reply zengid 1 hour agorootparentYou're winning because the goal is always to be in a room where you aren't the smartest! reply yunohn 6 hours agoprevHow does this compare to Tauri? reply jkelleyrtp 5 hours agoparentWrote about that here in our readme: https://github.com/dioxusLabs/dioxus/?tab=readme-ov-file#dio... Tauri puts your frontend in the webview and you need to communicate with native Rust functions through an IPC boundary (like electron). In Dioxus your Rust code lives on the native side, so you don't need IPC to do things like read from the file system, websockets, etc. Tauri also forces your frontend to compile to WASM, and a lot of interesting rust crates don't compile to wasm. It's a little hard to express how much simpler it is to build when you don't have an IPC boundary. Dioxus' tooling is also dedicated to just Rust, so you can go from zero to bundled `.app` in less than a minute (12 seconds fresh build, 20 seconds fresh bundle). That being said we're huge fans of Tauri and the flexibility it gives you (frontend in whatever web-compatible UI you want) and you can even use Dioxus in your Tauri apps! reply 01HNNWZ0MV43FF 5 hours agorootparentI see what you mean, but to a reader unfamiliar with tauri this makes it sound really bad. Here's how I use tauri: Almost everything is native rust in the \"backend\" process, which is where main is. I don't need any ffi calls to write files, open ports, etc, it's a normal rust program that happens to have a web view. So I've never had a problem with compiling to wasm, the GUI is TypeScript and the business logic is aot rust The ipc boundary is annoying. It'll be faster in tauri 2, but in 1 it uses json or something internally, so you couldn't e.g. write a video player that uses a custom rust codec. Getting uncompressed video frames through ipc would kill perf I'll take a look how dioxus solves this reply jkelleyrtp 5 hours agorootparentOne of this release's features is getting byte streams into the webview using custom protocols. It's not as ideal as say, sharing a GPU texture with the webview, but powerful enough to do video streaming and data viz. reply dceddia 2 hours agorootparentprev> Tauri also forces your frontend to compile to WASM Iâ€™ve been using Tauri (1.x) for a couple years shipping a video editor and I donâ€™t think this is true? I went searching to verify and I couldnâ€™t find anything saying it complies to WASM (or at least not that it requires compiling to WASM). Can you point me to where you saw this? reply jkelleyrtp 2 hours agorootparentIf you want to use a Rust frontend framework with Tauri you need to compile to wasm. You typically use svelte/vue/react etc as the frontend, or I guess you could attempt some sort of MPA approach with SSR. Here's a guide for using Yew with Tauri. Notice how you need to install wasm-bindgen and wasm-pack. https://dev.to/stevepryde/create-a-desktop-app-in-rust-using... reply dceddia 1 hour agorootparentOhh sorry, I misunderstood what you were saying there. I'm just using Svelte in TypeScript and running it in the browser so it doesn't need to do the WASM step. reply 01HNNWZ0MV43FF 2 hours agorootparentprevWhoa. Video editor is exactly what I assumed Tauri couldn't reasonably do. (See sibling comment - I also haven't used wasm since my UI is all TS) How'd you get that working? reply dceddia 1 hour agorootparentI initially ran into that issue too (sending frames over IPC was not gonna work!) so I create a native OS-specific overlay and draw on it with wgpu. The IPC layer has been a bit annoying and I'm looking forward to Tauri 2 where that'll get faster. I've worked around it for some stuff in the meantime by using a custom protocol and serializing stuff to binary. reply hotfixguru 4 hours agoprevYesterday there was another really interesting rust library, egui, on the front page of HN. I can tell that this is more like react, but how do they compare in other regards? reply jkelleyrtp 4 hours agoparentWrote about that here: https://github.com/DioxusLabs/dioxus?tab=readme-ov-file#diox... You're probably not going to be building an email client or the next instagram in egui, but it is good for stuff where you're fine with re-rendering every entire frame (data viz, graphics stuff). reply politician 4 hours agoprev [â€“] Dioxus is framework that compiles Rust to WebAssembly in order to build a webapp that uses the native OS webbrowser for rendering and interaction. reply Evan-Almloff 4 hours agoparent [â€“] Dioxus web compiles to WASM, but we compile to native code for desktop rendering to make it easier to interact with native APIs like the filesystem. We just use the web browser for rendering reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Dioxus 0.5, launched on March 28, 2024, brought significant enhancements, including a signal rewrite, omitting lifetimes, CSS hot reloading, and other features to streamline app development.",
      "The update enhanced component development, memory management, performance, and introduced new functionalities like CSS hot reloading and a cross-platform event system.",
      "Future Dioxus updates will focus on stabilizing the asset system, introducing server components, and integrating LiveView, while the team invites community contributions to further enhance the platform."
    ],
    "commentSummary": [
      "Dioxus 0.5 is a Rust framework for various applications, competing with Leptos and Yew, often combined with Bevy for desktop and mobile projects.",
      "Dioxus Labs works on enhancing user experience with potential self-hosted versions and licensing choices, concentrating on enterprise usage and upcoming distinctive features.",
      "Discussions entail open-source financialization, VC funding hurdles, and comparisons with frameworks such as Tauri, addressing concerns about unsafe Rust code, rendering methods, and application development disparities between Dioxus and Tauri."
    ],
    "points": 238,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1711636883
  },
  {
    "id": 39852118,
    "title": "AI Chatbots' Knowledge Retrieval Unveiled by LLMs",
    "originLink": "https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325",
    "originBody": "Researchers demonstrate a technique that can be used to probe a model to see what it knows about new subjects. Adam ZeweMIT News Publication Date: March 25, 2024 Press Inquiries Caption: Researchers from MIT and elsewhere found that complex large language machine-learning models use a simple mechanism to retrieve stored knowledge when they respond to a user prompt. The researchers can leverage these simple mechanisms to see what the model knows about different subjects, and also possibly correct false information that it has stored. Credits: Image: iStock Large language models, such as those that power popular artificial intelligence chatbots like ChatGPT, are incredibly complex. Even though these models are being used as tools in many areas, such as customer support, code generation, and language translation, scientists still donâ€™t fully grasp how they work. In an effort to better understand what is going on under the hood, researchers at MIT and elsewhere studied the mechanisms at work when these enormous machine-learning models retrieve stored knowledge. They found a surprising result: Large language models (LLMs) often use a very simple linear function to recover and decode stored facts. Moreover, the model uses the same decoding function for similar types of facts. Linear functions, equations with only two variables and no exponents, capture the straightforward, straight-line relationship between two variables. The researchers showed that, by identifying linear functions for different facts, they can probe the model to see what it knows about new subjects, and where within the model that knowledge is stored. Using a technique they developed to estimate these simple functions, the researchers found that even when a model answers a prompt incorrectly, it has often stored the correct information. In the future, scientists could use such an approach to find and correct falsehoods inside the model, which could reduce a modelâ€™s tendency to sometimes give incorrect or nonsensical answers. â€œEven though these models are really complicated, nonlinear functions that are trained on lots of data and are very hard to understand, there are sometimes really simple mechanisms working inside them. This is one instance of that,â€ says Evan Hernandez, an electrical engineering and computer science (EECS) graduate student and co-lead author of a paper detailing these findings. Hernandez wrote the paper with co-lead author Arnab Sharma, a computer science graduate student at Northeastern University; his advisor, Jacob Andreas, an associate professor in EECS and a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL); senior author David Bau, an assistant professor of computer science at Northeastern; and others at MIT, Harvard University, and the Israeli Institute of Technology. The research will be presented at the International Conference on Learning Representations. Finding facts Most large language models, also called transformer models, are neural networks. Loosely based on the human brain, neural networks contain billions of interconnected nodes, or neurons, that are grouped into many layers, and which encode and process data. Much of the knowledge stored in a transformer can be represented as relations that connect subjects and objects. For instance, â€œMiles Davis plays the trumpetâ€ is a relation that connects the subject, Miles Davis, to the object, trumpet. As a transformer gains more knowledge, it stores additional facts about a certain subject across multiple layers. If a user asks about that subject, the model must decode the most relevant fact to respond to the query. If someone prompts a transformer by saying â€œMiles Davis plays the. . .â€ the model should respond with â€œtrumpetâ€ and not â€œIllinoisâ€ (the state where Miles Davis was born). â€œSomewhere in the networkâ€™s computation, there has to be a mechanism that goes and looks for the fact that Miles Davis plays the trumpet, and then pulls that information out and helps generate the next word. We wanted to understand what that mechanism was,â€ Hernandez says. The researchers set up a series of experiments to probe LLMs, and found that, even though they are extremely complex, the models decode relational information using a simple linear function. Each function is specific to the type of fact being retrieved. For example, the transformer would use one decoding function any time it wants to output the instrument a person plays and a different function each time it wants to output the state where a person was born. The researchers developed a method to estimate these simple functions, and then computed functions for 47 different relations, such as â€œcapital city of a countryâ€ and â€œlead singer of a band.â€ While there could be an infinite number of possible relations, the researchers chose to study this specific subset because they are representative of the kinds of facts that can be written in this way. They tested each function by changing the subject to see if it could recover the correct object information. For instance, the function for â€œcapital city of a countryâ€ should retrieve Oslo if the subject is Norway and London if the subject is England. Functions retrieved the correct information more than 60 percent of the time, showing that some information in a transformer is encoded and retrieved in this way. â€œBut not everything is linearly encoded. For some facts, even though the model knows them and will predict text that is consistent with these facts, we canâ€™t find linear functions for them. This suggests that the model is doing something more intricate to store that information,â€ he says. Visualizing a modelâ€™s knowledge They also used the functions to determine what a model believes is true about different subjects. In one experiment, they started with the prompt â€œBill Bradley was aâ€ and used the decoding functions for â€œplays sportsâ€ and â€œattended universityâ€ to see if the model knows that Sen. Bradley was a basketball player who attended Princeton. â€œWe can show that, even though the model may choose to focus on different information when it produces text, it does encode all that information,â€ Hernandez says. They used this probing technique to produce what they call an â€œattribute lens,â€ a grid that visualizes where specific information about a particular relation is stored within the transformerâ€™s many layers. Attribute lenses can be generated automatically, providing a streamlined method to help researchers understand more about a model. This visualization tool could enable scientists and engineers to correct stored knowledge and help prevent an AI chatbot from giving false information. In the future, Hernandez and his collaborators want to better understand what happens in cases where facts are not stored linearly. They would also like to run experiments with larger models, as well as study the precision of linear decoding functions. â€œThis is an exciting work that reveals a missing piece in our understanding of how large language models recall factual knowledge during inference. Previous work showed that LLMs build information-rich representations of given subjects, from which specific attributes are being extracted during inference. This work shows that the complex nonlinear computation of LLMs for attribute extraction can be well-approximated with a simple linear function,â€ says Mor Geva Pipek, an assistant professor in the School of Computer Science at Tel Aviv University, who was not involved with this work. This research was supported, in part, by Open Philanthropy, the Israeli Science Foundation, and an Azrieli Foundation Early Career Faculty Fellowship. Share this news article on: X Facebook LinkedIn Reddit Print Paper Paper: â€œLinearity of Relation Decoding in Transformer Language Modelsâ€ Related Links Evan Hernandez Jacob Andreas Language and Intelligence Group Computer Science and Artificial Intelligence Laboratory Department of Electrical Engineering and Computer Science School of Engineering MIT Schwarzman College of Computing Related Topics Research Computer science and technology Artificial intelligence Machine learning Algorithms Human-computer interaction Computer Science and Artificial Intelligence Laboratory (CSAIL) Electrical Engineering & Computer Science (eecs) School of Engineering MIT Schwarzman College of Computing Related Articles Demystifying machine-learning systems AI agents help explain other AI systems 3 Questions: Jacob Andreas on large language models Solving a machine-learning mystery Previous item Next item",
    "commentLink": "https://news.ycombinator.com/item?id=39852118",
    "commentBody": "LLMs use a surprisingly simple mechanism to retrieve some stored knowledge (news.mit.edu)238 points by CharlesW 6 hours agohidepastfavorite89 comments mikewarot 1 hour agoI wonder if this relation still holds with newer models that have have even more compute thrown at them? My intuition is that the structure inherent to language makes Word2Vec possible. Then training on terabytes of human text encoded with Word2Vec + Positional Encoding makes it possible to then have the ability to predict the next encoding at superhuman levels of cognition (while training!). It's my sense that the bag of words input/output combined with limited context windows (to make Positional Encoding work) is a huge impedance mismatch. Thus I think that given the orders of magnitude more compute thrown at GPT-4 et al, it's entirely possible new forms of representation evolved and remain to be discovered by humans probing through all the weights. I also think that MemGPT could, eventually, become an AGI because of the unlimited long term memory. More likely, though, I think it would be like the protagonist in Memento[1]. [1] https://en.wikipedia.org/wiki/Memento_(film) reply autokad 15 minutes agoparentsorry if I misread your comment, but you seem to be indicating that LLMs such as chat gpt (which use gpt 3+) are bag of words models? they are sequence models. reply retrofrost 3 hours agoprevThis is amazing work, but to me it highlights some of the biggest problems in the current AI zeitgeist, we are not really trying to work on any neuron or ruleset that isnt much different from the perceptron thats just a sumnation function. Is it really that suprising that we just see this same structure repeated in the models. Just because feedforward topologies with single neuron steps are the easiest to train and run on graphics cards does that really make them the actual best at accomplishing tasks? We have all sorts of unique training methods and encoding schemes that don't ever get used because the big libraries don't support them. Until, we start seeing real varation in the fundamental rulesets of neuralnets we are always just going to be fighting against the fact these are just perceptrons with extra steps. reply visarga 3 hours agoparent> Just because feedforward topologies with single neuron steps are the easiest to train and run on graphics cards does that really make them the actual best at accomplishing tasks? You are ignoring a mountain of papers trying all conceivable approaches to create models. It is evolution by selection, in the end transformers won. reply foobiekr 1 hour agorootparent\"won\" They barely work for a lot of cases (i.e., anything where accuracy matters, despite the bubble's wishful thinking). It's likely that something will sunset them in the next few years. reply victorbjorklund 1 hour agorootparentThat is how evolution works. Something wins until something else comes along and win. And so on forever. reply nicklecompte 2 hours agorootparentprevHis point is that \"evolution by selection\" also includes that transformers are easy to implement with modern linear algebra libraries and cheap to scale on current silicon, both of which are engineering details with no direct relationship to their innate efficacy at learning (though indirectly it means you scale up the training data for more inefficient learning). reply wanderingbort 1 hour agorootparentI think it is correct to include practical implementation costs in the selection. Theoretical efficacy doesnâ€™t guarantee real world efficacy. I accept that this is self reinforcing but I favor real gains today over potentially larger gains in a potentially achievable future. I also think we are learning practical lessons on the periphery of any application of AI that will apply if a mold-breaking solution becomes compelling. reply retrofrost 2 hours agorootparentprevJust because papers are getting published doesn't mean its actually gaining any traction. I mean we have known that time series of signals recieves plays a huge role in how bio neurons functionally operate and yet we have nearly no examples of spiking networks being pushed beyond basic academic exploration. We have known glial cells play a critical role in biological neural and yet you can probably count the number of papers that examine using an abstraction of that activity in neural net, on both your hands and toes. Neuroevolution using genetic algorithms has been basically looking for a big break since NEAT. Its the height of hubris to say that we have peaked with transformers when the entire field is based on not getting trapped in local maxima's. Sorry to be snippy, but there is so much uncovered ground its not even funny. reply gwervc 2 hours agorootparent\"We\" are not forbidding you to open a computer, start experimenting and publishing some new method. If you're so convinced that \"we\" are stuck in a local maxima, you can do some of the work you are advocating instead of asking other to do it for you. reply Kerb_ 2 hours agorootparentYou can think chemotherapy is a local maxima for cancer treatment and hope medical research seeks out other options without having the resources to do it yourself. Not all of us have access to the tools and resources to start experimenting as casually as we wish we could. reply erisinger 1 hour agorootparentNot a single one of you bigbrains used the word \"maxima\" correctly and it's driving me crazy. reply vlovich123 1 hour agorootparentAs I understand it a local maxima means youâ€™re at a local peak but there may be higher maximums elsewhere. As I read it, transformers are a local maximum in the sense of outperforming all other ML techniques as the AI technique that gets the closest to human intelligence. Can you help my little brain understand the problem by elaborating? Also you may want to chill with the personal attacks. reply erisinger 1 hour agorootparentNot a personal attack. These posters are smarter than I am, just ribbing them about misusing the terminology. \"Maxima\" is plural, \"maximum\" is singular. So you would say \"a local maximum,\" or \"several local maxima.\" Not \"a local maxima\" or, the one that really got me, \"getting trapped in local maxima's.\" As for the rest of it, carry on. Good discussion. reply FeepingCreature 1 hour agorootparentA local maxima, that is, /usr/bin/wxmaxima... reply erisinger 1 hour agorootparentTouchÃ©... reply mikewarot 1 hour agorootparentprevMNIST and other small and easy to train against datasets are widely available. You can try out anything you like even with a cheap laptop these days thanks to a few decades of Moore's law. It is definitely NOT out of your reach to try any ideas you have. Kaggle and other sites exist to make it easy. Good luck! 8) reply retrofrost 58 minutes agorootparentMy pet project has been trying to use elixir with NEAT or HyperNEAT to try and make a spiking network, then when thats working decently drop some glial interactions I saw in a paper. It would be kinda bad at purely functional stuff, but idk seems fun. The biggest problems are time and having to do a lot of both the evolutionary stuff and the network stuff. But yeah the ubiquity of free datasets does make it easy to train. reply haltIncomplete 1 hour agorootparentprevAll weâ€™re doing is engineering new data compression and retrieval techniques: https://arxiv.org/abs/2309.10668 Are we sure thereâ€™s anything â€œnet newâ€ to find within the same old x86 machines, within the same old axiomatic systems of the past? Math is a few operations applied to carving up stuff and we believe we can do that infinitely in theory. So â€œall math that abides our axiomatic underpinningsâ€ is valid regardless if we â€œprove itâ€ or not. Physical space we can exist in, a middle ground of reality we evolved just so to exist in, seems to be finite; I canâ€™t just up and move to Titan or Mars. So our computers are coupled to the same constraints of observation and understanding as us. What about daily life will be upended reconfirming decades old experiment? How is this not living in sunk cost fallacy? When all you have is a hammerâ€¦ Iâ€™m reminded of Einsteinâ€™s quote about insanity. reply leoc 1 hour agorootparentprev(The singulars are â€˜maximumâ€™ and â€˜minimumâ€™, â€˜maximaâ€™ and â€˜minimaâ€™ are the plurals.) reply typon 2 hours agorootparentprevDo you really think that transformers came to us from God? They're built on the corpses of millions of models that never went anywhere. I spent an entire year trying to scale up a stupid RNN back in 2014. Never went anywhere, because it didn't work. I am sure we are stuck in a local minima now - but it's able to solve problems that were previously impossible. So we will use it until we are impossibly stuck again. Currently, however, we have barely begun to scratch the surface of what's possible with these models. reply dartos 3 hours agorootparentprevI mean RWKV seems promising and isnâ€™t a transformer model. Transformers have first mover advantage. They were the first models that scaled to large parameter counts. That doesnâ€™t mean theyâ€™re the best or that theyâ€™ve won, just that they were the first to get big (literally and metaphorically) reply tkellogg 3 hours agorootparentYeah, I'd argue that transformers created such capital saturation that there's a ton of opportunity for alternative approaches to emerge. reply dartos 1 hour agorootparentSpeak of the devil. Jamba just hit the front page. reply posix86 40 minutes agoparentprevI don't understand enough about the subject to say, but to me it seemed like yes, other models have better metrics with equal model size i.t.o. number of neurons or asymptotic runtime, but the most important metric will always be accuracy/precision/etc for money spent... or in other words, if GPT requires 10x number of neurons to reach the same performance, but buying compute & memory for these neuros is cheaper, then GPT is a better means to an end. reply ikkiew 1 hour agoparentprev> the perceptron thats just a sumnation[sic] function What would you suggest? My understanding of part of the whole NP-Complete thing is that any algorithm in the complexity class can be reduced to, among other things, a 'summation function'. reply ldjkfkdsjnv 2 hours agoparentprevCannot understand people claiming we are in a local maxima, when we literally had an ai scientific breakthrough only in the last two years. reply xanderlewis 1 hour agorootparentWhich breakthrough in the last two years are you referring to? reply ldjkfkdsjnv 20 minutes agorootparentthe LLM scaling law reply blueboo 1 hour agoparentprevThe bitter lesson, my dude. http://www.incompleteideas.net/IncIdeas/BitterLesson.html If you find a simpler, trainable structure you might be onto something Attempts to get fancy tried and died reply derefr 5 hours agoprevHelp me understand: when they say that the facts are stored as a linear functionâ€¦ are they saying that the LLM has a sort of N-dimensional â€œfact spaceâ€ encoded into the model in some manner, where facts are embedded into the space as (points / hyperspheres / Voronoi manifolds / etc); and where recalling a fact is â€” at least in an abstract sense â€” the NN computing / remembering a key to use, and then doing a key-value lookup in this space? If so: how do you embed a KV-store into an edge-propagated graphical model? Are there even any well-known techniques for doing that â€œby handâ€ right now? (Also, fun tangent: isn't the \"memory palace\" memory technique, an example of human brains embedding facts into a linear function for easier retrieval?) reply jacobn 5 hours agoparentThe fundamental operation done by the transformer, softmax(Q.K^T).V, is essentially a KV-store lookup. The Query is dotted with the Key, then you take the softmax to pick mostly one winning Key (the Key closest to the Query basically), and then use the corresponding Value. That is really, really close to a KV lookup, except it's a little soft (i.e. can hit multiple Keys), and it can be optimized using gradient descent style methods to find the suitable QKV mappings. reply naveen99 4 hours agorootparentNot sure there is any real lookup happening. Q,K are the same and sometimes even v is the sameâ€¦ reply toxik 2 hours agorootparentQ, K, V are not the same. In self-attention, they are all computed by separate linear transformation of the same input (ie the previous layerâ€™s output). In cross-attention even this is not true, then K and V are computed by linear transformation of whatever is cross-attended, and Q is computed by linear transformation of the input as before. reply ewild 2 hours agorootparentyeah a common misconception people think because the input is the same they forget that their is a pre attention linear transofrmation for q k and v (using the decoder only version obv v is diff with encoder decoder bert style) reply bionhoward 5 hours agoparentprev[Layer] Normalization constrains huge vectors representing tokens (input fragments) to positions on a unit ball (I think), and the attention mechanism operates by rotating the unconstrained ones based on the sum of their angles relative to all the others. I only skimmed the paper but believe the point here is that there are relatively simple functions hiding in or recoverable from the bigger network which specifically address certain categories of relationships between concepts. Since it would, in theory, be possible to optimize such functions more directly if they are possible to isolate, could this enable advances in the way such models are trained? Absolutely. After all, one of the best criticisms of â€œmodernâ€ AI is the notion weâ€™re just mixing around a soup of linear algebra. Allowing some sense of modularity (reductionism) could make them less of a black box and more of a component driven approach (in the lagging concept space and not just the leading layer space) reply thfuran 5 hours agoparentprev>isn't the \"memory palace\" memory technique, an example of human brains embedding facts into a linear function for easier retrieval? I'm not sure I see how that's a linear function. reply mike_hearn 5 hours agoprevThis is really cool. My mind goes immediately to what sort of functions are being used to encode programming knowledge, and if they are also simple linear functions whether the standard library or other libraries can be directly uploaded into an LLMs brain as it evolves, without needing to go through a costly training or performance-destroying fine-tune. That's still a sci-fi ability today but it seems to be getting closer. reply Animats 4 hours agoparentThat's a good point. It may be possible to directly upload predicate-type info into a LLM. This could be especially useful if you need to encode tabular data. Somewhere, someone probably read this and is thinking about how to export Excel or databases to an LLM. It's encouraging to see people looking inside the black box successfully. The other big result in this area was that paper which found a representation of a game board inside a LLM after the LLM had trained to play a game. Any other good results in that area? The authors point out that LLMs are doing more than encoding predicate-type info. That's just part of what they are doing. reply wongarsu 3 hours agorootparentThe opposite is also exciting: build a loss function that punishes models for storing knowledge. One of the issues of current models is that they seem to favor lookup over reasoning. If we can punish models (during training) for remembering that might cause them to become better at inference and logic instead. reply kossTKR 52 minutes agorootparentInteresting. Reminds me of a sci-fi short i read years ago where AI's \"went insane\" when they had too much knowledge because they'd spent too much time looking through data and get a buffer overflow. I know some of the smaller models like PHI-2 are training for reasoning specifically before by training on question answer sets, though this seems like the opposite to me. reply AaronFriel 4 hours agorootparentprevIt indeed is. An attention mechanism's key and value matrices grow linearly with context length. With PagedAttention[1], we could imagine an external service providing context. The hard part is the how, of course. We can't load our entire database in every conversation, and I suspect there are also challenges around training (perhaps addressed via LandmarkAttention[2]) and building a service efficiently retrieve additional key-value matrices. The external service vector database may require tight timings necessary to avoid stalling LLMs. To manage 20-50 tokens/sec, answers must arrive within 50-20ms. And we cannot do this in real-time, pausing the transformer when a layer produces a query vector stalls the batch, so we need a way to predict queries (or embeddings) several tokens ahead of where they'd be useful and inject the context in when it's needed, and to know when to page it out. [1] https://arxiv.org/abs/2309.06180 [2] https://arxiv.org/abs/2305.16300 reply politician 4 hours agoparentprevHah! Maybe Neo was an LLM. \"I know kung-fu.\" reply seydor 19 minutes agoprevDoes this point to a way to compress entire LLMs by selecting a set of relations? reply estebarb 5 hours agoprevI find this similar to what relation vectors do in word2vec: you can add a vector of \"X of\" and often get the correct answer. It could be that the principle is still the same, and transformers \"just\" build a better mapping of entities into the embedding space? reply PaulHoule 4 hours agoparentI think so. Itâ€™s hard for me to believe that the decision surfaces inside those models are really curved enough (like the folds of your brain) to really take advantage of FP32 numbers inside vectors: that is I just donâ€™t believe it is x = 0 means â€œflyâ€ x = 0.01 means â€œdriveâ€ x = 0.02 means â€œpurpleâ€ but rather more like x1.5 means â€œhotâ€ which is one reason why quantization (often 1 bit) works. Also it is a reason why you can often get great results feeding text or images through a BERT or CLIP-type model and then applying classical ML models that frequently involve linear decision surfaces. reply taneq 4 hours agorootparentAre you conflating nonlinear embedding spaces with the physical curvature of the cerebellum? I don't think there's a direct mapping. reply PaulHoule 3 hours agorootparentMy mental picture is that violently curved decision surfaces could look like the convolutions of the brain even though they have nothing to do with how the brain actually works. I think of how tSNE and other algorithms sometimes produce projections that sometimes look like that (maybe thatâ€™s just what you get when you have to bend something complicated to fit into a 2-d space) and frequently show cusps that to me look like a sign of trouble (took me a while in my PhD work to realize how PoincarÃ© sections from 4 or 6 dimensions can look messed up when a part of the energy surface tilts perpendicularly to the projection surface.) I still find it hard to believe that dense vectors are the right way to deal with text despite the fact that they work so well. For images it is one thing because changing one pixel a little doesnâ€™t change the meaning of an image, but changing a single character of a text can completely change the meaning of the text. Also thereâ€™s the reality that if you randomly stick together tokens you get something meaningless, so it seems almost all of the representation space covers ill formed texts and only a low dimensional manifold holds the well formed texts. Now the decision surfaces really have to be nonlinear and crumpled over all but I think thereâ€™s a definitely a limit on how crumpled those surfaces can be. reply Y_Y 3 hours agorootparentThis is interesting. It makes me think of an \"immersion\"[0], as in a generalization of the concept of \"embedding\" in differential geometry. I share your uneasiness about mapping words to vectors and agree that it feels as if we're shoehorning some more complex space into a computationally convenient one. [0] https://en.wikipedia.org/wiki/Immersion_(mathematics) reply whatever1 5 hours agoprevLlms seem like a good compression mechanism. It blows my mind that I can have a copy of llama locally on my PC and have access to virtually the entire internet reply Culonavirus 4 hours agoparentYea except it's a lossy compression. With the lost part being hallucinated in at inference time. reply Kuinox 4 hours agorootparentIf you've read the article, the LLM hallucinations aren't due to the model not knowing the information but a function that choose to remember the wrong thing. reply sinemetu11 2 hours agorootparentFrom the paper: > Finally, we use our dataset and LRE-estimating method to build a visualization tool we call an attribute lens. Instead of showing the next token distribution like Logit Lens (nostalgebraist, 2020) the attribute lens shows the object-token distribution at each layer for a given relation. This lets us visualize where and when the LM finishes retrieving knowledge about a specific relation, and can reveal the presence of knowledge about attributes even when that knowledge does not reach the output. They're just looking at what lights up in the embedding when they feed something in, and whatever lights up is \"knowing\" about that topic. The function is an approximation they added on top of the model. It's important to not conflate this with the actual weights of the model. You can't separate the hallucinations from the model -- they exist precisely because of the lossy compression. reply ewild 2 hours agorootparentpreveven this place has people not reading the articles. we are doomed reply krainboltgreene 3 hours agoparentprev> have access to virtually the entire internet It isn't even close to 1% of the internet, much less virtually the entire internet. According to the latest dump, Common Crawl has 4.3B pages, but Google in 2016 estimated there are 130T pages. The difference between 130T and 4.3B is about 130T. Even if you narrow it down to Google's searchable text index it's \"100's of billions of pages\" and roughly 100P compared to CommonCrawl's 400T. reply fspeech 3 hours agorootparent130T unique pages? That seems highly unlikely as that averages to over 10000 pages for each human being alive. If gp merely wants texts of interest to self as opposed to an accurate snapshot it seems LLMs should be quite capable, one day. reply zyklonix 2 hours agoprevThis reminds me of the famous \"King - Man + Woman = Queen\" embedding example. The fact that embeddings have semantic properties in them explains why simple linear functions would work as well. reply robertclaus 2 hours agoprevI think this paper is cool and I love that they ran these experiments to validate these ideas. However, I'm having trouble reconciling the novelty of the ideas themselves. Isn't this result expected given that LLM's naturally learn simple statistical trends between words? To me it's way cooler that they clearly demonstrated not all LLM behavior can be explained this simply. reply MuffinFlavored 5 hours agoprevI don't understand how a \"CSV file/database/model\" of 70,000,000,000 (70B) \"parameters\" of 4-bit weights (a 4 bit value can be 1 of 16 unique numbers) gets us an interactive LLM/GPT that is near-all-knowledgable on all topics/subjects. edit: did research, the 4-bit is just a \"compression method\", the model ends up seeing f32? > Quantization is the process of mapping 32-bit floating-point numbers (which are the weights in the neural network) to a much smaller bit representation, like 4-bit values, for storage and memory efficiency. > Dequantization happens when the model is used (during inference or even training, if applicable). The 4-bit quantized weights are converted back into floating-point numbers that the model's computations are actually performed with. This is done using the scale and zero-point determined during the initial quantization, or through more sophisticated mapping functions that aim to preserve as much information as possible despite the reduced precision. so what is the relationship to \"parameters\" and \"# of unique tokens the model knows about (vocabulary size)\"? > At first glance, LLAMa only has a 32,000 vocabulary size and 65B parameters as compared to GPT-3, > The 65 billion parameters in a model like LLAMA (or any large language model) essentially function as a highly intricate mapping system that determines how to respond to a given input based on the learned relationships between tokens in its training data. reply Filligree 5 hours agoparentIt doesn't, is the simple answer. The slightly more complicated one is that a compressed text dump of Wikipedia isn't even 70GB, and this is lossy compression of the internet. reply ramses0 4 hours agorootparentIs there some sort of \"LLM-on-Wikipedia\" competition? ie: given \"just wikipedia\" what's the best score people can get on however these models are evaluated. I know that all the commercial ventures have a voracious data-input set, but it seems like there's room for dictionary.llm + wikipedia.llm + linux-kernel.llm and some sort of judging / bake-off for their different performance capabilities. Or does the training truly _NEED_ every book every written + the entire internet + all knowledge ever known by mankind to have an effective outcome? reply CraigJPerry 4 hours agorootparent>> Or does the training truly _NEED_ every book every written + the entire internet + all knowledge ever known by mankind to have an effective outcome? I have the same question. Peter Norvigâ€™s GOFAI Shakespeare generator example[1] (which is not an LLM) gets impressive results with little input data to go on. Does the leap to LLM preclude that kind of small input approach? [1] link should be here because I assumed as I wrote the above that I would just turn it up with a quick google. Alas tâ€™was not to be. Take my word for it, somewhere on tâ€™internet is an excellent write up by Peter Norvig on LLM vs GOFAI (good old fashioned artificial intelligence) reply bionhoward 4 hours agorootparentprevYes, thatâ€™s known as the Hutter Prize http://prize.hutter1.net/ reply ramses0 3 hours agorootparentNot exactly, because LLM's seem to be exhibiting value via \"lossy knowledge response\" vs. \"exact reproduction measured in bytes\", but close. reply MuffinFlavored 5 hours agorootparentprevsay the average LLM these days has a unique token (vocabulary) size of ~32,000 (not its context size, # of unique tokens it can pick between in a response. English words, punctuation, math, code, etc.) the 60-70B parameters of models is basically like... just stored patterns of \"if these 10 tokens in a row input, then these 10 tokens in a row output score the highest\" Is that a good summary? > The model uses its learned statistical patterns to predict the probability of what comes next in a sequence of text. based on what inputs? 1. previous tokens in the sequence from immediate context 2. tokens summarizing the overall topic/subject matter from the extended context 3. scoring of learned patterns from training 4. what else? reply wongarsu 4 hours agorootparentThat would be equivalent to a hidden markov chain. Those have been around for decades, but we have only managed to make them coherent for very short outputs. Even GPT2 beats any Markov chain, so there has to be more going on Modern LLMs are able to transfer knowledge between different languages, so it's fair to assume that some mapping between human language and a more abstract internal representation happens at the input and output, instead of the model \"operating\" on English or Chinese or whatever language you talk with it. And once this exists, an internal \"world model\" (as in: a collection of facts and implications) isn't far, and seems to indeed be something most LLMs do. The reasoning on top of that world model is still very spotty though reply numeri 5 hours agorootparentprevYour suggested scheme (assuming a mapping from 10 tokens to 10 tokens, with each token taking 2 bytes to store) would take (32000 * 20) * 2 bytes = 2.3e78 TiB of storage, or about 250 MiB per atom in the observable universe (1e82), prior to compression. I think it's more likely that LLMs are actually learning and understanding concepts as well as memorizing useful facts, than that LLMs have discovered a compression method with that high of a compression ratio, haha. reply mjburgess 4 hours agorootparentLLMs cannot determine the physical location of any atoms. they cannot plan movement, and so on. LLMs are just completing patterns of text that have been given before, 'everthing ever written' is both a lot for any individual person to read; but also, almost nothing, in that to propertly describe a table requires more information text is itself an extremely compressed medium which lacks almost any information about the world; it succeeds in being useful to generate because we have that information and are able to map it back to it reply numeri 4 hours agorootparentI didn't imply that they know anything about where atoms are, I was just pointing out the sheer absurdity of that volume of data. I should make it clear that my comparison there is unfair and mostly just funny â€“ you don't need to store every possible combination of 10 tokens, because most of them will be nonsense, so you wouldn't actually need that much storage. That being said, it's been fairly solidly proven that LLMs aren't just lookup tables/stochastic parrots. reply mjburgess 3 hours agorootparent> fairly solidly proven that LLMs aren't just lookup tables/stochastic parrots Well i'd strongly disagree. I see no evidence of this; I'm am quite well acquainted with the literature. All empirical statistical AI is just a means of approximating an empirical distribution. The problem with NLP is that there is no empirical function from text tokens to meanings; just as there is no function from sets of 2D images to a 3D structure. We know before we start that the distributions of text tokens are only coincidentally related to the distributions of meanings. The question is just how much value that coincidence has in any given task. (Consider, eg., that if I ask, \"do you like what i'm wearing?\" there is no distribution of responses which is correct. I do not want you to say \"yes\" 99/100, or even 100/100 times. etc. what I want you to say is a word caused a mental state you have: that of (dis)liking what i'm wearing. Since no statistical AI systems generate outputs based on causal features of reality, we know a priori that almost all possible questions that can be asked cannot be answered by LLMs. They are only useful where questions have cannonical answers; and only because \"cannonical\" means that a text->text function is likely to be conidentally indistinguishable from a the meaning->meaning function we're interested in). reply pk-protect-ai 4 hours agorootparentprevThere is something wrong with these arithmetic: \"(32000 * 20) * 2 bytes = 2.3e78 TiB of storage\" ... The factorial is missing somewhere in there ... reply HarHarVeryFunny 2 hours agorootparentprev> the 60-70B parameters of models is basically like... just stored patterns of \"if these 10 tokens in a row input, then these 10 tokens in a row output score the highest\" > Is that a good summary? No - there's a lot more going on. It's not just mapping input patterns to output patterns. A good starting point to understand it are linguist's sentence-structure trees (and these were the inspiration for the \"transformer\" design of these LLMs). https://www.nltk.org/book/ch08.html Note how there are multiple levels of nodes/branches to these trees, from the top node representing the sentence as a whole, to the words themselves which are all the way at the bottom. An LLM like ChatGPT is made out of multiple layers (e.g. 96 layers for GPT-3) of transformer blocks, stacked on top of each other. When you feed an input sentence into an LLM, the sentence will first be turned into a sequence of token embeddings, then passed through each of these 96 layers in turn, each of which changes (\"transforms\") it a little bit, until it comes out the top of the stack as the predicted output sentence (or something that can be decoded into the output sentence). We only use the last word of the output sentence which is the \"next word\" it has predicted. You can think of these 96 transformer layers as a bit like the levels in one of those linguistic sentence-structure trees. At the bottom level/layer are the words themselves, and at each successive higher level/layer are higher-and-higher level representations of the sentence structure. In order to understand this a little better, you need to understand what these token \"embeddings\" are, which is the form in which the sentence is passed through, and transformed by, these stacked transformer layers. To keep it simple, think of a token as a word, and say the model has a vocabulary of 32,000 words. You might perhaps expect that each word is represented by a number in the range 1-32000, but that is not the way it works! Instead, each word is mapped (aka \"embedded\") to a point in a high dimensional space (e.g. 4096-D for LLaMA 7B), meaning that it is represented by a vector of 4096 numbers (cf a point in 3-D space represented as (x,y,z)). These 4096 element \"embeddings\" are what actually pass thru the LLM and get transformed by it. Having so many dimensions gives the LLM a huge space in which it can represent a very rich variety of concepts, not just words. At the first layer of the transformer stack these embeddings do just represent words, the same as the nodes do at the bottom layer of the sentence-structure tree, but more information is gradually added to the embeddings by each layer, augmenting and transforming what they mean. For example, maybe the first transformer layer adds \"part of speech\" information so that each embedded word is now also tagged as a noun or verb, etc. At the next layer up, the words comprising a noun phase or verb phrase may get additionally tagged as such, and so-on as each transformer layer adds more information. This just gives a flavor of what is happening, but basically by the time the sentence has reached the top layer of the transformer it has been able to see the entire tree structure of the sentence, and only then have \"understand\" it well enough to predict a grammatically and semantically \"correct\" continuation from which it is able to predict continuation words. reply Acumen321 4 hours agoparentprevQuantization in this context is the precision of each value in the vector or matrix/tensor. If the model in question has a token embedding length of 1024, even if it was a 1 bit quantization, each token has 2^1024 possible values. If the context length is 32,000 tokens, there are 32,000^2^1024 possible inputs. reply i5heu 4 hours agoprevSo it is entirely possible to decouple the reasoning part from the information part? This is like absolutely mind blowing if this is true. reply learned 3 hours agoparentA big caveat mentioned in the article is that this experiment was done with a small set (N=47) of specific questions that they expected to have relatively simple relational answers: > The researchers developed a method to estimate these simple functions, and then computed functions for 47 different relations, such as â€œcapital city of a countryâ€ and â€œlead singer of a band.â€ While there could be an infinite number of possible relations, the researchers chose to study this specific subset because they are representative of the kinds of facts that can be written in this way. About 60% of these relations were retrieved using a linear function in the model. The remaining appeared to have nonlinear retrieval and is still a subject of investigation: > Functions retrieved the correct information more than 60 percent of the time, showing that some information in a transformer is encoded and retrieved in this way. â€œBut not everything is linearly encoded. For some facts, even though the model knows them and will predict text that is consistent with these facts, we canâ€™t find linear functions for them. This suggests that the model is doing something more intricate to store that information,â€ he says. reply vsnf 5 hours agoprev> Linear functions, equations with only two variables and no exponents, capture the straightforward, straight-line relationship between two variables Is this definition considering the output to be included in the set of variables? What a strange way to phrase it. Under this definition, I wonder what an equation with one variable is. Is a single constant an equation? reply hansvm 4 hours agoparentIt's just a change in perspective. Consider a vertical line. To have an \"output\" variable you have to switch the ordinary `y=mx+b` formulation to `x=c`. The generalization `ax+by=c` accommodates any shifted line you can draw. Adding more variables increases the dimension of the space in consideration (`ax+by+cz=d` could potentially define a plane). Adding more equations potentially reduces the size of the space in consideration (e.g., if `x+y=1` then also knowing `2x+2y=2` wouldn't reduce the solution space, but `x-y=0` would, and would imply `x=y=1/2`, and further adding `x+2y=12` would imply a lack of solutions). Mind you, the \"two variable\" statement in this news piece is a red-herring. The paper describes higher-dimension linear relationships, of the form `Mv=c` for some constant matrix `M`, some constant vector `c`, and some variable vector `v`. On some level, the result isn't _that_ surprising. The paper only examines one layer (not the whole network), after the network has done a huge amount of embedding work. In that layer, they find that under half the time they're able to get over 60% of the way there with a linear approximation. Another interpretation is that the single layer does some linear work and shoves it through some nonlinear transformations, and more than half the time that nonlinearity does something very meaningful (and even in that under half the time where the linear approximation is \"okay\", the metrics are still bad). I'm not super impressed, but I don't have time to full parse the thing right now. It is a bit surprising; if memory serves, one of the authors on this paper had a much better result in terms of neural network fact editing in the last year or two. This looks like a solid research idea, solid work, it didn't pan out, and to get it published they heavily overstated the conclusions (and then the university press release obviously bragged as much as it could). reply ksenzee 5 hours agoparentprevI think they're trying to say \"equations in the form y = mx + b\" without getting too technical. reply 01HNNWZ0MV43FF 5 hours agoparentprevYeah I guess they mean one independent variable and one dependent variable It rarely matters because if you had 2 dependent variables, you can just express that as 2 equations, so you might as well assume there's exactly 1 dependent and then only discuss the number of independent variables. reply pb060 4 hours agoparentprevArenâ€™t functions and equations two different things? reply olejorgenb 5 hours agoparentprevI would think `x = 4` is considered an equation, yes? reply pessimizer 4 hours agorootparentAnd linear at that: x = 0y + 4 reply wslh 5 hours agoprevCan we roughly say that LLMs produces (training mode) a lot of IF-THENs in an automatic way from a vast quantity of information (nor techniques) that was not available before? reply uoaei 1 hour agoprevThis is the \"random linear projections as memorization technique\" perspective on Transformers. It's not a new idea per se, but nice to see it fleshed out. If you dig into this perspective, it does temper any claims of \"cognitive behavior\" quite strongly, if only because Transformers have such a large capacity for these kinds of \"memories\". reply leobg 5 hours agoprev> In one experiment, they started with the prompt â€œBill Bradley was aâ€ and used the decoding functions for â€œplays sportsâ€ and â€œattended universityâ€ to see if the model knows that Sen. Bradley was a basketball player who attended Princeton. Why not just change the prompt? Name, University attended, Sport played Bill Bradley, reply numeri 5 hours agoparentThis is research, trying to understand the fundamentals of how these models work. They weren't actually trying to find out where Bill Bradley went to university. reply leobg 1 hour agorootparentOf course. But werenâ€™t they trying to find out whether or not that fact was represented in the modelâ€™s parameters? reply wnoise 26 minutes agorootparentNo, they were trying to figure out if they had isolated where facts like that were represented. reply aia24Q1 5 hours agoprev [â€“] I thought \"fact\" means truth. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Large language models, like the ones behind AI chatbots, utilize basic linear functions to access stored data on various topics, enabling researchers to investigate the model and rectify inaccuracies.",
      "Identifying these functions allows researchers to correct false information within the model, enhancing the understanding of knowledge storage and potentially boosting the accuracy and dependability of AI chatbots.",
      "A group of scientists from MIT, Northeastern University, Harvard University, and the Israeli Institute of Technology conducted the research, which will be showcased at the International Conference on Learning Representations."
    ],
    "commentSummary": [
      "Participants delve into the challenges, advancements, and limitations of large language models (LLMs) and transformers in AI technology, focusing on knowledge retrieval mechanisms, computational power, and practical implementation costs.",
      "There is a debate on whether transformers have peaked or if there is untapped potential for advancement, along with concerns about the lossy nature of LLM compression and the models' ability to grasp concepts fully.",
      "Discussions include the complexity of language models, the role of linear functions in AI, the importance of training data, and optimizing functions, as well as knowledge transfer between languages and \"immersion\" in differential geometry."
    ],
    "points": 238,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1711636670
  },
  {
    "id": 39848862,
    "title": "Amazon Fined $8 Million in Poland Over Deceptive Design Tactics",
    "originLink": "https://techcrunch.com/2024/03/27/amazon-dark-pattern-design-fine/",
    "originBody": "(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window) Link Copied Commerce Amazon fined in Poland for dark pattern design tricks Natasha Lomas@riptari / 11:34 AM UTCâ€¢March 27, 2024 Comment Image Credits: alexsl/iStock / Getty Images Amazon has been fined in Poland for misleading consumers about the conclusion of sales contracts on its online marketplace. The sanction, of close to $8 million (or in local currency: PLN 31,850,141), also calls out the e-commerce giant for deceptive design elements which may inject a false sense of urgency into the purchasing process and mislead shoppers about elements like product availability and delivery dates. The countryâ€™s consumer and competition watchdog, the UOKiK, has been looking into complaints about Amazonâ€™s sales practices since September 2021, following complaints from shoppers, including some who did not receive their purchases. The authority opened a formal investigation into Amazonâ€™s practices in February 2023. Wednesdayâ€™s sanction is the conclusion of that probe. The UOKiK found consumers who ordered products on Amazon could have their purchases subsequently cancelled by the tech giant as it does not treat the moment of purchase as the conclusion of a sales contract, despite sending consumers confirmation of their order â€” even after consumers have paid for the product. For Amazon, the conclusion of a sales contract only occurs once it has sent information about the actual shipment. In a press release detailing the enforcement, it said Amazon failed to clearly communicate this salient detail to shoppers, finding it only provided the information at â€œthe last stage of purchaseâ€. It also found the information was sometimes â€œdifficultâ€ for consumers to access, noting for example Amazon could use a grey font on a white background in text displayed at the very bottom of a page â€” a classic example of so-called â€˜dark pattern designâ€˜. The UOKiK contrasts that deceptive design choice with suggestive messaging Amazon shows to shoppers on sales buttons â€” which read â€œBuy nowâ€ or â€œProceed to finalize the purchaseâ€ â€” which it said imply that by ordering the product the shopper is concluding a contract with Amazon. Which is not, in fact, the case. â€œThus, Amazon misleads consumers as to the moment of conclusion of the sales contract,â€ the authority wrote [in Polish; this is a machine translation]. â€œFor many people, this can also have negative consequences: The consumer does not receive the product, so he cannot use it, he loses the opportunity to buy at an attractive price that may no longer apply, and his money is frozen until he returns it.â€ Some of the complaints it received also found information about how to cancel an order may be provided long after it was placed, with the UOKiK citing the case of cancellations of e-book reader orders where the critical detail was not provided for a month. A meaningless countdown clock Its enforcement also calls out Amazon for using deceptive design to encourage shoppers to click buy by presenting misleading information about product availability and delivery windows â€” such as by listing how many items were in stock to be purchased and providing a countdown clock to order an item in order to get it on a particular delivery date. Its investigation found Amazon does not always meet these deadlines for orders, nor ship products immediately as they may be out of stock despite claims to the contrary shown to consumers. â€œAmazon treats the data it provides on availability and shipping date as indicative but the way it is presented does not indicate this,â€ the UOKiK noted, adding: â€œConsumers can only find out about this in the terms of sale on the platform.â€ Commenting in a statement, the UOKiKâ€™s president, Tomasz ChrÃ³stny, said: â€œInformation about product availability and its fast shipping is very valuable for consumers and for many people it may be the main reason why they make a purchase decision. However, such information cannot be a lure. If the entrepreneur provides a specific delivery date, he or she must meet it. This practice by Amazon is classified as so-called dark patterns because it uses pressure to make the consumer order the product as soon as possible.â€ While Amazon does offer a delivery guarantee â€” offering a refund if items do not ship within the stated time â€” the authority found it failed to provide consumers with information about the rules of this service before placing an order. It only offers details at the order summary stage. And then only â€œif the consumer decides to read the subsequent links specifying delivery details.â€ Shoppers who did not follow the link to read more may not have been aware of their right to apply for and receive a refund from Amazon if there is a delay in shipment. It also found the e-commerce giant failed to provide information about the â€œDelivery Guaranteeâ€ in the purchase confirmation sent to shoppers. Amazon was contacted for comment on the sanction but at the time of writing it had not responded. It has the option to appeal. Update: Amazonâ€™s press office in Poland has now responded with a statement, confirming it will appeal. The company also writes: Fast and reliable delivery across a wide selection of products is a top priority for us, and Amazon.pl has millions of items available with fast and free Prime delivery. Since launching Amazon.pl in 2021, we have continuously invested and worked hard to provide customers with a clear, reliable delivery promise at check out, and while the vast majority of our deliveries arrive on time, customers can contact us in the rare event that they experience a delay or order cancellation, and we will make it right. Over the last year, we have collaborated with the Office of Competition and Consumer Protection (UOKiK), and proposed multiple voluntary amendments to continue to improve the customer experience on Amazon.pl. We strictly follow legal standards in all countries where we operate and we strongly disagree with the assessment and penalty issued by the UOKiK. We will appeal this decision. Please login to comment Login / Create Account TechCrunch Early Stage 2024 April 25, BostonFounder Summit Savings End Tomorrow Sign up for Newsletters See all newsletters(opens in a new window) Daily News Week in Review Startups Weekly Event Updates Advertising Updates By subscribing, you are agreeing to Yahoo's Terms and Privacy Policy. Email Subscribe (opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window) Copy Tags Amazon amazon dark pattern design amazon fined in poland",
    "commentLink": "https://news.ycombinator.com/item?id=39848862",
    "commentBody": "Amazon fined in Poland for dark pattern design tricks (techcrunch.com)221 points by elsewhen 12 hours agohidepastfavorite59 comments scyzoryk_xyz 6 hours agoBizarre. Poland isnâ€™t a big market with Amazon, we have our own local monopoly in this sector called Allegro. edit: ok this is done by UOKiK, a consumer protection agency. This agency has supposedly been doing a stellar job keeping an eye on everything from banking to e-commerce sector. reply StefanBatory 5 hours agoparentPolish Amazon is such in a weird spot. Compared to Allegro, it has close to no offers, and search engine. Just. Doesn't. Work. reply kolinko 5 hours agorootparent+1. When in Poland I use Allegro all the time - way more reliable than Amazon.pl. Not as good as Amazon in the states though. My friends who moved back from the Bay Area still prefer to use Amazon, but they use Amazon.de instead - similar shipping times, and much better selection and reliability. reply chihuahua 4 hours agorootparentNot sure if this is still the case, but Amazon.de used to use fulfillment centers in Poland to deliver to Germany. So if you're in Poland and ordering from Amazon.de, your order could very well be delivered from Poland to Poland. reply gambiting 3 hours agorootparentIn fact there were 3 massive Amazon fullfilment centres in Poland before Amazon.pl even launched lol. It's a weird(but very interesting) market with its own big players that neither Amazon nor ebay managed to compete against. reply voytec 16 minutes agorootparentprevamazon.pl doesn't have English version. Auto-translated titles and descriptions are atrocious. amazon.de on the other hand has English version and stuff is sent from warehouses in Poland anyway. reply ivanjermakov 1 hour agorootparentprevAmazon's search in Poland is atrocious. I only get international offers where shipping costs are higher than good's price. What the hell? reply jakubadamw 5 hours agoparentprevI am honestly baffled Amazon hasn't found a way to compete with Allegro. I am happy about it, but also baffled. Allegro's customer experience is just stellar, whereas Amazon's interface continues to give the impression that it's still a bunch of widgets rendered by a hundred microservices and glued together without any elegant cohesion in mind. It's as if little has changed since the famous Steve Yegge's letter. reply scyzoryk_xyz 3 hours agorootparentI'm no fan of either - Allegro has Amazon executives and nearly identical Prime-free shipping strategy. Pretty sure Allegro has the same effect of monopolizing and driving up prices as Amazon has. I find the eBay-esque artifact interface absurd. It's likely Amazon hasn't found a way because an environment that isn't a monopoly isn't attractive to begin with for that business model. reply slowmotiony 4 hours agorootparentprevIt's even more baffling that Amazon.pl has one of the worst customer support I've ever seen while Amazon.de is a total opposite - an increadibly pleasant experience and packages almost always arrive on the next day. reply dehrmann 5 hours agoparentprev> stellar I'm not sure enough to know if that's sarcastic, but the circumstances make me wonder if this was to promote local competitors or score political points. reply scyzoryk_xyz 4 hours agorootparentNo no, I'm serious. I have friends in banking who had experiences coming under UOKiK scrutiny and they claim that it really has it's shit together. I have no doubt that there is dysfunction in the system, just not when it comes to regulation of this sector apparently. reply Animats 30 minutes agoprevStrange that Amazon would do this. The original selling point of their \"one-click\" system was that it had undo. Everybody else was requiring lots of confirmation, while Amazon was just click and go, with the opportunity to undo mistakes. Amazon has lost that, with their \"No, I don't want to buy Prime\", \"No, I really don't want to buy Prime\", and \"QUIT TRYING TO GET ME TO BUY YOUR PRIME SERVICE\" check out system. reply fy20 8 hours agoprevThe part about the countdown clock for delivery dates is interesting. Amazon is not in my country, but Amazon DE does ship here for not too much. It's often cheaper and sometimes even quicker to order from Amazon DE than a local e-retailer (they often don't have items in stock locally, and need to ship from a warehouse in another country). I wanted to purchase some items, and it gave the usual \"order in the next 8 hours for delivery on Sunday\". I wanted to add some other items later, and forgot about it. I finally got around to placing the order two days later. It gave me a delivery date of... the same Sunday. reply mdrzn 7 hours agoparentI've never had any issues with the countdown clock; it's usually for orders that I want to receive quickly, and it tells me \"if you order within the next 2 hours, it will arrive tomorrow\". So, I doubt that it's a dark pattern (at least in Italy). Then again, if third-party sellers are using this system as a dark pattern, that's a different matter. reply MatekCopatek 7 hours agorootparentJudging by the parent comment, the dark part is the fact that it might be fake pressure. As in - it's true that it will arrive tomorrow if you order within the next 2 hrs, but it will actually arrive tomorrow even if you take 4 hrs. reply aendruk 6 hours agorootparentIsnâ€™t the explanation just that delivery estimates have a wide margin of error? To guarantee delivery by a target date the order must be placed by the beginning of the margin, but if you order within the margin thereâ€™s some probability of getting that date by chance. To explain the two estimates days apart both returning the same Sunday, consider that the week is heterogeneous; maybe some regional hop is available specifically on Saturday regardless of how early you order. reply gambiting 3 hours agorootparentSure, but the regulator in this case is making an argument that it's creating an unfair pressure to make you purchase a thing, and that the timer is consistently shorter than it needs to be. It's the same thing as going on a website and it says \"order within next 30 minutes for a 50% discount\" and then you come back an hour later and it still says the same thing - it creates an incentive on you to purchase by creating an illusion of urgency. It's the illusion part that the regulators have a problem with. reply BeetleB 5 hours agorootparentprevThe dark pattern is actually the opposite. People who ordered in the next 2 hours might not get it the next day. If you tell someone \"buy it in the next 2 hours to receive it tomorrow\", you better make sure they get it tomorrow. reply tzs 4 hours agorootparentI don't see how that is necessarily a dark pattern. It would be a dark pattern if they were saying that when they knew it would not make it in time. But if most of the time they do make the deadline, and the times that they do not are caused by problems that arose unexpectedly after the order was places, it is not a dark pattern. reply BeetleB 3 hours agorootparent> and the times that they do not are caused by problems that arose unexpectedly after the order was places, it is not a dark pattern I think the contention here is that they intentionally overcommitted. One would have to see the statistics on how often they miss the promised timeline. reply mdrzn 6 hours agorootparentprevI mean usually the cut-off time is to \"order by 8 PM to get the product delivered the next day\". I'm not convinced that setting the order deadline at 8 PM instead of 10 PM significantly boosts sales. E-commerce platforms are full of dark patterns, but on Amazon (perhaps because I go there when I already know what I want to buy), I haven't noticed many. Another potential dark pattern is that the lowest price is shown for offers with Prime included, while sometimes there are lower prices available for the same product shipped without Prime. However, even in this case, I don't have any complaints. Not defending Amazon obviously, but since I pay for Prime, I definitely want the fastest shipment possible. reply Zigurd 6 hours agorootparentprevI suppose discovery, or even a study of whether the delivery countdown matters to actual delivery, in a case like this is enough to categorize it as a dark pattern. If it can be shown to not matter to actual delivery time, what other purpose does it serve? reply arkey 6 hours agorootparentprevIf you, like me, only go to Amazon when you've already decided to buy a certain thing, then you probably just stay with the \"will arrive tomorrow\" part. However the countdown could add some pressure if you're still deciding on buying something or not, in the form of \"now or never FOMO\". reply throw_a_grenade 5 hours agorootparentprevPolish official release linked in TFA (https://uokik.gov.pl/31-mln-zl-kary-dla-amazon) hints that the problem with that clock was, it wasn't actually a guarantee, because Amazon could have just cancelled the order. That it can just cancel the order based on some technicality (how Amazon defined conclusion of contract) is also illegal in itself. reply duxup 3 hours agoparentprevIt doesn't strike me as particularly unusual for the clock to give one time, and then a different time later. A lot of factors might go into making promises and each time they're evaluated variables may be different. I might give an ETA for some code, say 3 days, then do something else and find an easier way to do the task I was asked about earlier, dude to happenstance or even lower demands on my time ... so that later when asked again I might give an even even earlier ETA. reply Ekaros 4 hours agoparentprevFor Finland it seems they time their shipping by arrival date. So if arrival date is bit away, they only ship a few days later. But it will hit the arrival window. reply akkad33 1 hour agoprevThere's this fitness app called madmuscles https://madmuscles.com/ that takes dark patterns to the extreme. It has to be seen to be believed. I don't know how they get away with it reply croemer 4 hours agoprevExcellent, consumer protection orgs should do this much more frequently. Often they are the only ones with standing to sue in these types of cases. reply spike021 4 hours agoprevCan the NYT be next? (In the US of course) Recently I tried unsubscribing from The Athletic (now owned by NYT). They use every dark pattern in the book and multiple times also make it seem like you finally were successful only for no real confirmation message. reply alephknoll 4 hours agoparentDon't know why you are getting downvoted. NYT and many publishers are notorious with their dark patterns to keep you around. The only company that I know of that makes it easier to 'unsubscribe' than to 'subscribe' is netflix. I couldn't believe how easy it was. Didn't have to call them and have them guilt trip me into staying. Or chat with someone or some AI. Just cancel. Though they do email you deals from time to time. But even then only every few weeks or so. reply hnbad 6 hours agoprevIt sounds like Amazon (in Poland at least) has been playing it fast and loose with \"eventual consistency\" but violated the law by basing legally binding claims on the unreliable data. Selling goods that are already out of stock only to then cancel the order later, or indicating a false time pressure to purchase in order to meet a delivery date, etc, all sound like they could as well be genuine mistakes. Amazon just happens to be too big for that to be a valid excuse. reply kubanczyk 5 hours agoparentAccording to the gov investigator a big part of the \"darkness\" in this case were A's terms of service. They moved the moment of entering the legal sale agreement well after the customer could expect from their web interaction. reply jgeada 6 hours agoparentprevExcept they do still charge you first before figuring out they won't actually ship you the goods as promised. It is the charging and then not delivering that is the problem. reply rafram 5 hours agorootparentDo they? In the US, Amazon only actually charges your card once the items ship. Until then itâ€™s just a pre-authorization. reply gambiting 3 hours agorootparentNope, in Poland(and in UK as well) it charges you immediately, unless the item is specifically marked as pre-order(like new unreleased yet games and films - those get charged when they ship, everything else gets charged the moment of order). I've ordered a new router from Amazon few weeks ago, it was showing as \"shipping 5th of April\" (they were on backorder I guess) but they charged my card straight away. reply chihuahua 3 hours agorootparentprevIt seems bizarre to hear about these problems in Poland. Amazon had all this stuff figured out a long time ago. Which is why I order from Amazon all the time - it works reliably, 99.99% of the time. And they understand how to properly package things, which is what I would expect after they've shipped a billions packages over the past 25+ years. When I order from Target or Vitacost, there's a 25% chance that they throw things in a box, add a single inflated plastic bag, and ship it. Glass jars arrive smashed, shampoo bottles crack open and leak over the other items, etc. It's like day 1 for Amazon's competition in terms of packaging. reply zzz999 2 hours agoprevGood reply imwillofficial 2 hours agoprevI see digital sovereignty of various localities cracking down on big tech being one of the impending battlefields of the next decade. reply belter 6 hours agoprevCan Poland please fine the hell of Zoom, for the darkest pattern of pretending you need to install a client to join a meeting. And only after a few seconds, show at the end of the page you can join with a browser? reply bmmayer1 5 hours agoparentUntil this moment I had no earthly idea you could join a Zoom call from a browser. Good on them for their evil genius design team :-p reply belter 5 hours agorootparent\"PSA: Yes you can join a Zoom meeting in the browser\" - https://techcrunch.com/2020/03/20/psa-yes-you-can-join-a-zoo... \"Zoom's forced app is irresponsible\" - https://shkspr.mobi/blog/2020/03/zooms-forced-app-is-irrespo... Shady patterns mean shady company reply wubrr 4 hours agorootparentprevI used zoom in browser before using the apps.. and the annoying dark patterns basically pushed me to avoid zoom whenever I can at this point. A lot of these kinds of dark patterns sacrifice long term user satisfaction and brand reputation for short-term gains in questionable internal metrics (metrics that are often tied to bonuses for people who couldn't care less about the long-term success of the company or its customers). reply chihuahua 4 hours agorootparentI do not understand why people think Zoom is so good, and why companies pay money to use it. The app is so annoying. (At least on MacOS) it splits everything into many different windows that end up on different screens and it's so annoying having to scan all my screens to find the piece of the UI that lets me start screen sharing. Whenever I join a Zoom meeting from the Calendar, it first pops open a browser tab, and then that opens the Zoom app. In the year 2024, why can't it open the Zoom app directly? Surely one app can start a process to run another app? reply erikerikson 3 hours agorootparentI suspect it's two factors. The first is that it's not produced by a major and statistically we like an underdog. The second is that they made a video client that actually worked when all the majors under invested and produced clients with serious issues. From there, the market is sticky. It has worn a bit though, hasn't it? reply nextos 4 hours agorootparentprevBefore it was more evident you could join from your browser. It's just WebRTC, like Google Meet, Jitsi, etc. reply ivanjermakov 1 hour agoparentprevAnd still, Zoom's \"annotate\" feature is not available in web version, although there is absolutely no technical reason for that. reply wackget 5 hours agoparentprevZoom is terrible for this, but it's also sometimes the fault of the meeting organiser. There's a setting in the Zoom admin panel which allows admins to enable/disable the option of joining from the browser (or there used to be, at least). If you don't see the join from browser link even after jumping through Zoom's dark pattern hoops, ask the meeting admin to enable it. reply dixie_land 4 hours agoparentprevThis chrome extension is a lifesaver: https://chrome.google.com/webstore/detail/xoom-redirector/oc... reply BeetleB 5 hours agoparentprevIs this something specific to Poland. I join Zoom calls via a browser (on a PC) all the time - it was not at all hard to figure out. reply itslennysfault 5 hours agorootparentNo, just tested it out (in the US). I honestly had no idea there was a web client at all because of the pattern OP is talking about. When I clicked the zoom link it opens a browser window and pops up a system dialog to launch the zoom app. After I hit \"cancel\" on that dialog I was on a page with a large \"Launch Meeting\" button (and no link to use the web version). Then, I clicked the \"Launch Meeting\" button and it opened the same system dialog again. Then, after I clicked cancel on that dialog a small link appeared at the bottom that says: \"Having issues with Zoom Client? Join from Your Browser\" reply nolongerthere 4 hours agorootparentThatâ€™s so interesting, Iâ€™ve known about it from the very beginning of my introduction to zoom, back at the start of the pandemic when zoom was becoming ubiquitous someone released a chrome extension to always use the web client. reply Kwpolska 3 hours agorootparentprevWhat if you open it in incognito mode? I haven't had to use Zoom for a while, but last time I did, it would automatically download an exe/pkg when opening the page. reply jgwil2 2 hours agoparentprevHmm, I mean I hate patterns like this but also there are like a million apps out there that don't have a web client at all (not to mention the ones that do support web but constantly display popups saying \"x is better in the app\"), so it would seem odd to punish Zoom for this while letting all those other companies carry on. reply CGamesPlay 4 hours agoparentprevPSA: just click the â€œopen in appâ€ link (which wonâ€™t do anything since you donâ€™t have the app installed) and the â€œactually open in browserâ€ link will immediately appear. reply paulddraper 3 hours agoparentprevThat seems...excessive. Being fined for not offering an obvious web-only client. reply RajT88 4 hours agoprev [â€“] Nuke subscribe & save from orbit. reply jonathankoren 3 hours agoparent [â€“] I always love it when it suggests that I should get a subscription to a durable good. reply RajT88 3 hours agorootparent [â€“] I enjoy the fine print which says, \"your subscription price can change\". Which of course it does. There is a lot of price fuckery going on, where they lower it to drive subscriptions and then raise the price above the average price. I'm not sure why I'm getting downvoted, because subscribe & save is obviously a dark pattern along the lines of \"entice subscription, get people to forget about it\" only with variable pricing on top of it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Amazon has been fined in Poland for deceptive practices related to sales contracts on its online marketplace, with a penalty of nearly $8 million.",
      "Deceptive design elements, creating a false sense of urgency, misleading consumers on product availability and delivery dates, were highlighted by the consumer watchdog.",
      "The company's practice of canceling orders post-payment, considering the purchase not as the contract conclusion, and using 'dark pattern design' were major issues identified, allowing Amazon the opportunity to appeal the ruling."
    ],
    "commentSummary": [
      "Amazon has been fined in Poland for employing dark pattern design techniques, although it's not as dominant in the country as local rival Allegro.",
      "Users in Poland have raised concerns about Amazon's offerings, search engine, and customer service, prompting some to favor Amazon.de for a wider selection, reliability, and faster shipping.",
      "Discussions highlight dark patterns in e-commerce, especially deceptive urgency strategies employed by companies like Amazon, while users also criticize Zoom's interface and design, suggesting the necessity for enhancements."
    ],
    "points": 221,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1711614521
  },
  {
    "id": 39849727,
    "title": "Intel's $152B Buybacks Raise Questions on $8B Subsidy",
    "originLink": "https://www.commondreams.org/opinion/intel-subsidy-chips-act-stock-buyback",
    "originBody": "An illustration of INTEL and the US dollar is being displayed in Suqian City, Jiangsu Province, China, on February 17, 2024. The Biden administration is currently negotiating to provide more than $10 billion in subsidies to Intel Corp., which may include loans and direct grants. (Photo Illustration by Costfoto/NurPhoto via Getty Images) Intel Brags of $152 Billion in Stock Buybacks Over Last 35 Years. So Why Does It Need an $8 Billion Subsidy? Whatâ€™s to stop the chip-making giant from shoveling taxpayer grants into more stock buybacks?",
    "commentLink": "https://news.ycombinator.com/item?id=39849727",
    "commentBody": "Intel Brags of $152B in Stock Buybacks. Why Does It Need an $8B Subsidy? (commondreams.org)219 points by robtherobber 9 hours agohidepastfavorite273 comments sudhirj 8 hours agoIntel didn't get a subsidy because they're poor, the subsidy exists because the US Government wants the company to do something (setup a fab on US soil) that is not necessarily in the shareholders best interest (cheaper to set up a fab elsewhere). The subsidy is the difference in both parties judge to be the cost of doing the expensive thing (that matches US strategic interests) vs the cheaper thing. reply op00to 7 hours agoparentPerhaps the government should simply nationalize Intel if they continue to do stock buybacks. Thereâ€™s more knobs to turn than the free money faucet. reply ChadNauseam 7 hours agorootparentAre you suggesting the government buy Intel, or that they steal it from its current owners? You might have different opinions than I do about the morality of such a thing, but either way it would be disastrous as it would disincentivize all investment in things the US can steal. reply mattalex 7 hours agorootparentThe US could have required stock in Intel instead of taking nothing: Intel gets money, US gets influence over Intel. Just like it works everywhere else. reply bryanlarsen 7 hours agorootparentThere are 3 good ways to give money to the private sector: as a purchase order, in exchange for equity, or as an interest bearing loan. If the company won't accept money in one of those 3 forms they probably don't need it. reply Wytwwww 7 hours agorootparentprev> Just like it works everywhere else. That's certainly not the case, though. reply mdasen 6 hours agorootparentprevWhen giving a company like Intel money, you could give that in exchange for part of the company or for the company to do something for you. For example, the US could give Intel $8B for about 4% of Intel (at today's market price). However, that wouldn't get them the new US chip fab that they want. It would get them 4% ownership of Intel. Another example, the US could give Intel money to build them a supercomputer. The US would get a supercomputer, but it wouldn't get any ownership of Intel. When I buy Intel processors, I get a product, but no ownership of the company. In this case, the US wants to buy a product: a US based fab. You might say \"but the fab benefits Intel.\" You're totally right, but when I buy Intel processors it gives Intel capital they'll use for their benefit as well. The real question is whether the US is overpaying for this fab or if the fab is even worth it. Could the US have gotten the product it wants cheaper? Is having new US based fabs worth paying for? I think the answer to the latter is a resounding \"yes\" for strategic reasons. Tens of billions is a tiny drop in the bucket to help ensure something bad doesn't happen to one of the most important industries to US prosperity. We spend $850B/year on the military to try to ensure continued US security and prosperity. Giving Intel $8B is probably a bargain by comparison. Likewise, if you hate that Intel is being given $8B, you'll really hate how much Boeing, Lockheed, Raytheon, Northrop, and General Dynamics get from the government. Sure, the US could have required Intel stock as part of the deal, but depending on the amount of stock, Intel would have likely rejected it. Should the US have offered $11-12B for 2% of Intel plus a US fab? If that's the case, why doesn't the US government simply buy stock in Intel today? If your argument is that the US should end up with 20% of Intel for that cash, Intel would reject it. That's giving Intel a tiny fraction of what their stock is worth - 20% of Intel is worth $38B. If the government wanted to nationalize Intel, it'd probably cost them $210-250B. The government isn't just allowed to take something without just compensation. While Intel's market price is $188B, usually buying a whole company involves having to pay a premium over that. The US has taken ownership stakes in companies in some scenarios. For example, the bank \"bailouts\" gave the US preferred stock with a dividend rate of 5% that would climb to 9% from 2008-2013. The government also got warrants to purchase common stock at a very low price. Recipients generally repaid what they were given and the government made billions off the stock warrants. In the case of the bank \"bailouts\", the government was giving the banks money to help save the banks and demanded ownership in return. By contrast, Intel doesn't need help. The US government wants to get Intel to do something; the government wants to pay Intel to make them a product. Maybe the government could have gotten a better deal than $8B. However, given that few companies could legitimately create modern fabs and given that even companies like TSMC have been having difficulty at creating fabs in the US, $8B doesn't seem like a crazy amount of money to be offering as a carrot. It looks like the US is also spending $6B on Samsung and $5B on TSMC to get them to build fabs here. If the US wanted ownership and a new fab, it would cost more than $8B. If the US wanted a new fab plus 10% of Intel, it'd likely cost them $25-30B. reply refurb 5 hours agorootparentprevBuying $8B in equity of a $160B company might get you a board seat (one of 8) but itâ€™s not going to give you control over the company. reply transcriptase 7 hours agorootparentprevThis thread really brought an alarming number of tankies out of the HN woodwork. Not something you typically see on here! reply pjc50 7 hours agorootparentThere's always been people with really Out There political opinions On Here, but usually they're on the more libertarian side. It seems that mentioning China makes people want to beat them by being more Maoist. I don't know whether this is an effect of outflux from Twitter or some other social media phenomenon. reply Arthur_ODC 6 hours agorootparentprevWow, people are now throwing around the term \"tankie\" when simply discussing nationalization? That's crazy. That term is becoming as useless as calling someone a fascist or woke. reply troyvit 5 hours agorootparentDang and I just learned the word too. reply tasuki 7 hours agorootparentprevIf they were to buy Intel for a fair price, why should that disincentivize investment? reply Teever 7 hours agorootparentprevEminent domain is not theft. It is a legally defined practice in most legal systems. reply justinclift 7 hours agorootparentWell, it's still theft of the \"depriving the owners of their belongings\" variety. It's just that the groups that can do eminent domain tend to both have guns and be in charge of the local legal system. Which means they get to define the rules and make up their own name for when its them doing the thieving. ;) reply Teever 4 hours agorootparentBut you understand that as it is an aspect of the legal system, and one that is usually defined higher in the legal hierarchy that it can't be a thing that is defined later, right? You shouldn't misuse words like you're intentionally doing. Why not go all the way and call it rape or something. reply pjc50 7 hours agorootparentprevI'm sure the US taxpayer would be very happy to take one hundred and eighty five billion dollars and give it to the investors instead. reply jsight 7 hours agorootparentImagine Intel running at the full speed and efficiency of the US government. reply Wytwwww 7 hours agorootparentprevBut now there is chance that Intel will at some point overtake TSMC again and most(?)/much of their production capacity would be in the US? That chance would no longer exist if the government nationalized Intel.. so what would be the point? reply fragmede 7 hours agoparentprevBut were there strings attached that make Intel actually do that with this money, unlike last time? reply Workaccount2 7 hours agorootparentThere are a lot of strings. Ironically I am questioning where or not I should sell my shares because of those strings. Some companies didn't take the CHIPS act money because of them too. reply sudhirj 7 hours agorootparentprevNot sure why what would matter. One party (US taxpayers) is paying another party (Intel shareholders) to do something specific. What recipients do with the money is their own problem. EDIT: Sorry, read this as strings attached to what Intel could do with the money. I would assume the subsidy is contingent on Intel actually setting up the fab and some output numbers, seems idiotic to do it any other way. Don't think this was a bailout or handout at all. I haven't seen the agreement though. reply buran77 7 hours agorootparentPeople generally see subsidies given to companies as a contract. Subsidies in general aren't a contract. People don't have to \"do their part\" when they benefit from a subsidy (like vote for a specific party because they subsidized the price of gas), and usually neither do companies. reply javagram 7 hours agorootparent> People don't have to \"do their part\" when they benefit from a subsidy (like vote for a specific party because they subsidized the price of gas), and usually neither do companies. This is typically false, usually the subsidies are in the form of tax credits that are only awarded once you perform the desired action, or at least have to be paid back if you fail to do so. They donâ€™t just cut a check and wash their hands. This is true for individuals as well as corporations. When you do your taxes this year, take a look at credits like the renewable energy credit. You have to actually purchase insulation or solar panels to be eligible for the credit. reply pwillia7 8 hours agoparentprevYeah I was going to say this is the vig for not going with China for money because greed is the only virtue in the gilded age II reply mhb 7 hours agoparentprevIf it's such an important objective for the US government, perhaps they shouldn't muddle it up with DEI bullshit: https://thehill.com/opinion/4517470-dei-killed-the-chips-act... reply aceon48 8 hours agoparentprevGiven the criticality to National security interests, perhaps the US government should have brought the stick with heavy taxes / penalties for not having the US Based plant instead of the carrot of more corporate subsidies. This is still a US based company, with US leadership reply sschueller 8 hours agorootparentThe US Government could pass a new ruling requiring all chips in all military hardware (or even all hardware used by any government agency) down to the smallest IoT shit needs to be made in the US by a US firm. I doubt Intel would need any money or other incentive if the orders start coming in. reply lumb63 7 hours agorootparentThe supply chain for military hardware is already under heavy scrutiny. I donâ€™t think the CHIPS Act is about security; itâ€™s about onshoring production so the US can avoid caring about Taiwan. reply Workaccount2 7 hours agorootparentprevThis is basically already how it is. This is also why nobody ever wants to cut the DoD budget, it's basically the backbone of American manufacturing for everything. All the stuff our company makes for the military needs to be US made, despite us being able to get the same stuff from China for 1/10 the cost. It's also a kick-your-door-down-and-go-prison offense if you try and skirt this. My company knows that first hand (unintentional, but the DoD doesn't care) reply andsoitis 8 hours agorootparentprevIt is highly likely that that was considered but discounted for being suboptimal. reply wakawaka28 8 hours agorootparentprevThe military may not be a large enough customer to make such demands. Or perhaps a handful of companies would do it at 100x the cost of similar civilian products. It would turn into another $10k toilet seat fiasco. reply YetAnotherNick 8 hours agorootparentprevGood way to force Intel/all remaining chipmakers to move its headquarters to other country. reply rob74 8 hours agorootparentprev...and then stop buying military hardware for 5+ years, until these US-made chips are available? reply willcipriano 8 hours agorootparentPurchase orders like this happen years out. Before the deliveries dry up, Intel's cash flow will dip and investors will riot until Intel is ready to do business in the US. reply _giorgio_ 8 hours agorootparentprevHere's the crazy one. Punishing a company just because it's american. reply harimau777 8 hours agorootparentAlternative take: Punishing a company because it's selling out Americans in favor of cheap labor. reply addicted 8 hours agorootparentThis is a myth. Cheap labor is a benefit but not the primary reason companies are manufacturing in the U.S. today. Look at TSMC. It started setting up US operations years ago and is expecting to complete many years from now. OTOH they started setting up in Japan about a year or so ago and are already cranking out chips. reply fancyfredbot 8 hours agorootparentThe Japanese plant is less ambitious, using an older process on a smaller scale. The fact the Japanese plant was finished first says little about manufacturing in the US vs Japan. reply roody15 7 hours agorootparentprevhttps://www.bnnbloomberg.ca/tsmc-s-second-fab-in-arizona-del... TSMC is looking to bail completely on the second fab / even intel is now looking at delaying. The problem we are running into is a lot of DEI language was included in the chips act which is making it hard for TSMC (and Intel) to comply. This is not a good PR move to say this outright so they will just give more generic \"labor\" shortages etc as the official reason. reply api 8 hours agorootparentprevI think you meant â€œarenâ€™t manufacturingâ€ and you are correct. Itâ€™s not cheap labor, except for the lowest end manufacturing. Itâ€™s that you canâ€™t build anything in America anymore. The government needs to address that instead of subsidizing one off efforts. reply helsinkiandrew 8 hours agorootparentprev> it's selling out Americans in favor of cheap labor. Perhaps American workers. But an alternate take is that American consumers got cheaper chips and PCs - which resulted in more being sold, more companies and people using them, greater efficiency and new ideas and perhaps a more productive economy. It will be interesting in 5-10 years if the US needs to tax/block possibly cheaper and better components built outside the US being sold reply 34679 7 hours agorootparentIntel, like any other succesful company, prices its goods based on what the market will pay, not what it costs to make. Lower costs does not mean lower prices for customers, it means more profits for Intel. reply helsinkiandrew 6 hours agorootparent> Intel, like any other succesful company, prices its goods based on what the market will pay, not what it costs to make That may be true for Intel's CPUs but when products aren't produced by monopolies, those that have the cheapest costs and are in competition with others, often lower their prices to compete where the competitor can't. For example: AMD, graphics and motherboard parts reply prerok 1 hour agorootparentWell, I take it that it's always true and is a good lesson for anyone trying to set the price for their own product (like a hacked together side project one of us might be working on :) ). My understanding is that the price should never be set based on production cost but on the value it brings to the customer. Thereby, a simple program you or I could hack together in a month, might have a cost of 10k in labor only cost, but if it would save the customer millions each year, they would pay a million for it. So, you set the cost based on how much they are willing to pay, based on how much they would profit/save. If another competitor offers a similar solution, you just undercut them by 10%, or invest another 10k for superior features. reply amarcheschi 6 hours agorootparentprevFurthermore, up until at least a few years ago (i don't know how it is now) intel chips were more expensive than amd's, especially on server side, even accounting on performance/watt and intel adopted practices such as locking mobo to just one chipset and things like that. the situation might be different now tho reply gruez 8 hours agorootparentprevYeah I'm sure that's going to cause investors/other companies to think that the US is a good place to set up shop and/or make further investments. reply belorn 8 hours agorootparentI believe that $77B as a fairly good cause for investors/other companies to set up shop and make investment into the US semiconductors market. According to random market statistic site, it is also currently growing by 10% each year. Is that market so poor that subsidies really is needed on the basis of profitability? reply gruez 6 hours agorootparentA $77B market that's growing by 10% each year doesn't mean much when the government turns against you demands you do a bunch of expensive investments for nationalist reasons. See also: all the investors fleeing china because they were spooked by the tech crackdown/covid lockdowns. \"Punishing a company because it's selling out Americans in favor of cheap labor\" is basically the same thing but with a different coat of paint. reply owisd 8 hours agorootparentprevIntel is a product of Shockley, which was a product of Bell Labs, which was a product of â€œpunishingâ€ AT&T for â€œbeing Americanâ€. AT&T would have zealously guarded the transistor patent and never have licenced it out to Motorola, TI, etc. if they only cared about maximising shareholder value. reply skywal_l 8 hours agorootparentprevWouldn't be easier for the US government to buy Intel shares rather than subsidies it? It should actually be mandatory for the government to own part of a company that is so critical to national and security interest. reply DonnyV 8 hours agorootparentprevWe're always bending over backwards for a handful of companies instead of promoting a healthy market. We should of created a race with multiple companies to build the best chip factories. reply gruez 8 hours agorootparent> We should of created a race with multiple companies to build the best chip factories. That's insanely expensive. Today the only companies that make leading edge chips are TSMC, Samsung, and Intel. Global Foundries (headquartered in US) dropped out a few years ago because it was too expensive. How on earth are you going to fund \"a race with multiple companies to build the best chip factories\"? It's going to cost multiples of whatever the intel subsidy is. reply sgarland 8 hours agorootparentMultiples of $8 billion? Oh no, where would we find the money? If this is truly a national security issue, perhaps some of the DoDâ€™s ~$150 billion R&D budget could go towards it. reply prerok 50 minutes agorootparentTo be fair: to build whole companies would not cost multiples of 8B but multiples of 150B. And if you really wanted to cover all \"critical\" industries, even this would be a drop (or maybe a puddle) in the ocean. reply prerok 55 minutes agorootparentprevnit: should of -> should have reply specialist 7 hours agorootparentprevAccelerated consolidation was policy for decades. Clinton Admin's dept of defence pushed it really hard, esp for defense contractors. To reduce costs, make our nat'l champions more competitive internationally, make our hair more luxuriant, and cure rickets. Because reasons. Now the pendullum might finally be swinging back towards pro-competition and healthy open markets. reply willcipriano 8 hours agorootparentprevYour brother's idiot son doesn't get a no show job if you use the stick. reply taneq 8 hours agoparentprevIdeally this kind of subsidy would be paid any time the expected return on investment for the government was better than breaking even. Itâ€™s not about making sure only the most deserving get help, itâ€™s about making sure everyone (including the most deserving) gets more. reply nabla9 8 hours agorootparentIt's a strategic investment for national security with net negative value. The government does not want return of investment. The government wants to lose money so that national security gets better. reply kiba 8 hours agorootparentMaybe or maybe not in term of net tax revenue, but it's certainly an investment with an expectation of the preferred outcome of national security, with some portion of the subsidy maybe being returned as taxes of various kinds. reply User23 8 hours agorootparentprevInvesting money is different when you can create it from nothing. Needless to say the intuitions one develops from investing while not being able to create money at will are not entirely applicable. reply taneq 5 hours agorootparentprevI think we're using different definitions. A \"strategic investment for national security\" only has \"net negative value\" is the overall expected outcome is negative. War is pretty expensive so it's worth spending a bit of money to avoid it, or at least sway the outcome. The government doesn't want a dollar ROI in the sense of increased revenues because it defines the dollar. What happens to the local currency is just one factor in the overall considerations. reply pjc50 9 hours agoprev\"Stock buybacks are a form of stock manipulation\" - not really, they're a means of returning money to the shareholders while bypassing taxes on dividends. (Not an expert on the US tax system as I'm a Brit, but it seems that the tax treatment of dividends depends on how long the stock is held, and can be taxed at income tax rates, while stock buybacks result in inflating the stock value which is always CGT. Not sure what the tax treatment is for institutional investors?) NB that \"returning money to the shareholders\" is ultimately what companies are for, and we should completely expect them to do this because without it investors wouldn't invest in the first place. It's infinite zero-dividend growth that's weird (Amazon). reply concinds 9 hours agoparentThey're a means of \"returning money\", but they also pump up the stock price, to which managers' TCs are linked. Hence they are a form of manipulation. Unlike dividends, they don't return money to all shareholders, but to those who sell shares, which are the wealthiest, unnecessarily increasing inequality. Excessive buybacks and underinvestment are a big reason why Intel failed. Gelsinger (CEO) talked about this publicly. It's not just \"returning money to shareholders\", because it leads to perverse incentives and underinvestment. Under Otellini, Intel returned 109% of its profits to shareholders. reply throw0101b 7 hours agorootparent> They're a means of \"returning money\", but they also pump up the stock price [â€¦] Stock prices are also effected by dividends: > Dividends can affect the price of their underlying stock in a variety of ways. While the dividend history of a given stock plays a general role in its popularity, the declaration and payment of dividends also have a specific and predictable effect on market prices. After the ex-dividend date, the share price of a stock usually drops by the amount of the dividend. * https://www.investopedia.com/articles/investing/091015/how-d... This has been know since (at least) 1955: * https://www.jstor.org/stable/2976771 reply nabla9 8 hours agorootparentprev>Unlike dividends, they don't return money to all shareholders, That's false reasoning in so many level. Take every of your arguments and do counterfactual and you see. > leads to perverse incentives and underinvestment Investing is not alternative to paying dividends in any well managed company. Companies invest if they see better ROI for the investment than elsewhere. They give money back to shareholders (either dividends or buybacks) when they can't do better than markets. reply yborg 7 hours agorootparentThe positive ROI may accrue primarily to the top executives who are in a position to directly make that decision. Especially in a field like semiconductor processing where risks are high on new investment, it is almost always a lower risk decision to buyback the stock. I don't know the specifics of Otellini's pay package, but I would assume that his tenure resulted in massive wealth for himself, so this is certainly rational economic behavior but severely damaged the company. reply mamonster 6 hours agorootparentWell the other part is that a big part of share buybacks are simply \"sanitizing\" the dilution from stock based comps(which are increasingly the way that most people get paid). Intel SBC was 3.2 billion in 2023, and there haven't been any buybacks I think the last 2-3 years? Quite a bit of dilution which doesn't really make long term investors happy. reply nabla9 7 hours agorootparentprev>it is almost always a lower risk decision to buyback the stock. This is all about buyback versus dividend. How it is that people are thinking wrong counterfactual? reply prepend 8 hours agorootparentprev> Hence they are a form of manipulation. They are a form of manipulation we donâ€™t normally care about. Definitely not illegal. By this definition, productivity is manipulation. Or tax optimization is manipulation. Or IPOs are manipulation. Typically this word is used to indicate unethical and illegal behavior. Not just typical organizational behavior. reply diogofranco 6 hours agorootparentprevBuybacks \"pumping the stock price\" is a common misconception, but not actually true (unless the buyback is executed at prices lower than fair value). There are less shares outstanding afterwards, but there is also less cash, so if executed at fair prices there is no reason for the stock price to move. Just think through an example of a simple company which is a pot of $1000, and can get 10% returns on it. There are 100 shares, so if investors want 10% returns, shares should trade at 10$ (P/B = 1). If the company repurchases half the shares, there will be only 50 shares but the company only has 500$ now, making each share still worth 10$ for 10% hurdle rates. reply robertlagrant 9 hours agorootparentprev> They're a means of \"returning money\", but they also pump up the stock price, to which managers' TCs are linked. Hence they are a form of manipulation. Why would you say they're pumping up the stock price, rather than just raising the price? Is it a temporary pumping effect, like an Elon Musk tweet from 2017, or is it actually increasing the value of the remaining shares? reply thehappypm 7 hours agorootparentLet's say corp XYZ has 100 shares out, and they're owned by 50 people. At any point, there are people trading, buying and selling those 100 shares. Buyer 51 comes along and wants to buy a share. He can only buy a share if one of the 50 owners are selling. So, he has to offer a price that'll convince one of the 50 to sell. XYZ Corp decides to do a buyback. They buy 20 of those shares. In that moment, they will certainly create a spike in demand for the 20 shares. But later on, now there are only 80 shares out. When buyer 52 comes along to buy a share, there are fewer shares, and fewer sellers. He might have to offer more than Buyer 51 to actually get a share for that reason. reply tzs 6 hours agorootparent> But later on, now there are only 80 shares out. When buyer 52 comes along to buy a share, there are fewer shares, and fewer sellers. He might have to offer more than Buyer 51 to actually get a share for that reason. By buying that one share buyer 52 gets ownership of 1.25% of the company. Buyer 51 only got 1.00% of the company when they bought their share. You need to take that into account when comparing share prices. reply robertlagrant 7 hours agorootparentprevThat's not pumping stock, though, right? Pumping stock is artificially increasing the number of buyers, for a short period. You're describing reducing the number of sellers. Which may increase the price, or may not. reply thehappypm 6 hours agorootparentYou could argue that the buyback itself, like the moment where the company actually buys the shares back, is a pump moment. they could have the demand far outstrip the typical demand in the moment. But long-term, the price should be higher as they have decreased supply. reply concinds 8 hours agorootparentprevProbably only the latter. My point was that executives (share sellers) benefit and it creates potentially toxic incentives. reply kjreact 7 hours agorootparentExecutives are always incentivized to increase share value; thatâ€™s their job. Note: itâ€™s the board of directors that issues new shares not executives. Executives can sit on the board, but the two are not the same. Executives are actually appointed by the board. The reason stock buybacks are viewed somewhat negatively is because itâ€™s a lazy way to increase share value. Preferably executives would use the money to come up with new products/services to increase revenues. But if weâ€™re talking about huge mega corporations, who already spend a lot of money on R&D, capex and/or acquisitions, then using some additional cash flow on buybacks makes sense. In Intelâ€™s case, the buyback merits some discussion because it is implied that government subsidies are being used to buyback shares which is not the intention of the subsidy. Edit: IMO, I donâ€™t think Intel underinvested, I believe they invested in many failed ventures and under their past and current leadership they are not able to grow the company in any meaningful way. reply robertlagrant 7 hours agorootparentprev> My point was that executives (share sellers) benefit and it creates potentially toxic incentives. This seems like a good incentive. Executives of course don't have to have any shares, although they probably will, but that's not \"toxic\". I know that toxic is now the blandest word in the language due to overuse, but even given that this seems distortional. reply gruez 8 hours agorootparentprev>Under Otellini, Intel returned 109% of its profits to shareholders. Seems like everything is working as intended. What do you think that companies are supposed to do with their profits? Why do you think shareholders buy stocks in the first place? reply fancyfredbot 8 hours agorootparent> What do you think that companies are supposed to do with their profits? With hindsight it's clear that it would have been better for shareholders if Otellini had reinvested more profit into R&D rather than returning it to shareholders. Intel has now lost their process node advantage to TSMC. Their CPUs are not competitive on power efficiency with AMD and Apple. This is leading to smaller profits and ultimately a worse outcome for shareholders. reply concinds 8 hours agorootparentRight, more R&D and more CAPEX. The question is not whether shareholders deserve any return on their investment (yes), the question is short term vs. long term focus. Same with Boeing (161% of Boeing profits given to shareholders 2013-2019, underinvestment in talent and safety). reply fiprofessor 9 hours agoparentprevPrior to the Bush era tax cuts, all dividends were taxed at the income rate, which I think explains the biggest motivation in the shift from dividends to buybacks in that era. Nowadays, as you say, there is no difference in tax rates for qualified dividends. However, one big remaining benefit of buybacks is that a dividend forces one to incur a taxable event when the dividend is issued, even if one chooses to immediately re-invest the dividend in the company (as many people still in the accumulation phase of investing do). On the other hand, a buyback does not force those people to sell. On the other hand, a buyback should lower the market cap of a stock, so cap-weighted index funds ought to sell and re-balance when a buyback is issued, so most index investors would seemingly end up selling. However, they end up being able to avoid most of the capital gains taxes by re-balancing through redemptions and heartbeat trades. reply gizmondo 8 hours agorootparent> On the other hand, a buyback should lower the market cap of a stock You got it backwards. If a stock is priced fairly, a buyback is value-neutral. Reduction of the cash on hand is offset by the increase of future cash flow per share. It's dividends that reduce the market cap. reply fiprofessor 8 hours agorootparentNo, because the future cash flow per share is not reflected in the current market cap. Perhaps you are thinking of share price instead: there it is true that dividends reduce share price, while buybacks are share-price neutral at least theoretically, though it is commonly believed by many people that they do affect price. (Hence, under that same theoretical model, market cap must decrease if share price remains the same because market cap is total number of outstanding shares * share price. So if the former decreases while the latter stays the same, market cap must have decreased.) reply gizmondo 8 hours agorootparentYou're right, I need a coffee. reply otteromkram 8 hours agorootparentprev> On the other hand, a buyback should lower the market cap of a stock [...] Uhh...what? Buybacks are a return of value. Share prices adjust accordingly to the updated proportion of outstanding stock. Might want to select a new username, friend. reply pliny 8 hours agorootparentThe price of the share stays the same but there are fewer shares, so the market cap would go down. reply mrkstu 8 hours agorootparentBut EPS rises so equilibrium would suggest the price of the share would almost certainly rise to match the old EPS. reply fiprofessor 8 hours agorootparentThe earnings per share certainly increases. But this is (at least theoretically) offset by the fact that the firm's assets have decreased. For example, if the buyback was paid for with cash, then prior to the buyback, the shares represented a claim of ownership not just on future earnings, but also on that cash reserve. That said, this is all under a theoretical model (as in Miller-Modigliani theorem). In practice/empirically, there is reason to plausibly believe that e.g. the decision to announce a buyback has a signalling effect and so can increase share prices. reply mrkstu 5 hours agorootparentIs there a heuristic for how much of the value of a share is assigned to asset value vs forward looking earnings? Many of the â€˜hotâ€™ stocks like Nvidia seem almost all forward looking. reply pliny 5 hours agorootparentFor public companies you don't need a heuristic, as the balance sheet is included in quarterly earnings reports. reply User23 8 hours agorootparentprevWell it certainly makes a market for the lucky duckies who are the counterparties for the buyback. They benefit. reply User23 8 hours agorootparentprevThis isnâ€™t even necessarily true for dividend yield let alone for EPS. reply jenny91 6 hours agorootparentprevBy buying stocks, the company transfers money out of the company and to shareholders. Of course the market cap should go down: the fundamental value of the company has gone down (they have less cash). reply jorvi 9 hours agoparentprev> NB that \"returning money to the shareholders\" is ultimately what companies are for You have absorbed modern market brokenthink. Companies are for creating goods or services to sell to other parties. They existed long before the idea of shareholders. Following your logic, companies pre-VOC had no existing purpose. reply bryanlarsen 9 hours agorootparentBusinesses have always been for putting food on the table of their proprietors. We've got a few more levels of abstraction now, but the fundamental is the same. reply danbruc 5 hours agorootparentWhy does anyone work? Because they need or desire certain goods and services. They entire idea of a business falls flat if it does not produce stuff people want. It is of course true that from the perspective of the business owner running the business is how they work, how they get the stuff they want by making money to buy things, but putting the emphasize on that seems wrong to me, after all you can run a business without trying to make as much profit as possible but you can not run a business that produces nothing. reply ToValueFunfetti 3 hours agorootparent>you can run a business without trying to make as much profit as possible but you can not run a business that produces nothing This is not an even comparison. A business that produces the minimum amount (0) of product/service should be compared against a business that produces the minimum amount (-$assets) of profit, which corresponds to 0 revenue. Neither business can be run, but the former can at least sit on its assets or pivot into actually making something. A business can also produce too much and collapse (see Atari and DeLorean), but it can't collapse from too much profit. It makes more sense to put the emphasis on profit, I think. reply jorvi 3 hours agorootparentYou can run a business with negative profit (say, to capture market share or using a loss leader), but you canâ€™t run a business with negative production. Production is essential to a business and profit is not, strange as that may seem. reply ToValueFunfetti 2 hours agorootparentWhat does negative production mean to you here? I can run an incineration business or a demolition derby, as long as I get paid to do so. If that doesn't count as negative production (because I'm producing space or entertainment value; potentially at a loss to acquire market share), what does? If negative production is a physical impossibility, the claim that you can't run a business with it doesn't tell us anything about business. reply gtirloni 9 hours agorootparentprev> Companies are for creating goods or services to sell to other parties Out of autruism? If not, it's to make money for owners. Shareholders are sort of owners thus to make money for shareholders. reply ada1981 8 hours agorootparentYes, actually. >> For the first companies, the privilege of incorporation, often via royal charter, was granted selectively to facilitate activities that contributed to the populationâ€™s welfare, such as the construction of roads, canals, hospitals and schools. Allowing shareholders to profit was seen as a means to that end. Companies were deeply interwoven within the countryâ€™s or townâ€™s social fabric, and were meant to contribute to its collective prosperity.Companies are for creating goods or services to sell to other parties. They existed long before the idea of shareholders. Following your logic, companies pre-VOC had no existing purpose. Sure, but the owners (sole proprietors, shareholders, partners, etc.) of most companies want to make profit selling those services and goods. The more money you make the more you can grow the company or reward yourself (as owner). reply carlosjobim 8 hours agorootparentprevCompanies never existed without shareholders. It's in the name: \"company\", ie a group of people. You're thinking about \"ventures\" or \"businesses\". Which would exist by decree of the sovereign, for example. reply delusional 9 hours agoparentprev> NB that \"returning money to the shareholders\" is ultimately what companies are for And here I thought Intel was for producing computer chips. Silly me. I forget the entirety of human history was just an elaborate pyramid scheme. reply aembleton 8 hours agorootparentComputer chips that they sell for a profit that they return to shareholders reply boh 8 hours agoparentprevFrom a basic economics perspective, companies conduct buybacks when they have no other use for the money. Since re-investment supports shareholders on a longer timescale, Intel has essentially let the market know they don't have any other use for the money they have. The point of investing in a company is the funds to be used to generate wealth. If I invest in your company and you just give me back my money, what's the point of the company (especially if its money requiring extra leverage to produce). Buybacks are inefficient use of invested capital (see NVidia's stock price if you need a comparison for a more efficient use of cash and its effect on shareholder value). reply gizmondo 8 hours agorootparentWhether they are efficient or not entirely depends on the company. For every NVidia you can find another company (or ten) that reinvests inefficiently because managers tend to like building empires at the expense of their shareholders. reply boh 4 hours agorootparentOf course. Intel, specifically, does not make a compelling case that they spent their cash efficiently. reply onetimeuse92304 8 hours agoparentprevIt is a silly notion there is anything wrong per se about stock buybacks. Just as you can sell stock when you need cash (and lose some control) it is simply buying stock back when you saved some cash (and regain control). The only reason stock buybacks are thought of in negative light is that they seem to be a way for companies to not pay taxes... but the tax law is not companies' fault! It is our fault for the tax law to be this way! reply harimau777 8 hours agorootparentDon't the companies, their industry organizations, and the people who own them lobby congress to make that tax law? It seems to me that in that case, tax law is their fault. reply bradleyjg 9 hours agoparentprevI have no idea why journalists have such a hate boner for stock buybacks. Dividends can get favorable tax treatment too. Just allows owners to time the tax hit. reply matwood 7 hours agorootparentIt's like I mentioned when this came up yesterday, it's just a favorite boogieman. reply supertrope 1 hour agorootparentprevMost people don't own individual stocks. So their audience just pictures top hat wearing capitalists when they hear stock buybacks. It's the same reason why tenants garner sympathy while landlords are quickly called slumlords. reply Workaccount2 7 hours agorootparentprevIt gets clicks from people who aren't old enough yet to have any assets. reply patrickthebold 9 hours agoparentprevCouple of comments: Usually when people buy shares they are going to try and get the most shares for the least amount of money, but the incentives are a bit different for stock buybacks. I don't know if buybacks are large enough to \"move the market\" but I'd be curious to see details on how exactly orders are placed. I'm a big believer that we need more non-profits that simple exist to employ people and provide goods and services. I realize this is just a charity and depends on the good will of people with capital. reply overstay8930 9 hours agorootparentYou're probably thinking of co-ops, it is much harder to be a non-profit for most types of companies. reply andmarios 9 hours agoparentprevIt can be both at the same time. By buying out your stock, you alter the company's assets, but the price of the stock remains the same since you still have the same number of stocks issued. You just replaced your money assets with stock assets. Once you cancel the stocks you bought back, the rest of the shares will hold a more significant percentage of the company and increase in value. But this is one part of the equation. The other part is that your stock is inside a market, and buyers and sellers combined determine its price. If you keep buying your stock, you create buying pressure, helping keep the price from falling. reply boringg 9 hours agoparentprevStock buy backs functionally work no different them dividends at the end of the day. Your returns instead of getting issued as cash from a dividend are in the form of higher share value. Taxed as short term or long term capital gains vs dividend. Its a form of stock manipulation if you mean that buying stock increases the value of the stock. It doesn't mean its a form of manipulation in some kind of illegal unethical way that i think this comment thread is trying to make it sound. reply jsiepkes 9 hours agoparentprevIt's stock manipulation, we just chose not to see it as such. Just like alcohol is objectively a hard drug but we just chose not to categorize it as such. reply gpderetta 9 hours agorootparentIs a company issuing its own stock (i.e. selling) also market manipulation? It brings the price down. Buyback is the reverse operation. The difference from actual price manipulation, is that the price change in issues and buybacks is a permanent effect of the material change of the number of outstanding shares, not a fledging effect of the change in trade volume, i.e. the intrinsic value of the stock goes up or down. edit: of course buybacks, like dividends, decrease the value of a company, and issuing stock increase it, so it is not clear cut. reply pjc50 9 hours agorootparentprevWhy is company X buying its own stock on the open market \"manipulation\" rather than any other purchaser? reply Drakim 9 hours agorootparentWhy is me buying my own book to bring it to the best seller list any different than any other purchaser? Stocks are supposed to be a share of ownership in a company, and the price goes up and down because being an owner of a company goes up and down in desirability, based on how well the company is doing. Just like with buying your own book, buying your own stock artificially increases the desirability. reply pas 9 hours agorootparentthat's an argument for why best seller lists are stupid. companies can create new stock anytime out of thin air, and that decreases the price. why can't they do the opposite? some owners of the company decide to buy stocks from the others, thus consolidating ownership. that's what stock buyback is. note, the argument for taxing buybacks is completely different, and valid. (and it might make sense, it might not, it depends on the circumstances. externalities tax (pollution, tax on induced traffic, etc), LVT (land value tax) and wealth tax would be much better, than taxing transactions.) reply jmholla 5 hours agorootparent> companies can create new stock anytime out of thin air, and that decreases the price. why can't they do the opposite? So at any point, a company can devalue existing shares that people have already purchased? That also sounds like a problem. reply pas 2 hours agorootparentsure it can be securities fraud, but usually it's done to attract more investors. companies on stock exchanges usually do stock splits, etc. (and based on bylaws majority or 2/3rs or more of existing owners need to approve.) reply robertlagrant 8 hours agorootparentprev> Why is me buying my own book to bring it to the best seller list any different than any other purchaser? What's the best-seller list in this case? reply bvaldivielso 9 hours agorootparentprevThis is a misunderstanding of what stock buybacks are. Companies do not buy their stock from themselves. They buy the stock from participants in the market. Following your example, it'd be like the author of a book buying the book they wrote from someone else. If the author chooses to pay someone else 1000$ for their book, they can, but they will be wasting money. A company doing a stock buyback is trading off their own capital (they have to spend it, it's not an infinite money glitch where they buy it from themselves) to get back shares of the company itself at the then-market-price. The market chooses whether that's a good trade. It may not reply jsiepkes 9 hours agorootparentprevBecause you have inside knowledge and you are altering the stock price. reply koolba 9 hours agorootparentThe company is in charge of itself. Everything it does alters the price. Bought back shares strictly increase the price for existing shareholders as it takes them off the market. The entire concept is mainly due to stupidity in tax law that ends up double taxing direct dividends. reply chongli 9 hours agorootparentprevStock buybacks are heavily regulated. They need to be tracked and publicly reported and the plans for buybacks need to be announced by the company ahead of time. reply jomohke 9 hours agorootparentprevNote that buybacks must be announced beforehand by the company, so everyone selling their shares has the same knowledge. reply Retric 9 hours agorootparentprevBecause itâ€™s independent of other price signaling mechanisms. The company doesnâ€™t buy the stock because it thinks that stock is a good investment, it does so because of how it influences future prices. Ignoring inflation if a company issues the same inflation adjusted dividend forever say 1% at current prices. In theory the stock should stay roughly the same over the next hundred or thousand years. However, with a buyback the stock would increase constantly forever with endless stock splits. The second option is great for long term owners in terms of taxes, but itâ€™s also manipulation of the stock price. reply davrosthedalek 9 hours agorootparentNo, it buys it /because it has money to spare/. Having the money to spare makes it a good investment. reply Retric 9 hours agorootparentCompanies can have net profits and be terrible investments. The exact same company can be a great investment at 10$, and a terrible investment at 10,000$. You canâ€™t separate stock price from if something is a good investment or not. The example I gave was low risk 1% dividend, thatâ€™s not a stock I would want to own. Net result the company, which has inside information, should expect the price to correct ie fall at some point and thus be a poor investment until that point. That doesnâ€™t prevent them from buying it because the goal isnâ€™t a positive ROI. reply wmil 9 hours agorootparentprevIf you're going to stretch the difference that much the why not go all out? CEOs are constantly attempting to manipulate the stock price by trying their best to do a good job. reply daft_pink 8 hours agoparentprevJust want to mention since many commentors on this seem to miss this, three important points about stock buybacks missed by the back and forth partisan talking points on this comment: 1. They only make sense when the stock is undervalued and arenâ€™t purely driven by taxes. If the stock is undervalued, then investors benefit by owning more of the company for less. If the stock is overvalued, then investors donâ€™t benefit. The overall value of the price compared to its long term real value is important. There is a basic problem with this, because company executives probably never want to admit that their stock is overvalued. 2. Companies with strong incomes relative to their price can afford to do buybacks or with strong cash positions are the ones that make sense to do buybacks. Companies like this might be overvalued. When you see companies internet companies with zero income doing buybacks it makes very little sense and only established companies. Companies with strong financial positions relative to their stock price are more likely to be undervalued. 3. Because of the discounted cash value of income model for dividends where the value of a stock is based on future income and cash flow, dividends generally have to be stable and regular to ascribe significant value to a stock, which is why companies that have built up large cash balances but donâ€™t expect to regularly pay dividends opt for buybacks, because they donâ€™t want to create the constant pressure to regularly pay dividends. reply nr378 8 hours agorootparent1. Stock buybacks are always anti-dilutive regardless of the value of the stock, and so investors always benefit as future earnings are concentrated amongst fewer shares (all other things being equal). It's true that a lower price/value increases the magnitude of this effect, but the effect is always present. 2. Zero income stocks can still do buybacks when they're returning capital raised from shareholders to shareholders (this is essentially just partially reversing a funding round, which again undoes some of the dilution). 3. Companies can be deemed to be significantly valuable without paying any dividends. Companies that have a long history of paying dividends but then suddenly stop tend to be in distress, which is then reflected in their share price. reply daft_pink 6 hours agorootparentThese statements might be logically true, but I feel the logic ignores the overall strategic factors involved in buying back stock and that management needs to consider whether the stock is over or under valued, whether earnings are strong enough for this to make logical sense and the supply and demand among investors for dividend stocks and the ultimate value of a single lump sum distributed to investors vs the value of increased future earnings to the investor from the anti-dilutive impact of buying back stock. Discussing only the tax strategy as is happening in this thread is really stepping over some really important strategic operational factors. reply throw0101b 7 hours agoparentprev> NB that \"returning money to the shareholders\" is ultimately what companies are for [â€¦] That is one theory of corporate governance: * https://en.wikipedia.org/wiki/Shareholder_value * https://en.wikipedia.org/wiki/Friedman_doctrine There are others: * https://en.wikipedia.org/wiki/Stakeholder_theory * https://corpgov.law.harvard.edu/2012/06/26/the-shareholder-v... * https://sloanreview.mit.edu/article/the-shareholders-vs-stak... reply tgv 8 hours agoparentprevTrading stock isn't investing. There's no reason for companies to give money to shareholders that simply bought their shares on the stock market. The company doesn't profit from that. reply dubcanada 9 hours agoparentprevTax just depends on how long it's held and if it is part of a major index. If you held long enough and it's part of a major index it is taxed the same as a stock buyback would (assuming you sold). Otherwise it's taxed as income. reply danbruc 7 hours agoparentprevNB that \"returning money to the shareholders\" is ultimately what companies are for [...] This could not be further from the truth. Companies - and actually the entire economy - only exists for one purpose, to satisfy the needs of the people, to efficiently produce good and service that people need or desire. Profits are just means to the end, a control signal to steer the economy. Not that they are not important, but they are not why we have companies. reply oatmeal1 9 hours agoparentprevAgreed. It is a huge problem though that share buybacks are a way actual production (wages) is taxed at a higher rate than passive income. reply miga 5 hours agoparentprevStock buybacks return money to the investors. reply throwaway_ab 9 hours agoparentprevFor them to be effective at returning money to shareholders, the action of buying stock is intended to take stock out of supply thus increasing share price value. Exactly as you say. Yet, this is clearly a form of stock manipulation, as it's an action to manipulate the share price. Whilst it is stock manipulation, it's debatable if it should be legal. I believe it should be legal, it's an efficient way to increase share value without adding to someone's income, thus often carries no immediate taxable obligation. However one could argue that these methods of moving wealth around without taxable events triggering adds to the fuel for calls to tax unrealised gains on all stock. So in the long run we are all worse off. Those laws will likely come regardless, as a way to fight the billionaire class, so stopping stock buybacks at this stage is unlikely to do anything. reply matwood 7 hours agorootparentDividends also change the share price, should those be illegal? What about announcing new products? reply Drakim 9 hours agorootparentprevIt does effectively legalize a form of insider trading though, a company would never do a massive stock buyback right before dropping bad news because the stocks they are now holding goes down in the price. reply andsoitis 9 hours agorootparent> form of insider trading Rule 10b-18 is designed to prevent companies from using buybacks to manipulate the market, stating that share buy backs must meet 4 conditions: 1. all shares must be purchased during a single day and from a single broker or via a single deal 2. larger companies cannot authorize buybacks within the last 10mins of the day and smaller companies can't authorize them within the last 30 mins 3. companies have to buy back their stocks at a price lower than or equal to the highest independent bid 4. companies can't buy back more than 25% of the average daily volume reply StableAlkyne 8 hours agoparentprev> not really, they're a means of returning money to the shareholders while bypassing taxes on dividends. This is actually a new idea. Prior to a change by the Reagan administration in 1982, they were considered to be an illegal form of market manipulation. Dividends served the purpose of dumping excess funds to shareholders. reply User23 8 hours agoparentprevStock buybacks only pass money to those shareholders whose stock the company buys back. The buyback may raise the overall market price of the stock, but it also might not. reply ClumsyPilot 8 hours agoparentprev> NB that \"returning money to the shareholders\" is ultimately what companies are for And here I thought companies are there to provide me, the consumer, and the customer, with useful products and services. If the purpose is return of money to shareholders, then the best strategy is to over leverage the company, spend every penny on stock buybacks, then default on all obligations to suppliers, pension funds and customers. Because you can fund stock buybacks with debt, but you could not do that with dividends. We have made economic destruction profitable and itâ€™s happening across our economy - water companies in UK are going bankrupt because they have huge debt that they took out just for stock buybacks, and not for anything else, and now interest rates are up. Same thing happened with airlines, and many other firms. reply pjc50 7 hours agorootparentIt's always been \"both\"? (specifically for the PLC-type company). People invest in the expectation of a return, to be achieved by doing business. It's usually phrased as \"maximize shareholder value\", which is ambiguous about the timeframe, but for most cases the value is understood to be over the indefinite future. Not that that stops people from taking short term decisions which can be bad in the long term. > Because you can fund stock buybacks with debt, but you could not do that with dividends. There are plenty of companies with large debs that pay dividends on the US market, such as Ford. The overleveraged self-destruction is bad, but that tends to be a feature of private equity deals where there is a single majority owner doing it on purpose (e.g. Maplin, Jaguar Land Rover). Harder to do with a publicly owned company where the investors can see what you are doing and may sue you. The UK water companies should never have been privatized in the first place. They're dysfunctional because water isn't a normal market and arguably can't be, so they're ripe for this kind of looting of the state by capital depletion. reply scotty79 9 hours agoparentprev> \"returning money to the shareholders\" is ultimately what companies are for That's what shareholders want you to think. But societally and economically companies are mostly for everything else. If no company ever paid a single dividend or never bought back any of its stock nothing bad would happen. There are a lot of companies doing exactly that. But if companies stopped doing everything else they do that they are supposedly not for, the economy would end. reply fiprofessor 8 hours agorootparentWho would invest in or create a company that would never pay a dividend and never bought back its stock? How would shareholders ever yield gains from their investment? Short of some entity buying all stock and taking the company private (to then withdraw profits), there would be no way to return profits to shareholders. The companies currently not doing those things are in a growth phase, with the expectation that in the future they probably will be issuing dividends/buybacks. reply Aspos 8 hours agorootparentThose who benefit from the company exist would invest in it: state, employees, clients. reply Eisenstein 8 hours agorootparentprev> The companies currently not doing those things are in a growth phase, with the expectation that in the future they probably will be issuing dividends/buybacks. Berkshire-Hathaway has only paid dividends once since Buffet took over, and is the highest priced stock listed on the NYSE. reply fiprofessor 8 hours agorootparentBut Berkshire Hathaway does do stock buybacks. reply mypastself 9 hours agorootparentprevExcept that even then, an investor can sell their shares. If they couldnâ€™t, no company would ever be able to raise money in a public offering. reply paganel 9 hours agoparentprev>NB that \"returning money to the shareholders\" is ultimately what companies are for That's debatable in many instances of the modern economic system. Of course, some instances of capitalism focus on that particular goal you've mentioned, but that wasn't always the case and it still isn't, depending on the socio-economic circumstances. reply bradleyjg 9 hours agoprevNo one needs $8 billion in subsidies. But thatâ€™s how we run the United States now. Thereâ€™s no longer comprehensive legislation trying to solve a particular (perceived) problem. Instead we just drop money from the sky on various people and companies. Thereâ€™s a pandemic? Quick, cut 80% of the country a check. The childcare industry is structurally understaffed and unprofitable, letâ€™s just cut them all checks! Higher education keeps on growing to larger and larger percentages of GDP? Thatâ€™s okay weâ€™ll just cut checks blank tuition checks and then forgive all the loans. China is signaling that it might invade Taiwan. Thatâ€™s a tough one. Hmm. I got it, letâ€™s cut a check to semiconductor manufacturers! reply vasco 9 hours agoparentMy question shouldn't imply I disagree, but what's the alternative to allocating capital to industries or problems where government wants to drive change? reply bradleyjg 9 hours agorootparentRegulation or deregulation. Take loan forgivenessâ€”-the loans themselves are not the underlying root issue. They are a tertiary effect of a credentialism spiral and insane cost growth at institutions that donâ€™t face true market pressures. Just dropping money on borrowers is not even attempting to fix the underlying problem. Itâ€™s so unambitious it invites cynicism. reply ethanbond 8 hours agorootparentAnd how do you propose the government try to fix credentialism? For all the talk about how useless degrees are, companies still choose to require them, especially the companies helmed by â€œcollege is a scamâ€ zealots. reply bradleyjg 8 hours agorootparentCompanies have to still require them because they are a valuable signal and itâ€™s free to them. Kids have to go because companies require them. This is what a peacock spiral looks like. Government is fundamentally for breaking these kind of incentive failures. Not supercharging them through blank check forgivable loans. reply ethanbond 8 hours agorootparentNo, companies donâ€™t have to require them. Agreed the loan behavior exacerbates the issue rather than mitigates it, but â€œthe current solution is badâ€ doesnâ€™t necessarily mean the same agent is able to produce a good solution. If youâ€™re certain the government is capable of breaking it: how? reply bradleyjg 8 hours agorootparentI have ideas but if I post them, Iâ€™m guessing you are going to pattern match me to some ideological category and try to debate from that point of view. Thatâ€™s not my point at all. Itâ€™s that all our federal politicians and political parties have had their ambitions shrunk down to nothing. No one at all is sayingâ€”-hey this credentialism thing is a serious problem, vote for us and hereâ€™s how weâ€™ll attack it. Even if someone was proposing an idea I totally hated, I would at least appreciate the effort to actually solve a real problem. If you think credentialism is impossible for the government to make a difference on, pick something else. Anywhere you look for the last 14 years weâ€™ve had few to no ambitious proposals. reply ethanbond 6 hours agorootparentErrmmm... okay. The Biden administration actually has both talked extensively and taken several concrete steps against credentialism. Effective? I personally do not know. But it's blatantly false to say no one is talking about it or attempting to fix it. > The Department of Labor (DOL) is announcing an Advanced Manufacturing Registered Apprenticeship Accelerator Series that will support hundreds of employers to speed the development and launch of Registered Apprenticeship programs in high-demand occupations, such as industrial manufacturing technicians, robotics technicians, and industrial maintenance mechanics. Since the beginning of this Administration, the number of apprentices in advanced manufacturing Registered Apprenticeship programs has increased by 10 percentâ€”and this effort will build on that growth. The administration has backed numerous apprenticeship programs like BioFabUSA that explicitly do not require college degrees. The administration created \"Investing in America Workforce Hubs\" in several cities to attract private investment into programs that, again, prioritize high-quality jobs that do not require college degrees. So it is simply untrue that no one is saying credentialism is a problem and trying to attack it. The current administration talks about this to no end and has attempted dozens and dozens of substantial attacks on it. Again, if you have ideas other than grant funding and tax incentives, I'm truly curious to hear them. reply lossolo 8 hours agorootparentprevYou still do not offer any alternative solutions to problems you presented in your original post. reply vasco 8 hours agorootparentprevThanks for ellaborating! Although de-regulation and regulation have other properties, I'd posit they are in essense are forms of capital allocation. When you regulate an industry you require more capital investment from that industry, either by investing in new processes, implementing compliance mechanisms, maybe hiring extra quality-assurance people or having to dispose of trash in a better way, etc. Regulation mostly implies more investment by the participants in that specific segment of the market, it's like a reverse capital injection, or an added tax. The same way de-regulation is like giving that segment of the market a cash bonus because they can relax processes that require money to run and operate more efficiently. More importantly regulation and deregulation also add or remove rules, so they change the behavior of the participants. If you want to have the same effect of regulation and deregulation but not by driving change in rules of operation (maybe because as the government you don't know yet which rules to create - or the different political factions cannot agree), an easier way is to directly give money, and depending on how you allocate it, I think it can be a fair way to do it. Another way of thinking about this as a system is imagining the case where you want to promote investment in the semi-conductor industry but not at the expense of processes. Said another way, what would you de-regulate in the semiconductor industry to have the same effect as a capital injection to the leading semiconductor companies in your country? Surely you're not proposing them to be able to use more dangerous chemicals and dispose them however they want, or other types of de-regulation? It would reduce the barriers to entry and help semiconductor companies, but with negative externalities. Messing with regulations always has this potential for unpredictable secondary effects. I'm not convinced regulation/deregulation is in principle superior to just allocating money pools with fair rules to access them. I'm obviously against nepotism and influence peddling as part of the money allocation process and I'm not defending the injection into Intel specifically, which probably suffered from a big amount of influence peddling. reply wakawaka28 7 hours agorootparentprevTuition has only exploded because of unlimited government-backed student loans. They created this problem with the \"good intentions\" of providing everyone an opportunity to study any subject at any price regardless of job prospects. The problem isn't credentialism per se, although a large number of people were advised to go to college for the most generic stuff on the theory that \"any\" college degree doubles your lifetime earnings no matter what you study. reply YetAnotherNick 7 hours agorootparentprevRegulations is one of the major reason semiconductor industry shifted overseas. US used to be the undisputed leader in semiconductor manufacturing. If you think Intel will stay regardless of US regulation, you are definitely wrong. China will always allow manufacturing with minimal regulations. reply Drakim 9 hours agorootparentprevThe government as the strongest central power identifying weak or struggling areas of the country that needs help makes sense. That's like primary advantage of central power in the first place. The issue is that things like lobbying ends up shifting that focus over to already strong parts of the country that wants even more. reply vitiral 5 hours agorootparentprevTraditionally I believe tariffs and trade agreements were the typical approach at shoring up domestic production. I have very little knowledge over their current effectiveness or use. reply dgfitz 9 hours agorootparentprevCap tuition costs, raise wages for daycare centers? reply constantcrying 6 hours agoparentprevSure, but what is the alternative? Government subsidies keep the whole thing afloat, there is no removing them. And obviously that is by design. There is a marginal utility to increasing funding, but that isn't the point, the point is that the subsidies guarantee that the receiver is dependent on the sender. reply gtirloni 9 hours agoparentprevAs opposed to doing what in those cases? reply lossolo 7 hours agoparentprev> Thereâ€™s no longer comprehensive legislation trying to solve a particular (perceived) problem. Of course, there is, but some problems are different and difficult. Why are they difficult? Because it's hard to find an alternative solution that ticks all these boxes: one that is socially acceptable to all parties involved, does not incur additional problems or direct costs to any specific party or group of interest, and does not disrupt the market, among other considerations. You also need to take into account current laws, the social contract, and politics. Sometimes, the most efficient, easiest, least disruptive, and most acceptable solution is simply to allocate funds to address the problem. reply overstay8930 9 hours agoparentprevâ€œRaising children is expensive, letâ€™s make sure we make it even worse for them by removing our strategic autonomy!â€ Youâ€™re free to believe what you want, but you should probably reevaluate your position when itâ€™s parroting 1:1 what Chinese bots are spreading. reply shortsunblack 8 hours agoprevIf Intel is so important to national security, it should be nationalized. If Intel is not willing to willingly invest into U.S. manufacturing, it can be targeted with tariffs. A corporate handout by the taxpayer is not what should happen, though. And yes, stock buybacks are a form of market manipulation. That's why they were banned before Reagan. Funnily enough, SEC unbanned stock buybacks by using the Chevron deference, which is currently being challenged in courts. EPA being unable to regulate climate change might be offsetted by a minor win of making SEC not ignore law anymore by asserting its legitimacy. reply prepend 8 hours agoparentNationalizing is unlikely to increase productivity and innovation. Thereâ€™s multiple competing goals here and we need to think about how to achieve them. If we think that Intel is fixed and unlikely to need to change, perhaps nationalize and then just operate it as it slowly declines. But thatâ€™s also going to make other chip companies less likely to invest in the US as few investors want their investments nationalized. The purpose of these economic investments isnâ€™t primarily moral justice (although I think that should be part of the calculation). The purpose is to increase US chip production. It seems quite silly to think that nationalizing Intel would lead to greater US chip production. reply shortsunblack 7 hours agorootparentChina is banning Intel and AMD chips from their gov't use. When they catch up with tsmc in 7nm, they'll likely make an import ban on all U.S. chips. Who then will AMD and Intel sell to? Aging European population? Africa as it develops? Africans are likely to buy Chinese chips, seeing for all the material infrastructure China invests in. Intel and AMD will only sell to American-alligned countries, which are declining. Seizing the company and milking till it runs dry is the right move. Intel had all the capital it needed to innovate. It did not. The company is unable, despite all the cash it has on hand. It's a lost cause. One hopes AMD continues innovating. reply constantcrying 6 hours agorootparentThis is completely delusional. China isn't the entire world and trashing your own manufacturing because one market might somewhat soon see increased competition is a legitimately insane policy proposal. Also Intel did innovate, very clearly so and they don't compete with AMD when it comes to manufacturing at all. reply shortsunblack 6 hours agorootparentAMD has 1.5x larger market cap than Intel. All in 7 or so years where it was near bankruptcy. During AMD's weakness, Intel had near monopoly position on chips. It racked up all the cash it could. It hasn't innovated ever since. Chiplets came from AMD, 6 cores as minimum standard came from AMD (Intel sold 4 core entry CPUs well into Zen era because that's all you need!). Affordable motherboards (together with partners) and strong commitment to socket longevity came from AMD (AM4 is still supported and new products with 5600x3d are still released). In reference, Intel before AMD's Zen would release a new socket for each yearly release. And in fabs, Intel just isn't nowhere close. How's the 12nm++++++++++++ going? China is 5.2B of AMD's sales (2022). That's 65% of U.S.' with enormous growth potential as Chinese middle class gets richer. Europe is 1.77B of AMD's revenue. How does the capex investment equation play out when your 5.5B of sales just disappears into thin air? reply constantcrying 6 hours agorootparentMarket caps are literally made up by how investors feel. Intel and AMD aren't competitors in manufacturing semiconductors, as in they literally do not compete in that market. AMD isn't manufacturing, they are totally irrelevant when it comes to the discussion. >It hasn't innovated ever since. What are you on about? This is ridiculous. Do you know anything at all about this subject. reply sloowm 7 hours agoparentprevThe main problem of course is that the US government is so dependent on a single company because they allowed the instruction set to be protected IP since forever, allowed imports from countries without demanding they provide the same labor and environmental protections and they didn't invest in a well educated population that would allow for new advancements to be homegrown. If the buybacks are undesirable they should tax them. If Intel is trying to divest they should start working towards alternatives and put the government contracts towards companies that do not create these issues. reply Workaccount2 7 hours agorootparentThe instruction set has nothing to do with semiconductor fabrication... The reason Intel is the only one is because cutting-edge chip making is arguably the most capital intensive and challenging industry in the world. There are literally only three companies on Earth who do it. reply paxys 7 hours agoparentprevIf we ban stock buybacks then should we ban companies from issuing new shares as well? Why is one manipulation but not the other? reply nabla9 8 hours agoparentprev> And yes, stock buybacks are a form of market manipulation. Stock buybacks are not different from dividends, except for tax reasons. reply gmm1990 8 hours agorootparentthey reduce the supply of stock available, that is a difference. If its material is a different question, I'd argue it is but don't have data to back that up. If a company has to buy back 10 billion in stock over a fixed time period market participates should be able to drive up the stock price knowing they will have a buyer (the company) to sell to later. reply nabla9 7 hours agorootparentLets go this trough: Before: I own 100 stocks worth $100 each. =$10000. Option 1: 2% dividend. I have 100 stocks worth $98 each + $200 =$10000. Stock value drops immediately. Option 2: equal sized buyback: I have 100 stocks worth of $100 each = $1000. Buyback does not increase the stock value immediately. Company pays $200 for those who sell, but owns the stocks (or shareholders 'own them') so it's net neutral. This reduces the number of shares outstanding, thereby inflating (positive) future earnings per share. This typically leads to the value increasing. reply maxerickson 5 hours agorootparentprevBeing taxed differently is pretty significant. Kind of weird to impose a tax and then also have an easy way around it. reply nabla9 3 hours agorootparentIt just delays taxation. It's more important for small investors in the US, because in the US even index funds must pay tax for dividends. Here in EU we can buy US index funds not available for US citizens where dividends are reinvested without tax. For us it does not matter that much. reply maxerickson 34 minutes agorootparentIn a hand wavy theoretical sense you can maybe say it \"just\" delays taxation, but shareholders aren't going to go out of their way to ensure that they sell at a price that incurs the equivalent taxation. And then a tax that sort of directly relates back to the cashflow of the company is not equivalent to a tax that is based on the capital gains that shareholders end up with. reply wakawaka28 8 hours agoparentprevIt would be unfair to only put tariffs on Intel. Maybe tariffs could be part of the solution to retain essential production capacity in the US though. It should have been done before production left, though. Right now there is very little production left in the US for anything. reply transcriptase 9 hours agoprevBecause without it they will build somewhere cheaper to operate and then U.S. doesnâ€™t have a fab if/when China absorbs Taiwan. Itâ€™s not that difficult of a concept. And no, like others will inevitably suggest you canâ€™t just legislate a multinational company to build its facilities onshore because you need them to. If you need something from a company you make it worthwhile, which is whatâ€™s happening here. reply justin66 9 hours agoparent> And no, like others will inevitably suggest you canâ€™t just legislate a multinational company to build its facilities onshore because you need them to. Itâ€™s weird that people have forgotten this is a thing the government can do. reply transcriptase 8 hours agorootparentEven weirder that people have forgotten about the concept of second order effects. Which would cost the nation more? a) Setting a modern precedent that any company doing business in the U.S. can suddenly be treated as if theyâ€™re somehow owned by the U.S. government and forced to make capital expenditures against their will. b) A $8 billion subsidy that will eventually be recouped or at least offset by economic benefits. reply justin66 7 hours agorootparentI was just pointing out the silliness of acting as if a possible thing thatâ€™s been done before is impossible. I wasnâ€™t advocating a course of action. Pretty much every time we arrange things to favor or necessitate domestic production in an industry, itâ€™s done in the name of security (defense contracting and agriculture come to mind). Including semiconductors in that category is not crazy, and there is certainly more than one way to bring about those incentives. reply pjc50 7 hours agorootparentprev> Setting a modern precedent that any company doing business in the U.S. can suddenly be treated as if theyâ€™re somehow owned by the U.S. government and forced to make capital expenditures against their will. It's amazing how many people on here seem to think that the first response to China should be to turn the US into China and start doing state-directed capitalism. Maybe \"disappear\" a few dissident CEOs. reply transcriptase 7 hours agorootparentNo kidding. I never thought I would see a thread on here polluted with people saying the United States should start behaving like an authoritarian communist apparatus and nationalize or arbitrarily coerce corporations versus coming to a mutually beneficial financial arrangement. reply justin66 7 hours agorootparentI'm just impressed by how people are willing to, out of ignorance or... whatever, write things that obviously not true and then caricature other commentators as communists. I imagine this level of dialog exists on Fox News websites or something, but you should try harder here. reply transcriptase 6 hours agorootparentFor what itâ€™s worth I wasnâ€™t referencing you specifically. There were, at the time of my last reply, people elsewhere in this comment section advocating for exactly what I mentioned. My apologies. reply justin66 6 hours agorootparentThanks. reply eecc 9 hours agoparentprevWell, no? You can always target the company wirh crippling import tariffs unless it gets onto a roadmap to re-shore the strategic production you want them to. Of course, whether it works or not depends on your leverage as a country: the US should easily pull it off, it's the legislator that doesn't want to play that card for political positioning reasons. reply transcriptase 9 hours agorootparentCrippling tariffs on the thing youâ€™re trying to secure access to. And what happens when China says to Intel â€œhereâ€™s 60 billion a year, donâ€™t worry about America just keep doing what you do bestâ€? reply ethanbond 8 hours agorootparentEasy: https://en.wikipedia.org/wiki/Merck_&_Co.?wprov=sfti1#Nation... reply constantcrying 6 hours agoparentprev>And no, like others will inevitably suggest you canâ€™t just legislate a multinational company to build its facilities onshore because you need them to. Of course you can. But if you do, you have to accept the consequences. Again and again people here pretend that just becythe government does it there will be no consequences. reply lancesells 8 hours agoparentprevI'm not advocating or endorsing China invading Taiwan here but would that mean chips stop coming? Or is the fear they get backdoored? Would $8B be better used for a startup instead of IBM? Or is $8B far too low for a new company. reply pjc50 7 hours agorootparentCapturing TSMC intact by force is .. unlikely. Assuming it survives the fighting, there's definitely both Taiwanese and US factions advocating for blowing it up. https://press.armywarcollege.edu/cgi/viewcontent.cgi?article... ; all it would take is one patriotic officer in the retreat to decide to deny it to the enemy by chucking a grenade in the clean room, and the equipment is toast. Russia burnt down Moscow to deny it to Napoleon, and Hitler ordered that the same be done to Paris (but in that case the officers decided not to obey). A more likely scenario is simply that threats and internal political pressure cause Taiwan to \"\"voluntarily\"\" unify with the mainland. $8bn buys you about one (1) fab, but you also need the staff and institutional knowledge to run it, so realistically it has to go to some company that is already operating a similar fab. reply anonymousDan 9 hours agoparentprevI mean, you quite clearly can legislate that. Whether it's a good idea or nonis a separate question. reply transcriptase 9 hours agorootparentTrue. It comes down to whether or not it will cost more than $8 billion to attempt. And what would the enforcement mechanism be? â€œSorry Intel, if youâ€™re not going to play along with our attempt to coerce you into making sure we have a supply of chips then weâ€™re not going to allow you to sell chips here.â€ Seems a bit self-defeating. reply ethanbond 8 hours agorootparentIt has worked just splendidly before: https://en.wikipedia.org/wiki/Merck_&_Co.?wprov=sfti1#Nation... reply ejb999 9 hours agoparentprevtariffs and or new taxes on the chips imported from other countries would have served that same purpose - without the need for more billions of corporate welfare. reply eterevsky 8 hours agoprevStock buybacks are just a form of dividends. It's still subject to taxation via capital gains tax. Subsidy is just a way to create an incentive for Intel to build manufacturing facilities in the US. It's not paid because Intel lacks funds, but to ensure that factories are built in the US and not elsewhere. Intel can do whatever it wants with the money received from subsidies, provided it fulfills its obligations. Jobs aren't particularly important in this schema, but they are a nice talking point for politicians to show that at least part of the money paid via subsidies will return to American workers. reply specialist 6 hours agoparentAs stated elsethread, buybacks defer taxation. It allows the investor to control the timing of the taxable event. reply paol 9 hours agoprevIt doesn't need it, it's simply in a position where it can get it. From their perspective it's free money. It's the same situation with car manufacturers, they do this all the time. They get massive subsidies (usually in the form of permanent tax breaks) by pitting the governments of prospective factory sites against each other. (It's actually a form of the prisoner's dillema: governments would benefit in the net if no-one offered these subisdies, but the prize for defecting is just too great so someone always does.) reply vitiral 9 hours agoprevSomebody correct me if I'm wrong. I always thought of \"stock buybacks\" as a form of \"debt payment\". Stocks are created by companies out of thin air, as a tech worker I am (partially) paid in stocks. Those stocks aren't purchased by my company on the open market, they are manifested -- diluting shareholder stock. Buybacks put a payment on that \"loan\". I doubt people would be so up in arms about companies paying off their debt, even prematurely. The number I'm more interested in is total stock buybacks / total stocks issued, which of course is never reported. Am I wrong here? reply ourmandave 9 hours agoparentNot correcting you, but Investopedia has a f-ckton of articles on the basics of stocks and buy backs. Stock Buybacks: Why Do Companies Buy Back Shares? https://www.investopedia.com/ask/answers/042015/why-would-co... KEY TAKEAWAYS Companies do buybacks for various reasons, including company consolidation, equity value increase, and looking more financially attractive. The downside to buybacks is they are typically financed with debt, which can strain cash flow. Stock buybacks can have a mildly positive effect on the economy overall. Search for 'stock buy back' https://www.investopedia.com/search?q=stock+buy+back reply vitiral 8 hours agorootparentSo the article seems complete, but literally doesn't even mention continuous dilution due to employee compensation or related issues. It only mentions \"issuing stock\" like it's a single event instead of a continuous process. reply pjc50 7 hours agoparentprevEquity is specifically NOT a debt, but you're right that it's just the mirror image of stock issuance. See my other comment about it being a means of returning money to investors like dividends. reply justin66 9 hours agoparentprev> I always thought of \"stock buybacks\" as a form of \"debt payment\". Thatâ€™s obviously wrong. What follows will be wrong. Youâ€™re welcome. reply huntertwo 9 hours agoparentprevYes youâ€™re wrong - itâ€™s literally not paying back debt. Itâ€™s an attempt to appease stockholders because their actual financials canâ€™t keep up, thus reducing the price of the stock, thus reducing the compensation packages of the executives and wealth of the board, who is also elected by shareholders. reply vitiral 9 hours agorootparentI mean I get that argument too. But is what I said wrong? Isn't stock being continually issued, diluting the value over time? If buybacks were _never_ done, wouldn't it keep getting diluted forever? Edit: for instance, if Google has 200,000 employees and is granting an average of $50,000 stock per year, that is $10 billion. So id be okay with buybacks of that size. The actual buybacks are much bigger if memory serves, so that seems like manipulation like you're saying reply spicyusername 9 hours agorootparentOne thing that bothers me about the current economy is that most tech workers are are paid in stock and most Americans are required to invest to retire. This is basically a net fiscal transfer from regular Americans to tech workers, since tech stocks are typically the default investment when retirement is more than a decade away, artificially raising the price of tech stocks. Tech workers sell now while the price is artificially high and everyone else is left gambling later after all the tech workers have cashed out. reply lp4vn 9 hours agoprevThat shows the dominance of the financial market and the economic power over the structures of society. We find completely normal hundreds of billions be redirected to the owners of the capital but we would find an anomaly to think of a technological project that could bring real progress and costed that much. reply BeetleB 4 hours agoprev> Intel CEO Pat Gelsinger hauled in $179 million in 2021, most of it coming from stock-related compensation. When I see statements like this, I know to stop reading. No he didn't make $179M. He was awarded PSUs that will mature only if Intel stock hits a certain price (in a window of N years). Not only did it not hit that price, it has been down considerably. The grants will likely expire before Intel's price hits those goals (I think the lowest target is in the 80 dollars). His actual compensation that year? About $10M - quite a bit of it being a sign on bonus. reply Workaccount2 7 hours agoprevSites like commondreams (and their conservative counterparts) should just be blacklisted from being posted here. Seriously, it's hyper-partisan ideological brain damage material solely meant to foster clicks and outrage. reply giantg2 8 hours agoprev$152B in buybacks and the stock is still not trading high. Still not interested. Feels like Intel is basically at the GE stage of impending decline due to over corporatization. reply blackoil 9 hours agoprevUS wants me fabs in-house. For company, Korea/Taiwan or Israel may make more sense. So, US is paying up for it. reply tester756 9 hours agoprevtitle manipulation original title is: \"Intel Brags of $152 Billion in Stock Buybacks Over Last 35 Years.\" Current HN title made me think that they plan to spend $152 b on buyback in the future reply belter 9 hours agoprevBetween 1998 and 2018, Boeing spent more than $61.0 billion in stock buybacks. The budget for the development of the MAX was US$4 billion reply throwaway5959 9 hours agoprevIt doesnâ€™t. It needs to go into liquidation when the money men have finally driven it fully into the ditch. reply OscarTheGrinch 9 hours agoprevSeems to me that the CHIPS act doesn't go far enough to build up domestic competition. What would be the consequences if the government nationalised / heavily subsidised Intel ramp up domestic chip production? Or split Intel up to create new national champions? This state intervention seem to be working out well for China in electric vehicles and solar. The US risks squandering its technological advantage by pursuing half way measures. reply pjc50 9 hours agoparentNationalisation would be incredibly bipartisan unpopular in the US. Everybody seems to hate the idea of the Federal government running random businesses. It would probably also immediately implode from pay issues. Subsidy is what's happening, but people have (correctly) noticed that since Intel is profitable this is really a giveaway to Intel shareholders. reply wrren 9 hours agoprevIt doesn't need it, it wants it in exchange for setting up fabrication capacity in the U.S, where it would otherwise be uneconomical to do so. reply willcipriano 8 hours agoparentIf the US put tariffs on the chips Intel makes it would be uneconomical to not build a domestic fab. reply nojvek 5 hours agoprevI don't mind the US govt giving $8B to build out a US based fab. I mind when the US based fab doesn't get built or is just built for show but can't churn competitive chips. Both Boeing and Intel are showing their incompetence. US should give Nvidia $8B to build their AI GPUs on US soil. reply klelatti 7 hours agoprevI donâ€™t think that this is surprising at all. Stock buybacks are undertaken as the return the company can get on the cash returned is lower than they think shareholders want. Subsidies exist to get the company to invest in a project where the return would otherwise be inadequate for shareholders. I suppose you could force a company to invest in a project that was perceived to have inadequate returns but that seems a little unfair? reply 23 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Biden administration is in talks to offer more than $10 billion in subsidies to Intel Corp, raising questions about the need for additional funding given the company's history of $152 billion in stock buybacks in the past 35 years.",
      "Concerns have emerged regarding the potential misuse of taxpayer grants by Intel for further stock buybacks, casting doubt on the purpose and benefit of the proposed subsidy."
    ],
    "commentSummary": [
      "Intel has secured an $8 billion subsidy from the US government to establish a factory domestically, sparking debates on government ownership's implications, national security, and shareholder value alignment.",
      "Discussions center on stock buybacks' efficiency, impact on stock prices, relationship with dividends, and generating shareholder value, addressing tax bypassing, stock value impact, ethics, and manipulation.",
      "The conversation delves into government subsidies, balancing intervention and open markets, challenges of US manufacturing, and Biden administration's initiatives on apprenticeships, combating credentialism, and anti-manipulation regulations, aiming for socially acceptable economic solutions."
    ],
    "points": 219,
    "commentCount": 273,
    "retryCount": 0,
    "time": 1711624324
  },
  {
    "id": 39852219,
    "title": "Mining OpenAI's Discourse Reveals User Sentiment and Insights",
    "originLink": "https://julep-ai.github.io/",
    "originBody": "Anatomy of OpenAI's Developer Community OpenAI has an official developer community hosted by Discourse which is the centre place of people seeking help and conversations about OpenAI's APIs, ChatGPT, Prompting and more. The forum was launched on March 2021 and since then has seen 100,000+ posts by over 20,000 users. Given the size and concentration of topics on the forum, it is a great resource for understanding the general sentiment of developers, identify common problems and rabbit holes users face and gather feedback on OpenAI products. In order to get deeper insights to developer experience and shared sentiment about certain products, we downloaded all the posts from common categories from the forum, namely. The following categories and their relevant sub-categories are included: API API/Bugs API/Deprecations API/Feedback GPT Builders GPT Builders/Chat-Plugins GPT Builders/Plugin-Store Prompting Community Documentation We created a dataset of all posts and discussions in the above categories which took place on the forum till 28th February 2024. ðŸ¤— HuggingFace Link But... why? We believe there's a lot to learn from what people are struggling with, the developer sentiment over experience with using OpenAI's products. This dataset was made so that we could answer these questions. There's a lot potential in learning from OpenAI's mistakes and successes. We at Julep would love to hear what you built from the dataset! Hit us up on X/Twitter or email. Getting data from Discourse Every Discourse Discussion returns data in JSON if you append .json to the URL. Discussion URL: https://community.openai.com/t/{discussion_id} Discussion in JSON: https://community.openai.com/t/{discussion_id}.json Discussion in Markdown: https://community.openai.com/raw/{discussion_id} Raw data was gathered into a single JSONL file by automating a browser using Playwright. Let's walk through how the dataset was made and then showcase some initial trends we noticed. Feature Engineering Brief walkthrough to engineering the features. Since each row had one Discussion and each Discussion had multiple Posts in a thread, the dataset needed to be normalised to the post level; which were features of an individual post and post_discussion level; which were features of the discussion the post belonged to. For eg; Post-level features: post_id; post_author Discussion-level features: post_discussion_id; post_category_id In [ ]:%matplotlib widget In [ ]:import pandas as pd from datasets import Dataset, load_from_disk, load_dataset # hf_dataset = load_from_disk(\"9_dataset_with_topics\") hf_dataset = load_dataset(\"julep-ai/openai-community-posts\") df = hf_dataset.to_pandas() In [ ]:hf_dataset.features Out[ ]:{'post_discussion_id': Value(dtype='int64', id=None), 'post_discussion_tags': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'post_discussion_title': Value(dtype='string', id=None), 'post_discussion_created_at': Value(dtype='timestamp[ns, tz=UTC]', id=None), 'post_category_id': Value(dtype='int64', id=None), 'post_discussion_views': Value(dtype='int64', id=None), 'post_discussion_reply_count': Value(dtype='int64', id=None), 'post_discussion_like_count': Value(dtype='int64', id=None), 'post_discussion_participant_count': Value(dtype='int64', id=None), 'post_discussion_word_count': Value(dtype='float64', id=None), 'post_id': Value(dtype='int64', id=None), 'post_author': Value(dtype='string', id=None), 'post_created_at': Value(dtype='string', id=None), 'post_content': Value(dtype='string', id=None), 'post_read_count': Value(dtype='int64', id=None), 'post_reply_count': Value(dtype='int64', id=None), 'post_author_id': Value(dtype='int64', id=None), 'post_number': Value(dtype='int64', id=None), 'post_discussion_related_topics': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'accepted_answer_post': Value(dtype='float64', id=None), 'post_content_raw': Value(dtype='string', id=None), 'post_category_name': Value(dtype='string', id=None), 'post_sentiment': Value(dtype='string', id=None), 'post_sentiment_score': Value(dtype='float64', id=None), 'post_content_cluster_embedding': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'post_content_classification_embedding': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'post_content_search_document_embedding': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'tag1': Value(dtype='string', id=None), 'tag2': Value(dtype='string', id=None), 'tag3': Value(dtype='string', id=None), 'tag4': Value(dtype='string', id=None), 'post_discussion_url': Value(dtype='string', id=None), 'post_url': Value(dtype='string', id=None), 'topic_model_medium': Value(dtype='string', id=None), 'topic_model_broad': Value(dtype='string', id=None)} In [ ]:# Total number of posts print(\"Total number of posts: \", len(df)) # Total discussions print(\"Total discussions: \", len(df[\"post_discussion_id\"].unique())) # Total number of users print(\"Total number of users: \", len(df[\"post_author_id\"].unique())) Total number of posts: 97033 Total discussions: 18990 Total number of users: 21419 In [ ]:# Earliest and latest post print(\"Earliest post: \", df[\"post_created_at\"].min()) print(\"Latest post: \", df[\"post_created_at\"].max()) Earliest post: 2021-03-10T20:39:25.848Z Latest post: 2024-02-27T14:03:01.685Z Apart from Post and Discussion level features, the following class features were computed; Sentiment Vector Embeddings Topic Models Twitter-roBERTa-base Sentiment Using Twitter-roBERTa-base for sentiment analysis, we generated a post_sentiment label (negative, positive, neutral) and post_sentiment_score confidence score for each post. On average, most posts are neutral. In [ ]:df[\"post_sentiment\"].value_counts(ascending=True, normalize=True) Out[ ]:post_sentiment negative 0.185277 positive 0.219327 neutral 0.595395 Name: proportion, dtype: float64 However, by looking at the distribution per category, we see that the api category and api/bugs category has the most negative sentiment amongst different categories. On the other hand, community and gpts-builders/plugin-store has the most positive sentiment. which tracks as people often showcase cool projects, news and latest AI development in the community! In [ ]:# Group by 'post_category_name' and then apply normalized value_counts to 'post_sentiment' sentiment_percentages = df.groupby(\"post_category_name\")[\"post_sentiment\"].apply( lambda x: x.value_counts(normalize=True) ) # Convert the Series to a DataFrame and reset the index # sentiment_percentages = sentiment_percentages.mul( # 100 # ) # Convert fractions to percentages sentiment_percentages = sentiment_percentages.reset_index(name=\"percentage\") # Pivot the table for better readability pivot_df = sentiment_percentages.pivot( index=\"post_category_name\", columns=\"level_1\", values=\"percentage\" ) # Fill NaN values with zero if any sentiment labels are missing in a category pivot_df = pivot_df.fillna(0) pivot_df.reset_index() pivot_df.columns.rename(None, inplace=True) # Display the pivoted DataFrame in descending order pivot_df Out[ ]: negative neutral positive post_category_nameapi 0.188675 0.624195 0.187131 api/bugs 0.376378 0.533858 0.089764 api/deprecations 0.161049 0.662921 0.176030 api/feedback 0.261770 0.553672 0.184557 community 0.137866 0.502298 0.359837 documentation 0.137372 0.559727 0.302901 gpts-builders 0.260511 0.597313 0.142176 gpts-builders/chat-plugins 0.232624 0.538543 0.228833 gpts-builders/plugin-store 0.187500 0.506944 0.305556 prompting 0.133054 0.633530 0.233416 Vector Embeddings For calculating vector embeddings, Nomic Embed-Text v1.5 was ran locally with the help of text-embeddings-inference. Because of it's Matryoshka resizable nature, it's possible to use these embeddings in a bunch of future applications. Nomic Embed v1.5 was largely selected due to it's large context length. In [ ]:import matplotlib.pyplot as plt import seaborn as sns df[\"post_content_raw_length\"] = df[\"post_content_raw\"].apply(len) plt.figure(figsize=(12, 6)) sns.histplot( df[\"post_content_raw_length\"], bins=100, kde=False, cumulative=True, stat=\"density\" ) plt.title(\"CDF of Length Distribution of post_content_raw\") plt.xlabel(\"Length of post_content_raw\") plt.ylabel(\"Cumulative Density\") plt.show() /home/glitch/.conda/envs/julep/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and ={np_minversion} and0) ].drop_duplicates(subset=\"post_discussion_id\").sort_values( \"post_discussion_views\", ascending=False )[ [ \"post_discussion_title\", \"post_content_raw\", \"topic_model_medium\", \"post_discussion_views\", \"post_sentiment\", \"post_discussion_url\", ] ] Out[ ]: post_discussion_title post_content_raw topic_model_medium post_discussion_views post_sentiment post_discussion_url 11898 Cheat Sheet: Mastering Temperature and Top_p i... Presence\\_penalty was only mentioned once as a... Logit 113139 negative https://community.openai.com/t/172683 11179 OpenAI API keys in free account I have genertaed openai api keys in the free a... API Usage 89960 negative https://community.openai.com/t/348972 64217 Your account was flagged for potential abuse Same problem. And I canâ€™t write anything in [h... OpenAI 87260 negative https://community.openai.com/t/156597 5484 Getting response data as a fixed & Consistent ... I have such common issue where JSON data is no... JSON Format 78668 negative https://community.openai.com/t/28471 34098 Is chat GPT provided for free I have only $5 What are you jealous of? Pricing 75918 negative https://community.openai.com/t/86249 ... ... ... ... ... ... ... 194 Anyone experiences no message response using a... Hi, I just encountered very strange behavior w... Assistant Tools 53 negative https://community.openai.com/t/656254 1485 Request always fail after the first function c... I am using model gpt3.5-turbo with chat comple... Python3 Packages 53 negative https://community.openai.com/t/647723 839 Help with using openAI Assistants via API in J... Iâ€™m trying to create a simple chrome plugin th... Error Handling 53 negative https://community.openai.com/t/652635 223 Assistant API: Empty message is generated with... Hi whung,I think there might me some err... Assistants, API, Platform 52 negative https://community.openai.com/t/656170 77670 OpenAPI spec can have a maximum of 30 operations I am building an action for an API with lots o... Python3 Packages 31 negative https://community.openai.com/t/586484 2146 rows Ã— 6 columns Posts with Most Negative Sentiment by Topic Some topics tends to cause more frustration than other which we can see by sorting the topics based on the number of posts with negative sentiments. In [ ]:# add a column for the length of the post_content_raw topic_df[\"post_content_raw_length\"] = topic_df[\"post_content_raw\"].apply(len) # Filter the dataframe to include only posts with negative sentiment negative_posts = topic_df[topic_df[\"post_sentiment\"] == \"negative\"] # Group the negative posts by topic and count the number of posts in each topic negative_posts_by_topic = ( negative_posts.groupby(\"topic_model_medium\").size().reset_index(name=\"count\") ) # Sort the topics by the count of negative posts in descending order negative_posts_by_topic = negative_posts_by_topic.sort_values(\"count\", ascending=False) # Plot the bar chart plt.figure(figsize=(12, 6)) sns.barplot( x=\"count\", y=\"topic_model_medium\", data=negative_posts_by_topic, color=\"red\" ) plt.title(\"Posts with Most Negative Sentiment by Topic\") plt.xlabel(\"Number of Posts\") plt.ylabel(\"Topic\") plt.tight_layout() plt.show() Figure Percentage of Posts by Sentiment and Topic Surprisingly, the top 15 topics in this graph break the trend of negative posts being 18.5%. Specifically in these topics, the negative sentiment can be upto 50%! In [ ]:sentiment_percentages = df[\"post_sentiment\"].value_counts(normalize=True) * 100 print(sentiment_percentages) post_sentiment neutral 59.539538 positive 21.932745 negative 18.527717 Name: proportion, dtype: float64 In [ ]:# Group the posts by topic and sentiment, and count the number of posts in each group posts_by_topic_and_sentiment = ( topic_df.groupby([\"topic_model_medium\", \"post_sentiment\"]) .size() .reset_index(name=\"count\") ) colors = {\"negative\": \"red\", \"neutral\": \"blue\", \"positive\": \"green\"} # Calculate the total number of posts for each topic total_posts_by_topic = topic_df.groupby(\"topic_model_medium\").size() # Calculate the percentage of posts for each sentiment within each topic posts_by_topic_and_sentiment[\"percentage\"] = posts_by_topic_and_sentiment.apply( lambda row: row[\"count\"] / total_posts_by_topic[row[\"topic_model_medium\"]] * 100, axis=1, ) # Pivot the DataFrame to get the percentage of posts for each sentiment as separate columns pivot_df = posts_by_topic_and_sentiment.pivot( index=\"topic_model_medium\", columns=\"post_sentiment\", values=\"percentage\" ).fillna(0) pivot_df = pivot_df.sort_values(\"negative\", ascending=False) # Plot the stacked bar chart pivot_df.plot( kind=\"bar\", stacked=True, figsize=(12, 6), color=[colors[col] for col in pivot_df.columns], ) plt.title(\"Percentage of Posts by Sentiment and Topic\") plt.xlabel(\"Topic\") plt.ylabel(\"Percentage of Posts\") plt.legend(title=\"Sentiment\") # plt.xticks(rotation=45) plt.tight_layout() plt.show() Figure People really like to complain about performance! Wrapping up We've just began to scratch the surface to useful data that can be analysed about OpenAI's products, launches, tools and the trends surrounding their usage. This post is meant to be an introduction to the dataset and show some threads that can be explored further. We at Julep AI are building an open-source platform for crafting AI Agents. In the spirit of open-source, we decided to make this dataset public in hopes of helping out other people identify the cracks and the gaps that OpenAI cannot fix, doesn't want to fix or is opinionated against. Given the activity of the community and the ease of downloading the data, it made perfect sense to leverage this low-hanging fruit of knowledge. We hope that this dataset helps other people building AI stacks. We'd love to hear more about how you used the dataset or just talk in general! Hit us up at: Twitter/X: https://x.com/julep_ai Email: Ishita (ishita@julep.ai) / Sid (sid@julep.ai)",
    "commentLink": "https://news.ycombinator.com/item?id=39852219",
    "commentBody": "I scraped all of OpenAI's Community Forum (julep-ai.github.io)212 points by alt-glitch 6 hours agohidepastfavorite37 comments xfalcox 4 hours agoThat's super cool, thanks for sharing! I will share this as an easy to follow example of what we can with AI. > Allowing a Q&A interface using these embeddings over the post contents could speed up research over the community posts (if you know the right questions to ask :P). Let's view some posts similar to this one complaining about function calling That's indeed a great thing to surface, and that's exactly how the the OpenAI forum selects the \"Related Topics\" to show at the end of every topic. We use embeddings for this feature, and the entire thing is open-source: https://github.com/discourse/discourse-ai/blob/main/lib/embe... We also embeddings for suggesting tags, categories, HyDE search and more. It's by far my favorite tech of this new AI/ML gen so far in terms of applicability. > Using Twitter-roBERTa-base for sentiment analysis, we generated a post_sentiment label (negative, positive, neutral) and post_sentiment_score confidence score for each post. We do the same, with even the same model, and conveniently show that information on the admin interface of the forum. Again all open source: https://github.com/discourse/discourse-ai/tree/main/lib/sent... Disclaimer: I'm the tech lead on the AI parts of Discourse, the open source software that powers OpenAI's community forum. reply wavyknife 4 hours agoprev(disclaimer: I work for Discourse) Discourse has an AI plugin that admins can run on their community to generate their own sentiment analysis (among other things), though it's not quite as thorough as this write up! https://meta.discourse.org/t/discourse-ai-plugin/259214 We're always interested to see how public data can be used like this. It's something that can be a lot more difficult on closed platforms. reply Aachen 4 hours agoparent> helps you keep tabs on your community by analyzing posts and providing sentiment and emotional scores to give you an overall sense of your community for any period of time [...] > Toxicity can scan both new posts and chat messages and classify them on a toxicity score across a variety of labels Is that within the defined data processing purposes of all Discourse setups? Does the tool warn admins they might need to update their policies before being able to run this tool, perhaps needing to seek consent (depending on their jurisdiction and ethics)? It sounds somewhat objectionable, trying to guess my mental state from what I write without opt-in Edit: and apparently it also tries to flag NSFW chat messages, does Discourse have PM chats where this would flag private messages for admins to read or is it only public chats that this bot runs on? > tagging NSFW image content in posts and chat messages reply xfalcox 48 minutes agorootparent> Is that within the defined data processing purposes of all Discourse setups? It's an optional plugin that can be enabled / disabled by the site admin. Those modules are all disabled by default, and each need to be enabled by the site owner. > Edit: and apparently it also tries to flag NSFW chat messages, does Discourse have PM chats where this would flag private messages for admins to read or is it only public chats that this bot runs on? Discourse PMs can be read by admins, see the definition here: https://meta.discourse.org/t/guidance-and-best-practices-on-... reply eddd-ddde 1 hour agorootparentprevI don't think there's anything left for you to consent once you decide to post on a public forum. If I can read your post and guess your mental state so can any other bot. reply wavyknife 1 hour agorootparentprevDiscourse is not a centralized platform, so it's up to individual sites to ensure they're compliant with data and privacy regulations. reply BadHumans 3 hours agorootparentprevMore companies and communities than you think already do this without your knowledge let alone consent. reply david_allison 2 hours agorootparentThat doesn't mean we can't do better reply BadHumans 1 hour agorootparentBetter at what though? I don't even think it's a problem to begin with. reply SunlitCat 5 hours agoprevI didn't even knew they have community forums. Looking at the main homepage (openai.com), the only external links I can find are to chatgpt and their docs hosted on platform.openai.com. The other links lead to their socials, github and soundcloud (of all places). Maybe I'm not looking thoroughly enough, so I may be wrong, tho! reply hughesjj 4 hours agoparentI would also love to see these forums both to post and to lurk reply djantje 4 hours agorootparenthttps://community.openai.com/ (when you are logged in on platform.openai.com, there is a link from the menu) reply SunlitCat 2 hours agorootparentThank you! Gone are the days when you simply saw all the important links on the main page, it seems. :) reply miduil 5 hours agoprevThat's an interesting write-up, I wonder how this would look for other big Discourse communities such as NixOS. reply fzysingularity 3 hours agoprevSo epic, thank you for making this dataset available to everyone! reply velid0 5 hours agoprevNow train a gpt based on the data :D reply testfrequency 4 hours agoparentBut make sure to call it ClosedData or something so we know itâ€™s not open source (sorry, I think openai and sam are gross) reply davely 2 hours agorootparentMaybe I donâ€™t understand this sentiment, but are people really that hung up on the name? I see this sort of thing posted a lot (i.e., â€œit should be ClosedAI instead of OpenAI, lolâ€) What if it just means â€œOpen for Businessâ€ instead of â€œOpen Access for Allâ€? Or maybe they should just make it an acronym? Iâ€™m sorry for the confusion on my part, but thereâ€™s just been a lot of words dedicated toward expressing frustration with the company because they chose to use â€œopenâ€ in their name. Personally, I donâ€™t find it frustrating that Apple doesnâ€™t sell fruit and Intel doesnâ€™t actually give intelligence data. reply rootusrootus 2 hours agorootparentIs the frustration because of the name, or because open [access] was part of their ethos at the beginning, and people think they've abandoned it? reply startupsfail 2 hours agorootparentOpenAI is supposed to be a nonprofit. But, when the nonprofit board tried to exercise control, it became very clear that the nonprofit arm is not, in fact in control any longer. The board was wiped out, nearly everyone in the company seemingly was willing to join Microsoft or Sam Altman or what not. This doesnâ€™t seem to be compatible with continuing loftily call themselves with the same name, as the initial nonprofit mission. reply woopsn 2 hours agorootparentprevIt's a gimmick. When the nonprofit was organized in 2015, the name certainly did not mean open for business. It meant (loftily) undertaking the quasi-religious quasi-humanist mission \"in the spirit of liberty\" to generate a new kind of super wealth as \"broadly and evenly distributed as possible\". As in prepare for the end... THE END OF HIGH PRICES! > to benefit humanity as a whole, unconstrained by a need to generate financial return - https://openai.com/blog/introducing-openai reply xandrius 5 hours agoprevLove it, just for the sole reason of turning something OpenAI made into a dataset for everyone else :D reply codetrotter 3 hours agoparentI donâ€™t think OpenAI are gonna lose any sleep over this. Isnâ€™t a â€œcommunity forumâ€ like this basically just: â€œweâ€™re not gonna spend money on providing adequate customer support so instead here is a forum where yâ€™all can talk amongst yourselves and weâ€™ll give you some badges and imaginary points for doing the customer support yourselvesâ€? reply solardev 3 hours agorootparentThey probably just sic a customer service GPT on it and use it to train the other ones... reply enonimal 5 hours agoprev> Number of Posts with negative sentiment, grouped by Topic > # 1 Result: Python Packaging Checks out reply minimaxir 4 hours agoparentA pro-tip for using the OpenAI API is to not use the official Python package for interfacing with it. The REST API documentation is good, and just using it in your HTTP client of choice like requests is roughly the same LOC without unexpected issues, along with more control. reply rockostrich 4 hours agorootparentI've found this happens with a lot of first party clients. At work, we use LaunchDarkly for feature flags and use their code references tool to keep track of where flags are being referenced. The tool uses their first party Go client to interact with the API but the client doesn't handle rate limiting at all even though they have rate limiting headers clearly documented for their API. reply doctorpangloss 3 hours agoparentprevThe Python package is really well engineered, and the startup that is making the OpenAPI client based on it, Stainless, is doing a good job. This shows laypeople piling into a hype thing and running immediately into the roadblock of programming. Normal people don't want to like, put in effort to feel like they are a part of something. They are used to \"just\" having to turn on Netflix to feel like they are a part of the biggest TV show, or \"just\" having to click a button to buy a Stanley Cup, or \"just\" having to click a button to buy Bitcoin. The API and performance issues, IMO, they're not noise, but they are meaningless. To me this also signals how badly Grok and Stability are doing it, they are doubling and tripling down on popular opinions that have a strong, objective meaninglessness to them (like how fast the tokens come out and how much porn you're allowed to make). Whereas the Grok people are looking at this analysis and feeling very validated right now. I have no dog in this race, but I would hope that the OpenAI people do not waste any time on Python APIs for dumb people; instead, they should definitely improve their store and have a firmer opinion on how that would look. They almost certainly have a developing opinion on a programming paradigm for chatbots, but I feel like they are hamstrung by needed to quantize their models to meet demand, not decisions about the look and feel of Python APIs or the crappiness of the Python packaging ecosystem. Another POV is that the Apple development experience persists to be notoriously crappy, and yet they are the most valuable platform for most companies in the world right now; and also, JetBrains could not sustain an audience for the AppCode IDE, because everyone uses middlewares anyway; so I really don't think Python APIs matter as much as the community says they do. It's a Nice to Have, but it Does Not Matter. reply enonimal 3 hours agorootparentwe may think more similarly than you seem to think... this was more a slam on python packaging in general, than it is on the OpenAI implementation. I wouldn't be surprised if many of the issues under this topic are more related to Python package version nightmares, than OpenAI's Python implementation itself. reply dorkwood 4 hours agoprevI did a bit of data scraping for fun in the past, but I was never quite sure of the legality of what I was doing. What if I was breaking some law in some jurisdiction of some country? Was someone going to track me down and punish me? OpenAI has taught me that no one gives a shit. Scrape the entire internet if you want, and use the data for whatever you feel like. reply alt-glitch 4 hours agoparentWe were really heading someplace with The Semantic Web aka The Real Web 3.0 [1] Alas we have to fight against the machines in order to properly read the internet thru machines. I believe Discourse knowingly keeps its data easy to scrape though, so kudos to them! [1]: https://en.wikipedia.org/wiki/Semantic_Web reply ifyoubuildit 4 hours agoparentprevDo you think it would be better if someone did track you down and punish you? Which world do you want to live in? reply n0sleep 4 hours agorootparentI think large companies should be punished for stealing from people to make themselves richer. reply EcommerceFlow 4 hours agoparentprevA precursor to this would have been that Linkedin lawsuit Microsoft lost, allowing that one company to scrape all of Linkedin (technically \"public information\"). reply bsuvc 4 hours agoparentprev> OpenAI has taught me that no one gives a shit. Scrape the entire internet if you want, and use the data for whatever you feel like. Cloudflare gives a shit. My household had to use our 5G internet for most things for a week or two until our IP reputation recovered. reply stoorafa 3 hours agorootparentYeah itâ€™s probably worth renting a server if thereâ€™s any doubt about whether itâ€™s wholly appropriate to do something reply throwaway98797 5 hours agoprev [â€“] did they have the right to use all thier data? /s reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenAI operates a developer community on Discourse, hosting 20,000 users and over 100,000 posts starting from March 2021.",
      "A dataset was generated from the forum posts to study user experiences, sentiments, and extract insights, covering posts, discussions, sentiment analysis, and topic models.",
      "The data mostly consists of neutral posts, with certain categories showcasing additional negative or positive sentiments, accessible publicly for in-depth exploration of AI technologies."
    ],
    "commentSummary": [
      "The post explores utilizing AI for sentiment analysis of community forum posts on OpenAI's platform, highlighting worries about consent and privacy.",
      "Users express concerns about data processing, privacy issues, regulatory compliance, and share opinions on OpenAI forums.",
      "Criticisms arise from OpenAI's pivot towards a commercial focus, including disapproval of their \"open\" label, with suggestions to utilize the OpenAI API directly for better control and transparency."
    ],
    "points": 212,
    "commentCount": 37,
    "retryCount": 0,
    "time": 1711637073
  },
  {
    "id": 39847728,
    "title": "ST-DOS: Advanced Kernel with MS-DOS Compatibility",
    "originLink": "http://sininenankka.dy.fi/~sami/fdshell/doskernel.php",
    "originBody": "lEEt/OS Navigation Index Getting started Features Download System requirements Screenshots Videos Documentation Philosophy TCP/IP stack Software ST-DOS Bugs FAQ Try it online!ST-DOS The kernel can be compiled and linked using Open Watcom compiler. The kernel does not make other assumptions about the bootloader than that in the memory address 0xFC15 there must be the BIOS drive number of the system drive, and in the memory address 0xFC1C the 32-bit index of the first logical sector of the boot partition. The kernel can be loaded to anywhere in the memory (as long as the starting point is the beginning of a paragraph) and must be started by doing a far jump to the beginning of the code with offset 0. ST-DOS-specific features Changelog: Source for the kernel & userland Last updated: 28. March 2024 Source for the boot loader (can be assembled with NASM) The bootloader searches for a file named KERNEL.BIN from the root directory of a FAT12/16 filesystem and loads it to memory. Bootable 1,44 MB floppy image Bootable USB storage image Bootable \"El Torito\" CD image Bootable 360 kB floppy image for IBM PC and XT md5sums Features Support for large disks and 2 GB FAT filesystems Dynamic disk caching Dynamic file buffering Mostly MS-DOS-compatible API - most DOS programs should work Can create and mount disk images Calls DOS idle handler (int 28h) also during disk I/O Symbolic links (c) Sami Tikkanen 2020 - 2024",
    "commentLink": "https://news.ycombinator.com/item?id=39847728",
    "commentBody": "ST-DOS (dy.fi)191 points by snvzz 16 hours agohidepastfavorite44 comments marttt 8 hours agoThis sure is a Very Finnish Project. (Definition: a completely random Finn, always carrying a barely noticeable smirk, is taking an utterly improbable or completely unnecessary project and finishing it to absolute, ridiculous perfection. Warmest greetings to all Finns from the other side of the Gulf! I love you guys forever.) Also, there was more discussion on ST-DOS (involving the author) on the Dos Ain't Dead forum: http://www.bttr-software.de/forum/board_entry.php?id=20883 reply actionfromafar 7 hours agoparentIf only this power could be harnessed. But I think by definition, it can't. :-) reply rauli_ 6 hours agorootparentLike Linux or MySQL? reply omoikane 2 hours agorootparentThe first thought that came to my mind were actually the Future Crew, and one of their members were also named Sami (but seems unrelated to this author). reply wenc 6 hours agorootparentprevSisu? reply exikyut 8 hours agoparentprevFinnishing it* FTFY reply skissane 12 hours agoprevNot clear at first what this is. Turns out it is someoneâ€™s personal clone of MS-DOS. Nothing to do with Atari ST, the â€œSTâ€ is the authorâ€™s initials reply squarefoot 10 hours agoparentI was confused as well. Turns out the right link is this one: http://sininenankka.dy.fi/~sami/fdshell/index.php Tl;Dr: \"lEEt/OS is a graphical shell and partially posix-compliant multitasking operating environment that runs on top of a DOS kernel.\" [...] \"lEEt/OS is slowly but surely migrating from FreeDOS to ST-DOS, its own DOS kernel.\" reply quenix 5 hours agoparentprev> Nothing to do with Atari ST, the â€œSTâ€ is the authorâ€™s initials Or STM32, as I initially suspected. reply Findecanor 9 hours agoparentprevNot a far-fetched thought though. The Atari ST's \"TOS\" used MS-DOS formatted floppies. reply cmrdporcupine 8 hours agorootparentAnd its \"GEMDOS\" was basically a fusion of MS-DOS and CP/M, but on 68/k. (not surprising since it was made by Digital Research). reply vanderZwan 8 hours agoprevI don't know what it is about Finnish culture that results in such a significant number of permacomputing hackersÂ¹ that go to great lengths to preserve old-hardware, but I am grateful for it. Â¹ When I say significant I mean \"at least two, but one of them is viznut\"Â². That is significant, right? Â² http://viznut.fi/en/ reply jlundberg 38 minutes agoprevThis is really cool and inspiring. Looking forward to trying it on the 8086:es my kids have. Slightly related noteworthy project: http://svardos.org/ reply WalterBright 3 hours agoprevWhat's interesting is when I think about MS-DOS these days, I think I could make a functional duplicate in short order. But nobody did it at the time. (How I'd do it is write all the semantic code in D, such as the code for EDLIN, and debug it all. Then hand-translate it into asm.) P.S. One of the smartest things Gates/Allen did to write their original BASIC was to write an 8080 emulator on a PDP-10(?). This enabled much, much faster development than trying to hand-assemble code and toggle it in. reply ab5tract 2 hours agoparentWere there not many MS-DOS clones at the time? reply WalterBright 2 hours agorootparentThere was DR-DOS, but it came years later. I don't recall any others. reply jpalomaki 14 hours agoprevThere's also a link to an emulator, running in browser: https://archive.org/details/losb425# reply JdeBP 10 hours agoprevReading the documentation, \"this is a clone of MS-DOS\" turns out to be quite a misleading summary of what this is. The documentation claims things (which I have not verified personally) such as forking, signals, and pipes. Instead of a SUBST command there is a MOUNT command. And there's a convoluted piece of hooplah that stands in place of what MS-DOS could do with the SHELL= line in CONFIG.SYS . reply skissane 9 hours agoparent> Reading the documentation, \"this is a clone of MS-DOS\" turns out to be quite a misleading summary of what this is. Not a \"clone\" in the sense of 100% compatible... but a \"clone\" in the sense of borrowing a significant degree of ideas and APIs/syntax from it, yet also deviating at various points (whether for good reasons or for idiosyncratic ones) It is a clone more in the sense that the Japanese mainframe operating systems Fujitsu MSP and Hitachi VOS3 are/were clones of IBM MVS: they started out as a direct copy of MVSâ€“due to IBM having released earlier versions into the public domain, and Fujitsu/Hitachi illegally stealing the IP of later onesâ€“but over time diverged in incompatible directions reply smoppi 6 hours agorootparentST-DOS is a DOS implementation, but it is not meant to be a clone of MS-DOS. It is mostly syscall-compatible with MS-DOS, but the driver API and many other things are completely different. After all the definition of DOS is just \"disk operating system\". All real mode programs that are compiled with Watcom C/C++ should work. The most recent versions of Watcom's protected mode runtime don't currently work, because they use some undocumented MS-DOS syscalls that are not implemented in ST-DOS. I intend to create a compatibility TSR that will solve most issues with those MS-DOS programs. reply danbruc 13 hours agoprevI recently stumbled across the MS-DOS 1.25 and 2.0 source code [1]. [1] https://github.com/microsoft/MS-DOS reply hnlmorg 14 hours agoprevThe tag line in that site changes with each refresh. I had one which read something like > Hardware assisted multitasking was an error Which made me chuckle. reply marttt 7 hours agoprevQuestion: considering that the Mpxplay music player [1] supports native audio playback via Intel HDA on DOS (confirmed with FreeDOS), should it also work out of the box on ST-DOS? 1: https://mpxplay.sourceforge.net/ reply fsiefken 4 hours agoprevCan it run Windows 3.11 and if so would there be a multitasking, lfn, speed or memory advantage in doing so compared to dr-dos, ms-dos or freedos? reply TheDudeMan 11 hours agoprevOh, DOS. Fond memories. My first experience was the 3.x era. Does anyone else remember DR-DOS? reply aidenn0 4 hours agoparentI had a single game that, AFAICT, the CD-ROM version couldn't run on MS-DOS the normal way because the intro it showed needed more conventional memory that was possible with mscdex loaded[1]. There was a workaround that consisted of running the program that would resume from the latest save, then exiting to the main menu. If you had a large enough hard-drive, you could also run it by copying the data to your hard drive, then manually pointing the game at the path (thus allowing you to omit the CD-ROM driver). I managed to get it to run off the CD by using the nwcdex (From Novell Dos 7, after Novell purchased Digital Research), which could load itself into EMS. 1: This was the CD-ROM version of Master of Magic. The intro needed approximately 630KB of conventional memory to run. reply UncleSlacky 3 hours agoparentprevI enjoyed playing the built-in \"Advanced NetWars\" game: https://en.wikipedia.org/wiki/NetWars#Legacy reply b3lvedere 11 hours agoparentprevYes. Many years ago when i worked for a computer shop, i was kinda 'forced' by the shop owner to sell it whenever a new computer was sold. He bought lots of it and nobody would buy it. I hated it. Back in the BBS era i loved 4DOS, but looking back in hindsight it was just a bunch of extra tools on top of MS-Dos. reply TheDudeMan 10 hours agorootparentI had that one, too. Good stuff. Yeah, just tools, but useful. reply shzhdbi09gv8ioi 11 hours agoparentprevI remember my cousin ran DR-DOS 6 on their PC. reply Maakuth 12 hours agoprevhttps://github.com/Gessle/leet_os here's a github mirror of the source code, if you don't feel like downloading the zip for perusal. reply layer8 9 hours agoprevContext: http://sininenankka.dy.fi/~sami/fdshell/philosophy.php reply mtmk 7 hours agoprevNothing like the good old days of CRT monitors, buzzing floppy drives, loud hard disks, and the good ol' DOS prompt C:>. reply souvlakee 8 hours agoprevHow do people create a 90s old-school dial-up design in 2024? Is there a special framework for it? reply Sharlin 8 hours agoparentAll the HTML that worked back then still works, so Iâ€™m not sure what youâ€™re asking? Table layouting works just as it used to. HTML 4.01 Transitional doctype works. `` works. And so on. You just write HTML. By hand. As disturbing as it may sound in 2024. This specimen is particularly pure, not having any sort of a stylesheet (after all, we had CSS 2.0 already in 1998), the onlytag pointing to the RSS feed (which we didnâ€™t have until 1999)! reply scrumper 8 hours agoparentprevHaha really? Can't tell if joking. Something else we used to do in the '90s was View Source. reply esafak 15 hours agoprev [â€“] ST as in Atari? reply kqr 13 hours agoparentConfusingly, the operating system of the ST was called TOS â€“ The Operating System. reply efrecon 11 hours agorootparentor Tramiel Operating System? reply bregma 10 hours agorootparentThe ST was named using Sam Tramiel's initials, so I always assumed TOS was Tramiel Operating System. It's all Tramiel from Commodore on down. reply Findecanor 9 hours agorootparentOfficially ST stood for \"SixTeen\", as it was a 16-bit system. That was emphasised when the later 68030-based model in the series was named TT (\"ThirtyTwo\"). reply richrichardsson 9 hours agorootparentInteresting, I'd read somewhere that is was \"Sixteen/Thirty-two\", as M68k has a 16 bit data bus but is 32 bit internally. TT was then Thirty-two/Thirty-two as the '030 data bus was 32 bits. Yours makes more sense though. reply xenophonf 15 hours agoparentprev [â€“] Maybe! Could also be ST as in Sami Tikkanen, the author. Edit: Ooh, looks like ST-DOS is this person's MS-DOS clone. Nifty! reply otabdeveloper4 3 hours agorootparent [â€“] St.DOS (For TempleOS) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "ST-DOS is a kernel compiled with the Open Watcom compiler, offering features like large disk support, dynamic caching, and MS-DOS compatibility.",
      "The bootloader looks for KERNEL.BIN in a FAT filesystem to load into memory with specific requirements.",
      "Changelog updates are available, and the kernel's source code can be accessed online."
    ],
    "commentSummary": [
      "\"ST-DOS\" is a personal MS-DOS clone developed by Sami Tikkanen, combining MS-DOS concepts with unique elements.",
      "The discussion involves Atari ST, DR-DOS, and reminiscing about old-school computing with CRT monitors and dial-up aesthetics.",
      "It touches on MS-DOS source code and the evolution of DOS operating systems."
    ],
    "points": 191,
    "commentCount": 44,
    "retryCount": 0,
    "time": 1711599290
  },
  {
    "id": 39850925,
    "title": "Decentralized Social Network Fandom.ink Empowers Users with Search Options and Language Filters",
    "originLink": "https://fandom.ink/@Rozzychan/112161902225538242",
    "originBody": "Create accountLogin Recent searches No recent searches Search options has: media, poll, or embedis: reply or sensitivelanguage: ISO language codefrom: userbefore: specific dateduring: specific dateafter: specific datein: all or library fandom.ink is part of the decentralized social network powered by Mastodon. Administered by: Server stats: Learn more fandom.ink: About Â· Profiles directory Â· Privacy policy Mastodon: About Â· Get the app Â· Keyboard shortcuts Â· View source code Â· v4.2.8 Explore Login to follow profiles or hashtags, favorite, share and reply to posts. You can also interact from your account on a different server. Create accountLogin About",
    "commentLink": "https://news.ycombinator.com/item?id=39850925",
    "commentBody": "Google suspends romance author's account for writing sexually explicit content (fandom.ink)182 points by gcr 7 hours agohidepastfavorite192 comments paxys 7 hours ago\"I keep all my work on Google/Apple/Dropbox/Office\" is really the new version of \"I kept all my work on my hard drive and didn't back it up\". All of these companies have shown repeatedly that they will cut off your access with no notice for any or no reason and with no recourse. Cloud backups used to be a smart thing to do. Now they are a liability. reply giantg2 7 hours agoparent\"Cloud backups used to be a smart thing to do. Now they are a liability.\" If they're actually a backup they can be a good idea. If it's a single source, then yeah, it's asking for trouble. I even backup my GitHub stuff locally because who knows what could happen. reply paxys 7 hours agorootparentEven if they are just a backup, all these companies scan your data for offensive material and report it to the authorities if their algorithm deems it fit. There have been plenty of cases of parents being investigated by the police just for taking photos of their kids on their phone. reply Freak_NL 7 hours agorootparentFor this I would only consider something client-side encrypted a proper back-up when using the cloud. reply giantg2 7 hours agorootparentprevIt depends on how you want to store it. You could store it encrypted. Any true backup worthy of the title should, in my opinion, be encrypted. Otherwise it's just a copy. reply sillysaurusx 7 hours agorootparentSurely you jest, you joker you. The number of problems with that idea far outweigh the benefits. Should I go into detail? Love your profile text, by the way. EDIT: one quick example is that Iâ€™ve lost more data by forgetting passwords than I care to admit. Theyâ€™ve all been from an age where I thought it was a good idea to encrypt my secret documents, lest prying eyes get to them. Turns out the secrets wouldâ€™ve been interesting to me, but are no longer accessible. I suspect this isnâ€™t uncommon. reply hedora 6 hours agorootparentEven if you don't care about all your data being published in the future, and even if you don't care about getting your data deleted (or door knocked in) because of a random content scanner false positive, you still need to encrypt them. Many cloud storage services try to understand and then \"clean up\" file types they understand. If you don't believe me, upload and then download a TB or so of images, documents, music, videos, etc. Then, compare the checksums of the original and restored copies. On top of that, there are services like Amazon Cloud Drive that have content-type restrictions. The only reasonable litmus test I've seen in this space is \"there is a cryptographic proof that some middle manager didn't screw up my backup\". Unfortunately, that means you need to manage the encryption keys somehow. Cloud storage kind of sucks. reply Hizonner 4 hours agorootparentprev> Iâ€™ve lost more data by forgetting passwords than I care to admit This is a you problem. 100 percent PEBKAC. I've been encrypting every backup, local and cloud, and plenty of other things, for probably 30 years. I've done my share of restores, and have never lost the only key to anything I later wanted back. That's true even though I have forgotten a few passwords, because I had failsafes for that situation. This requires memorizing only three or four long passwords, which change very rarely, plus a little bit of discipline and occasionally some maintenance of your archives. On the other hand, putting something somewhere, like some cloud service, without seeing all the implications, is a mistake that's easy to make and hard to clean up. Storing stuff in the cloud in the clear en masse is an insane thing to make into a normal part of your routine. reply smarx007 37 minutes agorootparentMany cases where a recovery from backup is needed are due to PEBKAC. reply giantg2 6 hours agorootparentprevThat sounds like a password management problem and not a problem with encryption. reply philote 6 hours agorootparentprevPlease go into detail, I'm curious how encrypting your backups has more problems than benefits. reply planb 7 hours agorootparentprevReally? Do you have any source on that? reply mgr86 7 hours agorootparentprevDo you just push to another remote that you host locally, or are you capturing other github items too? Like, for example, Issues and PR reviews/discussions? reply giantg2 6 hours agorootparentI'm just capturing the code at a specific working version on external media. I'm not concerned about history and discussions since they are all small solo projects with low user bases (I suck). reply globular-toast 2 hours agorootparentWait... You do realise the entire point of git is to store versions? You just git clone and you have everything. reply giantg2 1 hour agorootparentYeah, I don't want all the history and stuff. I also don't want any sort of upstream connection from it. I just want the code. A snapshot of a working repo with no connections or dependencies to anything. reply polski-g 7 hours agorootparentprevNever forget: https://news.ycombinator.com/item?id=9966118 reply ghodith 7 hours agorootparentIt's a little unsettling to see so many people argueing that mass corporate censorship is desirable, especially back in 2015. reply glitchc 7 hours agorootparentprevAs long as your repos are up to date, they are already backed up. Did you mean that or something more explicit? reply giantg2 7 hours agorootparentI'll back my local up to a USB or a drive at a specific working version. reply lupusreal 7 hours agorootparentprevEven if the files are actually a backup it's not a good idea if it also gets your email/etc accounts nuked. Megacorps with many online properties are landmine fields because you can get banned from a dozen services for a BS 'violation' on just one of them. reply giantg2 7 hours agorootparentThat idea is true for the rest of those services too. We could just stop using all the services if they are all run by the same Corp and subjected to the same BS rules. If your Google drive got banned for explicit material, it's only a matter of time your Gmail would trigger it because you sent drafts between you and your publisher instead of using Drive. If it's a true backup, it should be encrypted in my opinion, especially on the cloud. Then it doesn't matter since they can't see it. reply freitasm 1 hour agoparentprevIt's not cloud backup if it syncs two ways. My family use a mix of Office 365, Exchange Online and Google Workspace for email, documents, etc. Add to this the required Microsoft Account for Windows logins and OneDrive. I use a Synology NAS and they have packages to backup all these kinds of accounts, including versioning. Even if an account is closed their files and emails live in our NAS. If someone's life depends on anything digital, backup is a minor inconvenience or cost. reply the_other 7 hours agoparentprevThey were always a liability. They were only ever \"the smart thing\" because they took some hassle away at the point of creating the backup. reply giantg2 7 hours agorootparentThey can still be smart for off-site backups in case of local catastrophic issues (like your house burning down). But they are just part of the solution and shouldn't be a single point of failure. reply npteljes 7 hours agoparentprevCloud backups are cool, it's the storing all eggs in one basket that's not cool. Whether that basket a cloud service, a hard disk or a pendrive. reply brianwawok 7 hours agoparentprevAll your eggs in 1 basket is never good. Local hard drive + a cloud provider should give you like 99.999999% reliability reply jlkuester7 7 hours agorootparent> Local hard drive + a cloud provider This has been my general strategy for personal data. I have also been trying to figure out if there was a reasonable way to get long-term very-cold storage (e.g. backups of family pictures). Something that would last decades just sitting in a fire-box somewhere (reasonable temps, no moisture). Been considering https://en.wikipedia.org/wiki/M-DISC, but interested to know if anyone has other ideas... reply Filligree 7 hours agorootparentDon't quote me on this, but Bluray is apparently supposed to be long-term stable. I haven't explored the claim. reply ryandrake 5 hours agorootparentprevKey point is that the cloud provider version should not be your \"main\" version, it should be used for backup only. If it's not on your physical computer that you have direct access to, it's not -your- data anymore. reply PurpleRamen 7 hours agoparentprev> All of these companies have shown repeatedly that they will cut off your access with no notice for any or no reason and with no recourse. The average user isn't aware of this. This kind of stories usually do not emerge in mainstream, or user-exclusive spaces. reply koolba 7 hours agoparentprev> Cloud backups used to be a smart thing to do. Now they are a liability. Itâ€™s not a backup when itâ€™s the primary (and only!) copy. reply offices 6 hours agoparentprevTerraria's dev being (temporarily) burnt by this was the catalyst for my de-googling. There are high-quality alternatives for everything. reply philistine 6 hours agoparentprevDon't write your smut on someone else's computer. If they're American, at some point the puritans will come knocking at the door. reply swarnie 7 hours agoparentprevSure, to us technically minded types who work in the industry. Do you think the average erotic fiction writer is keeping abreast (lol) of cloud data access + integrity news? reply idle_zealot 6 hours agorootparentWorse, these cloud storage providers actively mislead users into thinking their files are safe and durable when stored on their services. Google Drive and Apple iCloud advertise themselves as a safe place to keep all of your data, and will nag users of Android and iOS devices respectively into enabling their storage services, setting them as the default storage provider for documents, and enabling automatic deletion of local copies to \"free up space\". They want users to rely on them for all of their photo/note/mosc documents storage and synchronization needs, it's good for their business if they do. But they also don't want to store anything questionable and be held legally responsible, so they automatically scan all of the \"safely stored\" documents, and purge users who get flagged. So their business incentives align such that they - coerce as many users as possible to become maximally dependent on their services - retract those service that users depend on for any slight or potential liability and if business incentives say you do something, you do it, and no amount of techies informing the masses is going to outperform Google or Apple's messaging. So how do we fix this? We change the incentives; if you delete someone's data you should be punished. They trusted you with it, they may have even paid you to store it. If you break that agreement then you deserve some heavy fines at a minimum. reply bdw5204 7 hours agorootparentprevI imagine the overwhelming majority of them barely even know how to use a computer and just use Google Docs because it's convenient and they can access it on their iPad or their laptop. Most people, even most tech-savvy types, value convenience more than privacy, security and even reliability of the service. People are also in denial and believe that arbitrary account suspensions or other arbitrary moderation decisions can't happen to them. reply interglossa 7 hours agorootparentprevNo. Dennis Cooper lost work this way years ago. They need to be aware of this and let some of their followers help them. reply exitb 7 hours agoparentprevThat take has a \"victim blaming\" vibe going on. Those texts were not lost, they were deleted. Yes, backups are a good idea, but we shouldn't just accept that kind of behaviour. reply aaomidi 7 hours agoparentprevIâ€™ve always argued that we need regulation that prevents large companies from just yeeting your data. At most they should be able to put it in RO mode to let you take it out. reply seanw444 7 hours agorootparentWhy bandaid fix it at the government level, when you can solve it right now by yourself: stop creating single points of failure. Store backups in multiple locations. reply josephcsible 6 hours agorootparentBecause we all know that 99% of users aren't going to do that. reply aaomidi 3 hours agorootparentprevBecause actually some problems need a regulation based solution. reply coderpath 7 hours agoparentprevRichard Stallman has entered the chat... reply shrimp_emoji 7 hours agoparentprevKeep it on there in an encrypted volume! Cloud backup AND privacy in one. reply dotnet00 7 hours agorootparentWouldn't be surprised if \"too much encrypted data\" also triggers a ban because it'd stand out as unusual and a potential liability. reply bdw5204 7 hours agorootparentI suspect that large tech companies are going to be increasingly relying on AI moderation to identify \"unusual\" behavior and ban accounts for it. Failing to proactively ban a tiny obscure account posting illegal or extremely unpopular content just sets you up for political attacks either in the form of hostile new laws or of activist groups contacting your advertisers to convince them to stop doing business with you. Outlier users are definitely potential liabilities. reply tbrownaw 6 hours agorootparentprevRather than a ban, that would probably be \"you're acting like a business, so you need to switch to this much more expensive plan\". reply Waterluvian 7 hours agoparentprevI don't necessarily disagree, but I feel it's important to call out every time I see it in a tech community: this is a reasonable sentiment for the less than 1% of cloud storage users who are sufficiently tech savvy. For the other 99% who have little more than marketing material to direct their understanding, the cloud is Fort Knox for your data. reply hulitu 7 hours agoparentprev> ll of these companies have shown repeatedly that they will cut off your access with no notice for any or no reason and with no recourse. And yet people never learn. Every couple of months you see someone begging for help on HN because Paypal, Stripe, Google and so on cut their access reply shagie 7 hours agoprevScrolling through the screen shots linked on Instagram ( https://www.instagram.com/sloan_spencer_author/p/C48JN_TrvxO... ) > I find out at midnight tomorrow if I lose my docs all together. I've transferred them to word and backed up onto my hard drive. Further along ... > ... As of today, I'm unable to share my docs with my alpha and Beta readers. After reading the policies the only rule my docs \"violate\" is that they contain Ì¶sÌ¶eÌ¶xÌ¶uÌ¶aÌ¶lÌ¶lÌ¶yÌ¶ explicit content. I've since backed everything up to my computer and filled an appeal. ... Further along ... > As of right now, I don't know. I cannot access any of mine to check at the moment. Thankfully an alpha reader of mine saw it happening and I downloaded everything to my laptop before I submitted an appeal. After processing the appeal, a pop up said my account was frozen pending review. My assumption is after the review I'll either get everything back or lose it, but I don't know for sure. reply btbuildem 6 hours agoparent> My assumption is after the review I'll either get everything back or lose it There's a third outcome: the appeal is never finalized, all you get is \"your account is suspended while under review\" and it leaves you with absolutely no recourse. Maybe if you know someone at the company internally, or have a way to effectively threaten someone with decision-making power there -- otherwise, it's permanent limbo. reply shagie 7 hours agoparentprevIn the Instagram screen shots was a message that I believe linked to Abuse Program Policies & Enforcement - https://support.google.com/docs/answer/148505 > Sexually Explicit Material > Do not distribute content that contains sexually explicit material, such as nudity, graphic sex acts, and pornographic material. This includes driving traffic to commercial pornography sites. We allow nudity for educational, documentary, scientific, or artistic purposes. reply vsnf 7 hours agoprevSomething related Iâ€™ve been wondering about is the change in language catalyzed by social media companies and their morality / fear of advertisers. You see it especially in TikTok videos. When people arenâ€™t straight up censoring themselves with bleeps, dead audio, or cuts, they use euphemisms instead: kill -> unalive, rape -> grape, sex -> seggs. Even more concerning is that what is considered in need of censoring is expanding. I saw a video where the creator censored â€œwhiteâ€ when referring to Caucasians. reply Cthulhu_ 7 hours agoparentPart of it is feared censoring / demotion in the algorithms; part is hypersensitivity / hyperconsiderate, because some people have indicated they are triggered by certain words, and I'm guessing another part is maximising reach. That is, if you use explicit language, your content may be marked as 12, 16, 18+ content, and half your engagement may drop because people in comment sections seriously underestimate how much \"engagement\" a teenager with a phone and infinite time generates. reply vsnf 7 hours agorootparentYes, those are the the proximate causes. I'm worried about the effect these causes will induce going forward. With enough time, this expanded hypersensitivity will move out of TikTok and into wider culture permanently. reply somedude895 7 hours agoparentprevYou see that on Youtube as well. Creators will also censor su*cide, both in audio and video, because Google / advertisers don't like sensitive content and the video will make a lot less money if Google thinks it's about mental illness or suicide. reply indrora 2 hours agorootparentGoogle will straight up take down your videos if you mention suicide or death now. Two creators I follow had to re-upload censored versions of their videos after the youtube audio filter decided that \"dead\" was too spicy. reply Izkata 5 hours agoparentprevThere's an anime/manga/light novel that's set in this future: https://en.wikipedia.org/wiki/Shimoneta Basically everyone wears a combination bracelet and choker that works as a futuristic smartphone, but doubles as a \"sexually explicit language\" censorship device - say the wrong word and you're arrested. Offhand, substitutions I remember from that series include \"hose\" in place of \"penis\" and \"docking\" in place of \"sex\". It's mostly a comedy but gets pretty NSFW. Anime has both a censored and uncensored version. reply rifty 4 hours agoparentprevPopular words are easy sacrificial signals so that people can provide an example of social intent by avoidance if questioned. Itâ€™s annoying right now that we have a doubled dictionary to signal intention, but it is also concerning looking forwardâ€¦ Because at some point the social standard could expect technology to target the concept instead of the word to prove a good faith attempt to avoid interaction with non neutral ideas. reply scruple 6 hours agoparentprevThere's a lot of this to be found everywhere on the Internet. People have recently taken to spelling offensive and/or censored words backwards, and there's a lot of bigotry and racism on social media that gets through automated detection this way. reply btbuildem 6 hours agoparentprev\"advertisers\" along with \"shareholders\" are the hyper-aggressive cancer that is destroying the commons. Not to drag Orwell out of his grave for a commiseratory drink, but this is double ungood. reply kyrra 7 hours agoprevThe currently linked site is just a forum post, which links to Instagram, which is a screenshot of a discord chat. Instagram has the screenshots at least: https://www.instagram.com/sloan_spencer_author/p/C48JN_TrvxO... It does look like the author just lost access to docs they shared with others, not their entire account. Author is currently appealing. We have seen this kind of thing in the past. Drive has to be careful, as people will use private drive links and doc links (could have embedded images) to share explicit material that may be illegal. From my understanding, Google will start running some kind of automation against things when they are shared with other people if they might contain things that could be illegal. I have no idea what the heuristics are, or how often they get it wrong. But they are kind of between a rock and a hard place. Googler, opinions are my own. reply gcr 7 hours agoparentAuthorâ€™s last screenshot states that her whole account was frozen just after submitting the appeal and she no longer has access to her docs. I would have far less of an issue with this if certain docs were marked unsharable, or even if her entire account could no longer share, but losing access to previous work written before the policy change feels like a big misstep to me. Hereâ€™s what she said: > â€œAs of right now, I don't know. I cannot access any of mine to check at the moment Thankfully an alpha reader of mine saw it happening and I downloaded everything to my laptop before I submitted an appeal. Atter processing the appeal, a pop up said my account was frozen pending review. My assumption is after the review I'll either get everything back or lose it, but I don't know for sure.â€ reply beeboobaa3 7 hours agorootparent> Atter processing the appeal, a pop up said my account was frozen pending review Google presuming guilt until proven innocent. An appeal locking the account in retaliation is absolutely disgusting. reply cmrdporcupine 6 hours agorootparentMeta does this too. My guess it appears as some signal to some \"AI\" somewhere that this is Legit Bad Stuff, and they then send it over to an underpaid overworked exploited moderator somewhere who doesn't care, and just takes it to the next level. reply fmajid 4 hours agoparentprevThe problem is the blast radius. Google can and will delete your Android account for an unrelated issue, e.g. a billing dispute. Apple is just as bad. reply caskstrength 6 hours agoparentprevCare to explain what exactly \"may be illegal\" in this case? reply geraldhh 6 hours agorootparentthe writing please read the post before asking questions in bad faith reply caskstrength 3 hours agorootparentBad faith? Erotic writing \"may be illegal\" in the US? o_O reply shagie 2 hours agorootparentExplicit writing without some sort age verification may be in a gray area. The classic \"smutty writing magazines\" of old were still on the over 18 shelf in the magazine store. Some states may further restrict this and go after the distributor or publisher ( https://www.flsenate.gov/Session/Bill/2024/3/BillText/er/PDF ) (e) \"Material harmful to minors\" means any material that: 1. The average person applying contemporary community standards would find, taken as a whole, appeals to the prurient interest; 2. Depicts or describes, in a patently offensive way, sexual conduct as specifically defined in s. 847.001(19); and ... Media type is not defined - text may be interested to fall within that definition. Google is also a multi-national company and would need to comply with laws in other countries too. If the individuals are represented as being minors (again, changes with jurisdictions) this gets into further complications in many places. That share links are neither checked for age nor jurisdiction, google would be liable for knowingly distributing sexually explicit material without proper checks in place to limit consumption by minors or in jurisdictions where such content is restricted. reply nickelpro 7 hours agoprevMisleading title, none of the authors involved are claiming they're locked out of the accounts. The exact quote from the OP's mastadon is \"An author lost access to her explicit writing when she shared it with alpha and beta readers.\" Google says you may not use its services to distribute sexually explicit content. This is a very common and reasonable policy. The authors violated that rule, and while none of them are being straightforward about exactly what happened what seems to be the case is the violating content has been removed/locked. reply gcr 7 hours agoparentThatâ€™s not what the author wrote. A popup said her account was frozen. See the last screenshot. â€œAs of right now, I don't know. I cannot access any of mine to check at the moment Thankfully an alpha reader of mine saw it happening and I downloaded everything to my laptop before I submitted an appeal. Atter processing the appeal, a pop up said my account was frozen pending review. My assumption is after the review I'll either get everything back or lose it, but I don't know for sure.â€œ reply shoelessone 7 hours agorootparentI have no position here but reading this a few times (and not digging further for additional context) it's unclear of what the situation is here, at least to me. > ... I cannot access any of mine to check at the moment ... \"at the moment\" makes it sound like they were not on a computer, or out to eat or something where they couldn't easily check? > ...I downloaded everything to my laptop before I submitted an appeal... Makes it sound like they still have access to their account and were able to access the content in order to download a copy? reply gcr 6 hours agorootparentYour point about \"at the moment\" makes sense. I should have considered that when submitting. However, the point about downloading to her laptop is consistent with her story. Here's what we definitively know: 1. First, something about her ability to share her docs was disabled, but in a way that still left them accessible to her; 2. She then submitted an appeal; 3. Upon submitting the appeal, her account was summarily frozen pending review, and her docs were no longer accessible to her. reply aqme28 7 hours agoparentprevI understand the idea behind banning sexually explicit writing, but that basically means that large large percentage of literature cannot use Google services. Anyone writing a novel basically shouldnâ€™t use docs in case they might someday want to include sex in their writing. reply nickelpro 7 hours agorootparentGoogle's policy doesn't say anything about using their services to create sexually explicit content, only using their services for distribution. > Do not distribute content that contains sexually explicit material, such as nudity, graphic sex acts, and pornographic material. This includes driving traffic to commercial pornography sites. We allow nudity for educational, documentary, scientific, or artistic purposes. This squares with what happened to the authors here, who were only subject to enforcement actions when they shared the content via Google Docs. But yes I think the basic idea of being unable to \"trust\" a free service which has no contractual obligations to you as a user is a given under any circumstances. reply lupire 6 hours agorootparentThe problem is that the rules are Byzantine, and not every user has legal department. It's not true that you cannot share sexual material. What is true is that if you share sexual material, your whole account might be locked or disabled. That's a big difference. reply rsynnott 7 hours agorootparentprevOr, presumably, Office 365 (does Office still have a pure-offline mode?). What's an aspirant writer of Naughty Literature to do? Or, as you say, really any writer who might at some point add a sex scene, which is fairly common. reply soraminazuki 6 hours agorootparentprevYeah, share \"1984\" and get ready to be banned from Google because guess what Winston does with Julia in the novel? reply pavel_lishin 7 hours agoparentprevWhy is it reasonable? reply danpalmer 7 hours agorootparentDistributing sexually explicit material is subject to many tricky laws around the world. It's illegal in some places, requires age restrictions in others. It's reasonable for any hosting provider to say they are not going to get involved in that legal quagmire. reply margana 7 hours agorootparentIt is also reasonable for any client to say they are not going to involve themselves with a platform that will freeze their account and cause them to lose data because some faulty heuristic triggered and the company is not even willing to manually review things (even though they sometimes falsely claim they do review things when they didn't). reply danpalmer 7 hours agorootparentThat's reasonable, but a non-sequitur here surely. The author's account is not suspended, they have not lost data, and any heuristics were clearly correct in that they were publishing sexually explicit material. reply nickelpro 7 hours agorootparentprevYes, both things are reasonable, neither makes the other untrue. reply Cthulhu_ 7 hours agorootparentprevFor one example, Florida introduced a law enforcing age verifications for pornographic content; it's easier to prohibit using a platform to distribute said content, than to introduce a content rating and age verification system. reply snakeyjake 6 hours agorootparentprevIf HN can prohibit explicit content, why not Google? It's their servers, they can do with them what they want. reply jupp0r 7 hours agoparentprevWhy not remove the sharing flag instead of locking the author out of their own writing? reply nickelpro 7 hours agorootparentThings are very unclear. The author claims to have been able to download their own work prior to filing the appeal, so perhaps that's exactly what happened. We're following a bread crumb trail of discord screenshots and instagram posts, no one is being straightforward about what is going on. Google of course is a black box about enforcement actions on the foundation that transparency benefits spammers and doesn't help their bottom line, which is likely also true. reply soraminazuki 6 hours agoparentprevThe title is accurate. The linked Instagram post clearly states that the account was frozen. > This is a very common and reasonable policy. Common? Maybe. Reasonable? Debatable. At least the response isn't proportionate. Not even remotely. Locking people out of their digital lives like that is not okay. > none of them are being straightforward about exactly what happened That's some cheap victim blaming. It's hard to see this type of vague unfalsifiable claims as being made in good faith. Especially considering that you haven't even bothered to read the actual claims of the victim that you accuse of being unforthcoming. reply causi 7 hours agoparentprevThis information wildly alters the circumstances. Your comment should be at the top of the page. reply jlkuester7 7 hours agoprevGood open source self-hostable alternatives exist! https://nextcloud.com/ (no affiliation, just a longtime happy user) is great for file sharing and even collaborative online document editing. If you do not want to host your own instance, there are many great providers who will host one for you at a low cost. reply nicbou 7 hours agoparentMy nextcloud instance killed itself during an update. I wrote a blog post about it and people regularly write to thank me, so it wasn't an isolated instance. Syncthing is much simpler, and practically bulletproof. It really just works. reply BanazirGalbasi 7 hours agorootparentI have never once had Nextcloud updates work properly. It doesn't matter if I update as soon as the new version is ready or if I wait long enough for my current version to go EoL, the updater breaks something critical and my instance is non-functional. Despite that, nextcloud/owncloud do what I want/need and I'm not sure if Syncthing does. So I keep stubbornly re-trying and just spin up a new instance when the old one dies. reply wazoox 7 hours agorootparentWeird, I've been running and updating NextCloud since version 13, and I never had any problems as long as I didn't try to upgrade 2 release up at once and carefully applied the recommended database updates, etc. reply BanazirGalbasi 6 hours agorootparentDo you run many plugins, or do you keep it fairly stock? I'm beginning to wonder if that could be some of the issue, even though the upgrade guidelines include instructions on upgrading plugins. My setup has otherwise been pretty simple (single host for db and web server hidden behind a separate reverse proxy) and I follow the upgrade guidelines as closely as possible (which is usually exactly). Restoring from a backup doesn't work either because it thinks I'm trying to downgrade the version, which isn't supported. I just spun up a new instance, I'll see if keeping it simple works for me. It's also on a VM now so I can take a snapshot and roll back to that if it breaks rather than relying on the faulty backup steps. reply jlkuester7 7 hours agorootparentprevYeah, Nextcloud is not the first thing I would reach for if all you want is \"simple\" and \"bulletproof\". I am not a pro-SRE, but I have managed, with the help of backups, the successfully run a Nextcloud instance for a small group of people for the past ~5+ years. It has not been without glitches, but the challenges have been no worse than any other service I host. The more features you have, the more things can go wrong... reply somethingsome 6 hours agoparentprevI have so many problems with nextcloud! It kills itself from time to time, often during updates. Randomly problems with folder rights when everything was working before. It's slow and the code is php. The official documentation and forum are a mess. I have a lot of files, the database is not able to handle them correctly, even the cleaning commands take hours and do not work.. I regularly lose files in the database and need to re-upload them from the file in the server.. The app on Android has a lot of issues synchronizing my files, too many too often I guess. I'm hoping to see a good alternative to nextcloud one day. reply zb3 7 hours agoprevWhat's wrong with sexually explicit content? Is Google controlled by Taliban or something? reply danpalmer 7 hours agoparentGoogle operates in many countries and is subject to many laws. Even in the US websites need to check whether you're over 18 to view (or read?) pornography, and Google Docs does not appear to have an age check at 18. Do you think this is an important feature that Docs should be working on? I'm not sure I do personally. reply struant 6 hours agorootparentYou don't have to be 18 to read smutty literature. reply geraldhh 6 hours agorootparentyour local law probably has a different opinion on that reply jupp0r 7 hours agoparentprevWhere have you been living for the last 30 years? Most major tech companies have similar policies, for better or worse. reply perihelions 6 hours agorootparentNot sure where you're getting your information from: Google platformed hardcore porn up until 2015 [0]. Tumblr permitted it through 2018 [1], while Reddit and Twitter allow it today. [0] https://news.ycombinator.com/item?id=9098875 (\"Google bans 'explicit' adult content from Blogger blogs\", 2015) - \"Until today, Google's Blogger platform previously allowed \"images or videos that contain nudity or sexual activity,\" and stated that \"Censoring this content is contrary to a service that bases itself on freedom of expression.\" [1] https://news.ycombinator.com/item?id=18590944 (\"Tumblr will ban all adult content on December 17th\", 2018; 464 comments) reply caskstrength 6 hours agorootparentprevThey usually have them in order to not spook the advertisers who don't want to see their ad near anything remotely objectionable. Don't see why they care about somebody sharing a document from their Drive. reply btbuildem 6 hours agoparentprevWorse; they answer to advertisers. reply Zambyte 7 hours agoprevGoogle repeatedly letting it be known that they are simply a huge liability. reply diggan 7 hours agoparentAmerican companies are prudes, as the country tends to lean that way, nothing new really. Seems people never learn though, which is more worrisome. reply Cthulhu_ 7 hours agorootparentThe companies are prudes because the countries they operate in, as well as the payment providers they use, have laws and regulations regarding age-rated content. Having terms & conditions and blocking users that violate them is easier than dealing with the legal problems that may cause them. Restricting access entirely is another way, like what US based websites do for EU based visitors, or what Pornhub does for Florida. reply diggan 6 hours agorootparentI think the prudence is why the US have those laws, regulations and morals, not the other way around which you seem to point towards. reply isodev 7 hours agorootparentprevMany years ago, I used to work for a company specialising in IoT devices. One of their projects was about teledildonics and required the purchase of some ... testing gear. At the time they had their book keeping on Google Drive and when the invoice for said purchases had passed through their emails, their entire workspace was suspended for a couple of days until they could clear it up. reply hoosieree 7 hours agoprevWow, I'm so glad I use $OTHER_SERVICE. This will definitely never happen to me. reply ryandrake 5 hours agoparentYep, I wonder how many of these stories it's going to take for people to learn that if the data is not on your physical metal, inside of your physical property, it's not yours. reply ijijijjij 5 hours agoparentprevupload an encrypted version? reply thrdbndndn 7 hours agoprevThe post only says \"An author lost access to her explicit writing\", which sound to me that she cannot access that document anymore, not her account got suspended (I skimmed over comments and didn't see people said otherwise). Of course in this particular case, it might be worse (because she lost her entire writing if without backup), but it's not the same as losing an account. Anyway, it won't surprise me if she did also lose the account. In my experience, any shared documents or files (for Google Drive) are always very strictly moderated. reply diggan 7 hours agoparentThe Instagram post (https://www.instagram.com/sloan_spencer_author/p/C48JN_TrvxO) states: > one romance author explain that all her work was suspended by Google [...] She has no access to these files or her other works That would seem like an account suspension, not just one document. Edit: I guess it might also be a Google Drive/Docs specific suspension, rather than Google-wide. reply Sayrus 7 hours agorootparent> I've since backed everything up to my computer and filed an appeal > After processing the appeal, a popup said my account was frozen pending review Sounds like Docs only prevented her from sharing her work. Until she filled for an appeal and her account was frozen, which is perhaps even stranger than suspending the account in the first place. reply londons_explore 7 hours agorootparentprevI don't think Google does per-service suspensions, except for Google pay/adwords/adsense/YouTube. reply Sayrus 7 hours agorootparentI'm not sure if the author is in Europe but DMA lead to Google offering services separately[1]. The services are: Search, YouTube, Ad services, Google Play, Chrome, Google Shopping, Google Maps. I think Workspace (Mail, Docs, Drive, ...) are still a single service. If I remember correctly DMA or another recent law targeting gatekeepers also requires suspension to be followed with a way to appeal, proper justification and to only suspend \"one service\" (you don't loose your Mail if you get Youtube strikes). [1] https://support.google.com/websearch/answer/14202510?hl=en reply londons_explore 3 hours agorootparentI think thats data sharing, not the enabling/disabling of services. reply thfuran 7 hours agorootparentprev>I guess it might also be a Google Drive/Docs specific suspension, Do they do that? I've only ever heard of people being entirely locked out of their Google account, not specific services. reply diggan 7 hours agorootparentI'm not sure to be honest, but the other day I got a popup asking if Google Search could link their data about me with YouTube and some other Google services, so I'm assuming there is at least some isolation between the services. Not sure if that applies to suspensions though. reply paxys 7 hours agoparentprevFrom the thread it sounds like they only took away their ability to share. They still have access to the account and everything on it. reply gcr 7 hours agorootparentThe last screenshot states her entire account was frozen and her work is not accessible. reply londons_explore 7 hours agorootparentprevThat sounds like a reasonable response tbh reply bosco_mcnasty 1 hour agoprevtruly the darkest side of these is the opportunity to exploit if someone shares a document with the internet with read/write access, can I upload smut (or anything very naughty or illegal) onto their google doc from some anon connection/account? Can I get them banned thusly? Can I log into their wifi and post threats on whatever renowned toxic boards and again, get a person in trouble? The problem with the right-think industrial complex is the heavy hand itself can be fooled easily and thus weaponized. reply perihelions 6 hours agoprevFor the curious, here's what Google's official corporate communications on this general topic were, back in 2015: - \"Until today, Google's Blogger platform previously allowed \"images or videos that contain nudity or sexual activity,\" and stated that \"Censoring this content is contrary to a service that bases itself on freedom of expression.\" https://www.zdnet.com/article/google-bans-explicit-adult-con... Everything surrounding this current zeitgeist is a recent cultural development. It was not always this way. reply mrtksn 7 hours agoprevWow, the state of freedom of speech is probably worse than the soviets ATM, since during the soviet times the speech scanning tech was primitive and the thought control was rudimentary and blunt. Back in the old school totalitarian days at least your writings were banned after they were written. Even 10 years ago it was fine, the worst was about blocking keywords and making printers refuse to print images of money. What a sad state of affairs for the civilisation that used to claim to be about freedom not too long ago, even when The Matrix was released the internet was just catching on with the promise of global freedom. It turned into personalised police. reply Cthulhu_ 7 hours agoparentI'm not sure why you think getting your account blocked is equatable to being sent to the gulags. reply mrtksn 7 hours agorootparentYou are unsure because you are making both a strawman argument and historical inaccuracy. You don't go straight to gulags most of the time. Most of the time the officer screams at you and takes your books and notes your name. I also don't claim that this is the same as being sent to a gulag. This is just suppression of speech and mind control. It's going to be so much fun when those in power lose power to those they hate. Then they will be introduced to the value of privacy and freedom of speech. reply bsuvc 6 hours agoprevIt sounds like the author got her account suspended after sharing (\"distributing\" in Google's view) the book's sexually explicit content. Here is Google's Program Policies document that their Terms of Service references: https://support.google.com/docs/answer/148505#zippy=%2Csexua... The section about Sexually Explicit Material says: > Do not distribute content that contains sexually explicit material, such as nudity, graphic sex acts, and pornographic material. This includes driving traffic to commercial pornography sites. We allow nudity for educational, documentary, scientific, or artistic purposes I'm not defending Google's actions here. I'm just trying to interpret what led to this situation and what it means in a general sense. reply geraldhh 6 hours agoparentprobably an automation fuckup as this is clearly \"artistic\" in nature reply b800h 7 hours agoprevThis looks as though the author shared the document with around 20 people, which combined with the nature of the content would have flagged the author for sharing explicit spam. May be less of a big deal than is being suggested. reply danpalmer 7 hours agoparentOr just that it got flagged for review, and upon review was found to be in violation of the terms of service perhaps? The ToS say you can't distribute sexually explicit material. reply kmfrk 7 hours agoprevWhen YouTube Gaming was doing livestreaming, people who posted in stream chats also risked having their entire accounts flagged. In the EU, Google now offer the option of separating your Google accounts from each other (Gmail, YouTube, etc), but someone warned me that it broke a lot of stuff for their friends, so it sounds a little like the usual malicious compliance with regulators we're used to. Has anyone in the EU actually taken Google up on the offer and split up their Google/Alphabet accounts, and did you live to tell the story? reply Lacusch 6 hours agoparentI didn't because of what you mentioned: I don't want to break all my stuff. But I would also be happy to hear what others have to say. reply zackmorris 6 hours agoprevHow about a law that states: If a business profits from the personal data of its users, then it must back up their data for a duration (say 3 years after upload) and make that data available to them, even if it removes that data from public access due to terms of service (TOS) violations. Failure to do so would result in the business being dissolved, this clause would mainly be to protect stakeholders who go out of business and can't afford to maintain backups. This would work similarly to how a bank must be FDIC insured to lend out its customer deposits. Data is money in the information age and needs similar protections, especially with the rise of AI and profits generated from derivative works. A business which refuses to follow this law would be unaccredited, meaning that Google would be unaccredited in this case, so probably nobody should be using their services. IANAL, but personally I might extend this to work something like personally identifiable information (PII) laws, where all of the user's data is considered private, but part or all of it may be shared publicly under the TOS which the user agrees to. The sharing would be at the discretion of the business, but the data would always belong to the user under copyright law until proven otherwise. The process of proving copyright ownership would first require full sharing of the data back to the user under court discovery laws. The crux of the matter is that we have laws preventing the sharing of PII, but to my knowledge we don't have laws that protect access to a user's own information. Which seems doubly odd since companies profit from that data. Holding a user's data for ransom so that a business can make money from it seems akin to extortion, although I can't find the exact word for it. Maybe the California Consumer Privacy Act of (CCPA) or similar laws could be extended to protect access to one's own information? https://oag.ca.gov/privacy/ccpa https://www.neighborhoodindicators.org/sites/default/files/c... (pdf) Apologies if what I'm suggesting already exists, in which case filing a lawsuit should be straightforward. reply AH4oFVbPT4f8 6 hours agoprevCases like this always make me think of the 3-2-1 backup strategy. 3 copies of the data, 2 different media, and 1 off site. I sometimes feel like I'm paranoid when backup up my files and photos like this until I read stories like this. I don't know how people outside of IT would even think of making 3 copies. reply bradley13 7 hours agoprevThe cloud is \"someone else's computer\". You don't make the rules, they do. Keep your stuff on your own system, and maybe use the cloud for backup. Honestly, I don't even recommend that, unless you have actually read the T&C. The simplest solution is to get two memory sticks and copy your data to them. One stays with you, the other is in a safe-deposit box. Rotate them regularly. It's really not that much effort. That all said, WTF? Is this a new round of Puritanism come to visit? Why does Google care if adults are writing porn and sharing it? reply ijijijjij 5 hours agoparent> The simplest solution is to get two memory sticks and copy your data to them. One stays with you, the other is in a safe-deposit box. Rotate them regularly. It's really not that much effort. Another option is to keep a memory stick is in your car or even at work, if you keep it encrypted. reply johnea 3 hours agoprevThe modern puritanism is really shocking to a '60s child 8-/ How we've regressed... reply chucke1992 7 hours agoprevPuritans are taking over. reply 23B1 7 hours agoprevThe only thing I use gdocs for is collaboration. What are some of y'all's favorite alternatives? reply diydsp 7 hours agoparentNotion is okay. a bit heavy mem-wise(). i don't know how much it costs. () Recently I had a tab taking 644MB in Chromium (with no pix). After a ctrl-A, ctrl-C, and ctrl-V into notepad++, it was 52kB. That's about 10,000x... reply bayindirh 7 hours agorootparentNotion is $99/yr + $99/yr for AI access. While its database is useful, having no offline access is a big bummer. I don't use its AI features. reply otachack 6 hours agoparentprevI remember this from HN or otherwise when looking for an alternative solution: https://cryptpad.org/ There's a public instance in France to try it out. reply ptman 5 hours agorootparentCryptpad is really good. Self-hostable and works for most use cases. reply rabbits77 7 hours agoparentprevI always liked Quip. https://quip.com/ reply bayindirh 7 hours agoparentprevI continue to use Dropbox & Google Drive, with weekly backups to a hard drive, which are versioned with Borg. reply gostsamo 7 hours agoparentprevbackups in managed next cloud in hetzner. reply RedShift1 7 hours agoparentprevSelf hosted owncloud with onlyoffice reply Havoc 7 hours agoprevCompanies need to stop being morality police reply danpalmer 7 hours agoparentDo they also need to stop meeting legal obligations such as age verification for distributing/viewing sexually explicit material? reply Havoc 6 hours agorootparentLegal obligationsmorality police and you know it reply danpalmer 4 hours agorootparentThis is my point. Are Google being \"morality police\" here, or are they just meeting some possible legal requirements (IANAL)? All things being equal, a company would most likely rather do nothing, as that's the cheapest option. The fact they aren't suggests a good motivating reason, and potential legal obligations trump personal moral opinions, which are hard to pin down anyway in a large multinational company. reply dbspin 7 hours agoprevThis is terrifying. I'm a writer, and all my work is backed up on Google. Some of it likely only exists there. I'm literally shaking my head here in incredulity. How could anyone at Google have thought that this was a good idea? reply Filligree 7 hours agoparentFrom the rumor mill: The beta-reader reported the author for CP. I'm not sure there's much of a story here. reply Hizonner 7 hours agorootparentIt's a \"story\" if any random idiot can make a random claim about your work and get you cut off. For that matter, it's a \"story\" if you're exposed to judgements that affect your livelihood being made by automated crap and \"reviewed\" only by overworked near-slaves with almost no agency of their own. reply Filligree 5 hours agorootparentThat wouldn't be a 'random idiot'; it would be the story's beta-reader, and someone the document is shared with. Also- if it's true, then... what else was google supposed to do here? reply Hizonner 5 hours agorootparent> That wouldn't be a 'random idiot'; it would be the story's beta-reader, and someone the document is shared with. The System(TM) doesn't know what a \"beta-reader\" is, and will react the same way to any random idiot's report. You're pretending that Google somehow responds to categories that neither Google's policies, Google's automated systems, nor probably many of Google's employees and agents, even know or care about. Not that a \"beta-reader\" can't also be an idiot anyway. > Also- if it's true, then... You seem to be relying on the idea that Google might have been legally required to act against child pornography, so the \"it\" that would have to be true would be that the text was in fact child pornography. As far as I can find, US child pornography laws don't mention or apply to pure text. Even if the unsubstantiated rumor you're spreading were true, then the unsubstantiated claim underlying it still could not possibly be true. Any automated system or set of procedures that acts on the impossible supposition that a pure text document could even possibly be \"child pornography\" under those laws is automatically wrong. ... and the more credible claim is that the suspension was for \"sexually explicit content\", not \"illegal child pornography\", or the ever-popular \"illegal obscenity\", or illegal anything. That's a purely voluntary choice by Google. And even if that weren't true in this case, it is definitely true in many, many others. > what else was google supposed to do here? For the legal side, notice that text can never be \"child pornography\" in the US, and have it actually read for violations of any other law you're worried about by somebody who's actually qualified to evaluate its legal status and actually taking the time to do so. For the \"completely voluntarily chosen Google policy\" side, which is the one that actually seems to be at stake here, hold off on doing anything until the material has been reviewed by a human who actually understands the issues, actually has authority to make meaningful decisions, and has the time and motivation to do so. Also, don't adopt pointless, silly policies. Of course, commercial incentives assure that Google won't do any of that. And neither will any other provider of a similar cloud service. So what every single user should do is get the hell off of all of those services. That would be a good idea even if policies weren't silly and if policy enforcement weren't hair-trigger, error-prone, capricious garbage, but it's especially important because this and other stories give every reason to believe that they are. On all of them. That applies even if there is no commercially viable approach to handling these issues correctly. If a service can't be offered in any reasonable way, then that service should not be offered, or at least should not be used. \"What are they supposed to do?\" isn't a valid reason to use an unreliable, dangerous service. ... and the \"story\" is that many, many people are in fact using dangerous systems and should be moving off of them. reply rasengan 7 hours agoprevIf you're not self hosting in 2024, you're doing it wrong. With our internet connections being so fast and plethora of server daemons out there, there's really no excuse. reply Zambyte 4 hours agoparentAn unfortunately reasonable excuse is the ever-increasing complexity of the systems most people access. Trying to host something on my pocketable computer with cellular access ranges from nightmarish to impossible, for no good reason. And that's even on the Linux-based option (Android). reply cmrdporcupine 7 hours agoprevHow topical. My wife and I were having a freak out this morning about how vulnerable we are to having our lives choked out at Google's whims. They have no customer service, and delegate more and more to \"AI\" to manage these things. This has all been giving me anxiety since the time I had my Facebook account partially locked for over a month because I shared a picture of my son at the beach with no shirt on and their \"AI\" couldn't tell the difference between him and a girl because he has long hair and somehow concluded I was sharing explicit imagery. When I appealed, they extended my lock. I worked @ Google for 10 years and still wouldn't trust them even though I could possibly find someone on the inside to ring some bells for me (questionable). I backed up all my photos recently and am trying to figure out what to do about email. reply codazoda 7 hours agoparentI donâ€™t know if it will save me but I purchase a domain of my own, use an email address from that domain, and forward to Gmail. I could easily forward to any other service. When Google locks me out of my account Iâ€™ll see how resilient this idea is. Obviously Iâ€™ll lose the ability to search my decades of email, which will sting a little. reply squirrel 7 hours agoparentprevGoogle Takeout will give you an archive of your email (and everything else). reply cmrdporcupine 7 hours agorootparentYes I've done that recently, too. But it's really something that needs to be done periodically. By \"figure out about email\" I meant: where to move my email & whole life to. I'm thinking about registering a domain and taking up residence on another email hosting provider that lets me use my own domain. I have started self-hosting my own photos on my own local NAS running Immich, with limited, controlled exposure via tailscale for when I'm out. reply whitehexagon 6 hours agorootparentI switched to hetzner hosted 'own domain' a few weeks ago, which includes webmail (I use thunderbird client). YouTube failed to delete, even though I'd deleted all content a couple years back, but deleting the complete google account worked! (and feels great!) Funny thing was that I was then blocked from sending email to other gmail accounts. Turns out there are a couple simple switches in the hetzner web interface to enable some of the anti-spam measures these big tech receivers require. reply jsemrau 7 hours agoprevThe new puritans. reply overflyer 7 hours agoprevFuck yeaahhhh murrica ...we like all kinds of sick fucked up shit but nonono don't show my kid any titties on TV or lord behold text with sexually revealing vocabulary. Laughs in European ... reply kome 7 hours agoprevamericans-try-not-to-be-puritanical-and-impose-their-bigotted-moral-standards-on the-rest-of-the-world-by-the-means-of-their-techno-feudalist-corporation's challange: impossible. reply buescher 7 hours agoparentIt's weird and paradoxical isn't it? I have no idea what this lady was writing, but smutty romance novels and horror novels with weird sex scenes have been sufficiently acceptable to \"community standards\" all over the US to have been available in grocery stores at least as early as the seventies. Not so frequently seen anymore, but that's a death-of-brick-and-mortar-and-print-media problem. You could leave one on your desk at work without a visit from HR (just don't leave it open to a spicy page or read aloud from it). But share similar material from your google drive? I don't know! I really don't. reply vouaobrasil 7 hours agoprevThe other day, I saw a movie scene on YouTube where a guy is knife-fighting with another guy. There is a stab in the throat at the end, where all the life drains from his face. Blood is gushing and we see a human being kill another human being. I really don't understand why Google (and Western society) condones this sort of content while having a near zero-tolerance policy towards sex and love. But I figured it out today: violent media re-directs our rage against the unsustainable culture and gives it an outlet. I'm not bashing on violent entertainment BTW: I like martial arts movies. But it does have a deeper function: to give us a sense of justice (good versus bad), and distract us away from the atrocities of consumerism (destruction of the planet which gave us life). In short, violent media HELPS global capitalism and its destructiveness. Then why is sex banned? Yes, we can look for the superficial reasons, like \"oooh, parents don't want their kids to view this stuff\". But that does not even apply here, especially because this was in a private Google docs. No, sex is treated harshly because it is primal and goes against civilization: it represents a more primal human connection, and human connection is antithetical to consumerism and the destruction of the environment. Yes, we can also look for historical religious reasons, but there is a reason why such religious motivation survived, and other religious practices do NOT: any social practice which survives does so because it confers benefits to those who promote the practice. In this case, it confers benefits to the capitalists. reply namaria 7 hours agoparentViolence is channeled by western society as a righteous vengeance. Sex is channeled as the reproductive force of nuclear families. It's not that one is celebrated and the other oppressed. Violence against the innocent is always punished by a righteous warrior. And sex is not condemned. It is celebrated in the context of long term coupling to raise children. Promiscuity and non-reproductive sex is therefore seen as threat. An eligible target for the fury of the righteous. Non reproductive sex in western societies is only celebrated in the context of overpopulated urban centers. reply jupp0r 7 hours agorootparentThere is plenty of scientific evidence out there that even people in western rural areas enjoy sex because it's fun. reply namaria 6 hours agorootparentMainstream cultural mores as reflected in media is not the same as the values of everyone in a society. reply UncleEntity 6 hours agorootparentprevThough, to be fair, the barnyard animals might disagree... reply mjburgess 7 hours agoparentprevWatching violent films doesn't make you violent. Watching sexual content does (occasionally) make you want to have sex. There really isnt anything more to it than that. People who want to censor sexual content are accurately assessing its disposition to arouse audiences; and accurately assessing violent film's disposition to induce catharsis. reply nottorp 6 hours agorootparentCitation needed... reply mjburgess 6 hours agorootparentIt's a very easy experiment. Feel free to use yourself as a test subject. I don't anticipate a murder. reply nottorp 5 hours agorootparentAnd if i watch porn you anticipate rape? :) reply Al0neStar 3 hours agorootparentprevWhy do they have a problem with people being aroused? reply vouaobrasil 6 hours agorootparentprevI never said it made you violent, only that it provides an outlet for distraction. reply black6 7 hours agoparentprevActs of hate are allowed by the censors to be viewed, while acts of love are not. This speaks very highly about the state of American society. reply btbuildem 6 hours agoparentprevViolence is one of the key tools of the exploitative capitalist system. Society (as we have it set up) wouldn't function without a means of oppression, and so it is widely celebrated in popular culture. I'm not saying it's some wild conspiracy, it's just the side effects of it being one of the core mechanisms of the society we live in - it resonates throughout. reply throwaway220033 7 hours agoparentprevnext [3 more] [flagged] Hizonner 6 hours agorootparentBy \"the non-woke parts of the world\", you mean the parts with less advanced technology, less per-capita economic production by every measure, less personal security, less general education of the populace, and just generally less of every possible benefit of having \"a civilization\". And by \"always\" you mean times with less of all those things. You're not very good at this... reply throwaway220033 4 hours agorootparentDonâ€™t you sound so narcissistic? Was Roman Empire obsessed with sexuality when it was its peak? Was the western empire today obsessed with sexuality or more conservative when it was the superpower in the world? Western people project their trauma with Catholicism to all cultures and traditions for some reason and they think they owe their development to abandoning norms and just having public orgies in SF streets. When people think of west these days they think about pee and drug smelling dirty streets and collective madness of making all kinds of weird sexual acts public. The superiority of West of now is pure narcissism. High skilled people now prefer working remotely if they have to work for a western company, instead of moving there permanently. Visit China to see how civilization is built in 20 years. reply endisneigh 7 hours agoprev [â€“] Doesnâ€™t seem like a big deal - unshare it and copy to another platform, e.g. directly on discord, for sharing. Google really needs to stop preemptively locking accounts, though. They also need to warn ahead of time when someone is going to do something â€œbadâ€. reply inetknght 7 hours agoparent> unshare it and copy to another platform, e.g. directly on discord, for sharing Ahh you think Discord has better policies? You might want to rethink that. reply Aerroon 7 hours agorootparentIronically, I think the users are partly to blame for that. They were definitely complaining about some of the stuff that was on discord and discord then stepped up their enforcement of everything. reply dotnet00 7 hours agorootparentIt was less the users, and more hitpieces from censor-happy journalists. Kind of forces your hand when journalists are digging up relatively obscure discord \"servers\" with edgy jokes and racism, or trying to get 'activist' discords they disagree with banned, or finding leaked military documents and framing them all as Discord's fault. reply wredue 7 hours agorootparentprevI mean. For a time, I couldnâ€™t use discord for game parties cause 99% of the time, it was just man-children yelling n-bombs. I can very much see why people mightâ€™ve wanted some clean up. reply lakpan 7 hours agoparentprev [â€“] Warning is not possible, have you seen the amount of spam the web has? Whatâ€™s possible though is a better handling of these scenarios. Donâ€™t lock me out of my entire account, but stop the specific service/action breaking the ToS. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Fandom.ink is a decentralized social network running on Mastodon, providing search functionalities and language filters.",
      "Users can engage with posts, follow profiles, and navigate through the platform, with admins managing server stats and features.",
      "The platform allows for decentralized interactions and content discovery, offering a user-friendly social networking experience."
    ],
    "commentSummary": [
      "Google suspended a romance author's account over sexually explicit content, sparking a debate on the risks of depending exclusively on cloud services for data storage.",
      "Suggestions included securely backing up data with client-side encryption and managing encryption keys to maintain control over data and balance cloud with physical backups.",
      "Concerns highlighted potential account suspensions, censorship, and data loss on platforms like Google, along with debates on societal perceptions of violence and sexuality and tech companies' role in content moderation."
    ],
    "points": 182,
    "commentCount": 192,
    "retryCount": 0,
    "time": 1711631673
  },
  {
    "id": 39849126,
    "title": "Understanding DNA Repair in Long-Term Memory Formation",
    "originLink": "https://www.nature.com/articles/d41586-024-00930-y",
    "originBody": "NEWS 27 March 2024 Correction 27 March 2024 Memories are made by breaking DNA â€” and fixing it Nerve cells form long-term memories with the help of an inflammatory response, study in mice finds. By Max Kozlov Twitter Facebook Email Neurons (shown here in a coloured scanning electron micrograph) mend broken DNA during memory formation. Credit: Ted Kinsman/Science Photo Library When a long-term memory forms, some brain cells experience a rush of electrical activity so strong that it snaps their DNA. Then, an inflammatory response kicks in, repairing this damage and helping to cement the memory, a study in mice shows. The findings, published on 27 March in Nature1, are â€œextremely excitingâ€, says Li-Huei Tsai, a neurobiologist at the Massachusetts Institute of Technology in Cambridge who was not involved in the work. They contribute to the picture that forming memories is a â€œrisky businessâ€, she says. Normally, breaks in both strands of the double helix DNA molecule are associated with diseases including cancer. But in this case, the DNA damage-and-repair cycle offers one explanation for how memories might form and last. It also suggests a tantalizing possibility: this cycle might be faulty in people with neurodegenerative diseases such as Alzheimerâ€™s, causing a build-up of errors in a neuronâ€™s DNA, says study co-author Jelena Radulovic, a neuroscientist at the Albert Einstein College of Medicine in New York City. Inflammatory response This isnâ€™t the first time that DNA damage has been associated with memory. In 2021, Tsai and her colleagues showed that double-stranded DNA breaks are widespread in the brain, and linked them with learning2. To better understand the part these DNA breaks play in memory formation, Radulovic and her colleagues trained mice to associate a small electrical shock with a new environment, so that when the animals were once again put into that environment, they would â€˜rememberâ€™ the experience and show signs of fear, such as freezing in place. Then the researchers examined gene activity in neurons in a brain area key to memory â€” the hippocampus. They found that some genes responsible for inflammation were active in a set of neurons four days after training. Three weeks after training, the same genes were much less active. How to see a memory The team pinpointed the cause of the inflammation: a protein called TLR9, which triggers an immune response to DNA fragments floating around the insides of cells. This inflammatory response is similar to one that immune cells use when they defend against genetic material from invading pathogens, Radulovic says. However, in this case, the nerve cells were responding not to invaders, but to their own DNA, the researchers found. TLR9 was most active in a subset of hippocampal neurons in which DNA breaks resisted repair. In these cells, DNA repair machinery accumulated in an organelle called the centrosome, which is often associated with cell division and differentiation. However, mature neurons donâ€™t divide, Radulovic says, so it is surprising to see centrosomes participating in DNA repair. She wonders whether memories form through a mechanism that is similar to how immune cells become attuned to foreign substances that they encounter. In other words, during damage-and-repair cycles, neurons might encode information about the memory-formation event that triggered the DNA breaks, she says. When the researchers deleted the gene encoding the TLR9 protein from mice, the animals had trouble recalling long-term memories about their training: they froze much less often when placed into the environment where they had previously been shocked than did mice that had the gene intact. These findings suggest that â€œwe are using our own DNA as a signalling systemâ€ to â€œretain information over a long timeâ€, Radulovic says. Fitting in How the teamâ€™s findings fit with other discoveries about memory formation is still unclear. For instance, researchers have shown that a subset of hippocampal neurons known as an engram are key to memory formation3. These cells can be thought of as a physical trace of a single memory, and they express certain genes after a learning event. But the group of neurons in which Radulovic and her colleagues observed the memory-related inflammation are mostly different from the engram neurons, the authors say. Flashes of light show how memories are made TomÃ¡s Ryan, an engram neuroscientist at Trinity College Dublin, says the study provides â€œthe best evidence so far that DNA repair is important for memoryâ€. But he questions whether the neurons encode something distinct from the engram â€” instead, he says, the DNA damage and repair could be a consequence of engram creation. â€œForming an engram is a high-impact event; you have to do a lot of housekeeping after,â€ he says. Tsai hopes that future research will address how the double-stranded DNA breaks happen and whether they occur in other brain regions, too. Clara Ortega de San Luis, a neuroscientist who works with Ryan at Trinity College Dublin, says that these results bring much-needed attention to mechanisms of memory formation and persistence inside cells. â€œWe know a lot about connectivityâ€ between neurons â€œand neural plasticity, but not nearly as much about what happens inside neuronsâ€, she says. doi: https://doi.org/10.1038/d41586-024-00930-y Read the related News & Views: â€˜Innate immunity in neurons makes memories persistâ€™. Updates & Corrections Correction 27 March 2024: An earlier version of this story indicated that broken DNA accumulated in the centrosome. It is DNA repair machinery that accumulates in that organelle. References Jovasevic, V. et al. Nature 628, 145â€“153 (2024). Article Google Scholar Stott, R. T., Kritsky, O. & Tsai, L.-H. PLoS ONE 16, e0249691 (2021). Article PubMed Google Scholar Josselyn, S. A. & Tonegawa, S. Science 367, eaaw4325 (2020). Article Google Scholar Download references Reprints and permissions Latest on: Neuroscience Brain Jobs ECUST Seeking Global Talents Join Us and Create a Bright Future Together! Shanghai, China East China University of Science and Technology (ECUST) World-Class Leaders for Research in Materials Science National Institute for Materials Science (NIMS, Japan) calls for outstanding researchers who can drive world-class research in materials science. Tsukuba, Japan (JP) National Institute for Materials Science Professor of Experimental Parasitology (Leishmania) To develop an innovative and internationally competitive research program, to contribute to educational activities and to provide expert advice. Belgium (BE) Institute of Tropical Medicine PhD Candidate (m/f/d) We search the candidate for the subproject \"P2: targeting cardiac macrophages\" as part of the DFG-funded Research Training Group \"GRK 2989: Targeti... Dortmund, Nordrhein-Westfalen (DE) Leibniz-Institut fÃ¼r Analytische Wissenschaften â€“ ISAS â€“ e.V. PhD Candidate (m/f/d) At our location in Dortmund we invite applications for a DFG-funded project. This project will aim to structurally and spatially resolve the altere... Dortmund, Nordrhein-Westfalen (DE) Leibniz-Institut fÃ¼r Analytische Wissenschaften â€“ ISAS â€“ e.V.",
    "commentLink": "https://news.ycombinator.com/item?id=39849126",
    "commentBody": "Memories are made by breaking DNA â€“ and fixing it (nature.com)181 points by birriel 11 hours agohidepastfavorite71 comments lukeinator42 6 hours agoInterestingly, although the hippocampus plays a massive role in memory consolidation, memories are ultimately distributed throughout the cortex. I'm curious whether this mechanism generalizes to all neurons or is specific to how the hippocampus can learn quickly, especially since the hippocampus is the one place where neurogenesis has been found in adults. reply bjornsing 5 hours agoparentWhat evidence is there for this distribution over the whole cortex hypothesis? reply lukeinator42 5 hours agorootparentThe classic study of patient H.M., who had his hippocampus removed, showed that the hippocampus isn't where memories are stored long-term https://www.ncbi.nlm.nih.gov/pmc/articles/PMC497229/ (this was one of the first studies to discover the role of the hippocampus in memory). H.M. was still able to recall memories from before the surgery, and numerous animal and human studies have demonstrated this too. The hippocampus connects to most of the cortex, and there is an entire research area looking into hippocampal replay and how it facilitates consolidation, but there definitely isn't a singular place where memories are stored in the brain long-term. reply noworld 5 hours agorootparentprevhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4526749/#:~:tex.... reply namero999 4 hours agorootparentprevAs Michael Levin's work shows, one doesn't even need a brain or a nervous system for memory https://www.scientificamerican.com/article/brains-are-not-re... reply tamimio 6 hours agoprevHow does that work in visual memory, does it break and fix it too and that quickly? I have strong visual memory that I remember back in school I used to remember the page and itâ€™s page number just by looking at it for few seconds, and if I saw a face for a second even randomly anywhere, I can recall when and where for a long period after.. I find it hard to imagine or rather scary all that is breaking/fixing the dna.. reply softfalcon 6 hours agoparentMy guess would be that itâ€™s not all happening at once as you have short and long term memory. The simplest analogy is that your short term memory is a buffer that doesnâ€™t use DNA, but a limited electro chemical storage of new present-moment information. Then it is transcribed through several steps of ever longer term storage methods in the brain. Some of which require sleep. reply sva_ 6 hours agoparentprevThe article doesn't seem to claim that this is the only mechanism, even if the title seems to suggest so. reply RaftPeople 4 hours agoparentprevThere is a lot of activity with DNA for long term potentiation even without this breaking/fixing stuff. Learning requires epigenetic modifications to DNA in the neuron. DNA near the synapse (not necessarily in the Soma) is altered to produce the proteins that sustain the synapse at new level. reply thro1 1 hour agoprevEvery neuron in the brain has unique DNA and ancestorship - ongoing record of neuronal life history. https://www.science.org/doi/10.1126/science.aab1785 (2015) : Somatic mutations create nested lineage trees, allowing them to be dated relative to developmental landmarks and revealing a polyclonal architecture of the human cerebral cortex. Thus, somatic mutations in the brain represent a durable and ongoing record of neuronal life history, from development through postmitotic function. https://www.scientificamerican.com/article/scientists-surpri... reply throwaway4aday 9 hours agoprevInteresting that this involves a response similar to an immune response to a pathogen. I've read a couple articles about alternate theories of Alzheimer's linking it to an increased immune response in the brain. reply Jensson 7 hours agoparent> similar to an immune response to a pathogen Maybe that is the origin? Cells learning to counter different threats and communicating that information to other cells could be a plausible first step towards intelligence. reply dappermanneke 3 hours agorootparentthereâ€™s no learning involved in the immune response in the brain. the brain is limited to the innate immune system, of which TLRs and their binding to conserved domains are basically the major component. thereâ€™s no adaptive immune system that does â€œlearningâ€ here (and by learning in the adaptive immune system we mean recombination of antibodies, presentation of contents of each cell on the surface of the cells for antibodies to try and bind to, and the preservation of cells that carry antibodies that bound to something successfully as memory cells to enable long term immunity) reply delichon 10 hours agoprevFascinating that the apparatus for memory between generations may also be used for memory within a generation. \"Breaking\" and \"fixing\" DNA could also be taken as a description of meiosis or mitosis. Perhaps there is some code re-use there. reply api 4 hours agoparentAntihistamines that cross the blood brain barrier make people feel stoned or tired because histamine does something entirely different in the brain from what it does in the rest of the body. Seems like there's a lot of code reuse in the brain. It operates almost like a different sort of biology encapsulated within an animal body. reply juitpykyk 10 hours agoparentprevNeuron's DNA is not passed down, it would be quite logical for evolution to use neuronal DNA for weight storage. reply londons_explore 9 hours agorootparentMany nervous system behaviours do appear to be passed through genetics - for example, the ability to breathe, the reflex to avoid pain, etc. I suspect in the future we might find mechanisms beyond simple natural selection that allowed those mechanisms to get encoded in genetics. reply throwaway4aday 9 hours agorootparentI think you're talking to the wrong point. These memories aren't being encoded in germ cells, they are after the fact changes to DNA in mature neurons which have completely differentiated. I would think it's very possible at that stage of development for them to add or remove segments of DNA in order to encode new information not related to the development of the cell as long as it didn't interfere too much with parts that are actively used for the ongoing upkeep of cell activity. It would need to alter how the cell functions a little bit for the changes to modify the neuron's ability to process signals though. reply CuriouslyC 8 hours agorootparentI should note that studies have demonstrated that bacteria who have been modified not to be able to consume lactose will develop mutations that allow them to consume lactose again much more quickly than would be expected given the number of bacteria, the rate of random mutations and the size of the genome. It has been hypothesized that there is a cellular mechanism to control which portions of DNA are easily mutable, possibly through a combination of chromatin structure, epigenetic modification and changes to the local chemical environment via metabolism. This mechanism might exist in a scaled up form in humans. reply juitpykyk 7 hours agorootparentIsn't that what happens in antibody germinal centers? https://en.wikipedia.org/wiki/Somatic_hypermutation reply rolph 5 hours agorootparentprevbacterial plasmids are a common form of horizontal gene flow between individuals reply EVa5I7bHFq9mnYK 1 hour agorootparentprevCould they be transferred while in the womb? reply phkahler 6 hours agorootparentprev>> it would be quite logical for evolution to use neuronal DNA for weight storage. To pass that down you'd have to replicate the connectivity of the network for the weights to be relevant right? Related: The article doesn't say which DNA areas are broken and repaired. Nor does it say if they are modified. It seems like encoding weights in DNA would make them more robust but harder to change. If so, there should be a particular region where this is happening. Maybe there's a mapping between certain DNA areas and each synapse. That'd be really interesting. reply RaftPeople 4 hours agorootparentIndependent of this breaking/fixing, it's already known that DNA near the synapse (not necessarily in the neurons Soma) is modified via epigenetics to sustain the synapse at the new level. So yes, DNA epigenetic changes near the synapse are a key part of maintaining the \"weight\" or strength of that particular connection. (\"key part\" phrase because there is a lot of complexity and they haven't nailed it all down, there could be other \"key parts\"). reply phkahler 1 hour agorootparent>> DNA epigenetic changes near the synapse are a key part of maintaining the \"weight\" or strength of that particular connection. What do you mean by \"near the synapse\"? Is there DNA outside the nucleus or something? Is there DNA that maps (corresponds to) the synaptic pattern of the neuron? reply juitpykyk 6 hours agorootparentprevNeurons are not on the germ line, whatever happens to their DNA is not passed down to your children. There was another article in the recent years about neurons using RNA or DNA for storing information related to their activation patterns. reply axus 4 hours agorootparentThe baby is connected to the mother's placenta for months, maybe information could be transmitted then. I've never heard anything to support that idea, though! reply ChainOfFools 42 minutes agorootparentThis always seemed like one of those little biological details, like the well known example of that nerve which loops all the way down a giraffe's neck and back again in order to connect two regions only a few inches apart, that shows that nature doesn't refactor. Because it seems like such a waste of the opportunity afforded by extended physical secueity and direct connection between mother and developing child, that some means of transferring a portion of the mother's learned knowledge, or at least some coarse grained abstraction of it, to the fetus, has never developed. The lazy dismissal of this question is just to say, if nature needed it, it would have evolved it, but this doesn't seem to hold in every case [0]. It seems rather that there was no way for such a capability to be built out of extending existing mechanisms, with the major barrier being the absence of nerve tissue in the umbilical cord, where higher level CNS connectivity might have evolved from as a foothold [0] and certainly doesn't account for what may happen in the future unless nature is completely done developing everything that could be developed. Nor does it incorporate the idea that human manipulation of our own biology is not itself also part of nature. reply thro1 1 hour agorootparentprevWellcome. Sometimes it may happen that familiar stem cells cross maternal-fetal barrier in placenta, persist somehow and start to function regardless, where stem cells are needed - usually in younger sibling coming from the older, in place of original cells, even in the brain - forming part of it as of another person (more or less) - interconnected but not the same.. The Most Mysterious Cells in Our Bodies Don't Belong to Us https://www.theatlantic.com/science/archive/2024/01/fetal-ma... ( https://news.ycombinator.com/item?id=38861497 ) reply JPLeRouzic 3 hours agorootparentprevIn addition, most parts of the first cell of what will become a baby, come from the mother. This includes all DNA in mitochondria and another organelle that I don't remember the name. reply rolph 5 hours agorootparentprevepigenetic inheritance is real reply cjbgkagh 6 hours agorootparentprevI wonder if that means that each neuron could act as a mini turning machine reply rolisz 3 hours agorootparentCheck out Michael Levin's work, who's done some experiments with skin cell and has shown that they learn to do stuff. reply rolph 5 hours agorootparentprevstop wondering and look deeper, youve bumped into the begining of an incredible journey. even individual protiens, exhibit rule paring. reply cjbgkagh 4 hours agorootparentMy equivocation was to avoid downvote brigades that hit me last time I posited this same idea on HN. reply logtempo 10 hours agoparentprevso, my body is refactoring all the time? Cool 8) reply logtempo 10 hours agoparentprevso, my body is refactoring all the time? reply Vox_Leone 8 hours agoprevAlthough I have nothing substantial to contribute to the topic, I can't help but notice the beautiful mess of the neural field shown in the image; a reminder of the complexity of the real world and the challenges that still remain. Very far from our organized models arranged in layers of 'objects' and the didactic diagrams containing two neurons, or even convolutional network diagrams. Which brings to mind the good Professor â€œit must be made as simple as possible, but not simplerâ€. reply newzisforsukas 9 hours agoprevhttps://www.nature.com/articles/s41586-024-07220-7 reply LarsDu88 4 hours agoprevInteresting. I think TLR-9 stands for toll-like receptor 9. And these toll proteins were originally studied in fruit fly dorsal ventral patterning and also play a role in the innate immune system which we share with insects. If this study is right (who knows if it will end up being reproducible), then this would be a great example of how evolution recycles existing proteins to \"invent\" new stuff. Toll proteins were probably originally involved in body pattern formation, were recycled into a role in innate immunity, and finally in mammals may also play a role in triggering an immune response based DNA damage repair event that plays a role in memory formation. reply suoduandao3 3 hours agoprevinteresting. Brings to mind this study: https://sheldrake.org/files/pdfs/papers/An-experimental-test... Memory and DNA are both weird. As an appreciator of weirdness it's fun to see that there's some kind of connection between the two. Anyone know if there a theory of weirdness where it would compound? reply armchairdweller 4 hours agoprevI found one of the most interesting aspects of memory to be its non-locality. There were a lot of experiments in the 20th century (lesions etc.) showing that memory is fundamentally non-local. You could remove large parts of brains and the memories were still there. This is difficult to explain with \"local\" / neural-network-like theories of memory. If you lesion specific parts of GPT4, the \"memory trace\" will be gone. I find this incredibly interesting. Is this still the primary view? The hippocampus is involved in formation of new memories. Without it this process is not working at all. reply kenjackson 7 hours agoprevDumb question from a very last biology person. I thought memories were stored in the brain and The brain retrieved them. How does the brain get the data from the DNA for long term memories? The article seeks like a simple explanation, but it still doesnâ€™t make sense to me. reply pazimzadeh 6 hours agoparentLike most cells, brain cells have DNA. I don't think this is saying that the memory is directly encoded in the DNA, but that when a memory is formed (in this case a fear response), that can lead to breaks in neuronal DNA, and loose DNA in cells triggers the immune system, which then tries to repair the damage. reply kenjackson 6 hours agorootparentAnd the repairing of this broken DNA by the immune system somehow strengthens the encoding of the memory? But the DNA itself doesnâ€™t actually capture any of the memory. Is that accurate? reply namaria 5 hours agorootparent> And the repairing of this broken DNA by the immune system somehow strengthens the encoding of the memory? \"In other words, during damage-and-repair cycles, neurons might encode information about the memory-formation event that triggered the DNA breaks, she says.\" I'd say the researchers speculate something like what you said. The inflammatory response and the activities involved in DNA repair seem correlated with long term memory formation. reply rolph 5 hours agoparentprevso far its a correlate, not yet determined to be a direct mechanistic causation reply begueradj 5 hours agoprevThat's something we can use to interpret what is mentioned in \"The Talent Code\" book: https://www.amazon.com/Talent-Code-Greatness-Born-Grown/dp/0... reply cjbgkagh 6 hours agoprevHuh, I wonder if this is why RCCX genes associated with autoimmune conditions / inflammation is also associated with higher IQs. reply lupire 6 hours agoparentThe OP observation is that memory formation includes damaging DNA and repairing it , either as a side effect or as a mechanisms of memory formation, but it's unclear which. Generalized autoimmune disorders probably wouldn't increase memory formation as a mechanism -- that effect would be \"memorizing\" \"white noise\", not a specific meaningful memory (neuron path). But perhaps high IQ individuals, associated with hyperactivity/high metabolism of some kind, have more/faster neuronal activity, cause more of this DNA damage then the average person experiences, to the point where it has detrimental inflammatory effects? reply cjbgkagh 6 hours agorootparentI have multiple TNXB SNPs, tested very high IQ, and have debilitating levels of inflammation with ME/CFS. Wasnâ€™t so bad when I was younger but got really bad in my 20s and 30s. I have it under control now with quite an exotic mix of medications. My memory is pretty insanely good as is my ability to learn new things. I had previously thought it was due to interest and acumen but have come to accept that I am fortunate in ways that others are not - the difference being that I no longer blame others inability to learn as much or as quickly on an apparent laziness or lack of interest. ME/CFS is very debilitating though so most people with this will probably just fade away in their 20s and 30s. There are ways to treat it that I wish more people knew about. Edit; I should mention that too much inflammation is associated with brain fog which inhibits working memory and memory formation. Brain fog is one of the many core symptoms of ME/CFE. It would make sense if the body is optimizing childhood learning over long term health. reply wburglett 5 hours agorootparentWhat approaches are there for treating ME/CFS? reply cjbgkagh 5 hours agorootparentIt depends on the cause but for the TNXB subset which is probably a big chunk of them there is hGH peptides, Testosterone replacement therapy (TRT), low dose modafinil, amitriptyline, IGF-agonists (semaglutide/ozempic), low dose naltrexone (LDN), TUDCA, eliminate sugar (including fruit) from diet, melatonin, UV-A light therapy in eyes during the day, blue light blocking glasses at night, sleep hygiene, lower stress lifestyle, supplemental T3 hormone, caffeine, and resistance exercise. Cardio above a fast walk should probably be eliminated due to post exertional malaise (PEM). The cause of PEM is a tough one that Iâ€™m still working on. reply wburglett 3 hours agorootparentFor PEM specifically have you had any experience with pyridostigmine or cumin (the kitchen spice)? reply cjbgkagh 2 hours agorootparentIâ€™ve tried Enalapril which seems similar to Pyridostigmine, I ended up with pretty strong blood pressure swings. Iâ€™ll check it out though. The problem with testing PEM for me is the extreme downside if the test fails, it could be many months before Iâ€™m good again. Instead of trying these things myself Iâ€™m more apt to crowd source from people who I know that also have PEM and more open to testing it. reply bugbuddy 6 hours agoprevI am surprised no one has referenced the Animus here. reply Terr_ 5 hours agoparentWhile I see the association, there's no reason to think that DNA from a billions of nerve cells in your brain is somehow being synced to specific single cells. (Haploid cells that are missing half the usual load of DNA, to boot.) reply nicman23 5 hours agoprevdamn assassin's creed got it right? reply pfdietz 4 hours agoprevDoes this mean education is carcinogenic? reply darkerside 10 hours agoprevWhat might this news imply about NSAIDS and their impact on forming memories? reply newzisforsukas 9 hours agoparent> Participants using aspirin at baseline but not 5 years prior were more likely to develop cognitive impairment https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4670291/ Many related articles reply GlassOwAter 7 hours agorootparentUh oh.. my doctors never told me this. That explains the last 10 years x.x reply hoc 8 hours agoparentprevI immediately thought of that too. But also other influences on these reactions might be interesting to look at. From stress levels to metabolic issues including unbalanced supply with nutrients, infections, injuries. How do you remember your last exhausting argument or traumatic experience... Not sure about the actual mechanisms, but the idea of these kind of influences on individual memory formation is intriguing. After all, it's hacker news :) reply tomrod 10 hours agoparentprevIf it's not already known it opens an intriguing avenue for research. reply fragmede 7 hours agoparentprevShit, what does this mean for alcohol, and its ability to interfere with forming memories? We think we know why (alcohol affects glutamate which affects memory), but with this new information, does that change things? reply neom 6 hours agorootparentI was thinking recently about this thing I've encountered as a recovering alcoholic. I'm pretty sure I have a \"drunk memories\" brain and a \"sober memories\" brain - and I don't know I can access some of each while I'm in the other, that is to say sober memories when I'm drunk and drunk memories when I'm sober. I'd like to test this more, but I'm not willing to break my sobriety, so who knows if it's imagined or real. reply Terr_ 5 hours agorootparent> Research shows that individuals are less likely to remember information learned while intoxicated when they are once again sober. However, information learned or memories created while intoxicated are most effectively retrieved when the individual is in a similar state of intoxication. https://en.wikipedia.org/wiki/State-dependent_memory reply phkahler 5 hours agorootparentprev>> I'm pretty sure I have a \"drunk memories\" brain and a \"sober memories\" brain A pet hypothesis of mine is that maybe some of the brain chemicals act like an extra input to the neural network, and can be associated with various behaviors or memories. Lets say there are 5 of them which would create a 5 dimensional \"chemical space\" you're operating in. Certain things can be remembered and associated with regions in this space. Being anxious, depressed, afraid, or whatever could be temporarily \"cured\" by shifting you out of the current region in this space. Which chemicals work would depend on your specific programming. This might explain people who have a fear response to positive emotional situations (they were traumatized by someone that otherwise gave them positive emotions that release certain chemicals). Just a weird hypothesis - I bet it's been researched but I haven't looked. Edit: One of the other responses to the parent post provided this: https://en.wikipedia.org/wiki/State-dependent_memory reply ofslidingfeet 8 hours agoprev [â€“] Terrence McKenna called it. reply firtoz 7 hours agoparent [â€“] Please elaborate. reply neom 6 hours agorootparent [â€“] Terrence talked a lot about everything as code, and DNA being that code, or part of that code anyway. He's talked about it a lot in different ways, so I'm not sure what talk OP is specifically referring to. He gave a couple of talks that are related to I Ching, it might be in detail in one of those. https://www.youtube.com/watch?v=Zk8GsaRA6aY reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A study in mice, published in Nature, reveals that long-term memories are established through an inflammatory response aiding in DNA damage repair.",
      "The research indicates that during memory formation, intense electrical activity causes DNA breaks in brain cells, leading to an immune response for repair, potentially influencing neurodegenerative conditions such as Alzheimer's.",
      "This study underscores the significance of comprehending the mechanisms behind memory creation and maintenance within cells."
    ],
    "commentSummary": [
      "Memories are stored in various parts of the brain and include epigenetic changes in neurons, with DNA near synapses being modified to enhance neural connections.",
      "The focus is on the significance of DNA in memory creation, exploring mechanisms beyond natural selection, and examining how substances and mental states influence memory.",
      "The discussions emphasize the intricate nature of biological development, hinting at potential undiscovered mechanisms and complexities within the process."
    ],
    "points": 181,
    "commentCount": 71,
    "retryCount": 0,
    "time": 1711618000
  },
  {
    "id": 39853958,
    "title": "AI21 Labs Unveils Jamba: Cutting-Edge AI Model Based on Mamba Architecture",
    "originLink": "https://www.maginative.com/article/ai21-labs-unveils-jamba-the-first-production-grade-mamba-based-ai-model/",
    "originBody": "A121 Open Source AI21 Labs Unveils Jamba: The First Production-Grade Mamba-Based AI Model Jamba is a groundbreaking SSM-Transformer model that offers the best of both worlds, addressing the drawbacks of traditional Transformer architectures while maintaining their powerful capabilities. Chris McKay March 28, 2024 â€¢ 2 min read AI21 Labs, has just released Jamba, the world's first production-grade AI model based on the innovative Mamba architecture. Most models today (like GPT, Gemini and Llama) are based on the Transformer architecture. Jamba combines the strengths of both the Mamba Structured State Space model (SSM) and the traditional Transformer architecture, delivering impressive performance and efficiency gains. Jamba boasts an extensive context window of 256K tokens, equivalent to around 210 pages of text, while fitting up to 140K tokens on a single 80GB GPU. This remarkable feat is achieved through its hybrid SSM-Transformer architecture, which leverages mixture-of-experts (MoE) layers to draw on just 12B of its available 52B parameters during inference. The result is a model that can handle significantly longer contexts than most of its counterparts, such as Meta's Llama 2 with its 32,000-token context window, while maintaining high throughput and efficiency. Jamba delivers 3x throughput on long contexts, making it a more efficient model than Transformer-based models of comparable size like Mixtral 8x7B. One of the key advantages of Jamba is its ability to deliver 3x throughput on long contexts compared to Transformer-based models of similar size, like Mixtral 8x7B. This is made possible by the model's unique hybrid architecture, which is composed of Transformer, Mamba, and mixture-of-experts (MoE) layers, optimizing for memory, throughput, and performance simultaneously. It features a blocks-and-layers approach, with each Jamba block containing either an attention or a Mamba layer, followed by a multi-layer perceptron (MLP). This results in an overall ratio of one Transformer layer out of every eight total layers. AI21 Labs says this approach allows the model to maximize quality and throughput on a single GPU, leaving ample memory for common inference workloads. Jamba's impressive performance extends beyond efficiency and cost-effectiveness. The model has already demonstrated remarkable results on various benchmarks, matching or outperforming state-of-the-art models in its size class across a wide range of tasks. Jamba outperforms or matches other state-of-the-art models in its size class on a wide range of benchmarks. Jamba is being released with open weights under Apache 2.0 license. It is available on Hugging Face, and will also be accessible from the NVIDIA API catalog as NVIDIA NIM inference microservice, which enterprise applications developers can deploy with the NVIDIA AI Enterprise software platform. For now, Jamba is currently released as a research model without the necessary safeguards for commercial use. However, AI21 Labs plans to release a fine-tuned, safer version in the coming weeks. As the AI community continues to explore and refine new architectures, we can expect to see even more impressive gains in performance, efficiency, and accessibility, paving the way for a new generation of more capable AI models.",
    "commentLink": "https://news.ycombinator.com/item?id=39853958",
    "commentBody": "Jamba: Production-grade Mamba-based AI model (maginative.com)173 points by bubblehack3r 4 hours agohidepastfavorite37 comments cs702 48 minutes agoPlease link to the original post: https://www.ai21.com/blog/announcing-jamba Jamba looks fabulous. Good performance for its size and much more efficient than the available open alternatives. The key idea: One of out of every eight transformer blocks in Jamba applies dot-product attention with quadratic cost, but the other seven out of eight apply a Mamba layer with linear cost. And the entire model is a mixture of experts(MoE) so only ~12B parameters are used at once for inference. Thank you to the folks at AI21 for making Jamba available! reply a_wild_dandan 2 hours agoprevTo those curious about the tradeoffs between transformer and state space model layers, I highly recommend Sasha Rush's video on it: https://www.youtube.com/watch?v=dKJEpOtVgXc reply eigenvalue 50 minutes agoprevHas anyone gotten this to work in linux using 1 or 2 4090s? I get stuck on \"Loading checkpoint shards: 71%\" and then it bails. But weirdly nvidia-smi shows plenty of VRAM available. My machine has 256gb of RAM so I don't think that's the problem either. Really excited to try this one. reply Reubend 3 hours agoprevIt's great to see a full production level model using Mamba. But when it comes to long context window benchmarks, I'd love to see performance as well as throughput. I was under the impressions that Mamba has huge increases in throughput at the cost of modest losses in accuracy when using long contexts. reply samus 1 hour agoparentThis one should have you covered :-) one out of every eight layers is a traditional Transformer layer, which should ensure precision, at least over short distances. reply refulgentis 2 hours agoparentprevI would too -- long context has been such a red herring across providers, Claude 3 is the first I've seen that seems to genuinely have some sort of qualitative leap in noticing things. It is worth noting I'm fairly sure there's no inherent theoratical decrease to accuracy in long contexts, the claimed theoratical change is an _increase_ in long-term accuracy in long contexts. reply tempusalaria 1 hour agorootparentEvery long context sucks right now. All the model providers benchmark on fact recall which is very limited. Actual ability to do anything complicated beyond 16k tokens is not present in any current model I have seen. reply binalpatel 1 hour agorootparentprevGemini 1.5 Pro is really good at long context in my experience. reply Arthur_ODC 1 hour agorootparentprevLong Context is great and all, but it sucks that all of these LLM's have really poor output length. If I feed something an entire book and ask for a comprehensive summary then I'm expecting at least a full 3-page summary. I get that they try to force these things to be \"concise\" to save on compute, but good lord it's so annoying. reply CuriouslyC 1 hour agorootparentThat's a chat gpt problem, if you hit the API it's not nearly so hard to get good output. reply refulgentis 1 hour agorootparentI wouldn't say that, my latest big user story for making sure I'm handling huge inputs was \"translate Moby dick to zoomer\". Cant give any service chunks larger than ~5K tokens, over API, without it failing. (Miserably, like, I'd be fine if it gave a paragraph back. But at least on this \"map\" task, there's a critical point where there's so much input that the reward function ends up imitating the input more instead of chatting) reply skybrian 2 hours agoprev> Jamba boasts an extensive context window of 256K tokens, equivalent to around 210 pages of text, while fitting up to 140K tokens on a single 80GB GPU. I realize this is a big improvement, but itâ€™s striking how inefficient LLMâ€™s are, that you need 80GB of GPU memory to analyze less than 1 megabyte of data. Thatâ€™s a lot of bloat! Hopefully thereâ€™s a lot of room for algorithmic improvements. reply electric_mayhem 2 hours agoparentItâ€™s literally simulating a neural network. How much of your 5-sense experiential memories and decades of academic book learning are you bringing to understand my reply to your post? How many gigabytes do you think thatâ€™s equivalent to? reply skybrian 2 hours agorootparentJamba seems to be distributed as 21 5-gigabyte files [1] so I guess thatâ€™s another way of looking at it. [1] https://huggingface.co/ai21labs/Jamba-v0.1/tree/main reply _false 2 hours agorootparentprevI love both parent post perspectives on this. reply smusamashah 2 hours agoprevThere was a recent thread on explaining Mamba https://news.ycombinator.com/item?id=39501982 (https://www.kolaayonrinde.com/blog/2024/02/11/mamba.html) There was another one on the same thing, probably better https://news.ycombinator.com/item?id=39482428 (https://jackcook.com/2024/02/23/mamba.html) reply dang 1 hour agoparentThanks! Macroexpanded: Mamba Explained: The State Space Model Taking On Transformers - https://news.ycombinator.com/item?id=39501982 - Feb 2024 (93 comments) Mamba: The Easy Way - https://news.ycombinator.com/item?id=39482428 - Feb 2024 (60 comments) Is Mamba Capable of In-Context Learning? - https://news.ycombinator.com/item?id=39286410 - Feb 2024 (1 comment) Vision Mamba: Efficient Visual Representation Learning with Bidirectional SSM - https://news.ycombinator.com/item?id=39214939 - Feb 2024 (16 comments) MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts - https://news.ycombinator.com/item?id=38932350 - Jan 2024 (39 comments) Implementation of Mamba in one file of PyTorch - https://news.ycombinator.com/item?id=38708730 - Dec 2023 (109 comments) Fortran inference code for the Mamba state space language model - https://news.ycombinator.com/item?id=38687342 - Dec 2023 (1 comment) Guide to the Mamba architecture that claims to be a replacement for Transformers - https://news.ycombinator.com/item?id=38659238 - Dec 2023 (2 comments) Mamba outperforms transformers \"everywhere we tried\" - https://news.ycombinator.com/item?id=38606590 - Dec 2023 (25 comments) Mamba: Linear-Time Sequence Modeling with Selective State Spaces - https://news.ycombinator.com/item?id=38522428 - Dec 2023 (37 comments) Mamba: New SSM arch with linear-time scaling that outperforms Transformers - https://news.ycombinator.com/item?id=38520992 - Dec 2023 (2 comments) reply gautamcgoel 3 hours agoprevWhy include self-attention layers at all? In other words, why not just alternate SSM and MLP layers? reply NLPaep 2 hours agoparentMamba is bad with long context. It doesn't remember phone numbers https://www.harvard.edu/kempner-institute/2024/02/05/repeat-... reply a_wild_dandan 33 minutes agorootparentGood! DNNs unlock semantics (parsing, transforming, producing). That's the basis of general intelligence, not encyclopedic random string recall. Models shouldn't burn ungodly quantities of compute emulating DDR5 with their working memory. We need machines that think better, not memorize well. We already have plenty of those. Massive context windows, and their needle tests, are misguided. We won't reach human-level AGI by basically inventing a natural language RDBMS. Our resources should primarily target better reasoning systems for our models, reinforcement learning, etc. If we can build a GPT4-level problem solving system that coincidentally also can't remember telephone numbers, I'll consider it major progress. reply ninjahatori 55 minutes agoprevOn a side note: working over longer contexts also reminds me of MemGPT(https://github.com/cpacker/MemGPT) I think a similar concept can be applied to Mamba architecture models too. reply haddr 1 hour agoprevWill it be possible to run such model family in ollama? reply andy99 1 hour agoparentMamba is supported in llama.cpp so should be (edit - apparently it's not strictly the mamba architecture, it's a mix of mamba and transformers, so it looks like it would have to be ported to llama.cpp) reply kelseyfrog 3 hours agoprevI'm glad we're seeing exploration into scaling post-transformer LLM architectures, but I'm disappointed that it has a context window. That was kind of the selling point of Mamba(and SSM models in general), right linear scaling because state+input=next_state+output? reply a_wild_dandan 24 minutes agoparentstate = context The difference between SSMs and GPTs here is how that state/context scales. Per usual in engineering, there are big trade offs! reply kelseyfrog 12 minutes agorootparentI'm not following. State is a multi-dimensional vector and context is a list of tokens. State is perturbed by A and Bx(t), while context is appended to by sampling the predicted token distribution. reply refulgentis 2 hours agoparentprevI'm not sure I follow fully, it is also the case for (handwaves) \"traditional\" LLMs that state + input = next state + output. Its just that output increases, so as output becomes input, eventually state + input / next state + output is greater than the context size. Re: linear scaling, that means the runtime cost is O(n) to context size, rather than traditional transformer O(n^2) reply maccam912 1 hour agorootparentI think kelseyfrog meant that the state for a mamba model is supposed to \"remember\" stuff even if it doesn't have the actual tokens to reference any more. It might not be guaranteed to hang on to some information about tokens from a long time ago, but at least in theory it's possible, whereas tokens from before a context window in a tradional llms may as well never have existed. reply kelseyfrog 1 hour agorootparentYes, you said it better than I did :) reply visarga 1 hour agorootparentprevThat is valid for Mamba, this model (Jamba) is a mix of transformer and mamba layers, so it still has a quadratic memory cost, but divided by 8. reply google234123 1 hour agoprevIâ€™m pretty sure computational chemists were combining NNs with Kalman Filters for a while nowâ€¦ I recall the issue it was slow due to the N^2 size of the covariance matrix reply uoaei 1 hour agoparentSurprised they hadn't found ways to advance their techniques with e.g. low-rank approximations, etc. reply htrp 3 hours agoprevcompute still has cost? reply samus 1 hour agoparentIn not sure I understood your question. This model should have much lower computational cost since only one out of eight layers is a traditional transformer layer with masked self-attention. Additionally, half of the Mamba layers are MoEs. reply ipsum2 1 hour agoprev@dang this is blogspam for the official post: https://www.ai21.com/blog/announcing-jamba reply krasin 3 hours agoprev [â€“] The license is a proper open-source one: Apache 2.0. Thanks, AI21 Labs. reply popalchemist 17 minutes agoparent [â€“] In addition to the architectural and performance benefits, this is the big deal here, IMO. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AI21 Labs has introduced Jamba, the first AI model built on the Mamba architecture for production use.",
      "Jamba merges Mamba's Structured State Space model with the Transformer architecture, enhancing performance and efficiency.",
      "The model includes MoE layers for extended context windows and faster throughput, displaying impressive benchmark results and accessible under the Apache 2.0 license for research, with plans for a more commercially suitable version soon."
    ],
    "commentSummary": [
      "Jamba is a production-grade AI model derived from Mamba, developed by AI21, blending transformer and Mamba layers for enhanced efficiency and performance.",
      "The model boasts a broad context window and employs a mix of experts, utilizing approximately 12 billion parameters during inference, but some users encountered challenges running it on Linux with specific GPUs.",
      "Discussions emphasize the tradeoffs between transformer and state space model layers, and the potentials and constraints of extensive context windows. Jamba is accessible under the Apache 2.0 license."
    ],
    "points": 173,
    "commentCount": 37,
    "retryCount": 0,
    "time": 1711643816
  },
  {
    "id": 39848268,
    "title": "Endlessh-go: Golang SSH Tarpit for Trapping Bots and Visualizing Metrics",
    "originLink": "https://github.com/shizunge/endlessh-go",
    "originBody": "endlessh-go A golang implementation of endlessh exporting Prometheus metrics, visualized by a Grafana dashboard. Introduction Endlessh is a great idea that not only blocks the brute force SSH attacks, but also wastes attackers time as a kind of counter-attack. Besides trapping the attackers, I also want to visualize the Geolocations and other statistics of the sources of attacks. Unfortunately the wonderful original C implementation of endlessh only provides text based log, but I do not like the solution that writes extra scripts to parse the log outputs, then exports the results to a dashboard, because it would introduce extra layers in my current setup and it would depend on the format of the text log file rather than some structured data. Thus I create this golang implementation of endlessh to export Prometheus metrics and a Grafana dashboard to visualize them. If you want a dashboard of sources of attacks and do not mind the endlessh server, besides trapping the attackers, does extra things including: translating IP to Geohash, exporting Prometheus metrics, and using more memory (about 10MB), this is the solution for you. Getting Started Clone the repo then build from source: go build . ./endlessh-go & Alternatively, you can use the docker image: docker run -d -p 2222:2222 shizunge/endlessh-go -logtostderr -v=1 It listens to port 2222 by default. Then you can try to connect to the endlessh server. Your SSH client should hang there. ssh -p 2222 localhost If you want log like the C implementation, you need to set both CLI arguments -logtostderr and -v=1, then the log will go to stderr. You can set different log destinations via CLI arguments. Also check out examples for the setup of the full stack. Usage ./endlessh-go --help Usage of ./endlessh-go -alsologtostderr log to standard error as well as files -conn_type string Connection type. Possible values are tcp, tcp4, tcp6 (default \"tcp\") -enable_prometheus Enable prometheus -geoip_supplier string Supplier to obtain Geohash of IPs. Possible values are \"off\", \"ip-api\", \"max-mind-db\" (default \"off\") -host string SSH listening address (default \"0.0.0.0\") -interval_ms int Message millisecond delay (default 1000) -line_length int Maximum banner line length (default 32) -log_backtrace_at value when logging hits line file:N, emit a stack trace -log_dir string If non-empty, write log files in this directory -log_link string If non-empty, add symbolic links in this directory to the log files -logbuflevel int Buffer log messages logged at this level or lower (-1 means don't buffer; 0 means buffer INFO only; ...). Has limited applicability on non-prod platforms. -logtostderr log to standard error instead of files -max_clients int Maximum number of clients (default 4096) -max_mind_db string Path to the MaxMind DB file. -port value SSH listening port. You may provide multiple -port flags to listen to multiple ports. (default \"2222\") -prometheus_clean_unseen_seconds int Remove series if the IP is not seen for the given time. Set to 0 to disable. (default 0) -prometheus_entry string Entry point for prometheus (default \"metrics\") -prometheus_host string The address for prometheus (default \"0.0.0.0\") -prometheus_port string The port for prometheus (default \"2112\") -stderrthreshold value logs at or above this threshold go to stderr (default 2) -v value log level for V logs -vmodule value comma-separated list of pattern=N settings for file-filtered logging Metrics Endlessh-go exports the following Prometheus metrics. Metric Type Description endlessh_client_open_count_total count Total number of clients that tried to connect to this host. endlessh_client_closed_count_total count Total number of clients that stopped connecting to this host. endlessh_sent_bytes_total count Total bytes sent to clients that tried to connect to this host. endlessh_trapped_time_seconds_total count Total seconds clients spent on endlessh. endlessh_client_open_count count Number of connections of clients. Labels: ip: Remote IP of the client local_port: Local port the program listens to country: Country of the IP location: Country, Region, and City geohash: Geohash of the location endlessh_client_trapped_time_seconds count Seconds a client spends on endlessh. Labels: ip: Remote IP of the client local_port: Local port the program listens to The metrics is off by default, you can turn it via the CLI argument -enable_prometheus. It listens to port 2112 and entry point is /metrics by default. The port and entry point can be changed via CLI arguments. The endlessh-go server stores the geohash of attackers as a label on endlessh_client_open_count, which is also off by default. You can turn it on via the CLI argument -geoip_supplier. The endlessh-go uses service from ip-api, which may enforce a query rate and limit commercial use. Visit their website for their terms and policies. You could also use an offline GeoIP database from MaxMind by setting -geoip_supplier to max-mind-db and -max_mind_db to the path of the database file. Dashboard The dashboard requires Grafana 8.2. You can import the dashboard from Grafana.com using ID 15156 The dashboard visualizes data for the selected time range. The IP addresses are clickable and link you to the ARIN database. Contacts If you have any problems or questions, please contact me through a GitHub issue",
    "commentLink": "https://news.ycombinator.com/item?id=39848268",
    "commentBody": "Endlessh-go: a Golang SSH tarpit that traps bots/scanners (github.com/shizunge)145 points by fastily 14 hours agohidepastfavorite56 comments gnfargbl 11 hours agoGolang works well for this application because it can easily cope with very large numbers of idle goroutines. What the author may be missing is that golang also works well for bots and scanners, for exactly the same reason. Attackers' time isn't being \"wasted\" by this, their goroutines are just sitting idle for longer. reply aesh2Xa1 5 hours agoparentI think it still works. You have two scenarios where the attacker is efficiently using goroutines; (1) you also use goroutines or (2) you do not. In the latter, the attack is more expensive for you. Another detail is that an attacker with many idle connections to your host might not instantiate any new ones. Of course, in the scenarios where the attacker is not using goroutines then you have the upper hand as well. reply gnfargbl 5 hours agorootparentThis isn't a real ssh server, so the \"cost\" to you of the attack isn't really relevant. You can choose not to run this software at all, and the additional cost to you is zero. reply da768 10 hours agoparentprevThough for a large amount of HTTP bots, the authors don't even bother changing the default Python User-Agent. I'd assume a large proportion of these bots still can't run concurrently. reply Svip 11 hours agoprevThe original endlessh hints at this, but doesn't go further into details, and the endlessh-go's README doesn't mention it at all. Am I suppose to have endlessh run on port 22 and then have my real SSH server run on an obscure port? In none of the examples does it run on port 22. I feel like I'm missing something obvious, that the READMEs simply take for granted I know. reply dylan604 6 hours agoparentIsn't the point of a honeypot that it's not a real server? What guarantees are there that there won't be an exploit that allows escaping the honeypot into the real data? Personally, I do not believe anything is 100% secure. So inviting the vampire into your facade home, and then getting upset when the vampire sees the charade and walks into your real home is just one of those \"well of course that happened\" situations. reply rolph 2 hours agorootparentif you use port knocking, the first hit on your honeypot, can be the trigger to lockdown or redirect, a lot of other ports to somewhere away from your actual. reply ycombinatorrio 6 hours agoparentprevI run endlessh on the port 2222 and I configured fail2ban to redirect the source ip addresses who did X failed attempts from the dest port 22 to the dest port 2222 transparently. I use the table NAT and prerouting to achieve that, you can use ipset to match the source ip addresses. reply withinboredom 4 hours agorootparentI do something similar except send them bytes from /dev/random, providing free protocol fuzzing. reply pdimitar 4 hours agorootparentprevOh nice, do you have a blog post detailing it step by step? reply agilob 11 hours agoparentprevYes, check this distro https://hub.docker.com/r/linuxserver/endlessh reply nilsherzig 11 hours agoparentprevThat's how I have it setup reply nubinetwork 9 hours agoparentprevI don't think it matters, ssh bots will try any port that sends back the ssh banner. reply michaelcampbell 8 hours agorootparentThat's the theory. I have an internet facing box using ssh on a weird port with fail2ban on it just in case. In over 10 years I've never had a single probe on that port with ssh. reply AlecSchueler 7 hours agorootparentSame, I went from logging thousands of attempts per day to zero per decade with a simple switch of ports. reply skrause 9 hours agorootparentprevBut they don't scan every port. I've been running my SSH server on a non-standard port for a long time, it took four years until I had the first bot with login attempts. About a year ago I changed the port and haven't seen any bots since then. reply qwertox 8 hours agorootparentYou can surround your custom port by a couple of ports on which a simple server listens for connection attempts. Any connection attempt is considered hostile and the ip will then be blacklisted in iptables. This prevents portscans from reaching your port. reply metadat 8 hours agorootparentOnly works for sequential scans, most scanners are more targeted towards specific services. reply AlecSchueler 7 hours agorootparentIf they're targetting SSH specifically how are they going to guess i'm running it on port 1690 and not port 22 other than by scanning up in sequence? reply kevindamm 6 hours agorootparentDifferent quality of locks in the ever-escalating arms race. Probably there are many many more sequential scanners out there. For the persistent actors who are doing random ordering or shuffle then you could add port-knocking for the real sshd... but then they just have to find a working client and sniff the connection requests... to which you add a TOTP step for determining which ports to use, and so on... reply dambi0 5 hours agorootparentprevThere is a known upper bound they could randomise the guesses from the range. reply yard2010 4 hours agorootparentprevExcuse the old school metaphor - you put a lock on your door so your house is harder to break into, not to prevent anyone from breaking into your house. reply metadat 1 hour agorootparentAbsolutely agree, when I wrote this I was thinking more of defending against the low hanging fruit - mass scanners. Once someone has deemed you a worthwhile target and is carefully proving all ports, these more nuanced approaches become more worthwhile. Even then, a sophisticated adversary may have many unique src IPs at their disposal. reply freedomben 9 hours agorootparentprevThe more targeted/sophisticated ones will, but there's a crapload of bots that just scan all publicly addressable IPs for port 22 and attempt to connect. If your goal is to trap as many bots as possible in the tarpit, you'll get a lot more if you run on port 22. reply michaelcampbell 2 hours agorootparentprevThey CAN, but they don't. reply hwbunny 1 hour agoprevBut why? Just hide your ssh port. And port knock in. Or put it @ tor/wg/whatever. reply ok123456 7 hours agoprevFollowing the SSH hardening guide stops 99% of bots and scanners because they can't negotiate a cipher using whatever ancient ones their SSH implementation is set up to use. reply LinuxBender 5 hours agoparentThis, and a handful of simple firewall rules in the raw table can block about 90%+ of that remaining 1% just looking at the spoofable banner that none of the bots seem to spoof I assume due to being lazy like me. In the raw table: -A PREROUTING -i eth0 -p tcp -m tcp --dport 22 -d [my server ip] -m string --string \"SSH-2.0-libssh\" --algo bm --from 10 --to 60 -j DROP -A PREROUTING -i eth0 -p tcp -m tcp --dport 22 -d [my server ip] -m string --string \"SSH-2.0-Go\" --algo bm --from 10 --to 60 -j DROP -A PREROUTING -i eth0 -p tcp -m tcp --dport 22 -d [my server ip] -m string --string \"SSH-2.0-JSCH\" --algo bm --from 10 --to 60 -j DROP -A PREROUTING -i eth0 -p tcp -m tcp --dport 22 -d [my server ip] -m string --string \"SSH-2.0-Gany\" --algo bm --from 10 --to 60 -j DROP -A PREROUTING -i eth0 -p tcp -m tcp --dport 22 -d [my server ip] -m string --string \"ZGrab\" --algo bm --from 10 --to 60 -j DROP -A PREROUTING -i eth0 -p tcp -m tcp --dport 22 -d [my server ip] -m string --string \"MGLNDD\" --algo bm --from 10 --to 60 -j DROP -A PREROUTING -i eth0 -p tcp -m tcp --dport 22 -d [my server ip] -m string --string \"amiko\" --algo bm --from 10 --to 60 -j DROP Adding the server IP minimizes risks of also blocking outbound connections as raw is stateless I rarely do this any more given they rotate through so many LTE IP's. Instead I get the bot operators to block me by leaving SSH on port 22 and then giving them a really long VersionAdendum that seems to get the bots feeling broken, sticky and confused. There are far fewer SSH bot operators than it appears. They will still show up in the logs but that can be filtered out using drop patterns in rsyslog. VersionAddendum \" just put in a really long sentence in sshd_config that is at least 320 characters or more\" Try it out on a test box that you have console access to just in case your client is old enough to choke on it. Optionally use offensive words for the bots that log things to public websites. Only do this on your hobby nodes, not corporate owned nodes unless legal is cool with it, in writing. reply Snawoot 4 hours agorootparentWhy use PREROUTING chain? You could have achieved same with INPUT chain without specification of ingress interface and server IP address. reply LinuxBender 4 hours agorootparentAnything I explicitly drop I do so in the raw table to keep them out of the state table. The state table is more CPU expensive especially at high packet rates and runs the risk of depleting the default state table limits especially for anything that now has a broken state on purpose like these poor lil bots. Since I brought it up, here is how to increase the state table limits. Create /etc/modprobe.d/nf_conntrack.conf cat /etc/modprobe.d/nf_conntrack.conf options nf_conntrack expect_hashsize=256400 hashsize=256400 And then in /etc/sysctl.conf: # from /etc/sysctl.conf: increase state table limits. # Requires 1/4 mem to hash table plus 400 overhead because I am the cargo culting king: # cat /etc/modprobe.d/nf_conntrack.conf # options nf_conntrack expect_hashsize=256400 hashsize=256400 net.nf_conntrack_max = 1024000 Should people use default state table memory allocations on a busy node, everyone can be locked out of it regardless of how many TB of RAM are free. The node can appear \"down\". reply myself248 3 hours agorootparentprevinclude EICAR.TXT ;) reply daghamm 9 hours agoprevBut the bots can easily detect these, cant they? As long as there is a timeout on socket read, this shouldn't waste that much of the scanners time. Or am I misunderstanding this? reply LysPJ 6 hours agoparentEndlessh periodically sends data so the read timeout won't trigger. Specifically, it draws out the crypto negotiation stage indefinitely by exploiting a feature of the SSH protocol. (Of course, the bot author could detect that behaviour too.) There's more info from the author of Endlessh: https://nullprogram.com/blog/2019/03/22/ reply gnfargbl 6 hours agoparentprevYou're understanding perfectly. The way this works is that it sends a slow drip of junk before the SSH version banner string. A scanner running at any real scale is going to have an overall timeout beyond which it doesn't bother waiting any longer for the banner string. This is going to very slightly irritate some of the extremely low-level actors. Is setting up a tool to do that a good use of time? If you want to effectively deter attackers using a sand-trap approach, you need to find some kind of task with asymmetric cost in your favour. This isn't that. reply eddd-ddde 3 hours agorootparentWhat is a good example of assymetrical cost in your favour? reply arsome 9 minutes agorootparentYou could probably achieve better here by providing fake weak credentials and then getting an actual human to connect and check out the honeypot on as many IPs as possible. reply gnfargbl 2 hours agorootparentprevCAPTCHAs are an example. Although I am not sure if they're a good example. reply c0wb0yc0d3r 7 hours agoparentprevYes a bot can, and sophisticated bots do. At the same time it's much easier to write code that just died the bare minimum. Imagine you're a bot herder, if your bot net consists of stolen CPU cycles what difference does it make if your bots are slowed down. It doesn't cost you money. reply throw10920 6 hours agorootparent> if your bot net consists of stolen CPU cycles what difference does it make if your bots are slowed down. It doesn't cost you money. This is wrong. It does cost you money - either directly, because you paid money to use someone else's botnet, or as an opportunity cost, in that you can't use your bots on as many targets. reply INTPenis 3 hours agoprevFunny but my first thought wasn't wasting their time at all, that's easily fixed with a few code adjustments on their client end. My thought was to harvest their IPs and publish them in blocklists. reply rijoja 1 hour agoparent> My thought was to harvest their IPs and publish them in blocklists. Please do, it would mean good karma. reply sandos 7 hours agoprevI think you could employ the same tactics that advanced fuzzers do with these tarpits: then mutate the responses randomly, to try get \"new\" responses from the attackers, instead of new coverage in the code as in the fuzzer. Unless they are using static scripts, which would be boring. I have understood that most attacks are super-simple sort of, so probably not much to learn there. But an interesting project! reply lez 2 hours agoprevFor other usecases there is an ipfilter target TARPIT, that does a similar thing on the TCP level. reply schlonger0009 11 hours agoprevDoes it matter, though? You can easily scan out the correct SSH port. reply dugite-code 11 hours agoparentDepends on how well programed the bot is I guess. Personaly I use the encrypted packet port knocking package fwknop on my home server to hide the ssh port until I need it. reply bayindirh 8 hours agoparentprevYou can setup a VPN (or head/tailscale) and confine your \"real\" sshd there, and leave one of these tarpits in the open for fun and profit. reply nilsherzig 11 hours agoparentprevScanning all 65k ports takes time. Those aren't targeted attacks, just bots connecting to every 22 ports they can find reply scsh 11 hours agoparentprevThe point of this isn't to hide your actual SSH service, but to tie up resources for those who are somewhat blindly scanning/connecting to any open SSH port. reply nilsherzig 11 hours agoparentprevScanning all 65k ports takes time. Those aren't targeted attacks, just bots connecting to every 22 ports they can find reply HumblyTossed 8 hours agoprev [â€“] > Unfortunately the wonderful original C implementation of endlessh only provides text based log, but I do not like the solution that writes extra scripts to parse the log outputs, then exports the results to a dashboard, because it would introduce extra layers in my current setup and it would depend on the format of the text log file rather than some structured data. Thus I create this golang implementation of endlessh to export Prometheus metrics and a Grafana dashboard to visualize them. \" I didn't like the logging, so I re-implemented the entire thing.\" I'm not mocking, I just see this often (and have done it myself!). It's interesting the things we do to get around the little things we don't like. reply ffsm8 7 hours agoparentThe thing about coders is that they're often creators at heart. The stated reason is likely only the excuse they told themselves to justify the project. But the real reason was likely that they wanted to create something, and this was a good justification. Might just be me projecting though, because I do that all the time reply yard2010 2 hours agorootparentI've stopped lying to myself, I'm making cool stuff just for the sake of it. It's like playing a video game, it doesn't have to be productive if I enjoy it. reply rijoja 1 hour agoparentprev> It's interesting the things we do to get around the little things we don't like. Yeah and perhaps pick up valuable skills, that might help us down the road in ways that are hard to quantify. reply ajsnigrutin 6 hours agoparentprev [â€“] > \" I didn't like the logging, so I re-implemented the entire thing.\" And did that in the \"language of the week\" :) The stuff that was reinvented in eg. ruby a few years ago is now reinvented in go and rust. reply pantsforbirds 6 hours agorootparent [â€“] People build in languages they are comfortable with. Golang is fairly easy to ship with and the performance is fine for something like this. Seems like a good tool for the job reply 0cf8612b2e1e 5 hours agorootparent [â€“] In fact, Go is one of the better tools for the job given its ability to easily spin up network connections. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Endlessh-go is a Golang version of Endlessh, offering Prometheus metrics and displaying them on a Grafana dashboard while trapping SSH attackers and presenting geolocation data.",
      "It can be set up by building it from the source code or by utilizing a Docker image, allowing customization through different CLI arguments.",
      "The exported metrics cover client connections, data transmission, and time utilized on Endlessh, while the Grafana dashboard necessitates version 8.2 and can be integrated using a specific ID, with support available via GitHub for inquiries or problems."
    ],
    "commentSummary": [
      "The debate revolves around employing non-standard SSH ports, firewall configurations, and extra security measures to thwart bots and scanners.",
      "Strategies encompass leveraging tools such as Endlessh, implementing firewall rules in iptables, and tactics like CAPTCHAs and port hiding to discourage automated attacks.",
      "Users discuss their encounters with re-implementing tools like Endlessh in Golang to enhance efficiency and effectiveness."
    ],
    "points": 145,
    "commentCount": 56,
    "retryCount": 0,
    "time": 1711606999
  }
]
