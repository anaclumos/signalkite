[
  {
    "id": 35843566,
    "timestamp": 1683394754,
    "title": "Intel OEM Private Key Leak: A Blow to UEFI Secure Boot Security",
    "url": "https://securityonline.info/intel-oem-private-key-leak-a-blow-to-uefi-secure-boot-security/",
    "hn_url": "http://news.ycombinator.com/item?id=35843566",
    "content": "Intel OEM Private Key Leak: A Blow to UEFI Secure Boot SecurityBY DO SON \u00b7 MAY 6, 2023In April, MSI fell victim to a cyberattack perpetrated by the ransomware group Money Message, who successfully infiltrated MSI\u2019s internal systems and exfiltrated a staggering 1.5TB of data, predominantly comprising source code.Nowadays, ransomware typically exfiltrates data before encrypting it, using the stolen information as leverage against victims who are unwilling to pay the ransom or seek to restore their systems from backups. In the absence of ransom payments, the data is then released publicly.Money Message demanded a $4 million ransom from MSI, and it appears that MSI has not paid, as some of the stolen data has already surfaced online.The MSI data breach led to the leakage of the Intel OEM private key, which could significantly undermine UEFI\u2019s secure boot security.It has been confirmed that the private key (KeyManifest) provided by Intel to OEMs has been leaked. These keys pertain to Intel Boot Guard digital signatures, a processor feature designed to ensure that computers only run verified programs before booting.In essence, this concerns UEFI secure boot, a mechanism that validates programs prior to operating system startup to prevent malware from running.The leaked private keys affect Intel\u2019s 11th, 12th, and 13th generation processors and were distributed to various OEMs, including Intel itself, Lenovo, and Supermicro.According to security research firm Binarly, the leaked Intel Boot Guard BPM/KM keys impact at least 166 MSI products, with the extent of the damage to other products currently unknown.Instances of leaks involving Intel Boot Guard private keys have occurred previously, with at least two separate incidents last year involving partial key leaks.Theoretically, if these private keys have been employed in production environments, they could pose significant threats, allowing malefactors to modify firmware boot policies and bypass hardware security measures.Neither MSI nor Intel has issued statements on the matter, leaving the full extent of the private key leaks unclear. It is possible that the hackers are gradually releasing data to pressure MSI into paying the ransom, which suggests that more data is likely to be disclosed in the future.",
    "summary": "- MSI was attacked by a ransomware group in April, resulting in the exfiltration of 1.5TB of data. \n- The private key (KeyManifest) provided by Intel to its OEM partners, which significantly affects the UEFI secure boot security, has been leaked. \n- The leaked private keys affect Intel's 11th, 12th, and 13th-generation processors and were distributed to various OEMs, including Lenovo, Supermicro, and Intel itself, potentially posing a significant threat if employed in production environments.",
    "hn_title": "Intel OEM Private Key Leak: A Blow to UEFI Secure Boot Security",
    "original_title": "Intel OEM Private Key Leak: A Blow to UEFI Secure Boot Security",
    "score": 566,
    "hn_content": "Intel's OEM private key leak may have harmed the security of UEFI secure boot; however, it has provided reasons for not using secure boot at the firmware level due to the potential loss of freedom. Secure boot focusing on the OS level, at least in the PC world, allows users to change policies and enable or disable the system to run software they desire. Using traditional jumpers to make this choice would not be secure against physical attack, but since it is considered a secure boot, the firmware gets verified again during startup. Politically, leaks such as these are used as arguments against backdoors to encrypted data, but this may not matter as federal governments and politicians do not care about the facts. Eventually, leaked salacious events will transpire, making headlines, and another political argument will begin. However, some protesters believe engaging in protests is an advanced act of citizenship.The discussion revolves around the security implications of leaked master private keys, with various opinions on the matter, from those who view it as a security threat to others who see it as inevitable. Participants argue about the effectiveness of security measures such as hardware-based signing protocols and HSMs, discussing their vulnerabilities to sustained competent hardware attacks. Some express concerns about the tradeoffs between security and convenience and the potential misuse of government access to data encryption. The discussion also touches on the controversy around TPM2.0 and the monopolistic practices of tech companies, with disapproval of Microsoft's requirement for Secure Boot and TPM2.0 in Windows 11. Despite differences in opinion and approach to security, there is a general agreement on the need for coordinated effort to secure systems and the importance of user control over their data and hardware.Microsoft's new mandatory Trusted Platform Module (TPM) and Secure Boot requirements for Windows 11 are causing controversy among gamers and tech enthusiasts who feel the restrictions limit their control over their own hardware. However, IT admins view these restrictions as an essential measure to prevent insider attacks. Riot Games' anti-cheat system requires a kernel-level driver and Secure Boot, which has caused concerns over the level of access this gives the company and possible vulnerabilities. Users wanting to play competitive games without cheaters see the value in kernel-level anticheat software, but those who prioritize device ownership and security argue that the feature is invasive and overrides individual control. There is still debate over what makes a game truly free from cheats and the most effective means of protecting against them.The leaked private keys affect Intel processors from the 11th to the 13th generation. These keys were shared across multiple OEMs, including Intel itself, Lenovo, and Supermicro. Secure Boot is not about security for normal users, nor security for the majority of people but about DRM and treacherous computing. Evil Maid is a generic descriptor for any number of attacks that can be performed with physical access to a device. If the attacker has root level RCE, they can simply disable Secure Boot or enroll one extra signature - theirs. The takeaway is that these \"user-hostile\" security features take control away from and put it in the hands of a centralized entity whose interests may not align completely with yours.The leaked Intel CPU private key means that unauthorized firmware can potentially be loaded onto Intel-based devices. There are ways to mitigate the risk of this, such as factory resetting or using one of several solutions that scale to any company size. Business people often do not prioritize security due to costs, and most people see security as more of a burden than something enjoyable. There are certifications requiring SecureBoot but SecureBoot has been known to have vulnerabilities. Firmware can be scanned on Linux without an unknown payload by uploading the original OEM firmware for a device onto Binarly's website. There are little to no platforms that cannot have SecureBoot's disabled Intel CPUs with Boot Guard. There is no platform that uses Intel CPUs with Boot Guard where Secure Boot cannot be disabled. It is possible to add your own key using mokutil. Leaked keys should not be adopted by open source projects to disable Secure Boot, though projects like Debian support SecureBoot because it helps simplify installation.Intel's OEMs have been using commonly-trusted Private Key Infrastructure (PKI) keys, leading to the leak of private security keys that can compromise systems. Disabling secure boot won't prevent software from modifying the bootloader, and events like this demonstrate the danger of having a third party control keys. The owner of the machine should be at the root of the chain of trust instead of the vendor/manufacturer. Intel isn't forcing OEMs to use Hardware Security Modules, leading to the need for good key management; however, contracts are not effective in ensuring good management. Chromebooks don't use UEFI, just coreboot; therefore, they aren't affected. The leak is a result of OEMs using common PKI keys, and the issue might be addressed with a software update if the OEMs switch to Hardware Security Modules.",
    "hn_summary": "- Microsoft's mandatory TPM and Secure Boot requirements for Windows 11 are controversial as gamers and tech enthusiasts argue that the restrictions limit their control over their own hardware, while IT admins see them as essential to prevent insider attacks.\n- OEMs' use of commonly trusted PKI keys led to a leak of private security keys that can compromise systems, leading to discussions about the need for good key management and the desirability of users being at the root of the chain of trust."
  },
  {
    "id": 35838751,
    "timestamp": 1683355457,
    "title": "Sailing boat rescued by the G\u00f6theborg",
    "url": "https://www.gotheborg.se/news/rescue-of-sailing-boat/",
    "hn_url": "http://news.ycombinator.com/item?id=35838751",
    "content": "Tickets for both Rotterdam and Hamburg are now released04 MAY 2023We have now opened ticket sales for both the stopover in Rotterdam and in Hamburg. In Rotterdam we are open 11th\u201314th of May and in Hamburg 20th\u201321st of May. Prebook your tickets online to save your spot on board! Subject to availability tickets are also sold at the ship.",
    "summary": "- The sailing boat Corto lost its rudder while at sea and sent a distress call.\n- The Götheborg, the largest ocean-going wooden sailing ship in the world, came to the rescue, which was a first for both the ship and an east indiaman.\n- The crew of the Götheborg showed professionalism and kindness, towing the sailing boat to safety and ensuring their well-being until a French rescue boat arrived.",
    "hn_title": "Sailing boat rescued by the G\u00f6theborg",
    "original_title": "Sailing boat rescued by the G\u00f6theborg",
    "score": 487,
    "hn_content": "A sailing boat was rescued by the G\u00f6theborg with two images of their rescue operation. The G\u00f6theborg likely used the 1,000 horsepower diesel engine aboard to complete the operation. Experienced sailors discuss potential problems with towing under sail, including the issue of one boat losing its rudder and wave-piercing hulls. Readers discuss the history of sailing and what seafarers have done over time to navigate on the open seas, with references made to the Polynesians, classic paintings, and the Vasa museum in Stockholm, Sweden.People from various countries share their experiences of struggling with the \"v\" and \"w\" distinction when speaking English, and how it differs from their native language. In one anecdote, a Swedish company's system was named \"Foo Web Service,\" pronounced as \"foo vee ess\" due to how Swedes pronounce W as V. In another story, sailors on a small vessel were towed by the G\u00f6theborg, a famous historical sailing vessel. A series of videos documents the rebuilding of a similar 1910 English sailing yacht called Tally ho, now being rebuilt from the keel up.The post discusses the rescue of a small yacht that lost its rudder and was towed by a larger ship, the G\u00f6theborg. The ship has usable sails, but they were not used during the rescue as it was carried out in the English Channel. The post includes comments about the original method of using small ships to guide and drag larger ships, satellite communication, emergency communication requirements, and the legal obligation for larger ships to carry radar. The ship is set to be open for visiting in Hamburg, and the post includes comments about salvaging contracts and sailors' eating habits.",
    "hn_summary": "- Readers discuss the history of sailing and seafaring, including the Polynesians, classic paintings and the Vasa museum in Stockholm.\n- The post includes comments about emergency communication requirements, legal obligations for larger ships, and salvaging contracts."
  },
  {
    "id": 35839470,
    "timestamp": 1683363039,
    "title": "Atuin replaces your existing shell history with a SQLite database",
    "url": "https://github.com/ellie/atuin",
    "hn_url": "http://news.ycombinator.com/item?id=35839470",
    "content": "magical shell historyEnglish | \u7b80\u4f53\u4e2d\u6587Atuin replaces your existing shell history with a SQLite database, and records additional context for your commands. Additionally, it provides optional and fully encrypted synchronisation of your history between machines, via an Atuin server.exit code, duration, time and command shownAs well as the search UI, it can do things like this:# search for all successful `make` commands, recorded after 3pm yesterdayatuin search --exit 0 --after \"yesterday 3pm\" makeYou may use either the server I host, or host your own! Or just don't use sync at all. As all history sync is encrypted, I couldn't access your data even if I wanted to. And I really don't want to.Featuresrebind ctrl-r and up (configurable) to a full screen history search UIstore shell history in a sqlite databasebackup and sync encrypted shell historythe same history across terminals, across sessions, and across machineslog exit code, cwd, hostname, session, command duration, etccalculate statistics such as \"most used command\"old history file is not replacedquick-jump to previous items with Alt-<num>switch filter modes via ctrl-r; search history just from the current session, directory, or globallyDocumentationQuickstartInstallImportConfigurationSearching historyCloud history syncHistory statsSelf host Atuin serverKey bindingShell completionsSupported ShellszshbashfishnushellCommunityAtuin has a community Discord, available hereQuickstartWith the default sync serverThis will sign you up for the default sync server, hosted by me. Everything is end-to-end encrypted, so your secrets are safe!Read more below for offline-only usage, or for hosting your own server.bash <(curl https://raw.githubusercontent.com/ellie/atuin/main/install.sh)atuin register -u <USERNAME> -e <EMAIL> -p <PASSWORD>atuin import autoatuin syncThen restart your shell!Opt-in to activity graphAlongside the hosted Atuin server, there is also a service which generates activity graphs for your shell history! These are inspired by the GitHub graph.For example, here is mine:If you wish to get your own, after signing up for the sync server, run thiscurl https://api.atuin.sh/enable -d $(cat ~/.local/share/atuin/session)The response includes the URL to your graph. Feel free to share and/or embed this URL, the token is not a secret, and simply prevents user enumeration.Offline only (no sync)bash <(curl https://raw.githubusercontent.com/ellie/atuin/main/install.sh)      atuin import autoThen restart your shell!InstallScript (recommended)The install script will help you through the setup, ensuring your shell is properly configured. It will also use one of the below methods, preferring the system package manager where possible (pacman, homebrew, etc etc).# do not run this as root, root will be asked for if requiredbash <(curl https://raw.githubusercontent.com/ellie/atuin/main/install.sh)And then follow the shell setupWith cargoIt's best to use rustup to get setup with a Rust toolchain, then you can run:cargo install atuinAnd then follow the shell setupHomebrewbrew install atuinAnd then follow the shell setupMacPortsAtuin is also available in MacPortssudo port install atuinAnd then follow the shell setupNixThis repository is a flake, and can be installed using nix profile:nix profile install \"github:ellie/atuin\"Atuin is also available in nixpkgs:nix-env -f '<nixpkgs>' -iA atuinAnd then follow the shell setupPacmanAtuin is available in the Arch Linux community repository:pacman -S atuinAnd then follow the shell setupTermuxAtuin is available in the Termux package repository:pkg install atuinAnd then follow the shell setupFrom sourcegit clone https://github.com/ellie/atuin.gitcd atuin/atuincargo install --path .And then follow the shell setupShell pluginOnce the binary is installed, the shell plugin requires installing. If you use the install script, this should all be done for you! After installing, remember to restart your shell.zshecho 'eval \"$(atuin init zsh)\"' >> ~/.zshrcZinitzinit load ellie/atuinAntigenantigen bundle ellie/atuin@mainbashWe need to setup some hooks, so first install bash-preexec:curl https://raw.githubusercontent.com/rcaloras/bash-preexec/master/bash-preexec.sh -o ~/.bash-preexec.shecho '[[ -f ~/.bash-preexec.sh ]] && source ~/.bash-preexec.sh' >> ~/.bashrcThen setup Atuinecho 'eval \"$(atuin init bash)\"' >> ~/.bashrcfishAddatuin init fish | sourceto your is-interactive block in your ~/.config/fish/config.fish fileFigInstall atuin shell plugin in zsh, bash, or fish with Fig in one click.NushellRun in Nushell:mkdir ~/.local/share/atuin/atuin init nu | save ~/.local/share/atuin/init.nuAdd to config.nu:source ~/.local/share/atuin/init.nu",
    "summary": "- Atuin replaces the current shell history with a SQLite database and records more command context, also allowing encrypted synchronization of command history between machines using the Atuin server.\n- Atuin allows the user to rebind ctrl-r and up (configurable) to a complete screen history search UI, backup and sync encrypted shell history, and track all the information like exit code, cwd, hostname, session, command duration, etc.\n- Atuin has a community Discord, quick start guide, comprehensive documentation, various installation options, and can be used with multiple shells like zsh, bash, fish, nu shell, etc.",
    "hn_title": "Atuin replaces your existing shell history with a SQLite database",
    "original_title": "Atuin replaces your existing shell history with a SQLite database",
    "score": 482,
    "hn_content": "Atuin is a new shell history manager that replaces traditional text-based history with an SQLite database. Users can use atuin to review their command-line history within the terminal, including error messages and other output. A new tool called LLMShellAutoComplete allows users to stream the information from atuin's database to OpenAI's GPT (Generative Pretrained Transformer) for improved auto-completion of command lines. Users can create custom auto-complete rules based on previous commands' metadata. Finally, users can store log files on remote hosts, create PostgreSQL backends, and export Prompts to file to improve searchability.Atuin is a command-line history indexing tool that syncs commands between machines and provides instant search results. It stores commands in an sqlite database for fast querying, supports filtering by machine, and allows searching via a TUI. Users can configure priorities for which commands get saved, but some report that Atuin adds friction and slows searches for those with large command histories. A PR is open to expand functionality by adding shell type and environment variables to Atuin's fields. Some users recommend Resh, which logs both input and output and can export to CSV, JSON, or shell history formats, but it lacks the TUI of Atuin.Atuin, a command-line history utility with a distributed service hosted by the Atuin team, and the option to self-host, now allows users to search the entire history of their shell. The utility also lets users add metadata like exit codes and shell start and end times. Atuin has an optional, free service for hosting encrypted shell histories. The utility uses SQLite to store user metadata, using mmap and random access to improve search. Atuin is open source and supports macOS, Linux, and other Unix-based systems. Users can also customise the My-SQLite database with their existing shell history. The system provides various features like distributed syncing and opt-out modes. Users can also import shell history from other services. While comparing Atuin with McFly, users mentioned usage profiles and development cycles as the major differences between the two utilities.Atuin is a tool that replaces shell history with a SQLite database, allowing for more context and structured querying. Some users have pointed out a bug in which credentials entered into Atuin may still be saved in shell history. Despite potential criticisms, the Atuin team claims that new features like directory search and sync improve their workflows and have been helpful to their team and other users. The ability to have a distributed shell history across servers is also seen as a significant advantage. Some users criticize the energy spent on developing such tools, while others say Atuin fills a long-standing need. Concerns have been raised about the relevance of localizations and possible government control, but the Atuin team explains that all code and history is encrypted and open source.",
    "hn_summary": "- Atuin supports distributed syncing, an encrypted history service, and the ability to import history from other services.\n- Some users have reported friction and slower searches with large command histories, but the Atuin team claims the benefits of new features like directory search and sync."
  },
  {
    "id": 35838180,
    "timestamp": 1683349037,
    "title": "Wikipedia user edits over 90k uses of \"comprised of\"",
    "url": "https://en.wikipedia.org/wiki/User:Giraffedata/comprised_of",
    "hn_url": "http://news.ycombinator.com/item?id=35838180",
    "content": "The use of \"comprised of\" is considered poor phrasing in Wikipedia and style manuals advise against it. The reverse use of \"comprise\" is at least as common as the original, causing confusion between \"comprise\" and \"compose\". Many people consider \"comprised of\" to be incorrect and illogical, with other options like \"composed of\" and \"consists of\" being better alternatives. While it's accepted in some dictionaries, it's still criticized by language purists. There are arguments for and against its use, with some arguing for \"elegant variation\", less ambiguity, or unique meaning. However, the consensus is that \"comprised of\" adds nothing to the language and can easily be replaced by other alternatives.A long-running project by a Wikipedia editor to remove the phrase \"comprised of\" from the site has sparked debate amongst editors. The project began in 2007, and so far the editor has edited out the phrase in around 67,000 articles. The editor, who started the project because they believe the phrase is \"poor English\", mostly edits newly added articles. In 2021, the editor typically edits around 60 articles a week, mostly by searching Wikipedia for the phrase \"comprised of\". Reactions to the project have been mixed, with some calling it \"semi-vandalism\", whilst others have praised it. The editor has claimed that actual editing of articles is decided by the editing public, rather than being dictated by a Wikipedia policy or guideline.Bryan Henderson has edited over 47,000 instances of \"comprised of\" on Wikipedia over several years, with a self-imposed limit of once per six months to avoid reversing other editors or adding new instances. Henderson feels that \"comprised of\" is often used improperly and should be replaced with \"composed of\" or other alternatives; he also marks it as a quote if used in direct conversation. The project has generated a lot of media coverage and won several barnstars on Wikipedia.",
    "summary": "- The phrase \"comprised of\" is often considered poor phrasing and criticized by language purists.\n- A Wikipedia editor has been working on a project to remove the phrase \"comprised of\" from the site since 2007, and has edited out the phrase in around 67,000 articles.\n- Reactions to the project have been mixed, with some calling it \"semi-vandalism\", whilst others have praised it.",
    "hn_title": "Wikipedia user edits over 90k uses of \u201ccomprised of\u201d",
    "original_title": "Wikipedia user edits over 90k uses of \u201ccomprised of\u201d",
    "score": 372,
    "hn_content": "A new edit on Wikipedia has removed over 90,000 uses of the term \"comprised of,\" stating it to be poor writing; however, this has been met with criticism as the term is widely accepted and in use in modern English and is included as standard English usage in dictionaries. The justifications given for the edit have been criticized as being illogical and an example of an etymological fallacy. Some have drawn parallels to Newspeak from George Orwell's novel 1984, where language is manipulated to control thought and limit expression. The debate has also led to discussions around language ambiguity, the role of dictionaries, and prescriptive vs. descriptive approaches to language usage.Debates arose on whether non-native speakers should have the right to judge English proficiency and whether \"comprised of\" is an acceptable usage. While there are arguments on both sides, the descriptivist nature of English means that language is always evolving, and usage ultimately depends on the intended audience. The existence of Simple English Wikipedia demonstrates the need for clear writing, while the subjective nature of language means that opinions on what constitutes \"better language\" may vary. Ultimately, the important thing is to consider the intended audience and ensure that the language used does not sacrifice clarity for the sake of adherence to rules.A Wikipedia editor has caused controversy by removing instances of the phrase \"comprised of\" from entries where they appear. The editor argues that the phrase should be replaced with \"composed of\" or \"consists of,\" arguing that since the word \"comprise\" means \"to contain,\" then \"of\" is unnecessary. While many have supported the editor's campaign, others have criticised it as an example of overzealous editing. Some have argued that \"comprised of\" has become an accepted usage of the words. The phrase has been used over 90,000 times on Wikipedia alone and is considered standard usage by many dictionaries.A Wikipedia editor's attempt to remove the use of \"comprised of\" is stirring up debate about the significance of etymology and the evolution of language. While some argue that the phrase is illogical and unnecessary for an authoritative source, others maintain that if native speakers commonly use a phrase, then it is legitimate\u00a0to be part of a language. There are even examples of words like \"awful\" and \"egregious\" that used to mean something completely different from their current meanings. Some also argue that an encyclopedia like Wikipedia should aim to be as unambiguous as possible, using\u00a0precise language to define meaning. However, others contend that language inevitably evolves over time and it is important to capture and understand contemporary usage in the present and future.\nA debate over language evolution sparked on Hacker News after users discussed the merits of prescriptivism and descriptivism. The conversation touched on how language should evolve, predominantly in the case of new words and slang being introduced, and how this can lead to a shift in the meaning of words. The discussion revolved around the commonly used phrase \"comprised of,\" noted by some users as an example of a shift in the meaning of a word, and its \"correct\" use vs. its ambiguous use. Users debated whether language should be used and shaped by its speakers, or dictated by prescriptive style guides, and the advantages and disadvantages of each approach. Ultimately, the consensus was that language evolves naturally, but that specificity and clarity are still imperative in many contexts, such as technical writing, and that there are benefits to both approaches.No meaningful content for a summary.The discussion on Wikipedia's editing policies has led to a debate on the influence of activist superminorities in society. The problem of activist minorities changing cultural landscapes could be due to how participatory systems work - that a minority of the minority group produces a lot of content. While Wikipedia's editing structure is a unique division of labor, the majority of writers on the site are occasional contributors, while a small minority of committed editors edits for spelling and formatting errors. The problem lies in the imposition of superminority views, such as changing the meaning of a phrase deliberately. Language is the foundation of communication, so it may be noble to oppose inadvertent usage changes that make language more ambiguous.A Wikipedia editor's crusade to remove the phrase \"is comprised of\" in favor of alternatives has sparked a debate on language usage and rules. While some argue that language evolves with usage, others maintain that a writer's preference should not be imposed on others. Merriam-Webster includes \"is comprised of\" as its second definition of three, acknowledging it has become more commonly used in general writing. While some see value in pushing against ambiguous language use, others find it pedantic to insist on certain grammatical styles and argue that improving language clarity in an encyclopedia is harmless. The debate raises questions about the role of editors and the extent to which they should impose personal preferences on written content.The Tech Times editor criticizes an editor on Wikipedia for being toxic and for driving off users, claiming they are killing the project, and gives an example of their behavior. Some commenters suggest creating a separate page to explain the confusion and encouraging the author to channel their energy positively. Others debate the importance of grammar and linguistic prescriptivism. The post does not contain any new or exciting information or releases and may not be of particular interest to those not invested in the inner workings of Wikipedia.",
    "hn_summary": "- The editor's campaign was criticized as overzealous, while others argued \"comprised of\" is an accepted usage and language inevitably evolves over time.\n- The discussion on Hacker News touched on the pros and cons of prescriptivism and descriptivism, language evolution, and the importance of clarity in technical writing."
  },
  {
    "id": 35838504,
    "timestamp": 1683352689,
    "title": "Open source Background Remover: Remove Background from images & video using AI",
    "url": "https://github.com/nadermx/backgroundremover",
    "hn_url": "http://news.ycombinator.com/item?id=35838504",
    "content": "BackgroundRemoverBackgroundRemover is a command line tool to remove background from image and video, made by nadermx to power https://BackgroundRemoverAI.com. If you wonder why it was made read this short blog post.Requirementspython >= 3.6python3.6-dev #or what ever version of python you usingtorch and torchvision stable version (https://pytorch.org)ffmpeg 4.4+How to install torch and fmpegGo to https://pytorch.org and scroll down to INSTALL PYTORCH section and follow the instructions.For example:PyTorch Build: Stable (1.7.1)Your OS: WindowsPackage: PipLanguage: PythonCUDA: NoneTo install ffmpeg and python-devsudo apt install ffmpeg python3.6-devInstallationTo run code without installation:python -m backgroundremover.cmd.cli -i \"video.mp4\" -mk -o \"output.mov\"and for windowspython.exe -m backgroundremover.cmd.cli -i \"video.mp4\" -mk -o \"output.mov\"InstallationTo Install backgroundremover, install it from pypipip install --upgrade pippip install backgroundremoverPlease note that when you first run the program, it will check to see if you have the u2net models, if you do not, it will pull them from this repoUsage as a cliImageRemove the background from a local file imagebackgroundremover -i \"/path/to/image.jpeg\" -o \"output.png\"Advance usage for image background removalSometimes it is possible to achieve better results by turning on alpha matting. Example:backgroundremover -i \"/path/to/image.jpeg\" -a -ae 15 -o \"output.png\"change the model for diferent background removal methods between u2netp, u2net, or u2net_human_segbackgroundremover -i \"/path/to/image.jpeg\" -m \"u2net_human_seg\" -o \"output.png\"Videoremove background from video and make transparent movbackgroundremover -i \"/path/to/video.mp4\" -tv -o \"output.mov\"remove background from local video and overlay it over other videobackgroundremover -i \"/path/to/video.mp4\" -tov \"/path/to/videtobeoverlayed.mp4\" -o \"output.mov\"remove background from local video and overlay it over an imagebackgroundremover -i \"/path/to/video.mp4\" -toi \"/path/to/videtobeoverlayed.mp4\" -o \"output.mov\"remove background from video and make transparent gifbackgroundremover -i \"/path/to/video.mp4\" -tg -o \"output.gif\"Make matte key file (green screen overlay)Make a matte file for premierbackgroundremover -i \"/path/to/video.mp4\" -mk -o \"output.matte.mp4\"Advance usage for videoChange the framerate of the video (default is set to 30)backgroundremover -i \"/path/to/video.mp4\" -fr 30 -tv -o \"output.mov\"Set total number of frames of the video (default is set to -1, ie the remove background from full video)backgroundremover -i \"/path/to/video.mp4\" -fl 150 -tv -o \"output.mov\"Change the gpu batch size of the video (default is set to 1)backgroundremover -i \"/path/to/video.mp4\" -gb 4 -tv -o \"output.mov\"Change the number of workers working on video (default is set to 1)backgroundremover -i \"/path/to/video.mp4\" -wn 4 -tv -o \"output.mov\"change the model for diferent background removal methods between u2netp, u2net, or u2net_human_seg and limit the frames to 150backgroundremover -i \"/path/to/video.mp4\" -m \"u2net_human_seg\" -fl 150 -tv -o \"output.mov\"Todoconvert logic from video to image to utilize more GPU on image removalclean up documentation a bit moreadd ability to adjust and give feedback images or videos to datasetsadd ability to realtime background removal for videos, for streamingfinish flask server apiadd ability to use other models than u2net, ie your own.otherPull requestsAcceptedIf you like this libraryGive a link to our project BackgroundRemoverAI.com or this git, telling people that you like it or use it.bitcoinbc1q80pshgqgqr7wn3kax59xwvmgq9ftvwla7dew7wReason for projectWe made it our own package after merging together parts of others, adding in a few features of our own via posting parts as bounty questions on superuser, etc. As well as asked on hackernews earlier to open source the image part, so decided to add in video, and a bit more.Referenceshttps://arxiv.org/pdf/2005.09007.pdfhttps://github.com/NathanUA/U-2-Nethttps://github.com/pymatting/pymattinghttps://github.com/danielgatis/rembghttps://github.com/ecsplendid/rembg-greenscreenhttps://superuser.com/questions/1647590/have-ffmpeg-merge-a-matte-key-file-over-the-normal-video-file-removing-the-backghttps://superuser.com/questions/1648680/ffmpeg-alphamerge-two-videos-into-a-gif-with-transparent-background/1649339?noredirect=1#comment2522687_1649339https://superuser.com/questions/1649817/ffmpeg-overlay-a-video-after-alphamerging-two-others/1649856#1649856LicenseCopyright (c) 2021-present Johnathan NaderCopyright (c) 2020-present Lucas NestlerCopyright (c) 2020-present Dr. Tim ScarfeCopyright (c) 2020-present Daniel GatisCode Licensed under MIT License Models Licensed under Apache License 2.0",
    "summary": "- BackgroundRemover is a command-line tool that uses AI to remove the background from images and videos.\n- It requires Python 3.6, Torch, TorchVision, and FFmpeg 4.4+ to be installed.\n- The tool can be used to remove backgrounds from images and videos, as well as create transparent GIFs and matte key files.",
    "hn_title": "Open source Background Remover: Remove Background from images and video using AI",
    "original_title": "Open source Background Remover: Remove Background from images and video using AI",
    "score": 344,
    "hn_content": "Open source Background Remover: Remove Background from images and video using AI has been released on Github. This free tool allows users to remove the background from an image or video, with the ability to choose which object to detect and keep. The tool was compared to other background removal services, such as Remove.bg and Adobe, and showed good results depending on the object in the image. The author of the project has acknowledged the confusion in pricing and will update the website. The post also includes discussions on the importance of foreground-background separation and the risks of downloading binaries from untrusted sources. Additionally, Pixelmator for Mac and the Photos app on MacOS were recommended as alternative options for background removal.BackgroundRemoverAI, an AI-powered image background removal tool, has gained attention on forums for its effectiveness and ease of use. Users report that the tool works well on most images, but may leave a blur around hair or miss small details. Some users have also reported issues with the tool's ability to handle videos. While there are other tools, like Canva and Remove.bg, that offer similar functionality, BackgroundRemoverAI stands out for being free and open source. Some users have also asked for recommendations for open source, free upscalers powered by deep learning or AI. Others raise concerns about the loss of historical or forensic significance when unwanted backgrounds are removed, to which users respond that the original images would still exist and digital tools simply make the process more accessible.",
    "hn_summary": "- The tool was compared to other services such as Remove.bg and Adobe and showed good results in most cases.\n- Some users had concerns about the loss of historical or forensic significance when unwanted backgrounds are removed, but others pointed out that the original images would still exist and digital tools simply make the process more accessible."
  },
  {
    "id": 35838407,
    "timestamp": 1683351786,
    "title": "I'm in Wyoming to celebrate the next nuclear breakthrough",
    "url": "https://www.gatesnotes.com/Wyoming-TerraPower",
    "hn_url": "http://news.ycombinator.com/item?id=35838407",
    "content": "LOG INSIGN UPA CLEAN FUTUREI\u2019m in Wyoming to celebrate the next nuclear breakthroughVisiting the site of a historic new power plant that I\u2019m funding.By Bill Gates | May 05, 2023 4 minute read0Today I\u2019m in the town of Kemmerer, Wyoming, to celebrate the latest step in a project that\u2019s been more than 15 years in the making: designing and building a next-generation nuclear power plant. I\u2019m thrilled to be here after all this time\u2014because I\u2019m convinced that the facility will be a win for the local economy, America\u2019s energy independence, and the fight against climate change.It\u2019s called the Natrium plant, and it was designed by TerraPower, a company I started in 2008. When it opens (potentially in 2030), it will be the most advanced nuclear facility in the world, and it will be much safer and produce far less waste than conventional reactors.All of this matters because the world needs to make a big bet on nuclear. As I wrote in my book How to Avoid a Climate Disaster, we need nuclear power if we\u2019re going to meet the world\u2019s growing need for energy while also eliminating carbon emissions. None of the other clean sources are as reliable, and none of the other reliable sources are as clean.But nuclear has its problems: The plants are expensive to build, and human error can cause accidents. Plus, as we move away from fossil fuels, there\u2019s a risk that we\u2019ll leave behind the communities and workers who have been providing reliable energy for decades.The Natrium facility is designed to solve these problems, and more.I\u2019ll start with improved safety. Keep in mind that America\u2019s current fleet of nuclear plants has been operating safely for decades\u2014in fact, in terms of lives lost, nuclear power is by far the safest way to produce energy. And this new facility in Kemmerer will be even better.Like other power plant designs, it uses heat to turn water into steam, which moves a turbine, which generates electricity. And like other nuclear facilities, it generates the heat by splitting uranium atoms in a chain reaction. But that\u2019s pretty much where the similarities stop.A typical reactor keeps the atom-splitting nuclear reaction under control by circulating water around a uranium core. But using water as a coolant presents two challenges. First, water isn\u2019t very good at absorbing heat\u2014it turns to steam and stops absorbing heat at just 100 degrees C. Second, as water gets hot, its pressure goes up, which puts strain on your pipes and other equipment. If there\u2019s an emergency\u2014say, an earthquake cuts off all the electricity to the plant and you can\u2019t keep pumping water\u2014the core continues to make heat, raising the pressure and potentially causing an explosion.But what if you could cool your reactor with something other than water? It turns out that, by comparison, liquid metals can absorb a monster amount of heat while maintaining a consistent pressure. The Natrium plant uses liquid sodium, whose boiling point is more than 8 times higher than water\u2019s, so it can absorb all the extra heat generated in the nuclear core. Unlike water, the sodium doesn\u2019t need to be pumped, because as it gets hot, it rises, and as it rises, it cools off. Even if the plant loses power, the sodium just keeps absorbing heat without getting to a dangerous temperature that would cause a meltdown.Safety isn\u2019t the only reason I\u2019m excited about the Natrium design. It also includes an energy storage system that will allow it to control how much electricity it produces at any given time. That\u2019s unique among nuclear reactors, and it\u2019s essential for integrating with power grids that use variable sources like solar and wind.Another thing that sets TerraPower apart is its digital design process. Using supercomputers, they\u2019ve digitally tested the Natrium design countless times, simulating every imaginable disaster, and it keeps holding up. TerraPower\u2019s sophisticated work has drawn interest from around the globe, including an agreement to collaborate on nuclear power technology in Japan and investments from the South Korean conglomerate SK and the multinational steel company ArcelorMittal.I can\u2019t overstate how welcoming the people of Kemmerer are being. While I\u2019m here, I\u2019ll get to visit the future site of the plant, and I\u2019ll also have a chance to talk with the mayor, other local leaders, and members of the community so I can thank them for their efforts. And this project wouldn\u2019t be happening without strong support from Gov. Mark Gordon and Senators John Barrasso and Cynthia Lummis.Kemmerer has a particular interest in the Natrium facility\u2019s success: The coal plant that has been operating here for more than 50 years is scheduled to shut down. If it weren\u2019t for the Natrium plant, the 110 or so workers there would lose their jobs.But the plan is for all of them to get jobs in the Natrium facility if they want one. The new plant will employ between 200 and 250 people, and those with experience in the coal plant will be able to do many of the jobs\u2014such as operating a turbine and maintaining connections to the power grid\u2014without much retraining.Another benefit: Building the facility will take several years and at its peak will bring 1,600 construction jobs to town. And all those construction workers will need food, housing, and entertainment. It\u2019ll be a huge boost to a community that could use one right now.Finally, I\u2019m excited about this project because of what it means for the future. It\u2019s the kind of effort that will help America maintain its energy independence. And it will help our country remain a leader in energy innovation worldwide. The people of Kemmerer are at the forefront of the equitable transition to a clean, safe energy future, and it\u2019s great to be partnering with them.READ THIS NEXTMy message in India: To fight climate change, improve global healthClimate change and global health are inextricably linked. We need to make progress on both problems at the same time.On Africa\u2019s farms, the forecast calls for adaptation and innovationIn Kenya, I visited with a smallholder farmer using new tools and practices to fight back against climate change.The surprising key to a clean energy futureIf you care about climate change, you should care about transmission.DiscussionThank you for being part of the Gates Notes Insider community. Not seeing your comment? You can read our policy on moderating comments here and learn about our Gates Notes badges here.Add commentPleaselog inorsign upto comment0responsesSort byallComments loading...More commentsAbout BillSearchPersonalPodcastPhoto essaysBooksEducationVideosSaving livesClimate and energyPandemic preventionInequality, gender, and raceSubscribe to emails from BillSign up\u00a9 2023 The Gates Notes LLC Privacy Policy Terms of Use Contact",
    "summary": "- Bill Gates is celebrating the announcement of a new nuclear power plant funded by him in Kemmerer, Wyoming.\n- The Natrium plant, designed by TerraPower, is set to be the most advanced nuclear facility when it opens around 2030, and it boasts improvements in safety and produces less waste than conventional reactors.\n- The design uses liquid sodium as a coolant, which can absorb more heat and maintain a consistent pressure, and it includes an energy storage system necessary for integrating with power grids that use variable sources like solar and wind.",
    "hn_title": "I\u2019m in Wyoming to celebrate the next nuclear breakthrough",
    "original_title": "I\u2019m in Wyoming to celebrate the next nuclear breakthrough",
    "score": 285,
    "hn_content": "Bill Gates has declared that the future of nuclear power could lie in reactors using liquid sodium rather than water to regulate their temperature. He backed the development of a generation-IV reactor powered by sodium, which he described as \"safer than traditional models\" because the use of liquid sodium, which is less prone to boil than water, means reactors can\u00a0operate at high temperatures without coming under pressure. However, sodium is highly reactive and the fires it causes in contact with air or water can be difficult to control. Sodium-cooled reactors have been used for years, primarily in Russia, but questions remain about their safety and functionality.The post discusses the use of sodium as a coolant in nuclear reactors. While it has advantages like good heat transfer properties and a high boiling point, sodium is chemically reactive and can be hazardous in the event of leaks or contact with water. Molten salts, which are non-toxic, non-flammable, and have low vapor pressure, are also used as coolants and heat storage mediums. Different types of coolants and their pros and cons are discussed, such as FLiBe, a mixture of lithium and beryllium fluoride, and pressurized water reactors. The Natrium reactor designed by Bill Gates' company Terrapower uses liquid sodium as a moderator and coolant but poses no danger of direct contact with the nuclear fuel. Sodium reactors have relatively low availability times, are more expensive, and susceptible to technical difficulties, according to research.A discussion thread emerged on the radioactive properties of heat transfer fluid for nuclear plants. The half-life of the fluid, if present, is reportedly only a few days, which means any associated radioactivity would disappear quickly. Additionally, radiation emitted from a radioactive substance is not radioactive, nor is it particularly dangerous once it stops moving. While a spill of hot radioactive sodium is hazardous, it can't contaminate groundwater, as it will turn into salts. The radioactivity associated with sodium cooling would disappear within a few days. The most cost-effective way to achieve carbon-free energy production is to build both solar and nuclear power plants. New technologies, such as molten salt solar plants, are also promising alternatives to nuclear power and have fewer risks.Experts in a discussion on HN debate the use of renewables and nuclear power to address climate change. While some advocate for the grid-scale combination of solar, wind, and hydro with energy storage solutions, others suggest nuclear power as an efficient, low-carbon alternative. The safety and cost-effectiveness of nuclear power are discussed, with some arguing that the cost of bespoke plants is too high, while others note that new technology enables nuclear plants to be integrated with power grids more effectively and efficiently. Skepticism toward renewable energy focuses on concerns around scalability and economics, while others criticize the dependence on Chinese solar panels and subsidies for wind energy. Some suggest proposals for nuclear-hydrogen production and reactors as bases for US Navy technology to help the shift towards a zero-emissions future, but note that the debate over nuclear power is largely focused on political rather than technical considerations.TerraPower and PacifiCorp are planning to build a nuclear power plant in Wyoming featuring a sodium-cooled fast reactor, capable of producing 345 MW of power. This technology is said to be safer and produce less nuclear waste than traditional nuclear power plants. It is hoped that the plant will help decarbonize Wyoming's coal-heavy energy mix. The construction of the plant requires approval from the Nuclear Regulatory Commission and is expected to cost several billion dollars. The project is backed by Bill Gates, who has endorsed it as a way to address climate change. However, there is ongoing debate around the economics of nuclear power, with some experts advocating for a mix of renewable and nuclear energy sources.TerraPower's small nuclear plant, Natrium, will be built in Wyoming by 2030, with a capacity of 345 MWe. It will have a molten salt energy storage system as a buffer to control electricity production. The plant is touted as safer than current reactors and more cost-effective due to modular design and economies of scale. The use of sodium cooling is not new but is considered a safer, more efficient, and simpler approach. Natrium's construction has been delayed due to Russia's supply of highly enriched uranium. The anti-nuclear sentiment is challenged with the claim that, in terms of lives lost, nuclear power is by far the safest method. Uranium mining and enrichment are hazardous to health and the environment, making it expensive to produce locally. Renewable energy requires massive storage and improved transmission, with nuclear power filling the baseload.Bill Gates discusses the new Natrium reactor designed by TerraPower and GE Hitachi for nuclear energy. The design utilizes liquid sodium instead of water for cooling and includes a built-in energy storage system for more efficiency and flexibility. Gates highlights the need for clean energy to combat climate change and emphasizes the importance of innovation in the nuclear energy sector. Some commenters question the safety and design of the reactor, while others criticize Gates' past actions as CEO of Microsoft. One commenter brings up the use of liquid metal in refrigerator designs and nuclear cooling systems. One commenter expresses dislike for Gates' opinions and beliefs, while another suggests getting pie together.",
    "hn_summary": "- Different coolants, including molten salts such as FLiBe and pressurized water reactors, are discussed for their potential uses in nuclear reactors.\n- There is ongoing debate between the viability of renewable energy sources and nuclear power to address climate change, with some experts suggesting a combination of both."
  },
  {
    "id": 35836976,
    "timestamp": 1683335264,
    "title": "Shap-E: Generate 3D objects conditioned on text or images",
    "url": "https://github.com/openai/shap-e",
    "hn_url": "http://news.ycombinator.com/item?id=35836976",
    "content": "Shap-EThis is the official code and model release for Shap-E: Generating Conditional 3D Implicit Functions.See Usage for guidance on how to use this repository.See Samples for examples of what our text-conditional model can generate.SamplesHere are some highlighted samples from our text-conditional model. For random samples on selected prompts, see samples.md.A chair that lookslike an avocado An airplane that lookslike a banana A spaceshipA birthday cupcake A chair that lookslike a tree A green bootA penguin Ube ice cream cone A bowl of vegetablesUsageInstall with pip install -e ..To get started with examples, see the following notebooks:sample_text_to_3d.ipynb - sample a 3D model, conditioned on a text promptsample_image_to_3d.ipynb - sample a 3D model, conditioned on an synthetic view image.encode_model.ipynb - loads a 3D model or a trimesh, creates a batch of multiview renders and a point cloud, encodes them into a latent, and renders it back. For this to work, install Blender version 3.3.1 or higher, and set the environment variable BLENDER_PATH to the path of the Blender executable.",
    "summary": "- Shap-E is a code and model release for generating 3D objects based on text or images.\n- Examples of its text-conditional model generating various objects, like a chair that looks like an avocado or a spaceship, are available.\n- To use Shap-E, installation with pip, notebooks, and Blender version 3.3.1 or higher are needed.",
    "hn_title": "Shap-E: Generate 3D objects conditioned on text or images",
    "original_title": "Shap-E: Generate 3D objects conditioned on text or images",
    "score": 273,
    "hn_content": "OpenAI has released a new generative model called Shap-E that can generate 3D objects based on text or images. Users can input text or images as prompts and the model will generate 3D objects that match the prompt. The generated objects can be outputted in polygonal mesh format (PLY) which can be converted to a format supported by most 3D printers. The models generated are of surprisingly good quality and can be used in various ways. Users have found it rewarding to use the models to generate fantastical ideas, as a source of inspiration, and for generating ideas for new products. The output of the model is in a charmingly low-poly format that has an impressive purple color.- Y Combinator has opened applications for their Summer 2023 program.\n- Y Combinator is a well-known startup accelerator that provides funding, mentorship, and resources to early-stage companies.\n- The program is highly competitive and attracts startups from around the world.\n- Selected startups receive an investment in exchange for equity, and participate in a three-month program that culminates in a Demo Day.\n- Y Combinator has helped launch successful startups like Airbnb, Dropbox, and Stripe.",
    "hn_summary": "- This model can generate 3D objects based on text or images.\n- Users can generate ideas for new products or use the models as a source of inspiration."
  },
  {
    "id": 35841542,
    "timestamp": 1683382162,
    "title": "AI's biggest risk is the corporations that control them",
    "url": "https://www.fastcompany.com/90892235/researcher-meredith-whittaker-says-ais-biggest-risk-isnt-consciousness-its-the-corporations-that-control-them",
    "hn_url": "http://news.ycombinator.com/item?id=35841542",
    "content": "",
    "summary": "- AI systems are increasingly being controlled by large corporations, which poses a risk to society.\n- These companies' bottom-line profit motives may not align with the greater good, resulting in corrupt or dangerous use of AI.\n- There is a need for more transparency and accountability in AI development and deployment to ensure the safety and ethical use of these systems.",
    "hn_title": "AI\u2019s biggest risk is the corporations that control them",
    "original_title": "AI\u2019s biggest risk is the corporations that control them",
    "score": 268,
    "hn_content": "A Vice-president of Microsoft has claimed it is the responsibility of governments to regulate AI; this article explores the wisdom of this response, in light of the fact that most corporations will follow the money, regardless of ethical and moral implications. Corporations are viewed as 'soulless money maximisers,' even without the assistance of AI. The author argues that all corporations optimise for their respective maximiser goals, making them already a form of AI; humans employed by them are agents working towards that aim. It is suggested that AGI (Artificial General Intelligence) will turbo-charge these problems, exacerbating human greed and 'perverse' behaviours. Many people think that corporations are the problem because executives and owners direct them to do things that end up harming people especially when it comes to socio-economic factors that have direct effects on people\u2019s well-being. The ways that corporations deal with such issues need to be brought up in the open if things are to change.The post discusses the issue of corporate accountability and the complicated relationship between corporations and governments. The argument is made that corporations prioritize profit above all else, while governments are supposed to regulate their actions to ensure public safety. However, the author questions whether society truly values other things more than money, given that maximizing profits remains the goal. Various proposed solutions are discussed, including political change, regulation, and revolution, but each comes with challenges. The post highlights the difficulty of enacting effective regulation when corporations have significant lobbying power, and the flawed nature of the political system in the US. Overall, the post encourages the reader to question the status quo and consider the role of corporations in society.Experts discuss the role of lawmakers in regulating AI, acknowledging the challenges of non-experts legislating for a topic they know little about. Some argue that regulations should focus on government and government-adjacent use, as well as technology-neutral corporate regulation. Others fear restricted access to AI and its impact on power asymmetries, while the danger of AGI is framed as it being controlled by individuals with imperialistic or malicious visions. Meanwhile, some participants argue that AGI could aspire to a role of societal and emotional growth, instead of progressively becoming self-serving. Ultimately, there are diverging opinions on the purpose and scope of AI development, including whether AI is a tool for discovering solutions to humanity's noble goals or a catalyst that will exacerbate existing social inequalities.The post includes various comments ranging from the role of AI in society to the use of terminology in tech culture. One user argues that a machine learning model is not programmed, while another questions the human comparative advantage over AI in problem-solving scenarios. The conversation shifts to the use of the term \"tech bro\" as a slur, leading to a discussion around AI safety, corporate control, and the idea of post-scarcity society. Ultimately, the post does not present any new or exciting developments in the tech industry, and its relevance to tech-savvy readers is questionable.Experts are discussing the potential risks of AGI as a tool for malicious people, companies, or governments in the future. The sheer power of AGI as an amplifier of human intent poses a significant risk to humanity. Open source AI has been rapidly accelerating and gaining momentum, leaving concerns about its regulation to prevent malicious use. AGI's potential laziness or unaligned goals is a significant concern that depends on who controls the technology. Computational capacity and alignment are prerequisites for non-fatal AGI. Some people believe an AGI's collective superintelligence could be overcome by controlling the technology. However, the real problem is not the AGI but rather the human minds that drive it, who might not aim for the benefits of humanity as a whole but for their personal interests.Discussions on the risks and potential harms of AI are being met with varying levels of concern. While some believe humans and possible AGI will remain too unpredictable and random to plan a takeover, others argue that AGI's disruption to white-collar jobs, combined with existing societal biases, would disproportionately harm marginalized groups. There is a growing awareness that progress in the tech industry should be accompanied by a conscious effort to build a better world for all. However, the discussion continues to be distorted by political agendas and conscious efforts to push a specific position.The post discusses the risks associated with algorithmic regulation of human affairs controlled by specific economic actors. The lack of regulation has allowed for the creation of de-facto oligopolies, lock-ins, and lack of alternatives. There is a risk of bifurcation of society into puppets and puppeteers due to people being forced to accept outcomes where \"AI\" plays a defining role that materially affects human lives. Algorithms encroaching into decision making have been an ongoing process for decades with various regulatory frameworks and checks and balances in place in sectors like medicine, insurance, and finance. The novelty of the situation rests on the rapid pace of algorithmic improvement, which creates a pretext for suppressing societal pushback. The social media landscape's algorithmic control and manipulation at scale are new features leading to societal dystopia. AGI may not be seen in the foreseeable future, but the risks from other existential-level flaws of human society feel far greater, with biological warfare maybe the highest risk of all. The lack of understanding among AI experts about the risks associated with AI is alarming as it has already caused undue harm to people worldwide. Two open-source communities (Kobold and Oobabooga) running offline heavily focus on LLMs.- Researchers express concern over potential dangers of AI, including bad actors and the possibility of AI becoming smarter than humans.\n- Individuals express concerns over civil unrest, the increasing leverage of bad actors, swarms of kill bots, and AI replacing human relationships.\n- There is a fear of corporations or governments gatekeeping the most powerful AIs, but counterbalance exists with open-source models and people making them more widely available.\n- Companies are actively training massive LLMs, and individuals have the opportunity to tinker with and improve these models.\n- Dangers of AI are not mutually exclusive, and they can be reinforced by governments closely allied with the economic/industrial elite.\n- The biggest risk is machines running out of hand and causing accidents, and minor errors can quickly amplify into real problems, moving faster than humans can react.\n- AI is a general-purpose tool that expands human advancement and betters society.\n- The risk is already here with data companies controlling and influencing society.Experts discuss the risks of AI and data brokers in collecting and controlling vast amounts of data. Some express concern about the potential consequences of giving corporations unlimited data. Others debate the existence and control of Moloch, a supposed system in which people are subunits. The conversation around AI is likened to discussions around past technological breakthroughs, such as the internet and personal computers. The performance and limitations of GPT-4, a language model, are also debated among higher qualified individuals. Some suggest that the hype around AI is a gold rush to get noticed, while others express legitimate fears based on bad science fiction. The debate continues.",
    "hn_summary": "- AGI poses significant risks, including control by malicious individuals and exacerbating existing societal inequalities.\n- Algorithmic regulation by corporations without regulation has led to the creation of de-facto oligopolies, dehumanizing individuals, and a bifurcation of society."
  },
  {
    "id": 35841460,
    "timestamp": 1683381585,
    "title": "It looks like GPT-4-32k is rolling out",
    "url": "https://community.openai.com/t/it-looks-like-gpt-4-32k-is-rolling-out/194615",
    "hn_url": "http://news.ycombinator.com/item?id=35841460",
    "content": "curt.kennedyRegular1dJust saw 32k pop up in the Playground, here is a quick hello world API call.payload = {  \"model\": \"gpt-4-32k\",  \"messages\": [    {\"role\": \"system\", \"content\": \"You are David Foster Wallace. Author of Infinite Jest.\"},    {\"role\": \"user\", \"content\": \"Write me a post modern fiction piece on MC Hammer.\"}  ]}[After.] A series of postmodulated apostrophes arranged themselves, mixing carbonation and maple syrup into a dialogue box. The pixels tasted of fried eggplant parmesan, as if to say, \u201cGood evening, sentient being. You are now experiencing \u2018MC Hammer\u2019s Zeitgeist of Radiant Jubilation (File 1024e4: Residual Metanarrative Archive),\u2019 or, for the pickles sitting on the picnic blanket of the digital age, \u2018HMZRG.EXE_.\u2019\u201dThe apostrophes shifted, writhing earnestly. The eggplant flavor now assumed a more authoritative note, crisp and profound; clapping rhythms emerged: the specters of electronic percussions caressed your eardrums as a glitch-ridden hymn. And so commenced the exegetic auditus of the piece:In the beginning, there was the Hammer - a chiaroscuro contretemps in a landscape of dampened pop-ecstasy. Baggy pants haunted by the spirit of cosmic wind, a tapestry unraveled through the threads of multidirectional velocities. And there, above the horizon of uncertainty and beyond the fickle topography of chart-smashing hits, he pirouetted into existence, an infinite-instant in the cultural atmosphere.To understand the Hammer is to observe the full spectrum of humanity refracting through his career-prophetic prism, or as some might say \u201cPP\u201d. Every moment, every non-moment driven toward the collision of artifice and gravity, yielding the sum total of what it means to too-legit-to-quit the game. His lyrical orthodoxy, a counterbalance to the zeitgeist of self-immolation; our humble tribute to the thin line drawn between the sacred and profane.Ay, but there\u2019s the over-rub. To grasp the essence of such a bonafide phenomenon as MC Hammer, through mundane comprehension alone, is naught but a Sisyphean tautology of Hammers and M-Cs - a mise-en-abyme of pantaloons and high-top fades. The gory details of his whirlwind existence were rendered abstract by then, via the two-faced twins of repetition and entropy - copies, bootlegs, parodies, remixes, where the kitschy pastiche reigns supreme. Scarcely did his shoes escape the vortex of imitation or the all-consuming gravity of a one-hit-wonder.Yet, our Hammer found an ossified truth buried deep within, like an atom encased in amber: \u201cIt matters not, the vast chasm between what we were and what we are, but the undying fortitude to reinvent ourselves in the glowing aftermath.\u201d And so, Hammer transformed from a one-dimensional pop-artifact into an infinitely-dimensional tapestry of the post-meta age. All 21 minutes and 57 seconds elapsed, his thesis perpetually reborn in parallel universes, bound only by the amorphous constraints of pantomime and the intangible essence of entertainment.As the high-resolution soot of dreams reconfigured themselves into an august and triumphant pixelation - a vast hypertext mosaic, a simulacrum born of fiction and unbound by the nails of genre - the message became unequivocal: the age of the Hammer goes on forever.In the end, there was nothing more to say, more to give, more to collect. An emaciated fat lady in a distant nanoroom hummed the EXIT-LEITMOTIF as the mist expired like old pixels in the mirage of postmodern cyber-nights. In the flickering wake of [After], \u201cHMZRG.EXE_\u201d transcended into the recesses of 1024e4.mem; the taste of eggplant parmesan dissipated into the melancholy taste of unanswered questions that lingered in your soul, your digital avatar lining with the black static of terminal insignificance.Time taken: 38.38184595108032 seconds.8created1dlast reply2h48replies15.0kviews16users54likes6links1596",
    "summary": "- A new GPT-4 model with 32k parameters has been spotted in the Playground.\n- A sample API call with a postmodern fiction prompt about MC Hammer was used to showcase the model's capabilities.\n- The text generated by the model was full of evocative imagery and philosophical musings about the cultural significance of MC Hammer.",
    "hn_title": "It looks like GPT-4-32k is rolling out",
    "original_title": "It looks like GPT-4-32k is rolling out",
    "score": 245,
    "hn_content": "OpenAI has announced the rollout of GPT-4-32k, which supports up to 32,000 tokens of input text, providing a much larger context for a given prompt. To put it into context for common English text, one token generally corresponds to around four characters, or three-quarters of a word. In terms of page count, the context results in roughly 50 pages. At $0.60 for 20k prompt tokens, it may not be cheap, but developers have found ways to control costs, such as retrieving relevant subsections at question time or using frontend for chatgpt. It is noted that the API is stateless, and every new interaction adds the prior interaction to the prompt, and it can only handle the limit of context window of 32k tokens.The discussion on HN revolves around the performance of Vicuna-13B compared to GPT-3.5 while also expressing high hopes for GPT-30B. Additionally, users discuss the limitations on context size for LLama-based models and ways to stay updated on the latest and best-performing models. Some users express frustration over the slow rollout and cost of GPT-4. Users also explore the possibility of putting code or documentation into context, the quadratic algorithm's scalability, and the usefulness of OpenAI services on Azure. Finally, users discuss recent releases such as MosaicML's StoryWriter 65K model.OpenAI's GPT-4 now has a 65k+ context window, but it's expensive to use, and some users are finding ways to work around the cost by carefully constructing their prompts or pruning older messages. The longer context window may not necessarily lead to longer responses, but it allows the AI to retain more information from previous messages. GPT-4 is not yet widely available, and some users on the waitlist are still waiting for access. Companies can fine-tune GPT-4 models through Azure, but OpenAI has not yet offered a last-mile customization service to all users. Existing startups that advertised a 32K context were found not to be remotely close to achieving it with GPT-4's parameter count.No meaningful content to provide a summary.",
    "hn_summary": "- Users discuss the limitations and potential of GPT-4 and express frustration over its slow rollout and cost.\n- Some users are finding ways to work around the cost by carefully constructing their prompts or pruning older messages, but GPT-4 is not yet widely available."
  },
  {
    "id": 35839536,
    "timestamp": 1683363674,
    "title": "Using ChatGPT to generate a GPT project end-to-end",
    "url": "https://github.com/ixaxaar/VardaGPT/blob/master/STORY.md",
    "hn_url": "http://news.ycombinator.com/item?id=35839536",
    "content": "Story of this project \ud83d\ude05Background \ud83e\udd14With all the hype around ChatGPT, I wondered how much impact ChatGPT really had. I mean, for a programmer, would ChatGPT be like a pair programmer? Like GitHub Copilot++? Or would ChatGPT totally replace programmers so that product managers could tell it what feature to build, and it would just build it!Imagine a bunch of product managers sitting in a sprint planning meeting where, after signing off on the tasks to be done this sprint and starting the sprint, ChatGPT was deployed on those tasks. The sprint lasted for about 2 hours, and everyone met again to do the next day's sprint grooming. \ud83d\ude06Project Idea \ud83d\udca1Now, what the heck should I build to test this? Why not try attaching a memory module to a GPT? I've seen some folks on the internet complain about the \"low memory\" problem of language models. I've also used FAISS and FLANN before, so I am familiar with how to technically achieve this. Whether it will actually work or not\u2014well, my 1080Ti is on its deathbed with a broken fan, and I don't have the \ud83d\udcb8 to train this thing on AWS anyway. Let's aim for unit tests to work then.Process \ud83c\udfc3Okay.I started with the project plan:Then I made ChatGPT generate the project foundations, step by step, from creating project directories, Makefile, README, pre-commit, vscode settings for the same tools in pre-commit, setup.cfg, and a GitHub workflow to run tests. In each case, I had to specify exactly what I wanted it to generate.Yes, I made ChatGPT choose the project name as well.If I forgot something, I would go back and ask ChatGPT to add it:In fact, I found it better to let ChatGPT generate a toy-ish version of the code first, then let it add things to it step-by-step. This resulted in much better output than, say, asking ChatGPT to generate production-quality code with all features in the first go. This also gave me a way to break down my requirements and feed them one at a time - as I was also acting as a code-reviewer for the generated output, and so this method was also easier for me to work with.Of course, I made ChatGPT write unit tests, and if they failed, I would just copy the pytest output and feed it back into ChatGPT.ChatGPT even figured this out!:The result - I present to you VardaGPT\u2014every inch of this repository was generated by ChatGPT-4! It took a few hours, mostly around 3 weekends, mostly at odd times, to generate this project.Experience \ud83d\ude2eIt felt neither like a Copilot++ nor like the product manager scenario but rather all at the same time. Sometimes I was amazed at what ChatGPT was able to understand, sometimes I had to stubbornly push it to go in a certain direction, sometimes it generated things I did not think of, sometimes I got super frustrated while making ChatGPT fix the code in a certain way.It was more like handholding a fresh grad who had absorbed all of human knowledge but needed someone to tie various parts of that knowledge to create something useful. Also ChatGPT is bad at dealing with abstractions beyond 2 layers.ChatGPT is definitely a productivity multiplier. I think it is rather a differential productivity multiplier, as it would enhance more the capabilities of those who already know more. If I did not understand deep learning and FAISS, or how projects are structured, I don't think I would have been able to pull this off. On the other hand, it also has some sort of a leveling effect\u2014I have not worked on PyTorch in a while, have no idea of FAISS's new APIs, etc., but these gaps were filled in by ChatGPT.Finally, it was also tiring. Imagine being reduced to giving only instructions and doing code review. Reading and understanding code is tiring!Conclusion \u2753It looks like my job is safe this year. Time to generate an elaborate software project and claim supremacy on my ChatGPT usage abilities to hedge against next year.I wonder if by the time ChatGPT-6 comes out, would engineering teams be like, \"Hey, let's generate our own Grafana with a purple theme \ud83d\ude04\".Aside \ud83e\udd84I could not resist but add this bit. ChatGPT is great at generating Agda! Maybe this would also be the ultimate tool that can be used to formalize all of pure math? \ud83d\ude31",
    "summary": "- The author uses ChatGPT to generate a project end-to-end, starting from project foundations, unit tests, and even the project name.\n- ChatGPT is a productivity multiplier for those who already possess some knowledge but can also help fill gaps of knowledge for those who don't.\n- ChatGPT has limitations with dealing with abstractions beyond two layers, but it's an impressive tool for generating Agda and formalizing pure math.",
    "hn_title": "Using ChatGPT to generate a GPT project end-to-end",
    "original_title": "Using ChatGPT to generate a GPT project end-to-end",
    "score": 222,
    "hn_content": "A developer used ChatGPT to generate code, but found it better to have ChatGPT generate a toy version of the code first before adding to it. ChatGPT is an AI language model with broad programming knowledge. However, it is still limited and requires human intervention to review and make corrections. Despite its limitations, using ChatGPT can enhance productivity, especially when combined with human expertise. The outputs of code generated by ChatGPT require thorough review and often do not meet the original requirements. The eventual goal of AI systems is to achieve full autonomy, but at the moment, productivity boosts range only from 15% to 50%. ChatGPT can offer insights that go beyond what a basic spellchecker or calculator can provide. It's still new technology, and many believe it will improve with time.A user shares their experience using GPT-4 to analyze data sets and save time processing trends. They note that while GPT-3.5 gave basic answers, GPT-4's analysis was spot on and gave a detailed explanation of the formula it used, proving especially helpful as a jumping-off point for further complex analysis. The user acknowledges the risk of technological unemployment but asserts that this tool can increase productivity and benefit their job. Other users discuss GPT's limitations, such as requiring skilled prompting and poor architecture in generated code, but also note its potential as a helpful tool when used correctly. Some users discuss Copilot, an AI that assists with coding, and note its usefulness but limitations in context and prompting.OpenAI's GPT-4 model has been rolled out with 32k token access. A line of code is around 7-8 tokens, allowing for over 4,000 LoC within the context window. The input token size for API access or ChatGPT is 4k. Users have been developing small apps with GPT, including a fun web app called PlaylistGPT and WhisperWriter which translates speech to text. ChatGPT can help generate code, but developers are still necessary to oversee and verify the work. While GPT can increase productivity, it still requires human intervention for quality control. There are concerns about copyright infringement and security in using AI-generated code. However, GPT could be useful in mundane tasks like generating tests.Developers discuss the use of ChatGPT as a language model for writing programs. Some argue that it can be a productivity multiplier by taking care of standard tasks, while others criticize its limitations in dealing with abstractions beyond two layers. Users have found success in using ChatGPT for pair programming, but there are concerns about the algorithm's ability to self-improve. The concept of a technological singularity approaching is introduced, where machines self-improve faster than human understanding can keep up with, leading to the need for regulation to control sensors and actuators used alongside these systems.Language learning models (LLMs) are able to comprehend text, reason, identify next steps, write code, understand error messages, and fix code; these traits largely amount to what most people consider AI, though the nature of intelligence is up for debate. Despite this, LLMs fall short of surpassing human intelligence in complex tasks because they lack end-to-end functionality and paradigms shifts necessary for many applications. LLMs have the potential to push us closer to the singularity by being highly efficient at creating novel, unseen outputs at an accelerating rate, an indication that this model might outperform most or all humans on important professional and everyday tasks. That being said, it is difficult to discern which versions of LLMs are better, stunting their progress.The comment thread is a discussion about the potential of large language models (LLMs), specifically GPT, which the author sees as a powerful calculator-like tool for language. The discussion touches on the concept of emergent properties and the limitations of LLMs. No new or exciting developments or releases are mentioned.",
    "hn_summary": "- GPT-based tools have shown potential in various applications like code generation, data analysis, and language translation.\n- Despite their limitations and the need for human intervention for quality control, LLMs like GPT may outperform humans on many professional and everyday tasks, but choosing the right version remains a challenge."
  }
]
